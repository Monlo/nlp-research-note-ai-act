Organization,Feedback Content,Feedback Link,Page,Feedback reference,Submitted on,Submitted by,User type,Organisation,Organisation size,Transparency register number,Country of origin,Initiative,Additional Message
Consumer Technology Association (United States),CTA's comments are in the attached file.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551055_en,0,F551055,10 September 2020,Douglas Johnson,Business association,Consumer Technology Association,Medium (50 to 249 employees),,United States,Artificial intelligence – ethical and legal requirements,CTA's comments are in the attached file.
Center for Democracy & Technology (United States),CDT welcomes the opportunity to provide input to the Commission's choice of regulatory approaches for artificial intelligence. We respectfully offer the following suggestions: 1) Be more precise: No single approach to regulating “AI” will make sense in all scenarios. Instead the commission should start by clearly identifying potential or existing harms and work backward to identify the most effective points to apply legislative or regulatory...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551054_en,0,F551054,10 September 2020,Stan Adams,Non-governmental organisation (NGO),Center for Democracy & Technology,Small (10 to 49 employees),,United States,Artificial intelligence – ethical and legal requirements,"CDT welcomes the opportunity to provide input to the Commission's choice of regulatory approaches for artificial intelligence. We respectfully offer the following suggestions:
1) Be more precise: No single approach to regulating “AI” will make sense in all scenarios. Instead the commission should start by clearly identifying potential or existing harms and work backward to identify the most effective points to apply legislative or regulatory solutions. After identifying and articulating these harms and appropriate points of intervention, the Commission should consider how to measure their likelihood of occurrence for clearly articulated use cases of well-defined types of applications. This assessment will help distinguish and prioritise which use cases should be further addressed through rules and regulations according to their relative urgency. 

Although we support the idea that some applications pose higher risks of harm than others, we urge the Commission to invest further effort in articulating which use cases of which applications it seeks to include if it chooses regulatory approaches targeting “high risk” applications. This additional clarity will help provide greater certainty for potentially impacted entities and will help guide regulators and other stakeholders as they develop and assess concrete regulatory proposals. We are doubtful, even with a narrowly drawn scope for “high risk” applications, that a single legislative instrument could effectively address the range of harms presented by the diverse array of applications and their use cases. As an alternative, we suggest that regulatory approaches might be more effective if they are geared towards preventing common harms, rather than aimed at governing classes of applications. We suggest that, through a harms-based approach, much of the EU’s existing law could be brought to bear through clarification rather than through development of new rules.

2) Clarify where existing law applies and identify gaps: Many harms have already been addressed through legislation. Clarifying existing law for novel applications should be step one, and we support the Commission’s intent to apply current law in its efforts to address risks posed by AI applications. Before pursuing additional legislative instruments, we suggest that the Commission and relevant regulatory bodies should make a coordinated effort to assess which parts of existing law might be used to address risks posed by AI applications. 

For example, in our response to the Commission’s AI Whitepaper consultation, we suggest that remote biometric surveillance is likely prohibited in most cases because it cannot be justified under Art. 9 GDPR and conflicts with both the European Convention on Human Rights and the Charter of Fundamental Rights. Similarly, the Employment Equality Directive should apply whether or not employers use algorithmic tools, but the Commission may wish to clarify employers’ obligations such as how they can satisfy their burdens of proof when using algorithmic application processing systems.

After mapping existing laws onto the use of AI applications, the Commission can then better identify any gaps in the law or areas for which novel legislative solutions may be necessary. We suggest that this effort should take place before moving forward with a new legislative instrument to help avoid redundancies, confusion, and uncertainty.

3) Refine existing soft-law approaches: CDT generally supports a combination of clarifying and enforcing existing law alongside voluntary adherence to principles expressed in soft law documents such as the findings of the High Level Expert Group on AI. As with our suggestions for the clarification and application of existing law, we believe that the principles expressed in various soft law documents would benefit from refinement through their application to concretely defined use cases of applications."
ETNO - European Telecommunications Network Operators' Association (Belgium),"ETNO welcomes the Commission’s objective to foster the uptake of Artificial Intelligence technologies and products that abide by European ethical norms, legal requirements, and fundamental rights. Today, no specific EU legal framework to regulate AI exists. The development, deployment and use of AI are subject to a range of horizontal laws and principles such as on data protection and privacy, consumer protection, product safety and...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551053_en,0,F551053,10 September 2020,Paolo Grassia,Business association,ETNO - European Telecommunications Network Operators' Association,Micro (1 to 9 employees),08957111909-85,Belgium,Artificial intelligence – ethical and legal requirements,"ETNO welcomes the Commission’s objective to foster the uptake of Artificial Intelligence
technologies and products that abide by European ethical norms, legal requirements, and fundamental rights.

Today, no specific EU legal framework to regulate AI exists. The development, deployment and use of AI are subject to a range of horizontal laws and principles such as on data protection and privacy, consumer protection, product safety and liability.

We agree that the goals of the legal act should be to pursue a harmonised approach to Trustworthy AI applications, bolstering the EU’s capacity to innovate and remain competitive with other regions of the world. Divergent national requirements that raise barriers to the development and the uptake of AI technology across the single market should be avoided.

We encourage the Commission to examine the existing regulatory framework and assess whether adjustments are necessary to address the emerging risks posed by AI. We agree that several risks examined in the IIA are not necessarily specific to AI and new measures should be embedded in the broader framework. A new instrument could provide additional safeguards and clarifications necessary for a truly safe and lawful AI that respects fundamental rights.

Considering the above, ETNO would support a proportionate combination of soft law, e.g. a voluntary labelling scheme, and mandatory requirements that were guided by a risk-based approach (Option 4). Our views on the various options comprised in this mix are described as follows.

A soft law approach that enable industry initiatives through additional accountability and coordination (Option 1) should be preferred wherever possible, to build on the existing efforts already deployed by public and private organisations and make them more effective.

A voluntary labelling scheme (Option 2) could encourage the uptake of Trustworthy AI. Criteria underpinning the labels could relate to e.g. transparency, robustness, and human oversight. They must be meaningful to users, while avoiding excessive burden on businesses to not discourage adoption of labels. However, it is crucial to clearly define their assignment mechanism, and the role and the authority of testing centres. Governance and enforcement are key to ensuring that a single scheme is implemented across the EU and that labels are valued in the market.

Finally, we suggest examining existing regulation and whether adjustments are necessary, before introducing additional legislation. Any new legislative instrument establishing mandatory requirements should particularly be targeted to “high-risk” AI applications (Option 3b), avoid a sweeping regulatory intervention as in Option 3c, and build on the principles and criteria developed for the voluntary labelling scheme in order to ensure consistency.

To define the scope of mandatory requirements, we agree with the cumulative criteria of high-risk sectors and high-risk applications of AI in those sectors as suggested in the White Paper, with some adjustments and clarifications that consider the impact on the whole AI value chain. For our detailed views on the identification of high-risk AI, as well as on the requirements that could be set out in the legal act, we refer to ETNO’s position paper on the White Paper.

Enforcement mechanisms are key to ensure effective compliance with the various voluntary and mandatory provisions. We envisage a flexible and open EU governance structure, which delegate enforcement responsibilities to Member States. 

Lastly, we concur that a robust definition of AI is the key to an enabling framework that build legal certainty. We recommend to carefully delineate its perimeter, drawing from the definition rendered by the High-Level Expert Group in its Ethics Guidelines for Trustworthy AI."
EuroCommerce (Belgium),"Artificial Intelligence (AI) can offer significant benefits not just to businesses, but also to consumers and society. Retailers and wholesalers are central actors in the supply chain and are in daily contact with Europe’s 450 million consumers. Many retailers and wholesalers use and develop Artificial Intelligence applications to operate sophisticated and efficient systems ensuring reliable and safe sourcing and distribution of goods to meet...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551052_en,0,F551052,10 September 2020,Ena Salihovic,Business association,EuroCommerce,Small (10 to 49 employees),,Belgium,Artificial intelligence – ethical and legal requirements,"Artificial Intelligence (AI) can offer significant benefits not just to businesses, but also to consumers and society. Retailers and wholesalers are central actors in the supply chain and are in daily contact with Europe’s 450 million consumers. Many retailers and wholesalers use and develop Artificial Intelligence applications to operate sophisticated and efficient systems ensuring reliable and safe sourcing and distribution of goods to meet consumers’ demand and keep them safe. In most cases, AI applications used by retailers and wholesalers carry no direct impact or risks for individuals but improve shopping experiences and internal efficiencies.

EuroCommerce welcomes the opportunity to provide input to the Commission’s Inception Impact Assessment for the upcoming legislative framework on AI. We believe that the combination of set objectives in the Option 1 and Option 3.b are the best to support and foster further AI developments in the EU.

To secure a future-proof framework that will support an innovative and competitive retail and wholesale sector, EuroCommerce believes that:
• Having a positive narrative towards AI technologies is a prerequisite to unlock Europe’s tech sovereignty. 
• The future European framework for AI should be technology-neutral and focus more on achieving desirable outcomes rather than regulating AI tools, as it is already the case with existing legislation such as the General Data Protection Regulation. 
• The future EU framework for AI should support the digital development of SMEs. SMEs need to be supported in their digital transformation and provided with the right set of digital skills and training that will help them responsibly use the potentials offered by AI. 
• The future European framework for AI should rely on a simple, narrow, clear, and harmonised definition of ‘Artificial Intelligence’.
• The use of already existing AI applications should not be disrupted.
• Careful attention should be paid to avoid overregulation – especially considering recently adopted EU and national legislation, support the use of existing AI technologies and bolster innovation.
• Regulatory sandboxes for testing high-risk AI solutions could potentially enable businesses of all sizes to explore the potential of Artificial Intelligence.
• The European Commission’s priority should be to work towards a global framework that would secure a level-playing field beyond EU borders.
• Competition coming from outside the EU should not be ignored.
• B2B data sharing for the purpose of AI development should remain on a voluntary basis.
• Investing in skills, digital education and research should be a priority of the EU institutions. 

Please find attached more detailed input to the roadmap on Artificial Intelligence – ethical and legal requirements."
Slovak Alliance for Innovation Economy (Slovakia),"Smart government approaches to regulation will play an important role in boosting public confidence and ensuring that AI is used responsibly, while also encouraging innovation. However, it is important that a proportionate, risk-based approach is taken - balancing potential harms with the social and economic benefits that will be created by AI. In the following points we are providing our feedback to the policy options presented and share our...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551051_en,0,F551051,10 September 2020,Michal Kardos,Business association,Slovak Alliance for Innovation Economy,Micro (1 to 9 employees),,Slovakia,Artificial intelligence – ethical and legal requirements,"Smart government approaches to regulation will play an important role in boosting public confidence and ensuring that AI is used responsibly, while also encouraging innovation. However, it is important that a proportionate, risk-based approach is taken - balancing potential harms with the social and economic benefits that will be created by AI. In the following points we are providing our feedback to the policy options presented and share our comments on additional points of concern raised by the Commission's initiative.
Policy options:
No EU policy change
We welcome smart approach on setting up rules for AI. However, it is imperative to maintain clear focus in delivering EU policy change while acknowledging a number of already existing rules, including GDPR, medical devices regulation, and fundamental rights aquis. New prescriptive rules should only be considered in the areas where existing regulation is clearly insufficient.
Option 1: EU “soft law”
We are certain that the European AI industry would benefit greatly from the European Commission providing us with guiding principles for self-regulation and co-regulation, as they would play an important role helping European businesses to develop advanced technologies responsibly. We would expect this kind of support from the European Commission even if other policy options are pursued by the Union.
Option 2: EU legislative instrument setting up a voluntary labelling scheme
We are concerned that even a voluntary labelling scheme is likely to create a heavy administrative burden for AI innovators that are often SMEs with limited resources. As a result, the costs of such a scheme could quickly outweigh the benefits of encouraging uptake of AI across Europe. We would especially like to caution basing a labeling scheme on the Assessment List for Trustworthy AI from the EU High-Level Expert Group on AI as its nature inherently limits variation across settings for different cases of application. Just as in Option 1, we would encourage the Commission to work closely with the AI industry to develop a menu of labeling schemes for different AI application settings.
Option 3: EU legislative instrument establishing mandatory requirements for all or certain types of AI applications
We strongly encourage the Commission to factor in the opportunity cost of not using AI when considering any regulatory intervention into AI applications. In deliberating possible options it’s vital to reflect not only potential harms but also societal opportunities. The benefits of AI will often outweigh the risks, especially if risks can be mitigated in a thoughtful way with strong safeguards. Regulation must not discourage AI innovation, development, nor limit its use. Proportionality and clear focus of any regulation will help ensure legal certainty for AI innovators and increase trust in AI without unduly hindering AI-driven innovation.
On the enforcement mechanisms:
We believe a combination of ex-ante risk self-assessment and ex-post enforcement for high risk AI applications would likely achieve desired results within much faster timeframes and without risking unduly stopping innovation and creating unnecessary burdens. We strongly support building on existing industry practices, including ethical, legal and due diligence practices that guide the responsible and trustworthy development of AI. Furthermore, it would be most practical if regulators were to provide clear “due diligence” guidance for quality self-assessment procedures. We also would discourage relying on third party ex-ante assessments as such approach would subject commercial secrets to external exposure risks and due to lack of familiarity could easily misinterpret aspects of an AI system.

For more details please see the attached file. Thank you. Slovak Alliance for Innovation Economy"
LIDER Lab Scuola Superiore Sant'Anna (Italy),"Feedback for the EU Commission Inception Impact Assessment towards a “Proposal for a Regulation of the European Parliament and the Council laying down requirements for Artificial Intelligence” Denise Amram – Giovanni Comandé *LIDER Lab, DIRPOLIS Institute, Scuola Superiore Sant’Anna (Pisa- Italy) Table of contents: 1. Introduction. 2. Selecting Option 4 with option 3.c as a baseline (Option 4+3.c) 3. A combined approach towards AI Regulation...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551050_en,0,F551050,10 September 2020,Denise Amram,Academic/research Institution,LIDER Lab Scuola Superiore Sant'Anna,Large (250 or more),,Italy,Artificial intelligence – ethical and legal requirements,"Feedback for the EU Commission Inception Impact Assessment towards a “Proposal for a Regulation of the European Parliament and the Council laying down requirements for Artificial Intelligence”
Denise Amram – Giovanni Comandé 
*LIDER Lab, DIRPOLIS Institute, Scuola Superiore Sant’Anna (Pisa- Italy)

Table of contents: 1. Introduction. 2. Selecting Option 4 with option 3.c as a baseline (Option 4+3.c) 3. A combined approach towards AI Regulation. 4. A role for the GDPR.

1. Introduction.
This feedback is provided considering the ongoing studies undertaken within the research lines RIGHTS in the classifying society (https://www.lider-lab.sssup.it/lider/rights/) and ETHOS (EThics & law witH and fOr reSearch, https://www.lider-lab.sssup.it/lider/ricerca/linee/ethos-ethics-law-with-and-for-research/) developed within the LIDER Lab research activities (www.lider-lab.eu)  at Scuola Superiore Sant’Anna (SSSA; www.santannapisa.it).
Our remarks focus on two main issues: 1) providing operational tools to link the ethics and the legal dimension of a Trustworthy AI avoiding risks of ethics washing; 2) the role that the EU Regulation 2016/679 (General Data Protection Regulation, hereinafter “GDPR”) may play to achieve the purposes of the EU Strategy on Artificial Intelligence, providing a multilevel legal framework that may include a General Regulation on Artificial Intelligence and specific safeguards both in terms of national and domain legislation, as well as  in terms of soft law. 

Please see the attachment for further details."
Amsterdam AI Technology for People (Netherlands),"The Amsterdam coalition 'AI Technology for People' strongly supports the European Parliament and Council in their efforts to ensure that AI is safe, lawful and in line with EU fundamental rights. The overall goal of stimulating the uptake of trustworthy AI in the EU economy connects closely to the goals of Amsterdam coalition 'AI Technology for People'. The attached document provides a succinct response to the consultation document by 'AI...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551049_en,0,F551049,10 September 2020,Niek Brunsveld,Academic/research Institution,Amsterdam AI Technology for People,Large (250 or more),764189838543-45,Netherlands,Artificial intelligence – ethical and legal requirements,"The Amsterdam coalition 'AI Technology for People' strongly supports the European Parliament and Council in their efforts to ensure that AI is safe, lawful and in line with EU fundamental rights. The overall goal of stimulating the uptake of trustworthy AI in the EU economy connects closely to the goals of Amsterdam coalition 'AI Technology for People'.

The attached document provides a succinct response to the consultation document by 'AI Technology for People'. In it, we explain why, in laying down requirements for AI, 'AI Technology for People' encourages the EP and the Council to ensure that:
• The development, use and regulation of AI go hand in hand, because they are interdependent;
• Regulatory interventions are evidence-based, proportionate, and respond to identified  regulatory gaps pro-actively and without undue delay so they can create legal certainty without stifling innovation;
• Regulatory intervention is based on careful analyses of where actual conflicts between certain uses of AI and fundamental rights emerge or where AI has negative effects for a fair and inclusive society;
• Regulatory interventions should take into account the broader economic-institutional environment and implications for society, and ensure that the way AI is being used and implemented in products and services is fair and complies with fundamental rights;
• There is a fair legal playing field for European vis-à-vis non-European players; 
• Compliance costs are distributed fairly not only between low risk and high-risk AI but also directly related to the size of a company and the institutional dependencies it might create. 

The lead author of the attached document is Prof.Dr. Natali Helberger, University Chair in in Law and Digital Technology at the University of Amsterdam

Partners in the coalition AI technology for people: 
Amsterdam Economic Board, Amsterdam UMC, Antoni van Leeuwenhoek (of which the Netherlands Cancer Institute is part), Centrum Wiskunde & Informatica, Municipality of Amsterdam, Amsterdam University of Applied Sciences, Sanquin, University of Amsterdam, Free University Amsterdam"
"Department of Computer Science, University of Copenhagen (Denmark)","Department of Computer Science (DIKU) at the University of Copenhagen (UCPH) welcomes the opportunity to provide feedback to the European Commission’s (EC) Inception Impact Assessment for a Proposal for a legal act laying down requirements for Artificial Intelligence. EC is proposing four policy options. Below, we provide feedback on each option and some general considerations. Option 1 may likely lead to a lot of confusion about which...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551048_en,0,F551048,10 September 2020,Anders Pall Skött,Academic/research Institution,"Department of Computer Science, University of Copenhagen",Large (250 or more),,Denmark,Artificial intelligence – ethical and legal requirements,"Department of Computer Science (DIKU) at the University of Copenhagen (UCPH) welcomes the opportunity to provide feedback to the European Commission’s (EC) Inception Impact Assessment for a Proposal for a legal act laying down requirements for Artificial Intelligence. 

EC is proposing four policy options. Below, we provide feedback on each option and some general considerations.

Option 1 may likely lead to a lot of confusion about which guidelines and standards to adopt - and to the interpretation of the assessment lists. 

Option 2 seems attractive. However, this will greatly favour large corporations with RA/QA/QMS already in place. SMEs need assistance to be able to enter markets and get this AI quality label. A labelling based on assessment lists alone may provide very little trustworthiness in reality, since it is difficult to assess the quality of the process followed to complete an assessment list.

Option 3, having a legislative instrument establishing mandatory requirements also implies well established means to determine whether the requirements have been fulfilled, which could provide more trustworthiness than option 1 and 2. However, this may become a large burden, particularly for SMEs. There are already ISO standards for quality assured software development, risk assessment, and so on. Possibly, these could be slightly expanded to cover AI concerns instead of adding a separate AI Regulative?

An argument for expanding standards and legislation for general software products and development as opposed to making special legislation for AI is that AI is in itself a poorly defined term with no agreement on definitions among standardisation bodies. A legislation targeting the functioning and use of general software systems would be more robust than a legislation targeting AI applications. 

Regarding option 3 and 4, and in general, a risk-based approach could mitigate the burden to comply with the legislation but of course put demands on the standardisation and legislative framework for risk assessment. 

An argument for expanding standards and legislation for general software products and development as opposed to making special legislation for AI is that AI is in itself a poorly defined term with no agreement on definitions among standardisation bodies. A legislation targeting the functioning and use of general software systems would be more robust than a legislation targeting AI applications."
Clifford Chance LLP (United Kingdom),"Clifford Chance LLP welcomes the opportunity to respond to the European Commission's inception impact assessment on a ""Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence"". Our submissions are (i) made on our own behalf only, and (ii) based on our substantial experience as a global (including European Union) law firm, advising on issues relevant to the consultation for a...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551047_en,0,F551047,10 September 2020,William Hanway,Company/business,Clifford Chance LLP,Large (250 or more),,United Kingdom,Artificial intelligence – ethical and legal requirements,"Clifford Chance LLP welcomes the opportunity to respond to the European Commission's inception impact assessment on a ""Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence"". Our submissions are (i) made on our own behalf only, and (ii) based on our substantial experience as a global (including European Union) law firm, advising on issues relevant to the consultation for a diverse range of clients within and outside of the European Union. The comments below and our submissions do not necessarily represent the views of every Clifford Chance lawyer, nor do they purport to represent the views of our clients. 

Please see the attached PDF for our complete response."
IEEE Standards Association (United States),"The IEEE SA appreciates the opportunity to respond to the Commission’s IIA. As a resource, we suggest our publication, Ethically Aligned Design, First Edition. The law chapter provides commentary about how the law should respond to a number of specific ethical and legal challenges raised by the development and deployment of AIS and the benefits/risks of the incorporation of AIS into a society’s legal system. Please find our comments, by...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551045_en,0,F551045,10 September 2020,Kristin Little,Business association,IEEE Standards Association,Large (250 or more),,United States,Artificial intelligence – ethical and legal requirements,"The IEEE SA appreciates the opportunity to respond to the Commission’s IIA. As a resource, we suggest our publication, Ethically Aligned Design, First Edition. The law chapter provides commentary about how the law should respond to a number of specific ethical and legal challenges raised by the development and deployment of AIS and the benefits/risks of the incorporation of AIS into a society’s legal system. 

Please find our comments, by section, below.

Context
Care should be taken to prioritize social elements. We recommend language such as, ""the use of AI should prioritize socially and environmentally beneficial outcomes as a means for companies to demonstrate their key competitive focus on long term business sustainability while upholding key EU values.""

We recommend the use of the term “Artificial Intelligence Systems” as used by the OECD and IEEE, as opposed to “Artificial Intelligence.”

Problem the initiative aims to tackle
While material harm may relate to the “safety and health of individuals and their property,” we would suggest that material harm to the natural habitat also be considered.

Another element to consider is data portability. The context of sovereign data should also be discussed.

The Commission recognizes that AI systems can evolve. Such a situation may require a dynamic supervision not static repeated evaluation of conformity. In the event that safety risks materialize, the Commission notes that it could be difficult to determine the person, particular human action, or omission responsible for the damage. IEEE submits that evaluation and potential certification of accountability may address this concern.

Testing is not adequate for trust, nor can an adaptive learning system be tested only once as a basis for continual trust. We posit that a more dynamic environment for trust when it comes to autonomous learning systems is needed.

Objective
Regarding the Commission’s aim of preventing/minimizing significant risks to fundamental rights and safety, we note that some matters of safety and security are protected by existing regulations, and we suggest that ethical risks and the undermining of rights and values be considered.  

Policy option 2
Caution should be exercised for giving a fixed label to an essentially adaptive system, because such a scheme can qualify a product or system partially not wholly.

Policy option 3, sub-option 2
Limiting a legislative instrument to “high-risk” on the basis of two criteria (as set out in the White Paper) one should consider that AI safety is no different to any other class of safety. Safety of products and services is the most extensively addressed and covered facet of the legal system. A gap exists in the values and rights.

Likely economic impacts
Concerning trust, Government's approach to indicating and upholding it should also be transparent and achievable among the multiple stakeholders in order to realize the full economic benefits. 

SMEs may not be able to comply with the regulatory framework mechanisms. Incentives could also be considered.

Likely social impacts
To expect “no direct significant negative social impacts” is perhaps misguided. Ex ante this is not known. The impact on employment can be concerning as jobs lost in specific sectors may not be easily filled by potential new employment opportunities based on vastly different competencies.

Likely impacts on simplification and/or administrative burden
In addition to the downsides of legal fragmentation outlined, another negative impact to note is the free flow of products and services approved by different non-harmonized criteria.

Impact assessment
With respect to the preparation of an impact assessment for December 2020, an objective assessment framework should consider the likelihood as well as the potential outcomes of various scenarios. This amounts to a risk and reward profiling of the technology and can contribute to can contribute to  a better decision support framework."
APPLiA (Home Appliance Europe) (Belgium),"First of all, APPLiA would like to point out that the concept of Artificial Intelligence is still not well defined and as such we oppose regulating it, as there may be completely different understandings of AI by various actors on the market. A similar situation applies regarding the lack of definition of “high” / ”low” risk. As such, APPLiA would suggest that option “0”, baseline scenario or option “1” soft law, voluntary approach, are...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551044_en,1,F551044,10 September 2020,Michał ZAKRZEWSKI,Business association,APPLiA (Home Appliance Europe),Small (10 to 49 employees),04201463642-88,Belgium,Artificial intelligence – ethical and legal requirements,"First of all, APPLiA would like to point out that the concept of Artificial Intelligence is still not well defined and as such we oppose regulating it, as there may be completely different understandings of AI by various actors on the market. A similar situation applies regarding the lack of definition of “high” / ”low” risk. As such, APPLiA would suggest that option “0”, baseline scenario or option “1” soft law, voluntary approach, are considered as the initial way forward for the time being.  
However, if the approach to go ahead with an EU legislative instrument establishing mandatory requirements for all or certain types of AI applications prevails, APPLiA would support sub option 3(a) with the EU legislative instrument that could be limited to a specific category of AI applications only. We would then ask what the process is to define those specific categories, who defines the categories, and what are the boundaries for each specific category, notably remote biometric identification systems in public spaces."
COCIR (Belgium),"COCIR welcomes the inception impact assessment by the European Commission on ethical and legal requirements for Artificial Intelligence (AI) and the opportunity to provide feedback. Continuing our engagement in this area, and following the earlier consultation on the AI White Paper, COCIR is pleased to share its experience and expertise on the use of AI within healthcare. COCIR and its members have recently published a comprehensive in-depth...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551043_en,1,F551043,10 September 2020,Danny Van Roijen,Business association,COCIR,Micro (1 to 9 employees),05366537746-69,Belgium,Artificial intelligence – ethical and legal requirements,"COCIR welcomes the inception impact assessment by the European Commission on ethical and legal
requirements for Artificial Intelligence (AI) and the opportunity to provide feedback.

Continuing our engagement in this area, and following the earlier consultation on the AI White Paper,
COCIR is pleased to share its experience and expertise on the use of AI within healthcare.

COCIR and its members have recently published a comprehensive in-depth analysis of Artificial
Intelligence in Medical Device Legislation. The document provides a thorough analysis of the legal
requirements applicable to AI-based medical devices:

https://www.cocir.org/fileadmin/Position_Papers_2020/COCIR_Analysis_on_AI_in_medical_Device_Legislation_-_Sept._2020_-_Final_2.pdf

Based on this analysis COCIR sees no need for novel regulatory frameworks for AI-based medical devices, because the
requirements of the EU Medical Device Regulation4 (MDR) in combination with provisions of the General
Data Protection Regulation (GDPR) are adequate to ensure excellence and trust in AI in line with
European values

A more detailed response to the inception impact assessment and indicated policy options can be found in attachment.

COCIR looks forward to working with the EU institutions and relevant stakeholders to create the right
environment for further uptake and deployment of AI in healthcare for the benefit of the patients and
society, while safeguarding fundamental rights and providing the best possible care and protection."
Anonymous,Attached our comments and feedback to the impact assessment,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551042_en,1,F551042,10 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,Attached our comments and feedback to the impact assessment
RELX (United Kingdom),"RELX welcomes the opportunity to provide feedback on the European Commission’s Inception Impact Assessment (IIA) for a legislative initiative on artificial intelligence (AI). Below are our comments on the legislative options outlined in the IIA. Option 0 / baseline Before any new policy intervention on AI, a thorough review and assessment of existing legislation will likely clarify that in most regards AI is already covered by current...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551041_en,1,F551041,10 September 2020,Tim Stok,Company/business,RELX,Large (250 or more),338398611148-62,United Kingdom,Artificial intelligence – ethical and legal requirements,"RELX welcomes the opportunity to provide feedback on the European Commission’s Inception Impact Assessment (IIA) for a legislative initiative on artificial intelligence (AI). Below are our comments on the legislative options outlined in the IIA. 

Option 0 / baseline
Before any new policy intervention on AI, a thorough review and assessment of existing legislation will likely clarify that in most regards AI is already covered by current legislation and addressing new AI specific concerns could be best done through tweaks, rather than fundamental changes, to the current ecosystem. Approaching new legislative requirements through amending the existing framework would have the added benefit of avoiding duplication and the creation of legal uncertainty. 

Option 1 / soft-law
The benefits of industry-led interventions are i) the speed in which such solutions are implemented, leading to quicker and greater uptake of AI and ii) a soft-law approach often adapts quickest to nascent technologies. 

Option 2 / voluntary labelling
There could be advantages to voluntary labelling schemes, with industry involvement to ensure its uptake, and thus are worth exploring further.

Option 3b / mandatory requirements for “high-risk” AI applications
RELX supports the distinction between high and low risk AI-applications and would highlight the importance of the context within which an AI-system is regulated. RELX believes that if mandatory requirements are necessary the Commission is right to take a risk-based approach and target any requirements at high-risk AI applications. Determining what constitutes high-risk will need to be thought through carefully, ensuring due consideration is given to the specific context of an AI application.

Option 3c / mandatory requirements to cover all AI-applications
RELX would caution against this option as it completely negates the risk-based approach, which would lead to targeted fixes rather than a blanket overhaul. 

Option 4 / combination
RELX sees this as the most viable way forward to mitigate any potential risks stemming from AI-systems. We feel that a combination of Options 1 and 3b would be most effective in achieving the Commission’s policy goals to “ensure the development and uptake of lawful and trustworthy AI across the Single Market through the creation of an ecosystem of trust.”

Please find attached a more elaborate reflection on the IIA. RELX stands ready to further engage with the European Commission on the important topic of AI."
Anonymous,Feedback is in the attached file.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551040_en,1,F551040,10 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,Feedback is in the attached file.
Electronic Privacy Information Center (United States),"Electronic Privacy Information Center (EPIC) recommends that the commission adopt section 3, subsection c. Full comments are attached.",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551037_en,1,F551037,10 September 2020,Ben Winters,Non-governmental organisation (NGO),Electronic Privacy Information Center,Small (10 to 49 employees),,United States,Artificial intelligence – ethical and legal requirements,"Electronic Privacy Information Center (EPIC) recommends that the commission adopt section 3, subsection c. Full comments are attached."
Anonymous,"No broad EU policy change: Only for the fields where current regulation is not sufficient additional regulation may be introduced. Multiple rules, including GDPR, are overlapping with the suggested AI regulations, which will likely cause confusion. We support a narrow targeted approach. Option 1: EU “soft law”: The initiative to allow for self-regulation and co-regulation, by providing the principles and guidelines by EC is welcomed. It may...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551036_en,1,F551036,10 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,"No broad EU policy change:
Only for the fields where current regulation is not sufficient additional regulation may be introduced. Multiple rules, including GDPR, are overlapping with the suggested AI regulations, which will likely cause confusion. We support a narrow targeted approach.
Option 1: EU “soft law”:
The initiative to allow for self-regulation and co-regulation, by providing the principles and guidelines by EC is welcomed. It may provide guidelines to incorporate European values into various businesses processes, but it would not raise harm for various small businesses and AI startups. We support a soft law approach.
Option 2: EU legislative instrument setting up a voluntary labelling scheme:
We are concerned that even a voluntary labelling scheme is likely to create a heavy administrative burden for AI innovators, startups and SMEs with limited resources if applied broadly. It would restrict development across the EU. We would like to encourage the EC to work with the AI industry to develop a number of labeling schemes only for high-risk AI applications. We support a labeling scheme for high risk AI applications.
Option 3: EU legislative instrument establishing mandatory requirements for all or certain types of AI applications
We believe this approach is unfounded and damaging. Nowadays, various systems use a great range of different types of AI technologies. Said approach would lead to multiple bureaucratic bottlenecks for companies creating and developing AI technologies. EC should take into account the high risk of possible losses coming with additional regulations, and what economical impact it would have especially for AI startups and SME's. We are against this approach.
3a) EU legislative instrument limited to a specific category of AI applications
The list of AI applications will be large, and it will be too hard to objectively determine what should or should not be added to the list.
3b) EU legislative instrument limited to “high-risk” AI applications
We believe that regulation should be only limited to “high-risk” AI applications, where current legislation is not covered, is the best option. We support using a combination of sector and use/application as criteria to set up the risk-based approach.

3c) EU legislation covering all AI applications
As mentioned in the previous feedback, we believe that future regulation on AI should be limited to “high-risk” applications only. Otherwise AI applications posing no significant risk or harm would be subjected to disproportionate rules that in no way would advance development, trust and adoption of AI solutions in Europe. Over-regulating application of a technology with great potential and importance would likely result in severe opportunity costs for the society and quite possibly lower the bar for AI applications with significant risks.

Option 4: combination of any of the options above taking into account the different levels of risk that could be generated by a particular AI application.  
Realization of this option is not clear. We do not support this approach.

On high risk definitions:
The idea to implement strict rules based on European values to avoid any chances of mass surveillance is welcomed. However the current formulations put all Europe's biometric companies at disadvantage. We would like to draw attention to the fact that development of biometric identification technologies is different from possible malicious applications. EU regulations should be technology neutral: technology and applications should be clearly separated. Also we would like to note that “remote identification” term is used incorrectly, it can be mistaken for biometric identification performed in a cloud system. Academia and industry use different terms for the same concept, namely “recognition/identification at a distance”."
Center for Data Innovation (United States),"The Center for Data Innovation is please to submit feedback to the European Commission’s roadmap titled “Inception Impact Assessment: Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence."" The European Commission’s white paper on AI, published in February 2020, argues that AI may cause harm and existing legislation consumer protection, product safety, and liability do not...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551033_en,1,F551033,10 September 2020,Eline Chivot,Non-governmental organisation (NGO),Center for Data Innovation,Micro (1 to 9 employees),,United States,Artificial intelligence – ethical and legal requirements,"The Center for Data Innovation is please to submit feedback to the European Commission’s roadmap titled “Inception Impact Assessment: Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence.""

The European Commission’s white paper on AI, published in February 2020, argues that AI may cause harm and existing legislation consumer protection, product safety, and liability do not adequately cover these risks. The Commission believes the EU should address these risks to ensure the development of lawful and trustworthy AI that respects fundamental human rights. To that end, the Commission is proposing four policy options. In the attached submission, we provide feedback on each option.

Thank you for your consideration and this opportunity to contribute."
F-Secure Corporation (Finland),"F-Secure is very happy to see the discussion on ethical and legal requirements of AI progressing, as this is an important topic and a core part of the EU position towards AI. One fundamental aspect we fully agree with is having EU level approach instead of country-specific ones. We are happy to participate in the discussions and provide our expertise in preparing next steps and possible policy and legislative initiatives. Even though AI has...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551032_en,1,F551032,10 September 2020,Matti Aksela,Company/business,F-Secure Corporation,Large (250 or more),957279018810-11,Finland,Artificial intelligence – ethical and legal requirements,"F-Secure is very happy to see the discussion on ethical and legal requirements of AI progressing, as this is an important topic and a core part of the EU position towards AI. One fundamental aspect we fully agree with is having EU level approach instead of country-specific ones. We are happy to participate in the discussions and provide our expertise in preparing next steps and possible policy and legislative initiatives.

Even though AI has gotten a lot of public attention lately, the technologies themselves are not that new – AI and machine learning have been around for decades, and also the commercial use of AI has been active for years. It is also important to remember that current AI is not general AI but still – even if very impressive – very narrow. Current AI can be used for multiple purposes but still fundamentally does what it is set to do as opposed to having intent of its own. We should consider AI together with other software, automation and data processing technologies as it is a very similar technological enabler.

As such, a very important consideration is whether AI specific regulation is an approach that should be taken and if so, to what extent. As stated, there are several existing frameworks that (partially) apply, and we support augmenting those, also because finding a holistic definition of AI that is neither too narrow or too broad is very difficult. 

We would however challenge the logic that regulation consistently increases trust and with increased obligations benefits also increase. Regulation increases cost, but the link to increased benefits is not as obvious and may not realize to even near the expected extent – in fact regulation may at worst be mostly a cost for development, and if applicable to EU players primarily, it may severely hamper European competitiveness – a risk that must not be taken lightly. AI technologies already provide significant benefits in multiple industries without excessive regulation. There are cases where regulation can be beneficial, e.g. in medical applications, but it should not be generalized too widely – also a reason for avoiding too broad AI specific regulation.

A note on the energy impacts; even though the most prominent methods today are based on complex deep learning networks and are computationally very expensive, that is not the case for all AI. Actually, more efficient AI is one area where we see research focus should be directed to as that could make a huge impact also for the future development of AI.

Some high-risk applications may need strict regulation, but there is a significant challenge in defining those. The application depends on the domain, but even more on the use case and the data - making the right level of granularity challenging. E.g. there are HR related AI applications which can be high risk for discrimination – but a chatbot assistant that answers questions on open positions would hardly be one. If employed, great care must be taken and a very accurate and detailed description of high-risk applications is needed. That said, a very detailed description leaves the opportunity to circumvent the regulation and limit its effectiveness – a difficult problem to solve.

To encourage wide development and adaption of AI, as well as the growth in SMEs, as high regulatory requirements will favor large organizations with capability to address them, we recommend to have as little AI specific regulation as possible and even if such is needed, voluntary labeling and soft law would be preferred.

The use of data and AI is the future and will bring immense value to those who embrace it. We do need to protect individuals and human rights, but as we live in a global economy we should take extra care to allow European development to be in the forefront and avoid hindering advances and new solutions unnecessarily. It is a balance that is not easy to strike, but getting it right is absolutely vital for our future."
techUK (United Kingdom),"techUK welcomes the opportunity to respond to the Inception Impact Assessment proposed by the European Commission on the proposed legal act on Artificial Intelligence. Please find below our comments on the legislative options outlined: Option 1- EU “soft law” (non-legislative) approach techUK supports a soft law approach to AI and building upon existing initiatives, such as the AI HLEG assessment list and the development of a global set of...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551031_en,1,F551031,10 September 2020,Katherine Mayes,Business association,techUK,Small (10 to 49 employees),,United Kingdom,Artificial intelligence – ethical and legal requirements,"techUK welcomes the opportunity to respond to the Inception Impact Assessment proposed by the European Commission on the proposed legal act on Artificial Intelligence. 

Please find below our comments on the legislative options outlined: 

Option 1- EU “soft law” (non-legislative) approach
techUK supports a soft law approach to AI and building upon existing initiatives, such as the AI HLEG assessment list and the development of a global set of digital ethics standards. 

Option 2- Setting up a voluntary labelling scheme 
techUK supports further consideration of a voluntary labelling scheme. To ensure a flexible and future-proof approach, self-regulation based on a voluntary labelling system could in principle be an effective approach, to help signify trustworthy AI.

One other concept that could be explored– perhaps as a trial – is a system of voluntary ‘assurances’ provided by companies in the AI supply chain. Each company would issue an ‘assurance’ of the steps they had taken to deal with ethical issues arising in their part of the chain. A similar process called the supplier’s declarations of conformity (SDoCs) already exists during the safety and performance testing of a product, making this concept a viable option. 

Option 3a- Legislation establishing mandatory requirements for a specific category of AI applications only, notably remote biometric identification systems.
Any concerns around ‘remote biometric identification’ might be better approached through the existing (or modified) GDPR framework (such as Article 9(1) and Article 22) rather than through a specific AI piece of legislation. 

techUK supports the European Commission’s commitment to a wider public dialogue on the specific circumstances that facial recognition technologies are used. 

Option 3b- Legislation establishing mandatory requirements for “high-risk” AI applications.
techUK advises against imposing specific requirements for “high risk” AI. 

Defining a “high-risk” application in many cases is inherently difficult in practice. It may be better to envisage an approach which is essentially context-based. For most of the applications considered “high-risk” there are already existing laws and regulations which will apply (i.e. health & safety, IP rights, product safety and manufacturing standards, liability, etc.). We must avoid new AI requirements that could contradict or duplicate these provisions, and instead focus on providing guidance on the application of existing laws in contexts where the AI present a novel or unique challenge (for example by introducing complexity or opacity into a technology supply chain).

Each of the mandatory requirements listed (quality of training data sets, keeping records, human oversight etc.) are fundamental requirements that we believe are already addressed through existing regulation.

Option 3c: Legislation covering all AI applications. 
We do not support this option as it risks stalling innovation and significantly hindering the uptake and development of AI in the EU. Each type of AI application is associated with a different amount of risk and so there cannot be a “one size fits all” approach to legislating all AI applications. Such an approach would introduce unnecessary burden for businesses investing in AI-based technologies, particularly SMEs. 

Option 4: A combination of the options above taking into account the different levels of risk that could be generated by a particular AI application. 

techUK believe the Objective and Aims can be best met by a combination of options, including “soft law” approaches, a system of voluntary ‘assurances’, the enforcement of existing regulation and assessing the risk of AI applications under a sector-specific framework, when available."
Fédération Française de l'Assurance (France),"FFA welcomes EC’s initiative to encourage the ethical and responsible development of artificial intelligence (AI) in the EU. AI offers economic, societal and competitive advantages to European businesses and citizens. The appropriate ethical and legal framework, based on European values, in line with the Charter of Fundamental Rights, will allow for the deployment of improved AI. A European approach is necessary to limit the fragmentation of...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551030_en,2,F551030,10 September 2020,Solène Gastal,Business association,Fédération Française de l'Assurance,Medium (50 to 249 employees),,France,Artificial intelligence – ethical and legal requirements,"FFA welcomes EC’s initiative to encourage the ethical and responsible development of artificial intelligence (AI) in the EU. AI offers economic, societal and competitive advantages to European businesses and citizens. The appropriate ethical and legal framework, based on European values, in line with the Charter of Fundamental Rights, will allow for the deployment of improved AI. A European approach is necessary to limit the fragmentation of the internal market, ensure fair competition and protect European citizens and businesses from unreliable AI.
Calculating premiums, evaluating claims, provisioning funds using algorithms are the very essence of insurer's activities and AI can significantly improve operational efficiency and customer experience. Insurers fully acknowledge the necessity to protect fundamental rights as well as the safety of users and third parties. In that regard, a human-centric technology is needed. Insurers are more and more able to consider customers’ needs and expectations to offer the most adapted products through differentiation, without leading to discriminatory or anti-privacy practice, and further sectoral initiatives are in development. 
In addition, as outlined in the High Level Expert Group on AI’s report, aspects related to innovation are governed by extensive European legislation (GDPR, anti-discrimination rules, etc.). Likewise, insurance is a heavily regulated sector (Solvency II Directive, Insurance Distribution Directive, etc.). A soft-law approach to facilitate and spur industry-led intervention (Option 1) would be the most relevant approach to encourage a single set of AI principles while enforcing existing rules.
Another alternative is the establishment of a voluntary labelling scheme (Option 2). For insurers, it would allow AI applications to meet requirements, thus, creating an upward competition. However, to maintain the necessary level playing field, a solution could be to encourage labelling by providing a clear, simple and inexpensive model through a European reference system (see for example the French National Institute of Intellectual Property (INPI) recognition mechanism). This would prevent a fragmentation of labelling and of the internal market.
In case the EC is heading towards an EU legislative instrument establishing mandatory requirements for AI applications (Option 3), it should adopt a risk-based approach. The legislative instrument should be limited to specific category of AI applications raising high-risk for users and third-party so not generate disproportionate burdens hindering innovation. The identification of high risks should follow the conditions set out in the White Paper on AI.
Further debates with all stakeholders would then be needed to elaborate a clear and realistic definition of high-risk. AI can produce different effects and having a risk assessment scale for autonomous system should consider the different types of risks. Once defined, it is essential to avoid over-regulation of many sectors and hinder their development.  As stated by the EC, a double criterion should be applied: First, activities that could raise risks could be identified by the EC allowing for less fragmentation of the market. Second, competent sectoral authorities could then assess the high-risk potential of specific AI applications, which are not harmful in themselves and have an impact only based on their use. Only a sectoral authority would be able to understand the realities of a market and the specific context of AI applications.
Insurance should not be considered as a high-risk sector. Insurers assist their policyholders at every stages of their lives and on their daily routine. Certain insurers’ activities may be related to sectors that could raise risks (e.g. transport or health) and, the related AI applications should be assessed. It would however not be pertinent to individualize the insurance sector and to categorize the variety of its activities as a high-risk sector."
Developers Alliance (United States),"Developers Alliance welcomes the opportunity to further provide feedback on the European Commission’s proposals on requirements for AI. The Inception Impact Assessment presents several regulatory options and the underlying policy objectives, based on the approach initiated by the White Paper on AI. Our response emphasizes the need to avoid excessive regulatory burden and to adopt a fit-for-purpose approach aimed at promoting AI development...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551022_en,2,F551022,10 September 2020,Karina Stan,Business association,Developers Alliance,Micro (1 to 9 employees),135037514504-30,United States,Artificial intelligence – ethical and legal requirements,"Developers Alliance welcomes the opportunity to further provide feedback on the European Commission’s proposals on requirements for AI. 

The Inception Impact Assessment presents several regulatory options and the underlying policy objectives, based on the approach initiated by the White Paper on AI. Our response emphasizes the need to avoid excessive regulatory burden and to adopt a fit-for-purpose approach aimed at promoting AI development in the EU.

We commend the EC’s engagement to avoid “a fragmentation of the Digital Single Market into potentially divergent frameworks preventing the free circulation of goods and services containing AI”. 

Please find attached our detailed position."
Microsoft Corporation (United States),Microsoft appreciates the opportunity to respond to the European Commission’s Inception Impact Assessment (“IIA”) on its proposal for a legal act setting out requirements for artificial intelligence (“AI”). We support the Commission’s goal of ensuring that AI evolves in a manner that respects EU values and fundamental rights. An appropriate regulatory framework for AI could advance the responsible development and use of AI both within the EU...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551021_en,2,F551021,10 September 2020,Cornelia Kutterer,Company/business,Microsoft Corporation,Large (250 or more),0801162959-21,United States,Artificial intelligence – ethical and legal requirements,"Microsoft appreciates the opportunity to respond to the European Commission’s Inception Impact Assessment (“IIA”) on its proposal for a legal act setting out requirements for artificial intelligence (“AI”). We support the Commission’s goal of ensuring that AI evolves in a manner that respects EU values and fundamental rights. An appropriate regulatory framework for AI could advance the responsible development and use of AI both within the EU and internationally. Given the EU’s deep integration into the global economy, any legislative framework for AI also should be interoperable to the greatest extent possible with efforts in other jurisdictions and forums to promote trustworthy AI.

In our response to the Commission’s February 2020 AI White Paper (“AI White Paper Response,” uploaded separately), we welcomed the Commission’s proposal to adopt an incremental, risk-based approach to AI regulation. We noted that such an approach—one that imposes mandatory requirements on a discrete and clearly defined set of high-risk AI scenarios—will help protect people and society against AI use cases that raise significant risks of harm, while giving Europe’s AI sector the flexibility it needs to grow and mature. 

We continue to support that approach. Given the many nuances raised by the various scenarios in which AI can be deployed, we believe the Commission can most effectively achieve its goals through a mix of binding requirements for scenarios that pose the greatest risk, combined with soft-law approaches (e.g., codes of conduct, self-regulatory mechanisms) for lower-risk scenarios that incentivize the use of governance mechanisms and tools for promoting trustworthy AI. Microsoft addresses these issues primarily from the perspective of a developer and supplier of AI solutions that customers across the public and private sectors use for an almost unlimited range of purposes. These various uses may raise very different risks. In light of this reality, we urge the Commission give careful thought to which obligations are most appropriately placed on developers of multi-purpose AI solutions, and which are most appropriately placed on deployers.

Microsoft supports Option #4 of the IIA—namely, a combination of Options 1 through 3 that considers the different levels and types of risks that different AI scenarios may raise. This combination of measures is vital to ensure that the EU’s overall regulatory approach to AI is meaningful, balanced, and effective. It bears repeating at the outset that there is no “one-size-fits-all” approach to AI regulation. Many AI systems pose low or even no risks to individuals or society (e.g., AI systems that optimize storage of items in a warehouse or fix typing errors); these systems do not require new or mandatory regulation. And where meaningful risks do exist, they will often be different and context-specific, and thus require different mitigation measures, including regulation.

Please find attached a more detailed response."
DECO (Portugal),Our contributes in attach,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551020_en,2,F551020,10 September 2020,Carla Paquito,Consumer organisation,DECO,Medium (50 to 249 employees),005887421809-56,Portugal,Artificial intelligence – ethical and legal requirements,Our contributes in attach
Interactive Software Federation of Europe (Belgium),"ISFE represents the video games industry in Europe and is based in Brussels, Belgium. ISFE welcomes the opportunity to submit comments to the European Commission Inception Impact Assessment regarding the proposed policy options and instruments for Artificial Intelligence. Please find attached our comments.",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551019_en,2,F551019,10 September 2020,Ann Becker,Business association,Interactive Software Federation of Europe,Micro (1 to 9 employees),20586492362-11,Belgium,Artificial intelligence – ethical and legal requirements,"ISFE represents the video games industry in Europe and is based in Brussels, Belgium. ISFE welcomes the opportunity to submit comments to the European Commission Inception Impact Assessment regarding the proposed policy options and instruments for Artificial Intelligence. Please find attached our comments."
Eurocities (Belgium),"EUROCITIES welcomes the Inception Impact Assessment (IIA) on a proposal for a legal act laying down requirements for Artificial Intelligence (AI). AI is an enabler of change for local governments and is already transforming the governance of cities and society. As the level of governance closest to people, with increasing populations, access to talent and skills, universities, companies and infrastructures, local governments are crucial to...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551016_en,2,F551016,10 September 2020,Lodewijk Noordzij,Public authority,Eurocities,Medium (50 to 249 employees),12493392840-79,Belgium,Artificial intelligence – ethical and legal requirements,"EUROCITIES welcomes the Inception Impact Assessment (IIA) on a proposal for a legal act laying down requirements for Artificial Intelligence (AI). 
AI is an enabler of change for local governments and is already transforming the governance of cities and society. As the level of governance closest to people, with increasing populations, access to talent and skills, universities, companies and infrastructures, local governments are crucial to fostering an ecosystem of excellence and trust in AI in Europe. 
The problems described in the IIA correctly outline several key challenges related to ethical and legal application of AI. The lack of transparency for effective enforcement of existing law and liability compensations, a legislative void and the unavailability of tools for intervention present challenges for businesses, citizens and authorities alike. Missing requirements for preventing and/or mitigating negative outcomes of AI tools cause a lack of trust for embracing AI, slowing down its deployment.  
In its problem analysis, the IIA should also note that AI Adoption in cities is a long and costly process, which requires specific, high-level competences as well as new governance approaches. Moreover, the rapid exponential technological progress in AI will have a disruptive effect on the job market and creates the need in cities for skills development among its citizens. 
We support and underline the overarching objectives set out in the IIA for effective enforcement mechanisms to protect safety and fundamental rights. Emphasis should be put on the need to facilitate rights-based public services and the protection of European fundamental values. Building an ecosystem of excellence and trust is an important condition for a broad and swift uptake of AI, a condition for which local governments are crucial. 
Indeed, relevant documentation is needed for the purpose of private and public enforcement of EU rules. We add to that the need for documentation that is available and understandable for citizens. Everyone should have access to clear and accurate information about the technological, algorithmic and artificial intelligence systems that impact their lives, and the ability to question and change unfair, biased or discriminatory systems. 
The impact assessment should focus on those policy options that would achieve the overarching objectives. Emphasising the importance of safety and fundamental rights, voluntary schemes provided for and maintained by industry would not suffice. An assessment of a legislative instrument establishing mandatory requirements for AI, taking into consideration the possibility of addressing specific categories of (high-risk) AI applications would be a positive step.  
To ensure compliance with these requirements, a central EU body or agency should develop necessary verification and validation procedures to guarantee safe and ethical AI, protecting citizens’ fundamental rights.  
More detailed descriptions of possible high-risk use cases are needed to clearly understand effects on local public administrations. We encourage combining funding, capacities, competences and mechanisms to realise the competences for adopting AI, emphasising local governments as crucial capacities to fostering an ecosystem of excellence and trust in AI in Europe. 
The assessment of expected impacts should include the social and economic impacts for cities in the areas outlined under likely economic impacts (i.e. costs for public institutions to comply with mechanisms). 
Local authorities engage with citizens, understand their fears and concerns and provide collaborative platforms for citizens, businesses and academia to develop solutions together. The EU must work with local governments in the development of a future regulatory framework for trustworthy AI to incentivize its use. Therefore, the consultation strategy should recognise city authorities as stakeholders and involve representatives in any targeted consultations."
European Banking Federation (Belgium),The European Banking Federation (EBF) welcomes the opportunity to respond to the European Commission’s Consultation on its Inception Impact Assessment (IIA) on a Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence (AI). Please see the attached document for our comments. The responses to the different elements in the IIA complement the EBF’s response to the European...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551015_en,2,F551015,10 September 2020,Liga Semane,Business association,European Banking Federation,Small (10 to 49 employees),4722660838-23,Belgium,Artificial intelligence – ethical and legal requirements,"The European Banking Federation (EBF) welcomes the opportunity to respond to the European Commission’s Consultation on its Inception Impact Assessment (IIA) on a Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence (AI). 
Please see the attached document for our comments. The responses to the different elements in the IIA complement the EBF’s response to the European Commission’s Consultation on the White Paper on Artificial Intelligence."
TECH IN FRANCE (France),"Par la contribution à l’étude d’impact initiale sur l’Intelligence artificielle (IA) ouverte, TECH IN France souhaite poursuivre son implication vis-à-vis des travaux et des réflexions conduits par la Commission européenne dans le cadre de sa stratégie dédiée à l’IA. Ainsi, le souhait de la Commission européenne de créer un système européen à même de garantir la confiance des citoyens et stimuler l’adoption des usages IA, tout en assurant...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551014_en,2,F551014,10 September 2020,MARJORIE VOLLAND,Company/business,TECH IN FRANCE,Micro (1 to 9 employees),,France,Artificial intelligence – ethical and legal requirements,"Par la contribution à l’étude d’impact initiale sur l’Intelligence artificielle (IA) ouverte, TECH IN France souhaite poursuivre son implication vis-à-vis des travaux et des réflexions conduits par la Commission européenne dans le cadre de sa stratégie dédiée à l’IA.  

Ainsi, le souhait de la Commission européenne de créer un système européen à même de garantir la confiance des citoyens et stimuler l’adoption des usages IA, tout en assurant celle des entreprises dans le déploiement de leurs produits et applications IA et la capacité d’innovation en Europe, nous apparaît une stratégie ambitieuse et adaptée aux enjeux de développement du potentiel numérique en Europe. De nombreuses entreprises membres de TECH IN France se sont d’ailleurs exprimées publiquement au cours des derniers mois en faveur du principe de l’élaboration d’une régulation. 

Dans cette optique, TECH IN France et ses adhérents souhaitent réitérer ici l’attention portée à l’adoption d’une approche pragmatique et équilibrée dans la définition d’un nouveau cadre règlementaire par la Commission européenne. Ce principe d’équilibre dans l’élaboration d’une régulation européenne de l’IA apparaît comme essentiel pour créer les conditions de l’innovation via le développement d’un écosystème de l’excellence, dès le stade de la recherche et de l’innovation, incitant à une adoption rapide des solutions IA par les entreprises, notamment les TPE et les PME ; et pour être à même de stimuler l’innovation, en donnant aux entreprises la sécurité juridique nécessaire. Ce nouveau cadre réglementaire devra également éviter de faire peser sur les entreprises des contraintes disproportionnées par rapport à leurs compétiteurs internationaux, et devra répondre à leurs besoins de compétitivité dans la bataille mondiale de l’IA et des données.   

Dans le cadre de cette étude d’impact, il est proposé de revenir plus précisément sur les différentes options de régulation de l’IA envisagées par la Commission européenne et présentées au sein du Livre Blanc sur une approche européenne de l’intelligence artificielle en février dernier. Il nous apparaît ainsi important de préciser à nouveau les éléments et points de vigilance, formulés par TECH IN France au sein de sa réponse à la consultation sur le Livre Blanc [...]."
Insurance Europe (Belgium),"Insurance Europe welcomes the initiative to encourage ethical and responsible development of AI in the EU and supports the creation of an ecosystem of trust to stimulate its uptake. A European approach is necessary to limit fragmentation of the digital single market, ensure fair competition and protect European citizens & businesses. As noted by the Commission’s HLEG on AI in its recommendations, the development & use of AI is already covered...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551012_en,2,F551012,10 September 2020,Arthur HILLIARD,Business association,Insurance Europe,Small (10 to 49 employees),33213703459-54,Belgium,Artificial intelligence – ethical and legal requirements,"Insurance Europe welcomes the initiative to encourage ethical and responsible development of AI in the EU and supports the creation of an ecosystem of trust to stimulate its uptake. A European approach is necessary to limit fragmentation of the digital single market, ensure fair competition and protect European citizens & businesses.
As noted by the Commission’s HLEG on AI in its recommendations, the development & use of AI is already covered by a wide body of existing EU legislation, such as on fundamental rights, privacy & data protection, as well as product safety & liability. This is further complemented by national & sectoral regulatory frameworks. A horizontal, proportionate, principles- and risk-based framework that builds on this, addressing potential gaps where necessary, will help support the development & uptake of AI and avoid unnecessary burden.
We believe that option 1 would therefore be the preferable policy option, as it provides for a soft-law approach to facilitate and spur industry-led intervention. It would also be the most relevant approach to encourage coordination on a single set of AI principles, while enhancing enforcement of existing rules. 
To promote the uptake of AI & prevent innovative technologies from being stifled by premature regulation, the ethical use of AI should be supported by, and reinforced through, voluntary and/or non-legislative instruments as far as possible. Voluntary certifications have traditionally proven to be an effective means of ensuring high & transparent standards (eg in the area of IT security). They enable customers to easily identify trustworthy products and allow companies to demonstrate and promote the quality of their products. Many companies would have an interest in voluntarily opting to certify their AI applications to enhance consumer confidence, stay ahead of the competition and demonstrate compliance with current standards and regulation.
Moreover, an approach that focuses mainly on voluntary instruments (eg industry-developed codes of conduct or guidelines) remains compatible with the option to introduce legislative instruments containing mandatory requirements for certain AI applications, as set out in option 3. However, it is important to ensure that any EU legislative instrument that may be introduced is horizontal, proportionate & risk-based, and limited only to “high-risk” AI applications that are determined on the basis of clear criteria (as suggested in White Paper). Inclusion in the scope of such requirements of low-risk, common automation processes or applications that pose little or no risk to the rights of customers would hinder innovation and the uptake of new technologies, give rise to additional costs, and create a disproportionate burden in view of their low risk.
From the outset, the insurance industry has made extensive use of data and algorithms, eg in the calculation of insurance premiums. Such methods of analysis are long-established and already subject to supervision. The development of AI tools can help insurers to improve underwriting as well as to better monitor & predict risk, and thereby advise policyholders on how to reduce risk, which can in turn help reduce the frequency and severity of losses over time.
We would also stress that monitoring the use of AI applications should continue to fall within the competence of the relevant sectoral supervisory or regulatory authorities, as they remain best placed to understand the market in question and the specific context of the AI application vis-à-vis the applicable regulatory framework.
The existing liability regime (PLD) is fit for purpose to address the risks posed by AI but could benefit from additional guidance in certain key areas. Existing product safety legislation should be reviewed as to its fitness. New legislation should only be adopted where clear evidence demonstrates a need for action and should be proportionate to the concrete risks posed by the AI application in question."
Adigtal (Spain),Document attached,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551011_en,2,F551011,10 September 2020,Cristina Cartes Andres,Business association,Adigtal,Small (10 to 49 employees),972127919039-72,Spain,Artificial intelligence – ethical and legal requirements,Document attached
Science Europe (Belgium),"Science Europe welcomes the opportunity to react to the European Commission’s (EC) Inception Impact Assessment for a ‘Proposal for a legal act laying down requirements for Artificial Intelligence’. Science Europe Member Organisations, major national research funding (RFOs) and performing organisations (RPOs), are important users and producers of data. As such they can contribute to and be impacted by Artificial Intelligence (AI) developments...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551010_en,3,F551010,10 September 2020,Marie TIMMERMANN,Academic/research Institution,Science Europe,Small (10 to 49 employees),73131808686-11,Belgium,Artificial intelligence – ethical and legal requirements,"Science Europe welcomes the opportunity to react to the European Commission’s (EC) Inception Impact Assessment for a ‘Proposal for a legal act laying down requirements for Artificial Intelligence’. Science Europe Member Organisations, major national research funding (RFOs) and performing organisations (RPOs), are important users and producers of data. As such they can contribute to and be impacted by Artificial Intelligence (AI) developments in many ways. Science Europe considers that the implications of an AI legislation on the research and innovation (R&I) sector are currently not sufficiently taken into account. 

The importance of AI for R&I
The importance of AI for R&I is growing quickly. Future EU legislation on AI could have an impact on the activities of RPOs and RFOs, including:
• Research on the development of AI systems;
• Implementation and embedding of AI methods in, possibly, all fields of research;
• Use of AI in research administration and governance, for example to identify reviewers for grant applications or pre-assess project applications.

The EC analysis of the answers to the consultation in spring 2020 shows that fostering R&I on AI is of great importance to many respondents. It is therefore surprising that the EC Inception Impact Assessment from 23 July 2020 does not refer to the R&I sector at all and, instead, is purely business oriented. 
Science Europe would like to see R&I properly addressed in EU legislation on AI. In this respect, Science Europe invites the EC to take into account the following three points:

1. Developers’ and users’ liability
The question of liability for developers and users of AI systems does not only concern industry, as implied in the Inception Impact Assessment. Researchers are important contributors to the development of AI systems. The EC should ensure that potential EU legislation tackling liability issues provides the necessary safety guarantees to both users and developers of AI systems while at the same time fostering R&I on AI. 

2. Links between AI and Open Science
Science Europe members define and implement numerous Open Science policies, including Open Access to research publications and research data. Science Europe promotes Open Science policies and, moreover, Science Europe and some of its members are actively engaged in the development of the European Open Science Cloud (EOSC). 
EOSC will make data available on a large scale and across borders for researchers to use, based on the principle as open as possible as closed as necessary.’ The increased availability of data will lead to many researchers using AI technologies for data analysis. Healthy, unbiased datasets and data protocols are needed for researchers to produce quality research. The EC needs to ensure that future legislation on AI supports Open Science policies.

3. Solid scientific results depend on robust and reliable data
Researchers using AI systems to conduct their research, as well as research organisations using AI in their daily business for research administration and governance, need to be sure that the data and the AI systems they use are reliable. The quality of results provided by AI applications depends on robust data collection methodologies and tools, transparency of data sets, as well as monitoring and curation of data sets and algorithms. This is critical to ensure that AI systems do not cause erroneous results because of biased data. The EC services should take these aspects into account when considering a potential legislative or soft law approach on AI and ensure coherence with other legislative projects such as the proposal on European data spaces.

Science Europe would be happy to collaborate with the EC by providing further input from its member organisations and their expertise on AI in the R&I sector. Future EU legislation on AI needs to strike the right balance between safeguards for users and developers of AI systems and a legal environment that fosters R&I."
Johann CAS (Austria),Comments by Johann Čas on the European Commissions’ consultation on the inception impact assessment as part of the initiative “Artificial intelligence – ethical and legal requirements”. Johann Čas is a senior researcher at the Institute of Technology Assessment of the Austrian Academy of Sciences. Among other things he is co-author of the study “When algorithms decide in our place: the challenges of artificial intelligence in Switzerland”...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551005_en,3,F551005,10 September 2020,Johann CAS,EU citizen,,,,Austria,Artificial intelligence – ethical and legal requirements,"Comments by Johann Čas on the European Commissions’ consultation on the inception impact assessment as part of the initiative “Artificial intelligence – ethical and legal requirements”.
Johann Čas is a senior researcher at the Institute of Technology Assessment of the Austrian Academy of Sciences. Among other things he is co-author of the study “When algorithms decide in our place: the challenges of artificial intelligence in Switzerland” (https://www.oeaw.ac.at/en/ita/projects/the-social-effects-of-artificial-intelligence/)  (the main text is only available in German) and a team member of the H2020 PANELFIT project consortium (https://www.panelfit.eu/). 
All opinions and views expressed are personal.

Welcoming the opportunity of providing feedback on this legislative initiative I would like to provide the following comments and suggestions:

A. Context, Problem definition and Subsidiarity Check

The introduction appears to be based on overoptimistic perspective. Whereas the positive potentials certainly exist it should be also mentioned that they are also accompanied by corresponding risks, that their materialization depends on the creation of suitable framework conditions, which must also include a fair distribution of the possible benefits. A more realistic and sober assessment of opportunities and risks would be more helpful as a basis for deciding on regulatory options. To explain this recommendation in more detail, here an excerpt from a commentary I wrote during the consultations on the Ethics guidelines for trustworthy AI of the High-Level Expert Group on Artificial Intelligence (HLEG):
“Last but not least, the working document [draft Ethics guidelines for trustworthy AI] appears to overestimate the actual and potentially positive contributions of AI to solve the grand challenges our world is facing, missing to provide evidence for this positive overall evaluation. Whereas large and important positive potentials can be envisaged, past and current use of AI does not appear to support this judgement. Taking increasing economic inequality as an example, AI has rather contributed to it – e.g. in form of a key enabling technology of high-frequency trading on financial markets - but I’m not aware of making serious attempts to use AI to resolve imbalances on labour markets. On the political level, AI is rather threatening civil liberties and democratic systems than empowering citizens. On a global level, AI is rather supporting the establishment of worldwide monopolies than empowering consumers. Data based businesses possess unprecedented economic capacities, unparalleled political influence, powers to shape the results of democratic votes, unique possibilities to influence or to manipulate individuals in the information they receive or decisions they take. By disproportionately stressing the potential positive impacts and neglecting the already materialised threats the working document in the current form might contribute to an inappropriate reliance on AI when tackling urgent problems of the EU and the world. By missing to mention these dangers and threats it also misses to analyse them and consequently to develop measures and policies to counter them. This leads back to the ... [next] critical comment: we are primarily not in need of a trustworthy technology but of making good use of opportunities offered by technology in the human interest and keeping human agency.”

Complete comments are available in the attached pdf file."
American Chamber of Commerce to the European Union (AmCham EU) (Belgium),"The American Chamber of Commerce to the European Union (AmCham EU) has long called for a risk-based approach to artificial intelligence (AI) regulation, and fully supports the view that AI legislation must be targeted and focused on problems which are not already covered by existing legislation. Any risk assessment (or indeed rules/prohibitions) must take into account the context when assessing risk, since an AI application used for the same...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551004_en,3,F551004,10 September 2020,Edward Haynes,Business association,American Chamber of Commerce to the European Union (AmCham EU),Small (10 to 49 employees),5265780509-97,Belgium,Artificial intelligence – ethical and legal requirements,"The American Chamber of Commerce to the European Union (AmCham EU) has long called for a risk-based approach to artificial intelligence (AI) regulation, and fully supports the view that AI legislation must be targeted and focused on problems which are not already covered by existing legislation.

Any risk assessment (or indeed rules/prohibitions) must take into account the context when assessing risk, since an AI application used for the same purpose will pose different risks depending on the way it is integrated into business operations. While similar AI technologies in different use cases may present very different risk profiles. The focus should always be on the specific use case, not on the broad class of application or technology. As such, risk assessments must reflect the probability and severity of potential harm. We therefore agree with the Commission that any additional regulation should be focused on high-risk applications, and we encourage the Commission to propose a narrow definition of AI systems which would focus strictly on AI high-risk applications.

Please refer to our complete submission in the attached document."
Twilio (United States),Twilio thanks the European Commission for the opportunity to respond to the Inception Impact Assessment on developing requirements for Artificial Intelligence. Twilio has already submitted a response to the European Commission’s White Paper on Artificial Intelligence – A European Approach where the company highlighted its support for this important discussion and Twilio’s willingness to contribute constructively. Twilio wishes to see the...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551003_en,3,F551003,10 September 2020,Irina Michalowitz,Company/business,Twilio,Large (250 or more),067223231522-58,United States,Artificial intelligence – ethical and legal requirements,"Twilio thanks the European Commission for the opportunity to respond to the Inception Impact Assessment on developing requirements for Artificial Intelligence. Twilio has already submitted a response to the European Commission’s White Paper on Artificial Intelligence – A European Approach where the company highlighted its support for this important discussion and Twilio’s willingness to contribute constructively. 
Twilio wishes to see the development of a trusted ecosystem for AI development and deployment in Europe so that the company’s customers can easily and confidently adopt AI-enabled tools that transform how they connect with end-user consumers. With a well calibrated policy framework, particularly regarding the delicate issues of a risk-management and liability regime for AI deployments, Twilio believes that AI can be a key driver of business innovation and economic growth in Europe for years to come. 
Twilio looks forward to further discussion with the European institutions and to contributing to an AI policy framework that delivers real benefits for all Europeans. Please find enclosed Twilio's response to the impact inception assessment."
Fortum Oy (Sweden),"Fortum would like to see a regulatory framework for AI based on the following principles: Accountability should be the key element when creating an AI regulatory framework instead of creating exhaustive lists of sectors and critical use with demands of prior conformity assessments and approval. Accountability-based compliance and governance programs enable organizations to operationalize principles-based laws into risk-based, verifiable...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F551002_en,3,F551002,10 September 2020,Jens BJÖÖRN,Company/business,Fortum Oy,Large (250 or more),03501997362-71,Sweden,Artificial intelligence – ethical and legal requirements,"Fortum would like to see a regulatory framework for AI based on the following principles: 

Accountability should be the key element when creating an AI regulatory framework instead of creating exhaustive lists of sectors and critical use with demands of prior conformity assessments and approval. Accountability-based compliance and governance programs enable organizations to operationalize principles-based laws into risk-based, verifiable, demonstrable and enforceable corporate practices and controls, supported by technology tools. 

New regulation should only be introduced when there is a gap in GDPR or other legislation. It’s important to avoid regulatory overlaps and conflicts. 

Sectors that already have a primary authority for control and oversights should not be burdened with additional supervision. This would be the case with nuclear where new applications and systems usually gets approval from the national radiation authorities."
Agoria vzw/asbl (Belgium),"“Agoria is the Belgian federation for the technology industry. We are paving the way for all technology-inspired companies in Belgium pursuing progress internationally through the development or application of innovations and which, together, represent some 300,000 employees. We are proud that more than 1,900 member companies trust in the three pillars of our services: consulting, business development and the creation of an optimal business...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550994_en,3,F550994,10 September 2020,Jelle Hoedemaekers,Company/business,Agoria vzw/asbl,Medium (50 to 249 employees),68004524380-10,Belgium,Artificial intelligence – ethical and legal requirements,"“Agoria is the Belgian federation for the technology industry. We are paving the way for all technology-inspired companies in Belgium pursuing progress internationally through the development or application of innovations and which, together, represent some 300,000 employees. We are proud that more than 1,900 member companies trust in the three pillars of our services: consulting, business development and the creation of an optimal business environment.”. 

Agoria thanks the European Commission for its efforts to foster Artificial Intelligence and for the opportunity to provide inputs regarding its Proposal for a legal act laying down requirements for Artificial Intelligence, which presents several options for future legislation. 

Firstly, Agoria is in favour of Option 1 of the alternative options to the baseline scenario, i.e. EU “soft law”, implying a non-legislative approach to facilitate and spur industry-led intervention without putting forward an EU legislative instrument. In addition, we believe that a “soft law” approach could build upon existing national initiatives and encourage a quicker industrial transformation using AI-driven systems to automate and reinvent fundamental industrial processes. Secondly, we acknowledge that others may see specific risks relating to the usage of AI in certain situations, justifying a legislative intervention. However, we must stress that the possibility of such risks arising at some point in the future does not imply that this is the case today, neither sporadically nor systematically. We urge the European Commission to analyse what is wrong in practice, before considering the optimal means of resolving these issues. Once this is clear, requirements for these specific high-risk situations will become evident and remedies may be needed. Where remedies are needed, enforcement methods should be considered, but not beforehand. Suggesting ex-ante enforcement mechanisms without any background is causing a lot of uncertainty, and SME’s specifically will be put at a disadvantage by this. 

Agoria believes that before choosing any option for a legislative intervention, existing regulation must be analysed carefully, identifying potential gaps precisely. This analysis should help to propose the adequate tools to fill those gaps and to establish a legally sound definition of AI. Given that AI has many meanings for different people and that many definitions of this term exist already, it is vital for the success of any AI related legislative action to define AI in a robust way. The most important aspect to keep in mind is that AI is not a product in itself, but rather a technology embedded in products, services and applications, which may be used in an extensive array of sectors, which puts all concerns related to AI in another perspective. For example, the health sector is already heavily regulated, and additional requirements should fit into the existing mechanisms. Additional unnecessary AI-related requirements within the EU product legislation should be avoided."
Syntec Numérique (France),"Syntec Numérique soutient la Commission dans son ambition de stimuler le développement et l'adoption de l'IA et des nouvelles technologies, tout en veillant à ce que les risques potentiels soient traités de manière adéquate. Afin de garantir la cohérence avec la législation sectorielle existante, la future proposition de réglementation de l’IA devra tenir compte de la réglementation européenne existante et qui couvre déjà l’application de l’IA...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550993_en,3,F550993,10 September 2020,Anissa Kemiche,Trade union,Syntec Numérique,Small (10 to 49 employees),565078326484-60,France,Artificial intelligence – ethical and legal requirements,"Syntec Numérique soutient la Commission dans son ambition de stimuler le développement et l'adoption de l'IA et des nouvelles technologies, tout en veillant à ce que les risques potentiels soient traités de manière adéquate. Afin de garantir la cohérence avec la législation sectorielle existante, la future proposition de réglementation de l’IA devra tenir compte de la réglementation européenne existante et qui couvre déjà l’application de l’IA (protection des droits fondamentaux, des consommateurs et sécurité des produits). 

Compte tenu de la diversité des applications et des technologies de l'IA, nous recommandons à la Commission d'adopter une approche ciblée et fondée sur les risques. Une telle approche devrait être basée sur des définitions claires. Elle doit prendre en compte le risque posé par le déploiement d'un système d'IA, le domaine d'application, le type de déploiement et la nature des risques.

Vous trouverez ci-joint un détail de nos propositions sur les quatre options présentées dans l'analyse d'impact."
Huawei (Belgium),We are grateful to the European Commission for this opportunity to provide input towards proposals for legislative action on requirements for Artificial Intelligence (AI). We encourage EU policymakers to pursue a collaborative and inclusive approach for preparation of their proposals including the perspective from global industry. We feel that the challenge of risk assessment should be addressed as a priority in the proposals. A naïve...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550992_en,3,F550992,10 September 2020,Angeliki Dedopoulou,Company/business,Huawei,Large (250 or more),114467111412-38,Belgium,Artificial intelligence – ethical and legal requirements,"We are grateful to the European Commission for this opportunity to provide input towards proposals for legislative action on requirements for Artificial Intelligence (AI). We encourage EU policymakers to pursue a collaborative and inclusive approach for preparation of their proposals including the perspective from global industry.
We feel that the challenge of risk assessment should be addressed as a priority in the proposals. A naïve approached focused only on high-risk applications can be an unintentionally blunt approach to risk assessment of AI. A change to the contextual integrity of AI systems may trigger re-evaluation, re-training, or re-development. Huawei encourages a tech-neutral approach for risk assessment of applications according to scenarios instead of generic technologies. A better definition is needed for high-risk applications to ensure legal clarity and certainty. The definition of AI high risk applications provided in the AI White Paper is not the same as the one provided in the civil liability report. The majority of machine learning applications are not high-risk and would not be constrained by ex-ante requirements. 
Regulatory oversight complements legislation through consistency and harmonisation of decisions and requirements from competent authorities at the national-level and EU-level. Any definition of high-risk scenarios for conformity assessment should be as clear as possible and regularly reviewed through an industry-led, transparent process.
We recognize the challenge to achieve consistency with other relevant legislation. To ensure Europe is fit for the digital age the EU must enable continued trust in AI. Trust needs to be based on facts. Facts must be verifiable, and verification must be based on international, globally-recognized, common standards. We believe that this is an effective model for building trust in the digital era. Labelling is potentially problematic, and so what is required is a thorough analysis of the various approaches to this, such as certification, third—party audit, benchmarking and ratings etc. Huawei has commissioned a paper which will be published in Q4 2020 that speaks to the need for an assurance scheme that considers the complexity of the AI market – we are a rich and complex ecosystem that needs to come together to ensure high quality and high trust for customers. We are committed to supporting industry initiatives that, at a global level, achieve the design and promotion of standards.
It is also essential to work with standards organizations to further codify the best practices of AI governance into global standards and specifications. Closer partnership between the public and private sector would effectively collect industry best practices for AI governance and provide minimum acceptable standards for different parts of the supply chain.
Therefore, we recommend these proposals include a healthy diet of industry-led activity with self-regulation that complements any formal regulation on requirements for AI. This is why we also believe that a combination of the four different sets of policy options will better fit in the current context. We need multi-stakeholder initiatives and governance for a healthy and competitive market that can deliver sustainable economic growth and bring real benefits to people and society at large. Together, we can pass the benefits of digital technology to everyone.
Europe needs to lead the world out of the coronavirus pandemic and into its recovery. We believe in the power of innovation. Huawei has been a trusted partner in Europe for 20 years. We are committed to support EU policymakers prepare their proposals in the policy area of AI and deliver a Europe fit for the digital age."
Związek Pracodawców Branży Internetowej IAB Polska (Poland),Związek Pracodawców Branży Internetowej IAB Polska przedkłada w załączeniu wkład do konsultacji Komisji Europejskiej dot. Sztucznej Inteligencji.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550987_en,3,F550987,10 September 2020,Magda Bublewicz,Business association,Związek Pracodawców Branży Internetowej IAB Polska,Small (10 to 49 employees),050841318640-60,Poland,Artificial intelligence – ethical and legal requirements,Związek Pracodawców Branży Internetowej IAB Polska przedkłada w załączeniu wkład do konsultacji Komisji Europejskiej dot. Sztucznej Inteligencji.
SIENNA Project (United Kingdom),"SIENNA, a European Horizon 2020-funded project, is looking into ethical, legal and human rights issues and is developing ethical guidelines for human genomics, human enhancement and AI & robotics. We welcome the language that puts fundamental rights and societal values first. Unlike the European Commission White Paper on AI where the focus was on building consumers’ and businesses’ trust in AI to increase uptake of the technology, the...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550986_en,3,F550986,10 September 2020,Nicole Santiago,Other,SIENNA Project,Small (10 to 49 employees),,United Kingdom,Artificial intelligence – ethical and legal requirements,"SIENNA, a European Horizon 2020-funded project, is looking into ethical, legal and human rights issues and is developing ethical guidelines for human genomics, human enhancement and AI & robotics. We welcome the language that puts fundamental rights and societal values first. Unlike the European Commission White Paper on AI where the focus was on building consumers’ and businesses’ trust in AI to increase uptake of the technology, the Inception Impact Assessment rightly prioritises the protection and safety of individuals and society at large. While we recognize there are many beneficial applications of AI, any deployment must be accompanied by a necessity and proportionality assessment, as well as ensure adequate and sufficient measures are taken to protect the fundamental rights and societal values from potential harms.

We recommend a combination of Option 2 (EU legislative instrument setting up a voluntary labelling scheme) and Option 3 (EU legislative instrument establishing mandatory requirements). A legislative instrument should go beyond high-level principles and obligations. However, the framework cannot be too specific or detailed, as that risks unintentionally narrowing the scope and impact of the framework. Furthermore, the legislative framework must be agile enough to respond to the rapid development of AI and related technologies. As such, an EU legislative instrument should involve both ex-ante and ex-post enforcement mechanisms. 

We believe that Option 3(b) (limiting the scope to high-risk applications) may be sufficient if the determination of ‘high-risk’ is well-constructed. However, given this determination will be a crucial element of the whole framework and will have a significant impact on whether the framework will effectively serve its purpose, extreme caution should be taken to set the criteria in a manner that is robust. Regardless of whether the framework is limited to high-risk applications, specific rules will be necessary for specific categories of AI applications. 

Option 2 (EU legislative instrument setting up a voluntary labelling scheme) can be one complementary way to enhance trust and verify compliance with certain rules. However, it is vital that this must not be understood as a replacement for legal responsibility. Additionally, voluntary certification labels must not become self-serving or a business-manipulated front for hiding risks and harms.

We do not agree that there are no direct significant negative social impacts or environmental impacts expected from the proposed measures. Further assessment of expected impacts associated with the proposed regulatory framework for AI is needed, particularly in regard to social and environmental impacts."
SHERPA Project (United Kingdom),"SHERPA is an EU-funded Horizon 2020 project that focuses on ethical and human rights aspects of smart information systems (artificial intelligence and big data analytics). We welcome language in this Inception Impact Assessment that prioritises protection of human rights and recognises both the benefits and harms of AI. The protection of human rights and safety is a societal priority, and not only a means to create (or the outcome of creating)...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550985_en,4,F550985,10 September 2020,Rowena RODRIGUES,Other,SHERPA Project,Small (10 to 49 employees),,United Kingdom,Artificial intelligence – ethical and legal requirements,"SHERPA is an EU-funded Horizon 2020 project that focuses on ethical and human rights aspects of smart information systems (artificial intelligence and big data analytics). We welcome language in this Inception Impact Assessment that prioritises protection of human rights and recognises both the benefits and harms of AI. The protection of human rights and safety is a societal priority, and not only a means to create (or the outcome of creating) trustworthy AI.

We also strongly agree that existing EU law needs more effective enforcement, that effective redress mechanisms are needed, and that we must be concerned about intended and unintended negative outcomes. 

We believe that it is absolutely critical that the EU develop a mandatory regulatory framework of ex-ante and ex-post enforcement mechanisms to ensure that AI systems are safe and do not violate fundamental rights and ethical principles.  A strong legal standard must be set at the EU-level that establishes a baseline, encourages high standards of protection of fundamental rights and societal values, and minimizes inconsistency and fragmentation at the Member State-level. Therefore, the SHERPA project strongly supports a combination of Option 2 (EU legislative instrument setting up a voluntary labelling scheme) and Option 3 (EU legislative instrument establishing mandatory requirement for all or certain types of AI). Depending on how risk is determined, by whom, and which criteria are used, the SHERPA project might support limited regulation for high-risk only AI (sub-option 3(b)).

The SHERPA project also strongly recommends further assessment of expected impacts. An impact assessment should also evaluate the risks associated with failure to act, and not only the impacts of a potential regulatory framework."
FEDMA (Belgium),FEDMA previously answered the consultation on the white paper on AI. We would like to share the below insights: • The work of the High-Level Expert Group on criteria for risk assessment and the feedback that they are receiving from the industry should be considered. • Self-learning systems are not new nor is information gathering for a better more objective decision process (e.g. bank loan; better information might often help to get the...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550978_en,4,F550978,10 September 2020,Geraldine PROUST,Business association,FEDMA,Micro (1 to 9 employees),39300567160-02,Belgium,Artificial intelligence – ethical and legal requirements,"FEDMA previously answered the consultation on the white paper on AI. We would like to share the below insights: 
• The work of the High-Level Expert Group on criteria for risk assessment and the feedback that they are receiving from the industry should be considered. 
• Self-learning systems are not new nor is information gathering for a better more objective decision process (e.g. bank loan; better information might often help to get the loan). AI is simply an optimization of both. 
• If personal data is involved, Art 22 GDPR covers the data protection issues. 
• It is of the utmost importance that the GDPR be implemented in a fair and balanced manner. Indeed, legitimate interest and pseudonymization are key GDPR tools for companies to use AI (e.g. cleaning a contact list with a Robinson list). When the industry relies on legitimate interest for processing of personal data, the controller must do a legitimate interest assessment test in 3 steps: (a) is the purpose of the processing legitimate? (b) is the processing necessary? (c) do the interests of the controller override the rights and freedoms of the individual? Currently, legitimate interest is a legal basis which is under growing pressure and the EDPB has started the discussions on guidelines for LI. If the right balance is not met between consent and LI, then many industry sectors, such as data marketing, will disappear or will not be able to use AI, leaving behind a less competitive market dominant by large tech intermediaries.
• FEDMA previously referred to the EUTA High Level Principles on AI. In line with those principles, we have strong reservations about extending legal requirements to all AI applications. As the majority of AI day-to-day applications today are low risk, we urge the EU institutions to conduct a thorough assessment of the existing legislation, especially the civil liability regime, before introducing any new proposals specifically targeting AI-driven technologies and applications. Regarding the possibility of new risk assessment being imposed upon businesses to define whether they are using low or high risk AI applications, we encourage the European Commission to provide a framework for internal risks assessments for low-risk applications, and thoroughly assess who would be responsible for leading external risk assessments for high-risks applications. Indeed, it is likely that external auditors or agencies will need to gain access to sensitive personal data under GDPR to assess the fairness or degree of risk carried out by one AI system Checking the fairness or risks level in any algorithm will necessarily require the use of particularly sensitive data under GDPR, such as those related to sex, ethnicity, age, religion, etc. Soft law and voluntary labelling should be preferred to new regulations where feasible, as they create only marginal administrative burden where binding requirements could create further red tape for EU businesses. At the same time, providing a harmonised EU framework would reduce compliance costs for businesses operating across the EU and avoid a plethora of conflicting AI rules. We need to ensure that the future EU framework is sufficiently flexible so that it is not outdated in a short span of time. We disagree with the Commission’s assessment that the social impact of the future AI framework will be limited, AI will have an extensive positive social impact."
Pharmaceutical Group of the European Union (PGEU) (Belgium),"The Pharmaceutical Group of the European Union (PGEU), the organization representing community pharmacists in 32 European countries, welcomes the European Commission’s Roadmap aimed at addressing a number of ethical and legal issues raised by Artificial Intelligence (AI). We support the Commission’s general objective to ensure the development and uptake of lawful and trustworthy AI across the Single Market through the creation of an ecosystem...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550977_en,4,F550977,10 September 2020,Antonio Grasso,Non-governmental organisation (NGO),Pharmaceutical Group of the European Union (PGEU),Micro (1 to 9 employees),00086317186-42,Belgium,Artificial intelligence – ethical and legal requirements,"The Pharmaceutical Group of the European Union (PGEU), the organization representing community pharmacists in 32 European countries, welcomes the European Commission’s Roadmap aimed at addressing a number of ethical and legal issues raised by Artificial Intelligence (AI). 
We support the Commission’s general objective to ensure the development and uptake of lawful and trustworthy AI across the Single Market through the creation of an ecosystem of  trust. 

As AI applications develop fast, that AI will have a major impact on society and on a wide array of sectors of the economy is no longer a question. 

In the healthcare sector, PGEU acknowledges the value of innovative technologies such AI and Big Data analytics and considers these technologies to be a useful tool to support health professionals and EU health systems. In routine pharmacy practice at national level, we recommend that these tools shall always be accompanied by the supervision of pharmacists’ expert and professional advice, to use them to improve workflow efficiency, while promoting patient safety, therapy effectiveness and offering the highest standard of pharmacy services and pharmaceutical care to patients.

While we see great value in using AI in healthcare for enabling meaningful innovation, supporting health professionals and enhancing patient care, we are aware that it may also entail significant risks, for example in relation to the use of health and patient data. 
In order to fully harness the benefits of AI in healthcare, a key requirement is to develop trust by all stakeholders involved through guaranteeing a high level of data protection. Patient data must be processed under a high level of data protection standards within trustworthy infrastructures that enable the access to secure data services. It also has to be ensured that data access and analysis are amenable to European rules for privacy and data protection. 

Therefore, we consider an EU legislative initiative on AI, as envisaged under most policy options proposed by the Commission in the Roadmap, to be an adequate way forward to address the risks linked to the development and use of certain AI applications. 

We welcome in particular an EU legislative initiative following a risk-based approach as already defined in the White Paper on AI published in February 2020. Taking this into account, we support Commission’s ‘’Option 3’’ proposal in the Roadmap, with a preference for the second sub-option, recommending a EU legislative instrument which could be limited to ‘’high-risk’’ AI applications , including those which are likely to be deployed in the healthcare sector. We would as well support the proposed ‘’Option 4’’, which envisages to implement the sub-option above while taking into account the different level of risks that could be generated by a particular AI application. 

In view of the next steps in addressing ethical and legal issues related to AI, we urge the European Commission to involve community pharmacists, as experienced users of digital health tools, in the formulation of such policies as well as in the development of guidelines and methods on the deployment of AI in healthcare. To provide a full overview of our position on AI, please find attached to this feedback the PGEU Position Paper on Big Data & AI in Healthcare."
Verband der TÜV (VdTÜV) (Germany),"The Association of German Technical Inspection Agencies (Verband der TÜV e.V.) welcomes the Commissions Inception Impact Assessment and would like to provide feedback on the core issues raised. Artificial Intelligence (AI) is a fast evolving technology that can create significant economic and social benefits, but equally entails significant risks to the safety, health and privacy of users. A strong European legal framework is indispensable in...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550976_en,4,F550976,10 September 2020,Elisa Brummel,Business association,Verband der TÜV (VdTÜV),Small (10 to 49 employees),45013506457-28,Germany,Artificial intelligence – ethical and legal requirements,"The Association of German Technical Inspection Agencies (Verband der TÜV e.V.) welcomes the Commissions Inception Impact Assessment and would like to provide feedback on the core issues raised. 
Artificial Intelligence (AI) is a fast evolving technology that can create significant economic and social benefits, but equally entails significant risks to the safety, health and privacy of users. A strong European legal framework is indispensable in order to achieve an ecosystem of trust and to avoid a fragmentation of national rules and initiatives. 
The TÜV-Association strongly supports an EU legislative instrument stipulating mandatory legal requirements for all AI applications (Option 3c). Essential safety and security requirements should be established for all AI applications, regardless of their risk level or intended use. 
Moreover, what is needed is a risk-based approach when it comes to the level (and perhaps type) of mandatory requirements. The higher the risk potential of AI systems, the more stringent the mandatory requirements ought to be. The development of a high-risk category, as proposed in the White Paper on AI, is a valuable basis, but should be complemented by additional risk categories. A mere binary distinction between high-risk and ‘other’ applications does in our opinion not sufficiently reflect the diversity of AI applications.
Equally important to the level of requirements is the way how these requirements are enforced in practice. The TÜV-Association believes that an ex-ante conformity assessment is the best way to ensure that AI systems comply with all relevant legal provisions before they are placed onto the market. AI applications with a substantial risk level should be legally required to undergo certification by independent conformity assessment bodies. A substantial risk level is given when there is a risk to the health and physical integrity of the user or third parties, their privacy, as well as the confidentiality, integrity and availability of their data. For AI applications with a low risk level, the manufacturer/operator should have the choice to demonstrate compliance either through an independent conformity assessment body or through the self-declaration of conformity. 
In addition, it is important to further develop and refine conformity assessment procedures, in particular vis-à-vis specific aspects of AI, and to link them to existing procedures.  
For more information, please consult the attached position paper. 
About us: The TÜV-Association represents the policy and technical interests of its members, the TÜV organisations, who provide conformity assessment and technical services in almost all sectors of industry and commerce. TÜV stands for neutral and independent conformity assessment, such as testing (e.g. of household appliances, food or medical devices), inspection (e.g. of steam boilers, power plants or lifts), certification (e.g. of management systems or consumer products) and validation/verification (e.g. of greenhouse gas emission projects and reports)."
DIGITALEUROPE (Belgium),"DIGITALEUROPE thanks the Commission for this opportunity to provide feedback on the AI Inception Impact Assessment. In our attached contribution, we analyse the various Options proposed by the Commission and give our comments and recommendations.",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550975_en,4,F550975,10 September 2020,Jochen MISTIAEN,Business association,DIGITALEUROPE,Small (10 to 49 employees),64270747023-20,Belgium,Artificial intelligence – ethical and legal requirements,"DIGITALEUROPE thanks the Commission for this opportunity to provide feedback on the AI Inception Impact Assessment. In our attached contribution, we analyse the various Options proposed by the Commission and give our comments and recommendations."
Ibec (Ireland),Many thanks for the opportunity to comment. Please attached document.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550974_en,4,F550974,10 September 2020,Erik O DONOVAN,Business association,Ibec,Medium (50 to 249 employees),479468313744-50,Ireland,Artificial intelligence – ethical and legal requirements,Many thanks for the opportunity to comment. Please attached document.
Augmented Law Institute - EDHEC Business School (France),"This is a common statement of the Augmented Law Institute of EDHEC Business School (for the list of Professors composing this group, please click on the link: https://www.edhec.edu/en/legaledhec-research-centre#dexp_tab_item_2063327793). An extended version is attached. In this summary here we report just our main conclusions. Our feedback is based on 3 parts: 1) a definitional part, which aims to reply to the question “what to regulate?”;...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550973_en,4,F550973,10 September 2020,Gianclaudio Malgieri,Academic/research Institution,Augmented Law Institute - EDHEC Business School,Small (10 to 49 employees),,France,Artificial intelligence – ethical and legal requirements,"This is a common statement of the Augmented Law Institute of EDHEC Business School (for the list of Professors composing this group, please click on the link: https://www.edhec.edu/en/legaledhec-research-centre#dexp_tab_item_2063327793).

An extended version is attached. In this summary here we report just our main conclusions.

Our feedback is based on 3 parts: 1) a definitional part, which aims to reply to the question “what to regulate?”; 2) a methodological part, which aims to reply to the question “why regulate?” [Please see the attachment] ; and 3) a content-based part, which aims to reply to the question “how to regulate?”.

A first problem that we observe in the Impact Assessment and in the related White Paper is the lack of clear definitions. In particular, two terms urge to be clearly defined before to proceed:
1. artificial intelligence;
2. risk (to fundamental rights and freedoms, including human health and safety).

""AI"" was defined both in the EC Communication (2018)237 and then re-defined by the HLEG-AI in April 2019. Both the White paper and the Inception Impact Assessment are not clear about which definition of AI should be preferred. However, the implications can be relevant. In particular, since the definition of the Commission’s Communication does not define what “intelligent behaviour” is, there might be problems in understanding the scope of AI notion and whether some technological systems (e.g., Covid-19 Alert Exposure Apps, automatic entrance systems, etc.) are within or outside the scope of “intelligent behaviour”. Accordingly, we propose to prefer the HLEG definition, accompanied by an Annex with a non-exhaustive list of relevant examples of AI systems actually used.

The notion of risk is also very problematic. Section B of the Inception Impact Assessment is largely based on the notion of risk (e.g., options 3 and 4 of the “Alternative options to the baseline scenarios”). However, it is not clear what we should mean by “risk” and how the risk should be assessed for each AI system. We propose to clearly define what “risk” means and which level of severity and likelihood might amount to qualifying as “high risk”. In addition, we propose to use the White Paper’s definition of the severity threshold on “legal or similarly significant effects” to the rights and freedom of the subjects, possibly clarifying examples in an Annex where for each fundamental right or freedom mentioned in the EU Charter of Fundamental Rights there are some examples of legal or similarly significant effects. When analysing risks to fundamental rights and freedoms, particular attention should be dedicated to human health and safety.

In the EU law there are already several different pieces of legislation covering many different areas that are generally very relevant for AI systems (data protection law, anti-discrimination law, consumer protection & product liability law, administrative law): in the attached document we propose possible gaps in these fields that a Regulation on AI could cover and we suggest to consider also risks generated in public institutions.

The impact assessment shows 4 alternative options to regulate AI. Although each approach may have advantages and disadvantages, we consider that the voluntary labelling scheme is inefficient and ineffective for the declared purposes of a regulation on AI. Many other EU legal sectors recognise voluntary labelling scheme but only as an ancillary tool, related to other kinds of regulation. Depending on the definition of high-risk, the approach 3.b might be considered, but only with a clear blacklist of high-risk examples and with easy criteria to identify risks and to correlate each risk to a fundamental right or freedom as recognised by the EU Charter of Fundamental Rights and Freedoms. In addition, any sectoral amendment of existing laws should be advisable (including soft law actions, as amending the unfair commercial practice blacklist, etc.)."
BSA | The Software Alliance (Belgium),"BSA would like to underline the need for the Commission to carry out an in-depth inventory of EU law, and its application to AI, before suggesting possible legislative actions. Consistent with the risk-based, context-specific approach of the White Paper, any proposed legislation should avoid one-size-fits-all mandates. Future proposals should focus on high-risk scenarios where the deployment of AI poses a threat to fundamental rights. The...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550966_en,4,F550966,10 September 2020,Matteo Quattrocchi,Business association,BSA | The Software Alliance,Medium (50 to 249 employees),75039383277-48,Belgium,Artificial intelligence – ethical and legal requirements,"BSA would like to underline the need for the Commission to carry out an in-depth inventory of EU law, and its application to AI, before suggesting possible legislative actions. Consistent with the risk-based, context-specific approach of the White Paper, any proposed legislation should avoid one-size-fits-all mandates. 
Future proposals should focus on high-risk scenarios where the deployment of AI poses a threat to fundamental rights. The scope of any regulatory obligations should be a function of the degree of risk and the potential scope and severity of harm. 
BSA supports an incremental approach by limiting regulation to AI that is deployed in a high risk sector and used in a manner that significant risks are likely to arise. The Commission should extend this two-pronged approach to all possible high-risk scenarios, rather than identifying specific sectors where AI would be considered high-risk by default. Ensuring that the definition of high-risk is appropriately tailored will be critical, it is also crucial to provide a well-determined scope of application. 
Legal requirements for high-risk AI applications should be addressed to the actors best placed to address potential risks. In many cases developers may not know whether the technology is being deployed by an end-user in a manner that meets the definition of high-risk. Developers are better placed to describe the capabilities and limitations of an AI system, while disclosing the possible impact of AI use will typically be the responsibility of the deployer. 
The Commission should draw from existing concepts for establishing which entity is best placed to address potential risk, i.e. the entity that determines the purpose of the AI, similar to the concept of a controller under GDPR. In the context of AI, the AI controller will generally be the deployer. The processor/controller distinction provides organizations with a clear picture of their respective legal obligations, and helps ensure that data subjects rights are adequately protected.
Ensuring that the definitions of the entities involved are the same in different sectors, founded in established practices, would entail a more harmonized approach to AI. 
The Commission should not establish pre-marketing conformity assessment for AI systems, as such obligations are liable to turn into barriers to enter the market, a more scalable approach would be self-attestation.
BSA urges the Commission not to pursue a regulatory scheme based on prescriptive conformity assessment requirements. The risks that AI poses and the appropriate mitigation mechanisms are context-specific. The appropriate mechanisms and standards for training data, record keeping, transparency, accuracy, and human oversight vary depending on the nature and deployment of an AI system. The Commission should therefore avoid creating prescriptive, one-size-fits-all requirements around these categories. 
The Commission should articulate an impact assessment framework on high-risk AI for stakeholders, possibly on the basis of the HLEG ALTAI.
The Commission should consider specific rules for the use of remote biometric identification systems, by the public sector in particular, given the heightened risks inherent in governmental use of this technology.
BSA urges the Commission not to pursue the creation of a blanket voluntary labeling system for all no-high risk systems. Given the diverse range of AI products and services that will not be considered high risk, a one-size-fits-all labeling scheme would be unworkable. The benchmarks for evaluating whether AI systems are trustworthy are likely to be highly variable, driven in large part by system functionality and deployment context. A labelling system that could apply to all no-high risk AI would necessarily be very complex, and would limit customers understanding and engagement. Similarly, the governance of such a scheme would be exceedingly complex and would have to cover very diverse sectors and technologies."
WKO Austria (Austria),"WKO Austria welcomes the opportunity to provide input to the Commission’s Inception Impact Assessment for the upcoming legislative framework on AI. We strongly believe, that it is very important to secure a future-proof framework that will support an innovative and competitive European market, and also too much complexity and over-regulation should be avoided. General remarks: - The term ""AI"" must be clearly and unambiguously defined at...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550965_en,4,F550965,10 September 2020,wolfgang lindner,Business association,WKO Austria,Large (250 or more),10405322962-08,Austria,Artificial intelligence – ethical and legal requirements,"WKO Austria welcomes the opportunity to provide input to the Commission’s Inception Impact Assessment for the upcoming legislative framework on AI. We strongly believe, that it is very important to secure a future-proof framework that will support an innovative and competitive European market, and also too much complexity and over-regulation should be avoided.

General remarks:

- The term ""AI"" must be clearly and unambiguously defined at international level; this is a basic requirement for the design of the legal framework.
- The impacts of future jobs must be taken into account. It will be necessary to have more qualified (technical) ressources and new job profiles.

Options for regulation:

The aim should in any case to avoid complex administrative documentation obligations and legally uncertain considerations of fundamental rights.

WKO perspective has a preference for options 1 and 2 (soft law and voluntary labeling scheme)
Real laboratories could be an option for better regulation. Trial and development phases can help develop the right system of government.

If options 1 and 2 are probably not sufficient to provide an appropriate legal framework for this new technological challenge, it should go rather with option 3.a.
There should only be regulations where there are major risks in the area of application. In all other areas, no further regulation is required, only voluntary exchange and cooperation.
- Option 3b: From a purely technical point of view, it makes little sense to regulate according to the criteria presented in the White Paper (primarily according to economic sector). Any upcoming AI framework should be application-based and not technology-based
- Option 3.c would lead to possible over-regulation"
Anonymous,Liberty Global response to the roadmap (IIA) on Artificial intelligence – ethical and legal requirements (Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence) Liberty Global welcomes the opportunity to comment on the Commission’s roadmap on IIA of a possible initiative aimed at addressing a number of ethical and legal issues raised by AI. Liberty Global supports the...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550964_en,4,F550964,10 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,"Liberty Global response to the roadmap (IIA) on Artificial intelligence – ethical and legal requirements (Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence)

Liberty Global welcomes the opportunity to comment on the Commission’s roadmap on IIA of a possible initiative aimed at addressing a number of ethical and legal issues raised by AI. Liberty Global supports the Commission’s ultimate objective of ‘fostering the development and uptake of safe and lawful AI that respects fundamental rights across the Single Market by both private and public actors while ensuring inclusive societal outcomes’. In our response to the Commission’s AI White Paper (attached), we gave our support to the Commission’s twin objective of promoting the uptake of AI and of addressing the risks associated with certain uses of this new technology, noting that striking the right balance between the two is key to achieving an optimal outcome. We maintain that position in light of the updated, more precisely-defined objective. 

That objective, in Liberty Global’s opinion, can only be achieved in a balanced way through an EU legislative instrument establishing mandatory requirements for certain types of AI (policy option 3). Liberty Global considers a legislative instrument  appropriate specifically for and limited to ‘high-risk’ AI applications which can be identified on the basis of the two criteria set out in the aforementioned White Paper. In Liberty Global’s view, this approach also covers ‘specific categories’ of AI, such as biometric identification systems (first sub-option), for which extra safeguards are warranted. In order to promote innovation and investment, it is important that a potential legislative instrument create an adequate, high-level framework for the assessment of compliance. The detailed requirements for compliance themselves are then best laid down in Harmonized Standards. Such an approach will not prejudice the adoption of voluntary and industry-led interventions for non-‘high-risk’ applications, which would benefit from the work done by European standardisation organisations in the context of setting detailed requirements for those ‘high-risk’ applications. 

In light of the above, Liberty Global strongly supports the adoption of any potential legislative act on the basis of Article 114 TFEU, as is suggested by the on p. 3 of the IIA. The EU has a long and successful history of balanced legislation on this basis and its predecessors under the Treaties. Legislation, which through harmonisation furthers the (Digital) Single Market, creates the stable regulatory environment that is a prerequisite for innovation and investment – promoting consumer welfare – and at the same time pursues society’s wider interests. The harmonised application of strong and smart internal market regulation, using tools such as Harmonised Standards, gives the EU a global reach to promote values-based innovation in the forthcoming update of AI.

We recommend the Commission to seize this opportunity for the EU to become a leader in the development and uptake of lawful and trustworthy AI. This is only possible if regulatory fragmentation, through the adoption of diverging national approaches is prevented by a strong European approach. 

In our view, the prerequisites for the success of such a strong European approach are that it is technologically neutral, risk-based and laid down by a high-level framework which delegates the setting of detailed requirements for ‘high-risk’ AI applications to the European standards development organisations. This will, in turn, promote the adoption of and adherence to such standards, on a voluntary basis, for AI applications with a more limited risk profile. Through such an approach, European consumers and citizens will ultimately benefit from the swift uptake of values-based AI. For more detail, we refer to our supplementary position paper (attached)."
Technology Industries of Finland (Finland),"Technology Industries of Finland (TIF) represents more than 1,600 companies, active in Finland in various sectors of technology industries. Our member companies cover both developers and deployers of AI. Our main messages are: • There is no one, overarching AI. AI is a set of technologies for processing and extracting value out of data, automating decisions and extracting insights. • According to latest studies, solutions and tools of data...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550962_en,5,F550962,10 September 2020,Jussi Mäkinen,Business association,Technology Industries of Finland,Medium (50 to 249 employees),39705603497-38,Finland,Artificial intelligence – ethical and legal requirements,"Technology Industries of Finland (TIF) represents more than 1,600 companies, active in Finland in various sectors of technology industries. Our member companies cover both developers and deployers of AI. 

Our main messages are: 

• There is no one, overarching AI. AI is a set of technologies for processing and extracting value out of data, automating decisions and extracting insights.
• According to latest studies, solutions and tools of data economy, such as AI will play a major role in the green transformation of the industries. 
• Existing Product Safety legislation is technology-neutral and has stood the test of time. We urge Commission to carefully analyse whether use of AI would call for a piece of technology-specific piece of regulation?
• Instead of technology, the attention should be on data and the purpose of its processing. These define the riskiness of the use case. 
• On assessment of regulatory options, it is wise to apply legislation only when it is needed. However, singling out high-risk cases may prove problematic in terms of predictability and legal certainty. 
• Green transformation and ramping up productivity of European industries are our major challenges. Technology plays a major role when solutions are developed. To achieve this, we need steady and predictable environment for investments.
• Europe needs to remain a predictable member in global value networks and not use regulation for short-sighted leaps. Excellence is best built by building on strengths and agile solutions for European data economy. 

Please see the attachment for detailed comments."
FUJITSU (Belgium),"Fujitsu is one of the leading global ICT companies and the largest in Japan. Europe is at the heart of our global business. 1 Protecting fundamental rights We support the concept of trustworthy AI, based on European values and protecting Fundamental Rights. Fujitsu aims to incorporate ethics in the AI system lifecycle for all ‘high-risk’ AI solutions, consistent with guidance from the EU. We recommend the European Institutions to create...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550961_en,5,F550961,10 September 2020,Marco CANTON,Company/business,FUJITSU,Large (250 or more),441732425040-02,Belgium,Artificial intelligence – ethical and legal requirements,"Fujitsu is one of the leading global ICT companies and the largest in Japan.  Europe is at the heart of our global business.  

1 Protecting fundamental rights

We support the concept of trustworthy AI, based on European values and protecting Fundamental Rights. Fujitsu aims to incorporate ethics in the AI system lifecycle for all ‘high-risk’ AI solutions, consistent with guidance from the EU.
We recommend the European Institutions to create ""An Ecosystem of Trust"" where AI and Ethics can have a key guiding role in the development of new solutions (as set out in the Fujitsu Group AI Commitment ).  
Fujitsu is working on a design-oriented approach, based on our Human-Centric policy. We recognize the importance of ensuring transparency. 

2 Safety

Today, discussions on the safety and risks of AI-powered products have just begun on a sector-by-sector basis, and it is premature to expect then to converge. Today’s discussion is not about the safety requirements that apply to all AIs, but about which cases and sectors AI solutions should be implemented, in particular starting with high-priority areas. 
We would like to emphasize that the scope of the PL Directive should not be expanded to impose liability on AI-based technologies beyond those incorporated into the hardware. Such a change of scope could leave  AI system developers with  the responsibility for problems that they cannot have any control over, and could discourage industries from developing and using AI systems. 

3 Remote biometrics identification

Definition and correct understanding of ‘remote biometric identification’ needs clarification among stakeholders.  
The challenges with remote biometric identification technology, should be discussed separately to the question of its regulation, and without distinguishing between the three perspectives of remote biometrics identification (racial discrimination, abuse and privacy), which might be detrimental to the European market and industry. 
Personal data which biometrics use is already covered in the GDPR, and no new AI-specific regulation is needed. On the other hand, we recognize there is legal uncertainty amongst local regulations defining the use of biometric identification for country safety and security purposes. We strongly believe harmonization would be beneficial. 
We believe it is necessary to create a market environment in which companies that invest in protecting ethics, safety, and privacy do not have a price disadvantage in the market.
 
4 Fujitsu’s opinions on EC’s alternative options to the baseline scenario

Fujitsu would like to stress the importance of balancing innovation and regulation. 
We called it an “AI legislative comfort zone” to overcome the lack of clarity about what is possible and what is not with AI solutions. We support the Commission's proposal to prioritize high-risk AI applications following a risk-based approach based on the existing legislation and standards in sectors. 

In this sense “Option 4”, a combination of soft law, voluntary labelling schemes and EU legislation, establishing mandatory requirements for certain types of AI applications, could be the way forward to tackle the AI related challenges flexibly. 

Labels and standards for AI that are discussed at European level, should be constantly reviewed in cooperation with the international standards bodies, governments and other organizations representing industries, consumers and civil society.

5 Conclusion

Fujitsu strongly encourages the European Commission to pursue an effective AI approach and strategy for the European market, which is able to play a leading role at a global level in strong cooperation and alignment with the Japanese Government. 

We remain convinced that a step-by-step approach, based on the definition of concrete cases and risks, is the baseline. 
A combination of different regulatory tools should be the way forward in order to ensure sufficient flexibility and, at the same time, provide clear rules."
MedTech Europe (Belgium),"Artificial Intelligence (AI) in medical technologies has the potential to deliver on the promise of better healthcare in Europe. To optimise the value of AI in the healthcare sector, policies need to remain flexible and follow the evolution of technological development, allowing space for technology to thrive. Therefore, we at MedTech Europe, the European trade association for the medical technology industry including diagnostics, medical...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550949_en,5,F550949,10 September 2020,Michael STRÜBIN,Business association,MedTech Europe,Small (10 to 49 employees),433743725252-26,Belgium,Artificial intelligence – ethical and legal requirements,"Artificial Intelligence (AI) in medical technologies has the potential to deliver on the promise of better healthcare in Europe. To optimise the value of AI in the healthcare sector, policies need to remain flexible and follow the evolution of technological development, allowing space for technology to thrive. 

Therefore, we at MedTech Europe, the European trade association for the medical technology industry including diagnostics, medical devices and digital health, are keen to bring today our healthcare expertise and perspective to the AI policy conversation via our attached response to the public consultation on an EU legal act for Artificial Intelligence.

We greatly welcome the aim of the European Commission (EC) to address a number of legal and ethical issues, raised by AI, to foster the development and uptake of AI, and to avoid legal fragmentation across Member States. We agree that European citizens need to have confidence that their medical technologies, with or without an AI component, provide a high level of safety and quality for patients. In the medtech sector, the safety and effectiveness of medical device software, including ""AI with an intended medical purpose"", is already addressed through existing, recently reinforced, regulations, i.e. the Medical Device Regulation (EU) 2017/745 (“MDR”) and the In vitro diagnostics Regulation (EU) 2017/746 (“IVDR”).

It is for this reason, that MedTech Europe supports the idea that, while assessing the need for new legislation specific to AI, the application of existing regulations on AI should be taken into account to understand whether any gaps exist, to avoid overlap and conflicting regulations that could cause issues when AI is introduced.

Read our full response attached."
CEMA (Belgium),"CEMA considers the initiative from the European Commission to deal with ethical and legal requirements on AI must be coordinated to take into account: - Initiatives already initiated, for example the revision of the Machinery Directive to take into account new technologies - Initiatives initiated at international level to ensure consistency for our manufacturers CEMA is in favour of Option 1, as it offers the possibility to establish an...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550948_en,5,F550948,10 September 2020,Christophe TISSIER,Trade union,CEMA,Micro (1 to 9 employees),489575310490-58,Belgium,Artificial intelligence – ethical and legal requirements,"CEMA considers the initiative from the European Commission to deal with ethical and legal requirements on AI must be coordinated to take into account:
- Initiatives already initiated, for example the revision of the Machinery Directive to take into account new technologies
- Initiatives initiated at international level to ensure consistency for our manufacturers

CEMA is in favour of Option 1, as it offers the possibility to establish an overall harmonized European framework that takes into account the Human Fundamental Rights and ethical aspects without interfering with specific product regulations that defines e.g. Functional Safety requirements.

For our sector, the Machinery Directive 2006/42/EC already covers safety for those machines using AI-enhancements and/or Machine learning capabilities, since it has technology neutrality as one of its core principles."
Anonymous,We welcome the opportunity to provide feedback to this Roadmap. The creation of a policy framework that encourages the use of lawful and trustworthy AI in Europe is an important initiative by the European Commission. The uptake of this technology is accelerating fast so clear guidelines and rules are needed. We agree with the Commission’s recommendation to adopt as a general principle a ‘risk-based approach’. As stated by the Commission ‘As...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550947_en,5,F550947,10 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,"We welcome the opportunity to provide feedback to this Roadmap. The creation of a policy framework that encourages the use of lawful and trustworthy AI in Europe is an important initiative by the European Commission. The uptake of this technology is accelerating fast so clear guidelines and rules are needed. 

We agree with the Commission’s recommendation to adopt as a general principle a ‘risk-based approach’. As stated by the Commission ‘As a matter of principle, the new regulatory framework for AI should be effective to achieve its objectives while not being excessively prescriptive so that it could create a disproportionate burden, especially for SMEs. To strike this balance, the Commission is of the view that it should follow a risk-based approach’ (White paper on Artificial Intelligence, page 17).

A risk-based approach would ensure that companies that develop and deploy low risk AI applications could continue to innovate and invest in this technology without being burdened with unnecessary rules. At the same time, this approach would also ensure that AI applications which may endanger people’s lives or negatively impact fundamental rights would be regulated.

For these reasons, in our opinion the policy option that the Commission should adopt is a combination of options 1, 2 and 3b. EU ‘soft law’ (option 1) and voluntary labelling scheme (option 2) are the most appropriate instruments for low-risk AI applications. Voluntary labelling schemes could be particularly helpful: they would allow companies to demonstrate and promote the uptake of best practices in ethical applications of AI. As rightly suggested by the Commission, these schemes but also other initiatives and standards could be built upon the existing set of Ethics guidelines for trustworthy AI. 

However, an EU legislative instrument seems necessary for high-risk AI applications (3b). The scope of this instrument should be clearly limited to high-risk AI applications.  The criteria to identify and asses the level of risk could be the sector of application and the specific use/impact on rights or safety.

We remain at the Commission’s disposal for any comments or questions."
Mastercard (Belgium),Mastercard welcomes the opportunity to provide feedback to the European Commission’s Inception Impact Assessment (“IIA”) on an EU legislative initiative for AI. Mastercard wishes to express its support for Policy Option 4 as outlined in the IIA. We believe the Objectives highlighted by the IIA can be achieved in an appropriate and sufficient manner through a combination of Policy Options 1 (EU soft law (non-legislative) approach to facilitate...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550945_en,5,F550945,10 September 2020,Jasmien CESAR,Company/business,Mastercard,Large (250 or more),58204758673-16,Belgium,Artificial intelligence – ethical and legal requirements,"Mastercard welcomes the opportunity to provide feedback to the European Commission’s Inception Impact Assessment (“IIA”) on an EU legislative initiative for AI.

Mastercard wishes to express its support for Policy Option 4 as outlined in the IIA. We believe the Objectives highlighted by the IIA can be achieved in an appropriate and sufficient manner through a combination of Policy Options 1 (EU soft law (non-legislative) approach to facilitate industry-led intervention), 2 (EU legislative instrument setting up a voluntary labelling scheme) and 3b (EU legislative instrument establishing mandatory requirements for “high-risk” AI applications).

As outlined in our response to the Commission’s Public Consultation on the AI White Paper, we believe that regulatory guidance and/or codes of conduct (for instance on AI auditability) in combination with a voluntary labelling system at EU level allowing AI actors to demonstrate their compliance with an AI normative framework for no-high risk AI applications may serve to establish consumer trust in the use of AI technologies in the EU.

Whereas we support the idea in principle that the introduction of new compulsory requirements should be limited to high-risk applications, this is conditional on key aspects that are not yet clearly delineated, such as the test to determine if an application is “high-risk”, how and when an application will be assessed, and a clear definition of AI. We believe that the high-risk criteria outlined in the White Paper do not allow for the necessary flexibility for market actors and society to benefit from AI without producing onerous requirements. The qualification of certain specific sectors as high-risk does not consider the fact that sectors are constantly evolving and that AI applications may be used across sectors. The qualification of certain uses as “high-risk as such”, e.g. the use of AI for recruitment, is too rigid and ignores the potential benefits the AI application may bring as well as any available measures to mitigate risk.

In relation to an enforcement mechanism to ensure effective compliance with any applicable requirements related to fundamental rights, we believe an appropriate enforcement approach combines an ex-ante self-assessment and an ex-post compliance assessment similar to what is established in GDPR. A self-risk assessment process should be based on the structure and content of a Data Protection Impact Assessment under GDPR (as the use of AI often requires a DPIA) but could include additional AI-specific sections related to bias, explainability and auditability. If a self-risk assessment indicates an AI application is likely to create high risk to fundamental rights, in light of severity and likelihood of potential harm, an organization should take steps to reduce the risk, for instance by implementing technical & organizational controls. If after the remediation steps have been taken, the high risk remains, companies should consult with the relevant competent authorities prior to deploying the AI application. This is similar to the consultation process in Article 36 GDPR.

In relation to an enforcement mechanism for risks to safety, we believe that existing conformity assessment procedures in sectors where established structures already exist (automotive, healthcare, etc.) should be leveraged to address high safety risks engendered by AI applications in these sectors.

Finally, any effective legislative initiative on AI requires a clear definition of the technology. In this respect, it should be considered that certain AI-like applications, e.g. regression analysis, have been around for years without engendering risks that cannot be addressed by the existing regulatory framework. For the purpose of delineating the scope of this legislative initiative, the definition should cover applications entailing additional risks that cannot be addressed by existing legislation, such as unsupervised machine learning."
Bitkom (Germany),Bitkom welcomes the open consultation approach of the AI Inception Impact Assessment of Assessment of the European Commission for a proposal for a legal act of the European Parliament and the European Council regarding the „requirements for Artificial Intelligence“ (Future regulatory framework for AI in the European Union). The main basis for discussion on the future regulatory framework for AI is the White Paper on AI which Bitkom commented...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550944_en,5,F550944,10 September 2020,Benjamin LEDWON,Business association,Bitkom,Medium (50 to 249 employees),535 183 0264 - 31,Germany,Artificial intelligence – ethical and legal requirements,"Bitkom welcomes the open consultation approach of the AI Inception Impact Assessment of Assessment of the European Commission for a proposal for a legal act of the European Parliament and the European Council regarding the „requirements for Artificial Intelligence“ (Future regulatory framework for AI in the European Union). The main basis for discussion on the future regulatory framework for AI is the White Paper on AI which Bitkom commented in detail. 

At the outset, we would like to stress that we welcome the objectives of the European Commission in general: Support the EU in becoming leader in AI (chapter 4: ecosystem of excellence) complemented by introducing new safeguards for citizens (chapter 5: ecosystem of trust). In principle, we do not see the need for a specific AI-regulation throughout Europe. Before such regulation is introduced, it should be examined in detail from a legal point of view where there are blank spots on the EU regulation map and where significant restrictions of the digital single market are imposed by regulations in member states. This applies in particular to potential regulation that is explicitly introduced as a consequence of the increased use and dissemination of artificial intelligence in the economy and society. In our view, it has not yet been proven that the considerations made in the paper give rise to a general need for additional and especially horizontal regulation of AI. Furthermore the regulatory framework must be designed as technology neutral as possible.

Conclusion

We would like to underline again as Bitkom that we reject all proposals that would mandate specific requirements on all AI applications (i.e. Option 3c). This would simply not be proportionate or effective towards the Commission’s intended goal. 

We favour a combination of policy options 1 and 3b: The basis should be a “soft law”-approach. This will leave enough room for innovation and the development of AI-solutions , but also allow a precise assessment of the real risks of certain AI applications and potential regulatory gaps. 

If the mapping of existing regulatory frameworks in the sectors considered to be high-risk in the White Paper lead to the detection of blanks spots we recommend a further development of these existing regulatory frameworks and also of the enforcement regimes in these sectors. Therefore we support the introduction of a high-risk scheme as described in the whitepaper in this case in the respective sectors (evolutionary development from scenario 3a scenario 3b regarding the impact assessment scenarios). Regula-tory sandboxes as a lean and agile approach complement this framework and create a framework in which the promotion of innovation is in the foreground.

At least as important as the choice of scenario are the following questions. We have explained this in detail in our statement on the White paper:
Consideration and systematic mapping of existing sectoral regulatory frame-works and existing control, audit and enforcement authorities in the potential high-risk areas. All activities regarding future regulatory frameworks and enforcement authorities must be linked to the existing frameworks. 

There is no agreed mechanism for classifying AI applications as such. If a future regulatory framework plans to regulate AI, the concepts of AI and algorithmic systems must be defined in a way which makes them easy to handle for the eco-nomic operators involved to determine, if a specific data-driven application meets the criteria AI/algorithmic system.Furthermore clear and legally compliant processes that define which applications are high-risk AI applications are needed. 

Clarification of the question and provision of criteria where conformity as-sessements (ex-ante or ex-post) are needed and where self-assessements and self-regulation, for example through Code of Conducts, are sufficient. 

(Please find additional remarks in the attached paper)"
EURALARM (Belgium),"Euralarm welcomes the inception impact assessment on Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence. Euralarm shares the view that artificial intelligence (AI) can drive economic growth and improve the security and safety for the benefit of the citizens, the economic actors and the Member States by enabling new products, services and solutions. For AI-enabled products...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550938_en,5,F550938,10 September 2020,Benoît Stockbroeckx,Business association,EURALARM,Micro (1 to 9 employees),94201247949-87,Belgium,Artificial intelligence – ethical and legal requirements,"Euralarm welcomes the inception impact assessment on Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence. Euralarm shares the view that artificial intelligence (AI) can drive economic growth and improve the security and safety for the benefit of the citizens, the economic actors and the Member States by enabling new products, services and solutions.

For AI-enabled products, Euralarm is in favour of Option 1 of the alternative options to the baseline scenario: “soft law” (non-legislative) approach to facilitate and spur industry-led intervention (no EU legislative instrument). Embedded AI-based applications are considered products both by the EU (1) product safety legislation (before the placing on the market) and in the (2) Product Liability Directive (PLD - after the placing on the market). While the first set of rules imposes essential safety requirements for products to be assessed and thus distributed onto the market, the latter aims at compensating victims for the harm suffered from the use of defective good. Hence Euralarm doesn’t see any need for additional legislation addressed to AI-enabled products. Nevertheless, this “soft law” should be accompanied by provisions ensuring that no national rules would impair the free circulation of these products.

For AI-enabled services, Euralarm is in favour of Option 3.b: EU legislative instrument establishing mandatory requirements for “high risk” applications. The qualification of “high risk” should not be a consequence of an intended use or sector but should be based on a risk analysis. In order to ensure liability, the risk analysis should be guided by a list of clearly identified risks. However, this requires more detailed analysis and discussions with the industry, especially when it comes to the different levels of risks generated by AI applications. In Euralarm’s view, the quality of any future regulation will depend on the possibility to identify a common, transparent and easily applicable definition of “AI” and understanding of “high-risk”. High-risk situations should be defined in cooperation with industry, based on risk-benefit considerations and adjusted when needed.

Euralarm believes that the rollout of AI must not come with the new regulation as per se. The new regulation must be used only where it is necessary (e.g. addressing clear and proven risks) and where it delivers clear benefits (e.g. helps to uptake the new technologies by creating a level playing field, ensures safety etc.). General scrutinising of AI-technologies which hampers innovation and creates uncertainty must be avoided. Clear criteria must be established for identifying critical areas in a way that is legally certain.

Europe’s security and safety industries represent companies that innovate at the crossroads of digital and physical technology. AI offers opportunities to European industries not only for further grow at global level but also to build a safer and more secure Europe, provided that the right choices are made, particularly at EU level, to support its development and deployment."
ALLAI (Netherlands),"First and foremost, we would like express our support for the European Commission's efforts to establish an appropriate regulatory framework for AI. In establishing such a framework, one should both look at existing laws and regulations and determine if they are 'fit for purpose' for a world with AI as well as consider establishing new rules where current legislation is not adequate. In general, we recommend to broaden the description of the...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550937_en,5,F550937,10 September 2020,Catelijne Muller,Non-governmental organisation (NGO),ALLAI,Micro (1 to 9 employees),,Netherlands,Artificial intelligence – ethical and legal requirements,"First and foremost, we would like express our support for the European Commission's efforts to establish an appropriate regulatory framework for AI. In establishing such a framework, one should both look at existing laws and regulations and determine if they are 'fit for purpose' for a world with AI as well as consider establishing new rules where current legislation is not adequate. 

In general, we recommend to broaden the description of the problem that the initiative aims to tackle, i.e. addressing a number of ethical and legal issues raised by AI, and include ""societal issues raised by AI"". In the same spirit, we recommend to broaden the description of the ultimate policy objective of the proposal, i.e. to foster the development and uptake of safe and lawful AI that respects fundamental rights across the Single Market by both private and public actors while ensuring inclusive societal outcomes, so as to include ""fair societal outcomes"". 

The issue of defining the scope of a new legislative initiative for AI is the core element that needs to be addressed. Whereas the Inception Impact Assessment mentions a number of AI-techniques that either should or should not be covered by the instrument, we would like to recommend a different approach toward defining the scope of the instrument: an approach that looks at the level of impact of the technology on people and society at large, rather than (merely) on the technical specifications of a particular AI-system. An impact-level based approach lowers the risk of loopholes that could be exploited. 

As for existing legislation, we call for a broad legal AI stress test, because we see a large number of additional legal lacunae where it comes to AI, that were not mentioned in the Inception Impact Assessment, such as the GDPR, law enforcement, competition law, transportation, trade of dual use technology, medical devices, energy and the environment, to name a few. 

The Inception Impact Assessment lays down 5 policy options ranging from keeping the 'Baseline scenario' to a combination of several policy options. 

ALLAI would be most in favour of a combination of the policy options 2, 3a and 3b as described in the Inception Impact Assessment. This combination would entail soft law for low impact AI applications (or uses) including volulntary labelling, and EU instrument with mandatory labelling covering two elements: (i) clear restrictions, conditions, safeguards and/or boundaries for a limited number of exceptionally impactful AI-applications or uses and (ii) mandatory requirements for medium to high impact AI based on common denominators to determine the level of impact.

Finally, we call for an ex-durante (which would include ex-ante and ex-post mechanisms) mechanism to ensure a continuous, systematic, socio-technical governance approach, looking at the technology from all perspectives and through various lenses. For this we recommend to set up European AI Authority as part of a global framework of AI Authorities."
Anonymous,The feedback on behalf of ALLAI is attached.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550936_en,5,F550936,10 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,The feedback on behalf of ALLAI is attached.
Orgalim (Belgium),"Orgalim strongly endorses the overall policy objective of ensuring the development and uptake of trustworthy AI across the Single Market. As this inception impact assessment outlines various options, Orgalim would like to affirm its support for Option 1 of the alternative options to the baseline scenario – i.e. the option of an EU ‘soft law’, a non-legislative approach to facilitate and encourage industry-led intervention (with no EU...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550934_en,6,F550934,10 September 2020,Tadas Tumenas,Company/business,Orgalim,Small (10 to 49 employees),20210641335-88,Belgium,Artificial intelligence – ethical and legal requirements,"Orgalim strongly endorses the overall policy objective of ensuring the development and uptake of trustworthy AI across the Single Market. As this inception impact assessment outlines various options, Orgalim would like to affirm its support for Option 1 of the alternative options to the baseline scenario – i.e. the option of an EU ‘soft law’, a non-legislative approach to facilitate and encourage industry-led intervention (with no EU legislative instrument). In general, Orgalim believes that, before choosing any option, existing regulation needs to be carefully analysed, potential gaps precisely formulated, and the right tools adequately proposed, based on a realistic definition of AI. For the manufacturing sector, the most important aspect to keep in mind is that AI is not a product, but a technology embedded in products (applications), which puts all concerns related to AI into another perspective. There are very diverse applications that might be deemed AI-based or AI-operated systems, ranging from a driverless car to a smart-toothbrush, a robot-companion, or a non-embedded expert system for medical diagnosis. New regulation should be introduced only where it is necessary, and where it delivers clear benefits (e.g. helps to uptake the new technologies by creating a level playing field, ensuring safety etc.), and with a reference to industry standards which reflect the state of the art. It is important for policymakers to differentiate between the varying degrees of risk linked to use of AI technologies in their different applications. Clear criteria should be established for identifying critical areas in a way that is legally certain. In Orgalim’s view, the quality of any future regulation will depend on the ability to identify a common, transparent and easily applicable understanding of ‘high-risk’. High-risk situations should be defined in cooperation with industry, based on risk-benefit considerations and adjusted when necessary. Clear definition of criteria for perceived high-risk applications and the degree of autonomy is crucial, in order to avoid over-regulation of completely harmless automation. When something has been identified as a high-risk application (which we believe will be a minority of industrial AI applications) a targeted  approach to risk-management could be the right one. Taking this into account, it can for instance be concluded that most industrial AI application use cases have entirely different ethical implications compared to consumer-oriented AI solutions for end-consumers. It is crucial that the framework for identifying high-risk use cases is predictable and proportionate in order to create a stable environment for investments. From a policy-making perspective, clearly identifying the object to be regulated is essential. In the absence of a precise definition, which is currently the case for AI, the scope of any intended regulation would be uncertain, potentially being either over- or under-inclusive, and triggering litigation. Orgalim would like to highlight a definition of AI, as  outlined in our previous position papers and it is similar to the definition given by the Commission’s High-Level Experts Group on AI. More detailed analysis and suggestions, especially when it comes to the safety and liability of AI, can be found in the attached Orgalim position paper."
Gesamtverband der Deutschen Versicherungswirtschaft e.V. (Germany),Please find the complette feedback of the GDV in attachment.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550933_en,6,F550933,10 September 2020,Constantin Greim,Business association,Gesamtverband der Deutschen Versicherungswirtschaft e.V.,Medium (50 to 249 employees),6437280268-55,Germany,Artificial intelligence – ethical and legal requirements,Please find the complette feedback of the GDV in attachment.
Związek Przedsiębiorców i Pracodawców (Poland),"First, we would like to highlight the risks arising from the extension of the scope of future AI Regulation to automated decision making. Such inclusion would stand in opposition to the fundamental ideas laid out on the White Paper on Artificial Intelligence, which proposed to adopt a risk-based approach and focus on high-risk IA-based applications. Moreover, an extension of the definition of AI to automatic decision making would lead to an...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550925_en,6,F550925,10 September 2020,Kamila Sotomska,Business association,Związek Przedsiębiorców i Pracodawców,Small (10 to 49 employees),868073924175-77,Poland,Artificial intelligence – ethical and legal requirements,"First, we would like to highlight the risks arising from the extension of the scope of future AI Regulation to automated decision making. Such inclusion would stand in opposition to the fundamental ideas laid out on the White Paper on Artificial Intelligence, which proposed to adopt a risk-based approach and focus on high-risk IA-based applications. Moreover, an extension of the definition of AI to automatic decision making would lead to an unproportionate regulatory burden for various market operators. This, in turn, would hinder the development and implementation of IA technology as well as automated decision systems.
Secondly, the Union of Entrepreneurs and Employers expresses its concern over the potential introduction of a new category of harm, meaning immaterial harm.
Option “0”
In our view, even in the absence of AI-specific European regulation, the Commission should propose to adapt the existing legislative framework to the challenges raised by the development of new technologies, including AI. Here, it is also important to note that AI solutions do not operate in a legal vacuum, and are subject to an existing regulatory framework such as GDPR or medical device regulations.
Option 1
We support all measures, which engage the industry in setting regulatory norms. Therefore, we would suggest that the Commission takes into consideration the possibility of implementation of such a scheme regardless of the policy option, which would be eventually chosen. 
Option 2
Voluntary labelling scheme in the longer term could become a standard for large companies. However, compliance with such a scheme for SMEs could prove to be a significant regulatory burden, effectively deteriorating their position in the market. Keeping in mind the negative effects of the competition, we consider that the costs of such a voluntary scheme could outweigh its potential benefits.
Option 3
• Sub-option 1: It assumes that the EU regulation could be limited to a specific category of AI applications only, for instance, biometric identification systems. In our opinion, remote biometric identification systems are a good example of high-risk AI, which should be regulated by mandatory law. 
• Sub-option 2: In this case, the EU legislative instrument could be limited to high-risk AI applications. As mentioned above, we support the risk-based approach, which was initially outlined in the White Paper on Artificial Intelligence. Sectoral regulation limited only to high-risk AI applications would not hinder innovation and technological development, while safeguarding respect for fundamental rights. We would encourage the Commission to base its’ work on the proposal presented in the White Paper. Such a solution would not only increase the effectiveness of the process but also minimize uncertainty and ensure a smooth transition.
• Sub-option 3: The last sub-option proposes to regulate all AI-based applications. The Union of Entrepreneurs and Employers strongly advises not to adopt this solution. As mentioned above, various AI-based applications pose different levels of risk. In our opinion, such an approach would lead to over-regulation and result in various costs (administrative burdens, additional costs, hindrance of economic development). Moreover, a one-size-fits-all approach also means that IA-based applications, which pose high risks, could be under-regulated. Consequently, it could lead to the creation of a gap, where some of the negative effects of such high-risk applications could not be easily fit into the legal framework. Effectively, making documentation and obtaining damages for harm could become more difficult. 
We support ex-post enforcement. In case ex-ante regulation is deemed necessary, we encourage the Commission to work with the industry representatives in order to develop transparent and precise risk-assessment guidelines as well as implement a due diligence system.
For a more detailed analysis, please refer to the attached contribution."
Anonymous,We welcome the opportunity to comment on the European Commission’s Inception Impact Assessment on 'Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence'. Please find attached our contribution.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550924_en,6,F550924,10 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,We welcome the opportunity to comment on the European Commission’s Inception Impact Assessment on 'Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence'. Please find attached our contribution.
EUnited AISBL (Belgium),"EUnited is convinced that artificial intelligence (AI) drives and contributes to the digital and green transformation. It can do so across a broad range of sectors from healthcare to manufacturing and beyond, which in turn will lead to badly needed economic growth and the ability to meet numerous other societal challenges. EUnited supports the principle and pursuit of trustworthy, human-centric, and ethical AI in Europe. Nevertheless, it...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550923_en,6,F550923,10 September 2020,Jethro Schiansky,Business association,EUnited AISBL,Micro (1 to 9 employees),0289344948-82,Belgium,Artificial intelligence – ethical and legal requirements,"EUnited is convinced that artificial intelligence (AI) drives and contributes to the digital and green transformation. It can do so across a broad range of sectors from healthcare to manufacturing and beyond, which in turn will lead to badly needed economic growth and the ability to meet numerous other societal challenges.
EUnited supports the principle and pursuit of trustworthy, human-centric, and ethical AI in Europe. Nevertheless, it reminds the Commission that – contrary to the statements made in the Inception Impact Assessment - the reality today is that uptake and investment in AI is greatest in areas of the world where no regulation yet hampers or stifles its deployment. Europe is currently losing the global AI race. The stipulation of trustworthy AI being the major force for gaining a competitive edge vis-à-vis China and the US is unrealistic. We believe it is therefore of vital importance to strike the right balance between EU intervention on the one hand and ensuring the competitiveness and innovation potential of our businesses, whilst protecting the rights of our citizens, on the other. In general, we believe that more work can be done to boost EU businesses by, for example, open-sourcing datasets and sharing ongoing research. Finally, it should also be pointed out that the compliance costs related to - what might appear to be only minor regulatory interventions - may be decisive for the competitiveness of many European businesses, especially SMEs. 
EUnited favours Policy Option 1 contained in the Inception Impact Assessment (IIA). We believe that this soft law approach could quickly allow industry to harness the potential of ongoing national initiatives thus increasing uptake of AI systems across many industrial sectors and thereby accelerating the green and digital transformation. A good way to ensure that the complex socio-technical systems being created with AI will in practice adhere to ethical standards is to actively involve all people devising and implementing such systems. Option 1 ensures the involvement of those taking responsibility and accountability for the ethical implications. At this stage a soft law approach is preferable to risking a serious disturbance of this transformation. Such disturbance could arise as a result of a lengthy and difficult legislative procedure borne out of the desire to introduce hard law to regulate only a very few contentious applications, already covered by other parts of EU law (e.g. data, privacy, safety and liability). 
Whilst EUnited also believes that there may be some benefit to pursuing regulation for highest risk applications (i.e. Policy Option 3(1)), we think that it is premature given the difficulties we will inevitably face in distinguishing risk levels related to vastly different use-cases of similar or identical applications, all in a rapidly evolving context. To put it another way, an application such a facial recognition could be totally benign or extremely risky depending on the use-case. Sectors such as ours rely heavily on innovation through offering new functionalities to the customer. Indeed, this is the key to remaining competitive. So a one-size-fits-all approach to the regulation of different applications of AI is not in the interest of Europe. EUnited therefore clearly rejects an Option 3(3) approach. It adds no additional benefit while seriously damaging European competitiveness.
The potential for European industry to support the green and digital transformation through uptake of AI shouldn’t be overlooked. The European institutions should keep the competitiveness of Europe at the forefront when considering any legal intervention on AI, particularly given the breadth of coverage of the exiting legal framework. EUnited recommends the approach set out in Policy Option 1 to best strike the balance at this stage."
Fair Trials (United Kingdom),"Fair Trials is aware that the Inception Impact Assessment considers the entire and wide array of economic and societal issues in relation to AI across a spectrum of industries and social activities. However, this response is concerned specifically with AI in the context of criminal justice and will consider the legal and policy measures needed for the regulation of AI in criminal justice. Rapid technological advancements in recent years have...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550917_en,6,F550917,10 September 2020,Bruno Min,Non-governmental organisation (NGO),Fair Trials,Small (10 to 49 employees),302540016347-29,United Kingdom,Artificial intelligence – ethical and legal requirements,"Fair Trials is aware that the Inception Impact Assessment considers the entire and wide array of economic and societal issues in relation to AI across a spectrum of industries and social activities. However, this response is concerned specifically with AI in the context of criminal justice and will consider the legal and policy measures needed for the regulation of AI in criminal justice.

Rapid technological advancements in recent years have made machine learning and algorithmic automated decision-making systems, often referred to as artificial intelligence (‘AI’) a prominent aspect of our lives. There is little doubt that these systems have great capacity to increase human potential and improve the lives of many, but their increasing role in assisting important public functions has also highlighted serious risks and challenges, particularly in the context of criminal justice. If not subject to proper regulation and oversight, AI can threaten fundamental human rights and, far from expanding human potential, it can amplify and worsen harmful aspects of our society, including inequality and injustice.

Fair Trials is grateful for the opportunity to submit feedback on the EU Commission’s AI Inception Impact Assessment. We submitted a response to the EU Commission’s consultation on the White Paper, ‘Regulating Artificial Intelligence for Use in Criminal Justice Systems in the EU’, which provided evidence and analysis about the negative impact that ‘AI’ can have on criminal justice.

We are pleased that the EU Commission recognises that AI represents risks for fundamental rights, including the right to a fair trial, as well as the need for improvements to the EU’s legislative framework on AI, particularly the ‘effective application and enforcement of existing EU and national legislation’, as well as the ‘limitations of scope of existing EU legislation’.

We are also pleased to see that the objectives identified in the Roadmap include preventing or minimising significant risks for fundamental rights, as well as ensuring the effective enforcement of rules of existing EU law to protect fundamental rights and avoid illegal discrimination. However, with regards to the policy options stated in the Roadmap, in order to achieve the above stated objectives to protect and minimise risks to fundamental rights and prevent discrimination, we believe that there is a clear need for a legislative solution under Option 3. For the purposes of protecting rights in criminal justice, any legislative proposal would at the very least need to cover ‘high-risk’ applications (Option 3, second sub-option b), but more comprehensive protection may be offered by a legislative act which covered all AI applications (Option 3, third sub-option c)."
José Antonio Parrilla (Spain),"Since February 2020 I am part of PANELFIT, an EU 2020 research project whose objectives and outcomes are: - To facilitate the implementation of European data protection new regulation by producing a set of outcomes that serve as operational standards and practical guidelines able to reduce the ethical and legal issues (ELI henceforth) posed by ICT technologies while promoting innovation and market growth, enabling high-quality job creation...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550910_en,6,F550910,10 September 2020,José Antonio Parrilla,EU citizen,,,,Spain,Artificial intelligence – ethical and legal requirements,"Since February 2020 I am part of PANELFIT, an EU 2020 research project whose objectives and outcomes are: 
- To facilitate the implementation of European data protection new regulation by producing a set of outcomes that serve as operational standards and practical guidelines able to reduce the ethical and legal issues (ELI henceforth) posed by ICT technologies while promoting innovation and market growth, enabling high-quality job creation and ensuring a high level of privacy and security/cybersecurity.
- To suggest possible concrete improvements to the current regulatory and governance framework for the same purpose
- To create mutual learning and support tools and to promote networking among stakeholders and policymakers
- To increase the quantity and quality of the information available to policymakers, professionals, journalists and the general public.

As part of these objectives, I submit comments on the EU Proposal for a legal act laying down requirements for Artificial Intelligence. The feedback focuses on the convenience of the different levels of intervention explained in the Proposal and two specific issues: the black box phenomenon as a problem for developing rules on AI-tools liability and the accountability principle (art. 5.2 GDPR) as a current rule to guarantee AI-tools transparency."
European Tech Alliance (Belgium),"In February 2020, members of the European Tech Alliance (EUTA) joined forces to publish the EUTA High Level Principles on AI ahead of the publication of the European Commission’s White Paper on AI. EUTA members strongly believe the EU has the potential to become a world leader in AI. Europe benefits from a vibrant ecosystem of top academic talent, leading AI research labs and an ever growing number of AI-driven start-ups. This fruitful...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550909_en,6,F550909,10 September 2020,Jan Rempala,Business association,European Tech Alliance,Micro (1 to 9 employees),189607519323-76,Belgium,Artificial intelligence – ethical and legal requirements,"In February 2020, members of the European Tech Alliance (EUTA) joined forces to publish the EUTA High Level Principles on AI ahead of the publication of the European Commission’s White Paper on AI. EUTA members strongly believe the EU has the potential to become a world leader in AI. Europe benefits from a vibrant ecosystem of top academic talent, leading AI research labs and an ever growing number of AI-driven start-ups. This fruitful ecosystem is supported by industry best practices and the strong fundamentals of the EU's regulatory architecture. 

 Against this backdrop and our contribution to the public consultation on the AI White Paper last Spring, we welcome the opportunity to share the following comments, attached,  on the European Commission’s inception impact assessment “Artificial Intelligence – Ethical and Legal requirements”"
Zsolt BARTFAI (Hungary),"I am in favour of a piece of sectoral legislation that provides a comprehensive legal framework of the privacy related aspects of the AI. This legal act should – while preserving the principles of the privacy (e.g. GDPR) –, surely, deter from the rules of the GDPR to the necessary extent in order to provide AI-tailored privacy provisions. Therefore, Option 3 (as presented in the Inception Impact Assessment) seems to be the best option. The...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550908_en,6,F550908,10 September 2020,Zsolt BARTFAI,EU citizen,,,,Hungary,Artificial intelligence – ethical and legal requirements,"I am in favour of a piece of sectoral legislation that provides a comprehensive legal framework of the privacy related aspects of the AI.  This legal act should – while preserving the principles of the privacy (e.g. GDPR) –, surely, deter from the rules of the GDPR to the necessary extent in order to provide AI-tailored privacy provisions. Therefore, Option 3 (as presented in the Inception Impact Assessment) seems to be the best option. 
The followings could be – from privacy perspective – topics of an AI-related sectoral legislative act (taking also into account the principle laid down in recital 4  of the GDPR):
a) Declaration of the possibility of use AI solutions that meet the requirements of the given legislative act – this would create the legal ground (different from the GDPR) for the use of AI;
b) Limitation on the potential use (i.e. the purposes) of AI solutions (either “blacklist” – i.e. forbidden use, or “white list” – i.e. allowed use), including the special conditions to be met. On the other hand, the new legislative act should adapt specific rules “to permit organizations to repurpose data already collected, as long as doing so poses only minimal risk of harm to individuals and does not involve the transfer of data from one controller to another”; 
c) Special rules for some data processing activities, e.g. general permission for use of personal data as training data – with no or limited possibility to opt out. In this way, the future legislation might ease the strict interpretation of “data minimization” principle as well;
d) Specific rules on transparency, inc. the minimum set of information to be shared with data subjects on the “logic” of AI;
e) If necessary, some limitations on the data subject rights (e.g. on erasure or objection to ensure the availability of the data for the purpose of training of AI); 
f) AI-specific data security measures (e.g. compulsory pseudonymization or anonymization, other rules stricter than the general ones);
g) Allocation of obligations on those actors who are “best placed to address any potential risks”. It means that the personal scope of the new legislative act should not be limited to data controller and data processors, but should “include the developer, the deployer (the person who uses an AI-equipped product or service) and potentially others (producer, distributor or importer, service provider, professional or private user)” – with carefully allocated adequate responsibilities."
The Polish Confederation Lewiatan (Poland),"Jasna i szeroko rozumiana definicja sztucznej inteligencji będzie miała kluczowe znaczenie dla skuteczności wszelkich przyszłych ram regulacyjnych. Dlatego przestrzegamy przed zdefiniowaniem Sztucznej Inteligencji, jako tzw. automatycznego system podejmowania decyzji. Tak rozumiana definicja Sztucznej Inteligencji byłaby sprzeczna z kierunkiem regulacji zaproponowanym przez KE w Białej Księdze. Co więcej, mogłaby doprowadzić do powstania...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550907_en,6,F550907,10 September 2020,Elżbieta Dziuba,Non-governmental organisation (NGO),The Polish Confederation Lewiatan,Medium (50 to 249 employees),,Poland,Artificial intelligence – ethical and legal requirements,"Jasna i szeroko rozumiana definicja sztucznej inteligencji będzie miała kluczowe znaczenie dla skuteczności wszelkich przyszłych ram regulacyjnych. Dlatego przestrzegamy przed zdefiniowaniem Sztucznej Inteligencji, jako tzw. automatycznego system podejmowania decyzji. Tak rozumiana definicja Sztucznej Inteligencji byłaby sprzeczna z kierunkiem regulacji zaproponowanym przez KE w Białej Księdze. Co więcej, mogłaby doprowadzić do powstania nieuzasadnionych obowiązków regulacyjnych, z których wiele może znacznie utrudnić rozwój i rozpowszechnienie korzystnych zastosowań Sztucznej Inteligencji w Europie. 
Zwracamy uwagę na nieprecyzyjny charakter pojęcia ""szkody niematerialnej"". Niestety, definicja ta może oznaczać wszystko, od strat gospodarczych do bolesnych emocji, i może prowadzić do niepewności prawnej, zniechęcając do inwestycji i innowacji. W zamian proponujemy, aby przyszłe regulacje odnosiły się do pojęcia ""znacznego ograniczenia korzystania z praw podstawowych"". Pojęcie to jest zbliżone do istniejących ram prawnych.
Przede wszystkim, jesteśmy przeciwni jakimkolwiek nowym regulacjom. Stoimy na stanowisku, że już obecnie Sztuczna Inteligencja podlega wielu istniejącym przepisom, takim jak choćby RODO. Dlatego też przed stworzeniem jakichkolwiek nowych regulacji, należy zapewnić prawidłowe wdrożenie obecnych przepisów prawnych UE w tym zakresie. 
Niezależnie od tego jakie podejście regulacyjne jest stosowane, należy zapewnić wsparcie przemysłu we wdrażaniu norm w zakresie odpowiednich praktyk w zastosowaniu Sztucznej Inteligencji. 
Ponadto, jesteśmy przeciwni tzw. systemowi etykietowania. Uważamy, że nie spełni on zakładanej funkcji, a przyczyni się z znacznym stopniu do jeszcze większego obciążenia administracyjnego MŚP, a także nałoży na tych przedsiębiorców nowe obowiązki dotyczące oznakowania. Koszty dostosowania się do tego typu systemu mogłyby znacznie przewyższyć korzyści z niego płynące. 
Ważne jest, aby przy konstruowaniu jakichkolwiek nowych regulacji zachować elastyczność interpretacji prawnej i współpracować z osobami zajmującymi się rozwojem AI w celu opracowania przepisów, które będą wykonalne z technicznego punktu widzenia. AI to zestaw technologii zdolnych do uczenia się, wnioskowania, dostosowywania i wykonywania zadań  w sposób inspirowany przez umysł ludzki. Technologia ta stale się rozwija i ulepsza. Potencjalne korzyści z rozwoju AI są olbrzymie. Przepisy powinny uwzględniać szybkie tempo postępu technologicznego.
Komisja słusznie stwierdziła potrzebę dobrze zdefiniowanego, opartego na ryzyku podejścia do regulacji AI, które nie stosuje logiki „jeden rozmiar dla wszystkich” w niezliczonych aplikacjach AI. Dobrym przykładem rozwiązania, do którego można by zastosować obowiązkowe wymogi w oparciu o analizę ryzyka jest chociażby system zdalnej identyfikacji biometrycznej. Należy pamiętać, że każda ocena ryzyka powinna mieć charakter holistyczny, odzwierciedlający nie tylko potencjalne szkody, ale również możliwości społeczne. Sztuczna inteligencja to zestaw technologii zdolnych do uczenia się, rozumowania, dostosowywania i wykonywania zadań w sposób zainspirowany przez ludzki umysł. Technologia ta stale się rozwija i doskonali. Potencjalne korzyści płynące z jej rozwoju są ogromne. Przepisy powinny uwzględniać szybkie tempo postępu technologicznego. Mając to na uwadze, należy wprowadzić szereg dostosowań, aby zapewnić, że wszelkie potencjalne regulacje będą ukierunkowane na właściwe przypadki użycia, zwiększą pewność prawną i nie zniechęcą do rozwoju i rozpowszechniania AI. 
Uważamy, że najlepsze podejście do aplikacji AI wysokiego ryzyka to ocena rozwiązań ex-post. Rozumiemy oczywiście, że są dziedziny, w których ocena ex-ante stanowi utrwaloną praktykę, np. medycyna, jednakże w tych dziedzinach postulujemy, aby ocenę ex-ante połączyć z oceną stosowanych praktyk sektorowych."
Japan Business Council in Europe (Belgium),"JBCE welcomes the European Commission’s efforts to establish a common European approach to AI. This will help the EU’s AI market reach scale and avoid legal uncertainty or fragmentation of multiple policies among EU Member States, through protecting our safety, consumer rights and fundamental rights when we use AI applications. 1.Our recommendation Considering the different levels of risk that could be generated by AI applications, we...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550904_en,7,F550904,10 September 2020,Takenobu Kurihara,Business association,Japan Business Council in Europe,Micro (1 to 9 employees),68368571120-55,Belgium,Artificial intelligence – ethical and legal requirements,"JBCE welcomes the European Commission’s efforts to establish a common European approach to AI. This will help the EU’s AI market reach scale and avoid legal uncertainty or fragmentation of multiple policies among EU Member States, through protecting our safety, consumer rights and fundamental rights when we use AI applications.

1.Our recommendation

Considering the different levels of risk that could be generated by AI applications, we support the Commission’s proposal of a risk-based approach and would recommend Option 4. This means that the EU’s consideration on regulation should be limited to high-risk AI only, with detailed requirements being determined by industry via a soft law approach. The EU must also help avoid duplications between future regulations and current laws and ensure harmonization with international rules and existing regulatory schemes, minimizing the burden on businesses.

2.Scope of high-risk AI

2.1.We welcome the preliminary ideas proposed by the Commission in the White Paper (p. 17 – sector and specific use), but it is essential to develop clear criteria and definitions through dialogues with industry to ensure legal certainty and to distinguish between high-risk and low-risk AI. In our view, some examples of non-high-risk AI include, but are not limited to, the following types of applications:

Mobility
Driver assistant safety and monitoring systems, biometric ID to unlock and start automobiles, vehicles navigation systems with voice recognition and telematic services.

Manufacturing
Fiber laser processing machines, intellectualization of industrial robots, real-time data analyzers.

Home, offices & shops
Air conditioning systems, digital still cameras/camcorders (automatic focus, smile detection), emotion visualization, ID card.

3.Requirements on high-risk AI

3.1.We welcome the scenario outlined in the IIA p.5 in which the principles and basic regulatory framework are legislated by the EU institutions, but the details of each requirement should be determined by industry (soft law approach). AI is constantly evolving, and it is difficult to pre-determine detailed regulations or to amend them in a timely manner. Therefore a future-proof regulatory framework, rather than specific and sectorial regulations that could stifle the EU’s competitiveness in this field, has to be preferred.

3.2.New ex-ante conformity assessments such as testing and algorithms verifications or data sets, inspections and certifications could be disproportionate for certain applications, but we would support further discussion on how to build a credible assessment mechanism that is capable of checking the trustworthiness of AI applications throughout their life time.

3.3.It is important to ensure that there is no duplication between the future regulatory framework for high-risk AI and existing EU legislation. We also believe that the establishment of a new independent AI authority could bring low added value: some of the potentially high-risk sectors or AI applications are already subject to strict ex-ante rules, which should continue to be covered under existing law and amended if necessary.

4.Facial recognition and biometric data

4.1.There is a broad range of facial recognition technologies and applications that process biometric data. As such, we would warn against adopting a one-size-fits-all approach when considering regulation for these applications. A general ban would compromise innovation and competitiveness for the development of new technologies, products and services.

4.2.For AI solutions based on biometric parameters, we encourage the development of a framework that excludes non high-risk applications.

4.3.Some remote biometric identification solutions used in public spaces could be identified as high-risk applications. They should be regulated under the EU’s future framework on AI, but as long as such solutions are complying with future requirements, they should be allowed in publicly accessible spaces."
Bundesverband der Deutschen Industrie (Germany),"The BDI welcomes the efforts of the European Commission to develop an appropriate ethical and legal framework based on the Union's values with the overriding goal to take on a global leading role in AI. A selective adaptation of the existing legal framework for AI can in-crease legal certainty for companies and foster trust in AI applica-tions. However, it must always be borne in mind that too high regulatory re-quirements can hinder the...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550900_en,7,F550900,10 September 2020,Clemens Otte,Business association,Bundesverband der Deutschen Industrie,Medium (50 to 249 employees),1771817758-48,Germany,Artificial intelligence – ethical and legal requirements,"The BDI welcomes the efforts of the European Commission to develop an appropriate ethical and legal framework based on the Union's values with the overriding goal to take on a global leading role in AI. A selective adaptation of the existing legal framework for AI can in-crease legal certainty for companies and foster trust in AI applica-tions. However, it must always be borne in mind that too high regulatory re-quirements can hinder the development and thus the uptake of AI. We therefore expressly welcome the fact that the EU Commission not on-ly considers the effects on social and ethical aspects of AI regulation but al-so the compliance costs and the impact on the innovative and competitive capacity of Europe. It is of uttermost importance to balance innovation and consumer protection appropriately. 
 
The BDI is of the opinion that a selective adjustment of the legal framework is generally sufficient to meet the challenges posed by AI. Should the Commission decide to introduce new measures on AI, BDI prefers option 4, a combination between option 1 and an adapted option 3b. This approach would be based on horizontal EU-wide AI principles, which serve as a European standard. The principles could build on the work of the High Level Expert Group. The EU would provide guidance and recommendations on how to best implement the AI principles. Industry standards could supplement as needed (option 1). 
 
Furthermore, consideration could be given to additional requirements for high-risk applications. This requires a clear definition of high risk and a uni-form framework for the risk assessment. However, it does not seem to be suitable to define the sector as one of two main criteria in order to classify AI as high risk. A sectoral differentiation would only make sense if the vast majority of AI applications used in a given sector pose a significant risk or if the vast majority of AI applications from a given sector are completely risk-free. The BDI doubts that such a clear distinction is possible. More im-portant than the sector affiliation is the concrete field of application of the AI system. In addition, the criterion of sector affiliation is softened by the considered exceptions in the white paper on AI and therefore appears to be inconsistent. In order to achieve sector-specific differentiation, it is more purposeful to transfer general horizontal requirements for high-risk applica-tions to existing sector-specific regulation. 

Regarding the liability regime for AI applications, BDI is of the opinion, that the currently existing national and European legal provisions on safety and liability issues, which are based on a technology-neutral approach, are largely fit for purpose and provide an adequate legal framework that also co-vers AI as a source of risk. Only if actual liability gaps can be proven, should cautious adjustments be made. However, a fundamental readjustment of the liability framework is not necessary.  
 
BDI outlines its position to the Commission’s ongoing consultation in the document attached."
Information Technology Industry Council ITI (Belgium),Please refer to the attached position paper for our detailed feedback.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550893_en,7,F550893,10 September 2020,Marco Leto Barone,Business association,Information Technology Industry Council ITI,Small (10 to 49 employees),061601915428-87,Belgium,Artificial intelligence – ethical and legal requirements,Please refer to the attached position paper for our detailed feedback.
Anonymous,"The German Federal Association of Interpreters and Translators (BDÜ) welcomes the opportunity to comment on this roadmap, and on developments related to artificial intelligence in general. Translators and interpreters are affected by technological developments, as epitomised by the progress achieved by neural machine translation (NMT). We embrace change and are ready to adapt our skills and processes, but want to raise awareness concerning...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550892_en,7,F550892,10 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,"The German Federal Association of Interpreters and Translators (BDÜ) welcomes the opportunity to comment on this roadmap, and on developments related to artificial intelligence in general.

Translators and interpreters are affected by technological developments, as epitomised by the progress achieved by neural machine translation (NMT). We embrace change and are ready to adapt our skills and processes, but want to raise awareness concerning two major aspects:

Technology must protect citizens' interests and privacy, not just in the EU. There are certain areas where human beings must obtain (or retain) ultimate responsibility for translation and interpretation - including, in particular, the areas of law/legal practice, medicine/healthcare, integration and immigration. In this respect, translators and interpreters also protect society through their services.

This has also been recognised by the Commission:
https://ec.europa.eu/info/sites/info/files/about_the_european_commission/get_involved/documents/discovertranslation-info-sheet-world-without-translation.pdf

Skilled translators and interpreters and their professional assocations must be actively involved in the assessment of technological trends concerning and affecting their professions (and livelihoods). We are ready, and will be happy, to contribute our skills and expertise."
Computer & Communications Industry Association (CCIA) (United States),"The Computer & Communications Industry Association (CCIA) welcomes this opportunity to respond to the European Commission’s inception impact assessment on Artificial Intelligence (AI). We support the Commission’s aim to “create trust and incentivise the use of such AI systems by citizens and businesses”. We agree that AI “can contribute to a wide array of economic and societal benefits”. Like any other technology, risks lie not in the AI...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550891_en,7,F550891,10 September 2020,Christian BORGGREEN,Business association,Computer & Communications Industry Association (CCIA),Small (10 to 49 employees),15987896534-82,United States,Artificial intelligence – ethical and legal requirements,"The Computer & Communications Industry Association (CCIA) welcomes this opportunity to respond to the European Commission’s inception impact assessment on Artificial Intelligence (AI). We support the Commission’s aim to “create trust and incentivise the use of such AI systems by citizens and businesses”. We agree that AI “can contribute to a wide array of economic and societal benefits”.

Like any other technology, risks lie not in the AI application itself, but in its usage. We therefore support a regulatory focus on “high risk” use cases.

Comments on policy options:

Option 0: No EU policy change:
AI is already subject to EU legislation and we therefore encourage EU lawmakers to ensure that existing law is properly implemented before proposing any new AI-specific regulation.

Option 1: EU “soft law”:
We support this approach and agree that it can “facilitate and spur industry-led intervention”.

Option 2: EU legislative instrument setting up a voluntary labelling scheme:
While in principle in favor of such voluntary measures, we would caution that any such scheme would have to; remain voluntary; focus only on low risk applications, and; must not place a costly administrative burden nor delay time to market. We must avoid overburdening developers and startups given their minimal resources.

Option 3a: EU legislation limited to a specific category of AI applications only, e.g. remote biometric identification (RBI) systems:
We agree that some use cases of RBI systems could be considered high risk, and therefore warrant mandatory requirements. However, facial recognition technologies can also be used to reduce risks, e.g. a search for missing persons on the Internet or secure login on a smartphone.
We would caution against focusing on regulating a specific technology, given that there is no risk inherent to a technology, and instead recommend a clear emphasis on specific “high risk” use cases to address specific and known risks and harms. The Commission can build on, without duplicating, existing specific vertical legislations that already identify specific risks, e.g. in the areas of medical devices and transportation.

3b: EU legislation limited to “high-risk” AI applications:
We support the Commission’s risk-based approach and the distinction between high and low risk AI systems. We would suggest a clear and narrow definition of “high risk” applications, with emphasis on specific (high risk) use cases rather than blanket categories of technologies. Inspiration can be drawn from existing EU sectoral legislation as mentioned above.

3c: EU legislative act covering all AI applications:
We would oppose this option which would be disproportionate, overburdensome, and run counter to stated goals to make the EU a leader in the data economy. This would also ignore the necessary risk-based approach of linked EU policies, e.g. GDPR.
We finally would caution against considering significantly expanding the scope of the future AI regulation to the open ended category of “automated decision making.” This would go against the initial, thoughtful direction proposed in the AI White Paper that proposes to focus on the risk-based, double-criterion for sectorial and application/use-based AI technologies.

Option 4: Combination of any of the options above taking into account the different levels of risk:
We support a combination of policy options, notably we favor the main elements of options 0, 1, 3a, and 3b.

Enforcement: Ex ante and/or ex post:
We support a combination of ex ante and ex post enforcement. Ex ante self-assessment and testing procedures should be based on clear due diligence guidance from regulators made against recognised global standards. Authorities can moreover conduct ex post intervention when required and in limited circumstances. We would finally caution against any bureaucratic, lengthy, ex-ante assessments. 

Thank you for this opportunity to comment. We stand ready to provide further information."
IKEA / Ingka Group (Netherlands),"Since 2018, Ingka Group, the strategic partner in the IKEA franchise system, has embarked on a journey to transform our company into a retailer fit for the 21st century. We are becoming data-driven, using digital tools such as Artificial Intelligence (AI) to meet customers wherever and whenever they choose, with the range and services they want, always at prices they can afford. We are developing Data Ethics Principles, stemming from our...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550883_en,7,F550883,10 September 2020,Elise Cachin,Company/business,IKEA / Ingka Group,Large (250 or more),1095068839-59,Netherlands,Artificial intelligence – ethical and legal requirements,"Since 2018, Ingka Group, the strategic partner in the IKEA franchise system, has embarked on a journey to transform our company into a retailer fit for the 21st century. We are becoming data-driven, using digital tools such as Artificial Intelligence (AI) to meet customers wherever and whenever they choose, with the range and services they want, always at prices they can afford. We are developing Data Ethics Principles, stemming from our company culture and values to put people first, and put transparency and accountability at the core of our personalised relationships with our customers. 

We welcome the commitment of the European Commission to the digital transformation of the European economy. A future-proof European framework for Artificial Intelligence should rely on a human-centric approach to AI that creates a positive stance towards AI technologies, supports innovation and creates a level-playing field to the benefit of consumers. 

An EU legislative instrument establishing mandatory requirements limited to ‘high-risk’ AI applications (option 3.b) should highlight the benefits of AI and provide risk management mechanisms where needed. We have the following recommendations to secure a future-proof European framework for Artificial Intelligence:
> EU rules should focus on achieving desirable outcomes rather than regulating tools, as it is already the case for other technologies (e.g. software updates). Introducing new obligations such as ‘non-discrimination by design’ would secure positive outcomes in an innovation-friendly manner.
> The future EU rules for AI should rely on a more precise definition of ‘Artificial Intelligence’. A specific and targeted definition of Artificial Intelligence will foster trust among society, and secure the legal certainty needed for businesses to innovate in the European Union. 
> Whether Artificial Intelligence is deemed ‘high risk’ should be equally based on the type of AI application being used (i.e., likelihood and magnitude of adverse outcomes) and on sectoral use. 
> ‘High-risk’ applications should be assessed based on their intended use, i.e., on whether they will be used for (i) internal operational processes, (ii) consumer-facing use, (iii) decision tools, and (iv) physical use that presents safety risks including harm to human body. 
> EU rules for remote biometric identification systems should balance privacy concerns with opportunities for consumer experience improvement. The General Data Protection Regulation (GDPR) has already created a clear framework for remote biometric identification systems in which biometric data processing should be a last resort option. Retailers would welcome the opportunity to explore innovative biometric-based services for our customers and visitors, such as to cashier-less check-out processes. 

A voluntary labelling scheme (option 2) would likely overflow consumers with information and refrain them from using AI technologies by putting forwards the notion of risks rather than benefits. Such a scheme would also increase administrative burdens for developers and reduce the attractiveness of the European Union for AI innovation and development.

Artificial Intelligence is driving the ability of the European economy to grow, compete and become greener tomorrow. Agile innovation-focused human-centric rules for AI will help us innovate and develop new services that will provide consumers with more and better choices. We stand ready to support building a responsible AI-powered economy ensuring a future for Europe that is fair and equal for all, climate neutral, and digital."
Anonymous,"First of all, as a private sector stakeholder, we are pleased to submit our feedback to the Commission on the proposal for a legal act laying down requirements for Artificial Intelligence. In our opinion, the objectives defined by the Commission are adequate and necessary considering the current legal issues raised by AI. Especially, achieving the objectives (d) and (f) will answer the private sector's needs. To begin with, it is crucial to...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550881_en,7,F550881,10 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,"First of all, as a private sector stakeholder, we are pleased to submit our feedback to the Commission on the proposal for a legal act laying down requirements for Artificial Intelligence. 
 
In our opinion, the objectives defined by the Commission are adequate and necessary considering the current legal issues raised by AI. Especially, achieving the objectives (d) and (f) will answer the private sector's needs. To begin with, it is crucial to have a harmonized framework to reduce compliance costs derived from legal fragmentation mostly in cross-border activities. It is known that some Member States like Germany, Denmark, and Malta, have implemented separate regulatory initiatives. Alongside the burdensome compliance costs, these fragmented practices limit private sector stakeholders to extend their solutions and products to the Single Market. Ensuring a level playing field for trustworthy AI is another important aspect and also the reason why we do not agree with the approach of Option 1.
 
Option 1 purposes to promote industry initiatives for AI and suggests implementing monitoring and reporting on voluntary compliance. In our view, this is not applicable because it will lead to further fragmentation first among the Member States and secondly among different industries. An industry-led initiative does not guarantee a harmonized cross-border approach since not all industries have an EU level umbrella organization. Therefore, it could bring some practices, which contradict the principles and goals of the European Single Market. Moreover, it can cause diversified practices among different industries, and maybe also among those usually work together and interact, ruling out the level playing field for trustworthy AI. 
 
We express some doubts also on Option 2. Although a voluntary labeling scheme is not a non-preferable solution per se, it is not clear according to which criteria AI applications will be identified and labeled. The Ethical guidelines piloted by the HLEG lay the foundation and counter the applicable criteria nevertheless the Guidelines are not specific enough to follow in a labeling process. Thus, if the Commission decides to pursue this option, it is necessary that the authorities identify those criteria.
 
Taking into consideration the arguments developed above, we assume that, in a general manner, Option 3 can work best for the private-sector stakeholders, in particular for service providers. Establishing mandatory requirements for AI applications can reduce fragmented practices and enhance cross-border activities. However, it should be noted that limiting these requirements to a specific category of AI applications only, as described in Option 3a, can leave some risky application out of the regulatory framework. Therefore, requirements being limited to ""high risk"" AI applications, as it is described in Option 3b, on basis of two criteria as set out in the White Paper (sector and specific use/impact on rights or safety) would be optimal. The Commission's newly published short summary report from the public consultation on Artificial Intelligence indicates a divided opinion on the issue but we think that some sectors are fragile or, in other words, risky, in nature due to the information they use or to the scope. For example, regulating facial recognition does not prevent risks raised by other AI applications in healthcare. However, this approach requires constant and periodical reviews. A periodically reviewed public list can be a possible solution with particular attention to the delisting activities since compliance requires providers to spend time and resources. 
 
Finally, in our view, a ""trustworthy-by-design or default"" system, like the successful application introduced by the GDPR, can be an alternative option. This would prevent incorrect application at the development phase and assure the trustworthiness and explainability of an AI application. 
 
Sincerely"
APDSI - Associação para a Promoção e Desenvolvimento da Sociedade da Informação (Portugal),"● Âmbito: ○ Não nos parece adequado expandir o âmbito do futuro regulamento de IA para a categoria aberta de ""tomada de decisão automatizada"". Isso iria contra a ideia inicial refletida no Livro Branco da IA, que propõe concentrar-se e basear-se no risco e no duplo critério para as tecnologias de IA setoriais e de aplicação/utilização. Se a IA fosse definida como ""tomada de decisão automatizada"" para efeitos da futura regulamentação, este...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550875_en,7,F550875,10 September 2020,APDSI Secretariado,Non-governmental organisation (NGO),APDSI - Associação para a Promoção e Desenvolvimento da Sociedade da Informação,Micro (1 to 9 employees),TR 435520331024-09,Portugal,Artificial intelligence – ethical and legal requirements,"● Âmbito: 
○ Não nos parece adequado expandir o âmbito do futuro regulamento de IA para a categoria aberta de ""tomada de decisão automatizada"". Isso iria contra a ideia inicial refletida no Livro Branco da IA, que propõe concentrar-se e basear-se no risco e no duplo critério para as tecnologias de IA setoriais e de aplicação/utilização. Se a IA fosse definida como ""tomada de decisão automatizada"" para efeitos da futura regulamentação, este conceito criaria obrigações regulamentares que dificultariam o desenvolvimento e a implantação de aplicações baseadas em IA na Europa bem como de sistemas automatizados que não representam qualquer risco ou dano.

● Opções políticas:
○ Opção 0 (base): Acreditamos que há mérito em assegurar que o regulamento existente da UE é devidamente implementado no que diz respeito à IA, antes de se estabelecerem quaisquer novas regras prescritivas específicas para a IA. 
Atualmente, a IA não funciona no vácuo legislativo, está sujeita a uma série de regras existentes, incluindo o RGPD, o regulamento sobre os dispositivos médicos, e o acervo dos direitos fundamentais.

○ Opção 1 (intervenção liderada pela indústria): Independentemente das opções de políticas públicas que sejam seguidas, é útil dar apoio à indústria na definição e implementação de normas que estabeleçam práticas responsáveis e partilha das mesmas. 

○ Opção 2 (legislação sobre rotulagem voluntária): Parece-nos uma ideia interessante mas somos céticos em relação à eficácia da adesão a este instrumento que pode tornar-se um encargo administrativo para as PME que poderia pesar mais e prevalecer significativamente, em relação aos benefícios que traria.

○ Opção 3 (legislação com requisitos obrigatórios): No geral, o custo de oportunidade da não utilização da IA deve fazer parte da avaliação quando se considera qualquer legislação destinada a reduzir o risco e os danos decorrentes da utilização de aplicações de IA. A legislação deve garantir a segurança jurídica, ser proporcional e aumentar a confiança na IA, sem prejudicar, indevidamente, a inovação conduzida pela mesma. 

■ 3a: Os sistemas de identificação biométrica remota podem ser um bom exemplo de uma aplicação à qual poderiam ser aplicados requisitos obrigatórios numa abordagem baseada no risco.

■ 3b: Apoiamos uma abordagem bem definida, baseada no risco, ao regulamento sobre IA, que tenha em conta tanto a gravidade como a probabilidade de dano. Critérios de base de utilização/aplicação e setoriais - tal como proposto pelo Livro Branco da Comissão Europeia - parecem em geral ser um bom ponto de partida.

■ 3c: Advertimos contra um ato legislativo da UE para todas as aplicações possíveis de IA, que não faça distinção entre as aplicações de IA que possam representar um risco/perigo significativo e as que não comportam riscos ou têm um perfil de risco inferior. Tal instrumento legislativo seria significativamente desproporcional aos problemas até agora identificados pela CE, criaria barreiras significativas à adoção de IA na Europa, resultaria em custos de oportunidade em algumas aplicações devido à falta de implementação de IA, e arriscar-se-ia a baixar a fasquia para aquelas aplicações de IA que são muito suscetíveis de levantar riscos significativos.

● Aplicação da regulamentação:
○ Apoiamos a aplicação ex post, para quando os problemas surgirem, como sendo o mecanismo mais apropriado e proporcional, exceto em campos onde as avaliações ex ante já são prática estabelecida. Nestas situações, recomendamos o alinhamento de qualquer avaliação ex-ante com os procedimentos existentes.

○ Uma abordagem prática, mais eficiente que a avaliação ex-ante por terceiros, consistiria em que os reguladores fornecessem modelos detalhados e orientações sobre como realizar e documentar a avaliação de risco, delegando porém, a responsabilidade àqueles que utilizam o sistema de IA e estão mais familiarizados com este, a fim de realizar uma avaliação precisa."
Association for Financial Markets in Europe (AFME) (Belgium),Please see the attached submission from the Association for Financial Markets in Europe (AFME),https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550864_en,7,F550864,10 September 2020,Fiona WILLIS,Company/business,Association for Financial Markets in Europe (AFME),Medium (50 to 249 employees),65110063986-76,Belgium,Artificial intelligence – ethical and legal requirements,Please see the attached submission from the Association for Financial Markets in Europe (AFME)
Agoria vzw/asbl (Belgium),"Agoria is the Belgian federation for the technology industry. We are paving the way for all technology-inspired companies in Belgium pursuing progress internationally through the development or application of innovations and which, together, represent some 300,000 employees. We are proud that more than 1,900 member companies trust in the three pillars of our services: consulting, business development and the creation of an optimal business...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550863_en,7,F550863,10 September 2020,Jelle Hoedemaekers,Business association,Agoria vzw/asbl,Medium (50 to 249 employees),68004524380-10,Belgium,Artificial intelligence – ethical and legal requirements,"Agoria is the Belgian federation for the technology industry. We are paving the way for all technology-inspired companies in Belgium pursuing progress internationally through the development or application of innovations and which, together, represent some 300,000 employees. We are proud that more than 1,900 member companies trust in the three pillars of our services: consulting, business development and the creation of an optimal business environment.

Agoria thanks the European Commission for its efforts to foster Artificial Intelligence and for the opportunity to provide inputs regarding its Proposal for a legal act laying down requirements for Artificial Intelligence, which presents several options for future legislation. 

Firstly, Agoria is in favour of Option 1 of the alternative options to the baseline scenario, i.e. EU “soft law”, implying a non-legislative approach to facilitate and spur industry-led intervention without putting forward an EU legislative instrument. In addition, we believe that a “soft law” approach could build upon existing national initiatives and encourage a quicker industrial transformation using AI-driven systems to automate and reinvent fundamental industrial processes. Secondly, we acknowledge that others may see specific risks relating to the usage of AI in certain situations, justifying a legislative intervention. However, we must stress that the possibility of such risks arising at some point in the future does not imply that this is the case today, neither sporadically nor systematically. We urge the European Commission to analyse what is wrong in practice, before considering the optimal means of resolving these issues. Once this is clear, requirements for these specific high-risk situations will become evident and remedies may be needed. Where remedies are needed, enforcement methods should be considered, but not beforehand. Suggesting ex-ante enforcement mechanisms without any background is causing a lot of uncertainty, and SME’s specifically will be put at a disadvantage by this. 

Agoria believes that before choosing any option for a legislative intervention, existing regulation must be analysed carefully, identifying potential gaps precisely. This analysis should help to propose the adequate tools to fill those gaps and to establish a legally sound definition of AI. Given that AI has many meanings for different people and that many definitions of this term exist already, it is vital for the success of any AI related legislative action to define AI in a robust way. The most important aspect to keep in mind is that AI is not a product in itself, but rather a technology embedded in products, services and applications, which may be used in an extensive array of sectors, which puts all concerns related to AI in another perspective. For example, the health sector is already heavily regulated, and additional requirements should fit into the existing mechanisms. Additional unnecessary AI-related requirements within the EU product legislation should be avoided."
Visa Europe (United Kingdom),Please see attached file.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550862_en,8,F550862,10 September 2020,Pedro Simoes,Company/business,Visa Europe,Large (250 or more),61954192201-58,United Kingdom,Artificial intelligence – ethical and legal requirements,Please see attached file.
Workday (United States),"Please find attached Workday's comments on the Inception Impact Assessment Best regards, Jens-Henrik Jeppesen Director, Public Policy, EMEA",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550853_en,8,F550853,10 September 2020,Jens-Henrik Jeppesen,Company/business,Workday,Large (250 or more),021253717373-58,United States,Artificial intelligence – ethical and legal requirements,"Please find attached Workday's comments on the Inception Impact Assessment

Best regards,

Jens-Henrik Jeppesen
Director, Public Policy, EMEA"
EDiMA (Belgium),"EDiMA welcomes the opportunity to provide feedback on this Roadmap. EDiMA and its members can offer insight into the interplay between the technical aspects of AI and its broader impact on the economy and society, and are committed to maximising the benefits of AI for Europe. While the current and potential benefits of AI are numerous, concerns about AI are important and legitimate, and should not be discounted. Developments in AI are...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550846_en,8,F550846,10 September 2020,EDiMA EDIMA,Business association,EDiMA,Micro (1 to 9 employees),53905947933-43,Belgium,Artificial intelligence – ethical and legal requirements,"EDiMA welcomes the opportunity to provide feedback on this Roadmap. EDiMA and its members can offer insight into the interplay between the technical aspects of AI and its broader impact on the economy and society, and are committed to maximising the benefits of AI for Europe. While the current and potential benefits of AI are numerous, concerns about AI are important and legitimate, and should not be discounted. Developments in AI are advancing quickly and will have a transformative impact on our society, so we agree with the Commission on the importance of fostering an ecosystem of trust.

The need for a clear, workable definition 
A crucial prerequisite for targeted and effective regulation will be to clearly define AI. A delicate balance needs to be struck between avoiding an overly-broad definition, encompassing all contemporary software systems, and an excessively narrow definition, which could quickly become outdated due to the rapid pace of digital innovation.
A sensible definition of ‘high-risk AI’ is also vital, and the two-step approach proposed in the EC’s White Paper goes in the right direction. We strongly recommend removing vague and open-ended clauses from the risk definition - such as ""exceptional instances"" and ""immaterial damage"" - to improve legal certainty and avoid any potential overreach. The process to decide whether new sectors should be added to the list of ‘high-risk sectors’ must also be robust and transparent, also considering the views of relevant experts and consulting with all stakeholders.

A balanced approach to tackle future AI challenges
EDiMA members continue to agree with the White Paper’s viewpoint that regulatory oversight should  be limited to applications carrying the highest risks for users A legislative instrument covering all types of AI applications - regardless of risk of harm, as mentioned in the Roadmap - would be unnecessary and disproportionate, with detrimental implications for innovation and competitiveness in the European economy, as well as for consumers. A wide intervention also bears its own risks in limiting certain AI technologies which are themselves known to reduce harm.  Furthermore, we believe that most of the concerns raised by AI applications are addressed through existing legislation, and there is merit in ensuring that this is properly implemented before putting in place any new AI-specific rules. For example, the GDPR, while the P2B Regulation and new consumer rules have recently revised transparency requirements for ranking guidelines.
We would also caution against the expansion of the scope of future AI regulation to the open-ended category of “automated decision making” – to do so would risk creating disproportionate regulatory obligations that would deter the development of automated systems that do not pose any risk nor harms.

Industry-led intervention: the most flexible way to anticipate and overcome AI challenges
EDiMA strongly believes that the best way to ensure that AI is trustworthy, secure and respectful of EU values and rules is a combination of ex-ante risk self-assessment and ex-post enforcement for high-risk AI applications.
Concerns related to AI are mostly factored into the development stages of the technology. Accounting for potential risk and having strong processes in place can help to minimise risks, which is essential to creating high quality products and services. An example of such a process is checking the quality of the datasets within the model used to train it, and by performing rigorous testing. It is essential that these processes are flexible in order to adapt to widely different applications of AI. Such a flexibility would also be needed if a single voluntary labelling system was to be considered. AI labelling system that is not flexible enough could quickly become outdated and provide false assurances to consumers, undermining their trust in AI applications. 

We look forward to working with the Commission on AI in the future."
Confederation of Industry of the Czech Republic (Czechia),Please find attached,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550845_en,8,F550845,10 September 2020,Ondřej Ferdus,Business association,Confederation of Industry of the Czech Republic,Medium (50 to 249 employees),785320514128-81,Czechia,Artificial intelligence – ethical and legal requirements,Please find attached
(FERMA) Federation of European Risk Management Associations (Belgium),"The Federation of European Risk Management Associations (FERMA) welcomes the opportunity to comment on the Commission’s Inception Impact Assessment, specifically on the relevant policy options and policy instruments in the area of Artificial Intelligence. Our input here is complemented by our attached position paper. FERMA brings together 22 risk management associations in 21 countries. They represent nearly 5000 professional risk managers...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550840_en,8,F550840,10 September 2020,Charles Low,Business association,(FERMA) Federation of European Risk Management Associations,Micro (1 to 9 employees),018778010447-60,Belgium,Artificial intelligence – ethical and legal requirements,"The Federation of European Risk Management Associations (FERMA) welcomes the opportunity to comment on the Commission’s Inception Impact Assessment, specifically on the relevant policy options and policy instruments in the area of Artificial Intelligence. Our input here is complemented by our attached position paper. 

FERMA brings together 22 risk management associations in 21 countries. They represent nearly 5000 professional risk managers active in a wide range of business sectors. Risk managers utilise a number of tools and methodologies for measuring risk, particularly Enterprise Risk Management (ERM) and the ‘Three Lines of Defense’ model. ERM and the ‘Three Lines of Defense’ have already been applied effectively in the digital context, such as GDPR and cybersecurity, and have proven build organisations’ capacity to mitigate and assess risk. 

We are therefore encouraged to see that the Commission has incorporated a risk-based approach to AI. The promotion and utilisation of risk management methodologies such as ERM and the ‘Three Lines of Defence’ can help organisations support such a risk-based approach. On this note, FERMA is committed proactively contribute its risk management expertise to the work of the European Commission to ensure a robust ‘risk-based approach’ is enshrined in AI legislation moving forward.

FERMA believes it is important to balance any future legislation against the clear need for innovation and market development. At the current stage of market maturity, FERMA is in favour of applying broad, market-based principles. With specific reference to the policy options presented in the Inception Impact Assessment document, FERMA supports Options 2, and 3. B therefore believes that Option 4, which would see a combination of policy tools being used that take into account the different levels of risk of particular AI applications, is ultimately the most sensible approach.

In addition to the comments above, FERMA takes the view that AI raises a number of concerns related to liability. This is why FERMA believes that the existing European legislative framework in this area, the Product Liability Directive, needs to be re-examined before creating a new liability regime specific to AI. To that end, FERMA believes the primary goal of action in this area should be to ensure legal certainty since this will allow risk managers and the insurance industry to adjust their solutions to market needs. 

Even with legal certainty, AI will always pose risks. To mitigate AI-related risk, FERMA recommends the Commission to create a mix of ex-ante incentives to encourage regulatory compliance based on good-faith disclosures and reasonable transparency requirements, combined with a light-touch ex-post enforcement mechanism.

FERMA remains committed to working with the European Commission to build a holistic AI legislative framework that accounts for risk inherent to AI without stifling innovation."
Keidanren (Japan),"The feedback by AI Utilization Strategy Task Force, Committee on Digital Economy, Keidanren is over 4000 characters. Please find attached file.",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550832_en,8,F550832,10 September 2020,Committee Digital Economy,Business association,Keidanren,Medium (50 to 249 employees),267303827175-27,Japan,Artificial intelligence – ethical and legal requirements,"The feedback by AI Utilization Strategy Task Force, Committee on Digital Economy, Keidanren is over 4000 characters. Please find attached file."
Anonymous,Se attachment,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550805_en,8,F550805,09 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,Se attachment
ACEA (European Automobile Manufacturers Associations) (Belgium),"ACEA welcomes the opportunity to comment on this Inception Impact Assessment on a potential initiative on AI. AI represents a key technological area for the entire automotive value-chain and EU industry at large. We therefore endorse Commission’s plans to mobilise EU resources and R&D efforts, as no Member State alone could support our global competitive standing in this field. However, for the EU to remain competitive against global players...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550804_en,8,F550804,09 September 2020,Marta Marazzi,Business association,ACEA (European Automobile Manufacturers Associations),Small (10 to 49 employees),,Belgium,Artificial intelligence – ethical and legal requirements,"ACEA  welcomes the opportunity to comment on this Inception Impact Assessment on a potential initiative on AI.

AI represents a key technological area for the entire automotive value-chain and EU industry at large. We therefore endorse Commission’s plans to mobilise EU resources and R&D efforts, as no Member State alone could support our global competitive standing in this field. However, for the EU to remain competitive against global players and preserve its innovation power, a light-touch and sectoral approach to regulation is advisable. A horizontal AI initiative would not appropriately address the automotive sector’s specificities: hence, ACEA recommends policymakers to integrate new potential AI requirements in the sectoral legislation.

The automotive sector is already subject to strict ex-ante conformity controls (Type-Approval) and ex-post (CoP, Market surveillance, in-service compliance). Before adopting any proposed option, Commission is encouraged to consider where existing vertical certification requirements and regulatory frameworks can be used in a way to promote technological innovation and completed where necessary with practical guidelines. Only afterwards should gaps be determined. If legal gaps exist based on demonstrable evidence, new potential AI requirements should be included in the existing sectoral frameworks. This is essential to prevent duplication or invalidation of certification testing and market surveillance for the AI Regulatory Framework and European Union Whole Vehicle Type Approval (potential AI requirements put forward in the AI White Paper are well-established in the processes governing the automotive sector and tackled by applicable legislation).

In the specific case of automated driving, regulation should take into account the level of automation and vehicle behavior (functional requirements and methods for validating the function) rather than the technology used for implementing transport automation – something which would allow for a technology neutral approach to regulation. The work carried out at UN level on automated driving, where DG GROW is actively involved, goes in this direction: the recently adopted UN regulation on Automated Lane Keeping Systems is an example of how safety relevant aspects can be covered; also the concept of a future Automated Driving Systems will incorporate all safety aspects including those related to the specificities of using AI algorithms for driving functions. Coordination and alignment with UNECE WP.29 and DG GROW are crucial.

It is in the interest of vehicle manufacturers to put on the market/on road vehicles that comply with the maximum safety and ethical standards. Safety validation is ensured by provisions dictated in the Vehicle Type Approval/General Safety Regulation. In parallel, in order to accelerate the adoption of practical tools nurturing the objectives of the HLEG Ethical principles for AI, vehicle manufacturers support, as suggested in this Inception Impact Assessment, the further development of industry-led initiatives (e.g. standards/codes of conduct) for implementing road transport automation and promoting the deployment of AI in a way that secures greater trust in and public acceptance of new technologies. 

ACEA calls for a risk-based approach for the assessment/classification of AI applications, carried out on a case-by-case basis and by applying a set of criteria. A narrow definition of high-risk is required, so to avoid moderate risk/narrow AI use cases being classified as high-risk and being overregulated. Criteria for the risk assessment should be spelled out and consist of factors, such as: safety-relevancy, autonomy of learning, autonomy of decision-making, type of algorithmic model, potential impact of AI systems on a larger group of people. It is finally recommended that the remits of existing type-approval authorities are extended to cover in-vehicles AI applications, so that the sectoral expertise is further enhanced."
EnBW Energie Baden - Württemberg AG (Germany),"As EnBW Energie Baden-Württemberg AG we welcome the approach of European Commission to conduct an Impact Assessment concerning ethical and legal requirements for AI. For several years already we have developed AI solutions in the energy sector. As operator and service provider in the field of critical infrastructures, we at EnBW operate multiple self-developed AI services already productively. These include AI-assisted overhead power line...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550748_en,8,F550748,09 September 2020,Josua Semme,Company/business,EnBW Energie Baden - Württemberg AG,Large (250 or more),13324391892-74,Germany,Artificial intelligence – ethical and legal requirements,"As EnBW Energie Baden-Württemberg AG we welcome the approach of European Commission to conduct an Impact Assessment concerning ethical and legal requirements for AI. For several years already we have developed AI solutions in the energy sector. As operator and service provider in the field of critical infrastructures, we at EnBW operate multiple self-developed AI services already productively. These include AI-assisted overhead power line inspection by using drones, predictive maintenance of offshore wind turbines, securing public places by means of AI-assisted barrier systems, automatic detection of road damage and detection of damage to gas and water pipes. Lately we have been awarded “AI-Champion of Baden-Württemberg” - as EnBW we would like to share our expertise in an ecosystem of excellence in the EU.

Our view on the outlined alternative options to the baseline scenario:

Option 3c would most probably be an overall inhibitor as from the start.

3b puts up heavy hurdles for some selected sectors. As outlined in the white book on AI, the energy sector would suffer under this form of general suspicion of being a “high-risk” sector (white paper on AI, page 17). The first criterion already gives rise to fears of bureaucracy, while being too broad at the same time. In the coming years we need room for innovation instead of discrimination of individual sectors. For a risk-assessment of particular applications, a clear definition of “high-risk” would be very much needed from an industrial perspective. Rather soft measures (e.g. guidelines or other approaches which leave room for innovation) should be preferred before introducing bureaucratic certification processes.

Concerning the outlined alternative options to the baseline scenario, we would advocate option 2. A voluntary labelling scheme would complement the existing EU legislation, which already sets high standards for example concerning liability (e.g. the product safety directive for products) or personal data (GDPR). A good example to operationalise AI ethics using labels can be found under: https://www.ai-ethics-impact.org/en

Similarly, page 19 of the German report on the data ethics commission lines this out. (https://www.bmjv.de/SharedDocs/Downloads/DE/Themen/Fokusthemen/Gutachten_DEK_Kurzfassung.html;jsessionid=6202CA13F73BDB281E78F2F374F783E8.1_cid334?nn=11678504)

Because of the diversity of products, services, customers and processes, it would be best to have individual labels and industry-inspired processes to qualify. Common guidelines might be helpful. For customers and employees it is important to understand the path of getting to a label – transparency is important, explainability creates trust."
EGMF (Belgium),"EGMF, the European Garden Machinery Federation, would like to provide its feedback in the attachment, on the Commission inception impact assessment regarding a proposal for a legal act on AI requirements.",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550741_en,8,F550741,09 September 2020,Ioana Smarandache,Business association,EGMF,Micro (1 to 9 employees),82669082072-33,Belgium,Artificial intelligence – ethical and legal requirements,"EGMF, the European Garden Machinery Federation, would like to provide its feedback in the attachment, on the Commission inception impact assessment regarding a proposal for a legal act on AI requirements."
Enel SpA (Italy),"Dear Members of DG CNECT .A.2, Enel SpA, a multinational company in the energy sector, highly appreciates the EC proposal for a legal act laying down requirements for Artificial Intelligence. At Enel, we use Artificial Intelligence and technology to make the energy and power systems more efficient, more predictable and more sustainable, making easier for our customers to interact with us and to play a more active role in the energy system...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550740_en,9,F550740,09 September 2020,Almudena Díaz,Company/business,Enel SpA,Large (250 or more),6256831207-27,Italy,Artificial intelligence – ethical and legal requirements,"Dear Members of DG CNECT .A.2,
Enel SpA, a multinational company in the energy sector, highly appreciates the EC proposal for a legal act laying down requirements for Artificial Intelligence. 

At Enel, we use Artificial Intelligence and technology to make the energy and power systems more efficient, more predictable and more sustainable, making easier for our customers to interact with us and to play a more active role in the energy system, mainly in the liberalised energy market.

The European digital strategy released on February this year, stresses that citizens need to be able to trust the technology itself as well as the way in which it is used. The European Commission White Paper on AI, maps out various policy options and reveals that clear and mandatory requirements would “in principle” apply only to AI systems or applications which are considered ‘high-risk’, i.e. employed in sectors where significant risks can be expected to occur, or used in such a manner that significant risks are likely to arise.

In line with the non-binding Ethics Guidelines by the AI HLEG, the White Paper on AI suggested that the mandatory requirements for high-risk systems could cover the following aspects:
• Training data;
• Data and record-keeping;
• Information to be provided;
• Robustness and accuracy, with an ex-ante consideration of the potential risks;
• Human oversight;
• Specific requirements for certain AI applications, such as remote biometric identification.

Considering this and welcoming a risk-based approach, Enel advices the European Commission that the risks are in the infringement, not in the technology or in the sector and, recommends to assess and establish the characteristics of different types of risks and threats with a ‘sector-by-sector’ approach, requiring inter alia a ‘sectoral’ data protection assessment. 
Within this view, the different classes of use-cases must be integrated. It is worth noting that in the energy sector, which is considered “high-risk” according to section C of the White Paper, all its AI based applications cannot systematically be categorised such as “high-risk”. 

For instance, an application utilised to interact online with clients about customer care activities will normally not pose risks of such significance to justify, at this time, legislative intervention. Possible mandatory legal requirements to be imposed on high-risk applications should be carefully evaluated before establishing them as (ex-ante) obligations for businesses.

Enel believes also necessary to better define ‘high-risk’ and the methodology to assess it. Poor categories and definitions might deter private investments and become a competitive disadvantage to European companies. 

Given the actual economic crisis together with the financial risk nature of research and innovation activities, Enel urges the Commission to build a financial structure to back organisations involved in the mentioned ‘high-risk’ sectors. If the EU system is not supportive towards innovation, the opportunity for innovations to come from Europe will be reduced.

Therefore, the Enel Group promotes the development of long-term European action plans on digital policy, which should be evidence-based, promote security by design, guarantee high data quality standards, promote ethical evaluation for different use cases and enable new technologies and business models, without imposing unnecessary burdens and costs nor obstacles to innovation."
The Good Lobby (Belgium),"The Good Lobby welcomes the opportunity of providing feedback on this legislative initiative. Without a doubt, Artificial Intelligence (AI) is already changing the world, its potential impacts having long been discussed and analysed. Other than the many benefits of this technology, presented by the Commission both in its White Paper and in its Communication on AI, it also poses numerous risks, some of which have been highlighted in the same...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550729_en,9,F550729,09 September 2020,Alexandru Circiumaru,Non-governmental organisation (NGO),The Good Lobby,Micro (1 to 9 employees),,Belgium,Artificial intelligence – ethical and legal requirements,"The Good Lobby welcomes the opportunity of providing feedback on this legislative initiative. Without a doubt, Artificial Intelligence (AI) is already changing the world, its potential impacts having long been discussed and analysed. Other than the many benefits of this technology, presented by the Commission both in its White Paper and in its Communication on AI, it also poses numerous risks, some of which have been highlighted in the same documents and in the Ethics Guidelines prepared by the High-Level Expert Group on AI. Therefore, we believe it is encouraging and commendable that the European Commission pays close attention to the way in which AI can be regulated and that this is the right time for it to do so.

Looking at the options provided, The Good Lobby strongly supports a combination of options 2, 3a, and 3b. The risks that AI poses, which are very much present, with plenty of concrete examples of biased algorithms from the past 12 months alone, are too great to be addressed through a soft-law approach. We believe that in order to address these risks appropriately there is a need for a decisive and comprehensive legislative intervention. 

While a voluntary labeling scheme - option 2 - is not in and of itself sufficient, we recognise that there is some value to this idea. As suggested in the White Paper, such an approach could be appropriate for low-risk applications of AI. Nevertheless, we are not persuaded that it would properly address the challenges posed by high-risk AI.

While option 3c would have the advantage of minimising the risk of fragmentation and uncertainty, it would also greatly stifle innovation and have negative consequences over the development of AI in Europe, discouraging organisations, and in particular SMEs, from engaging with this technology.

We do not support regulating only certain categories of AI. Such an approach has the risk of being too narrow, too broad, or both too narrow and too broad depending on the circumstances. Should that happen, there is a danger that certain applications of AI that pose considerable risks would not be considered because they do not fall within a certain more loosely or narrowly defined category or that low-risk applications from one such category are overly regulated. Nevertheless, we see value in option 3a and that is why we are recommending it is pursued, together with options 3b and 2 as discussed above. The value we see is related to regulating certain particular uses of AI, for example, remote biometric identification systems. In such a case the risks are so clear and blatant that comprehensive regulation is, without a doubt, necessary.

From the options put forward, the most appropriate, in our view, is option 3b despite the difficulties with defining different categories of risks accurately and efficiently, which have been repeatedly emphasised and the risks of fragmentation and uncertainty already discussed. While the White Paper does provide two criteria on which risks could be assessed, this is just the beginning of a difficult process of setting out categories of risks which will have to be kept under constant review and flexible enough to allow for modifications where necessary.

From the two criteria provided, we believe that risks should be calculated taking into account the impact on rights and safety rather than the sector and specific use. As we talk about a human-centric approach, it seems only fitting that this should be the case.

On enforcement, The Good Lobby believes that for it to be effective, it needs to combine an ex-ante mechanism, which to allow for the scrutiny and questioning of the design of an AI system with an ex-post approach, to review how the system is actually working and the concrete decisions it produces to allow for correction of legal errors and the intervention of human oversight - or equity and mercy, as described by Lord Sales."
Big Data Value Association (Belgium),"BDVA welcomes the possibility to provide feedback on the Inception Impact Assessment concerning a Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence. As already highlighted in BDVA response to the AI Whitepaper, BDVA strongly supports the development of a solid AI European approach based on European values. BDVA response to the AI Whitepaper already focused on one of the key...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550724_en,9,F550724,09 September 2020,Martina Barbero,Other,Big Data Value Association,Micro (1 to 9 employees),042849916153-53,Belgium,Artificial intelligence – ethical and legal requirements,"BDVA welcomes the possibility to provide feedback on the Inception Impact Assessment concerning a Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence. As already highlighted in BDVA response to the AI Whitepaper, BDVA strongly supports the development of a solid AI European approach based on European values. BDVA response to the AI Whitepaper already focused on one of the key themes of the present Inception Impact Assessment and notably the fact that PRCS (Policy, Regulation, Certification, and Standards) issues are pivotal for building an AI ecosystem based on trust and they are likely to become a primary area of activity for the new AI, Data and Robotics Partnership. Building on these considerations and on the response to the AI Whitepaper, BDVA wishes to underline a few important elements concerning both the challenges identified in the Inception Impact Assessment and the possible policy options.

Comments on the issues identified
• European businesses see Industrial AI as more of an opportunity than a threat. However, the business, economic and societal context to which AI is applied needs to be considered as decisions are not made in a vacuum but within the socio-economic context of a society of humans which, in the European case, requires the AI application to be trustworthy. 
• Businesses are aware that AI systems may be used in value chains, and see the possibility that liabilities emerge; for example, when an AI system bases its outputs on data that is created by another AI system from a value chain partner. 
• Requirements on AI algorithms may have to be scoped carefully; usually, an algorithm is trained before it can be used operationally (it is called a model, then) and in such case, the training data is also part of the behaviour of the AI system. Thus, requirements for AI systems may have to be extended to training data as well. It may even be considered that the specific business process in which the AI system operates can be seen as part of the algorithm, or that the design criteria (including team composition and stated business goals) could be in scope. This will become complex, so careful scoping is needed.
Comments on the policy options
• Many stakeholders see certification in relation to AI systems as a critical trust-building mechanism for adoption of AI solutions. A methodological approach to certification could include best practice from other sectors being mapped to AI in tandem with the Standardization Landscape approach. Standards provide the foundational documentation for certification, regulation, legislation, compliance and ultimately enforcement.
• Awareness of potential issues needs to be addressed. Voluntary certification and labelling schemes can have several benefits, both for purchasers of the certified AI system as well as for its producer. Such certification increases the confidence of users in AI systems as it indicates the producer’s commitment towards higher safety and quality standards. At the same time, however, voluntary certification should be carefully addressed as it can result in a meaningless label and evens increase non-compliant behaviour when there are no proper verification mechanisms. Voluntary labelling may make end-users more aware, just like Nutriscore intends to make consumers more aware of the features of the food that they are buying. When a voluntary labelling scheme is adopted, producers of AI will also become aware that end users may assess their products or services in a specific way; which will mean opportunities for producers who want to be transparent about their products and services.
• It is already acknowledged in the AI Whitepaper that regulatory intervention should be targeted and proportionate. Such an approach will reduce the risk of overregulation and hence slow down technological innovation. In the Whitepaper the European Commission seemed not to want to regulate all AI systems but"
Romanian Business Leaders - Repatriot (Romania),"O definiție clară și pe larg înțeleasă a IA este esențială pentru eficacitatea viitorului cadru de reglementare. La fel cum Cartea albă a Comisiei privind IA a descris principalele elemente ale IA ca date și algoritmi, la fel și această evaluare a impactului inițial încearcă să sugereze un domeniu de aplicare prea larg pentru reglementarea viitoare a IA. De exemplu, în cazul în care AI ar fi definit ca „luarea de decizii automatizată”, ar...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550710_en,9,F550710,09 September 2020,Marius Raul Bostan,Non-governmental organisation (NGO),Romanian Business Leaders - Repatriot,Large (250 or more),,Romania,Artificial intelligence – ethical and legal requirements,"O definiție clară și pe larg înțeleasă a IA este esențială pentru eficacitatea viitorului cadru de reglementare. La fel cum Cartea albă a Comisiei privind IA a descris principalele elemente ale IA ca date și algoritmi, la fel și această evaluare a impactului inițial încearcă să sugereze un domeniu de aplicare prea larg pentru reglementarea viitoare a IA. De exemplu, în cazul în care AI ar fi definit ca „luarea de decizii automatizată”, ar pierde focalizarea dorită bazată pe risc și ar include sisteme automate care nu prezintă niciun risc. Orice viitoare reglementări AI ar trebui să evite obligațiile de reglementare disproporționate și nejustificate, deoarece altfel ar avea efecte negative asupra dezvoltării și implementării aplicațiilor bazate pe IA în Europa. 

Noile norme prescriptive ar trebui luate în considerare numai în domeniile în care reglementarea existentă este în mod clar insuficientă. 
Industria europeană a IA ar beneficia mai mult dacă Comisia Europeană ar oferi principii directoare pentru auto-reglementare și cooperare  Întreprinderile europene trebuie să dezvolte tehnologii avansate în mod responsabil și noi bariere de reglementare ar frâna dezvoltarea.

Un sistem de etichetare voluntară ar putea crea o povară administrativă grea pentru inovatorii AI care sunt adesea IMM-uri cu resurse limitate. În consecință, costurile unui astfel de sistem ar putea depăși rapid beneficiile încurajării adoptării AI în întreaga Europă. Am dori, în special, să avertizăm că o schemă de etichetare se bazează pe lista de evaluare pentru AI de încredere din Grupul de experți la nivel înalt al UE în domeniul IA, deoarece natura sa limitează inerent variația între setări pentru diferite cazuri de aplicare. Comisia să colaboreze îndeaproape cu industria AI pentru a elabora un meniu de scheme de etichetare pentru diferite setări ale aplicațiilor AI. 

Costul de oportunitate al neutilizării IA va fi foarte mare dacă intervenție de reglementare în aplicațiile de IA nu sunt făcute ""inteligent"". În deliberarea posibilelor opțiuni, este vital să reflectăm nu numai prejudiciile potențiale, ci și oportunitățile sociale. Beneficiile AI vor depăși adesea riscurile, mai ales dacă riscurile pot fi atenuate într-un mod atent, cu garanții puternice. Regulamentul nu trebuie să descurajeze inovarea, dezvoltarea și nici să limiteze utilizarea AI. Proporționalitatea și concentrarea clară a oricărei reglementări vor contribui la asigurarea certitudinii juridice pentru inovatorii AI și vor spori încrederea în AI, fără a împiedica în mod nejustificat inovația bazată pe AI.

Viitoarea reglementare AI ar fi bine să se refere doar la aplicații AI cu „risc ridicat”, bine definite. Aș sublinia sublinia necesitatea proporționalității atunci când definim aplicațiile „cu risc ridicat” ale IA. Procedând astfel, este important să reflectăm la probabilitatea de a face rău și nu doar posibila gravitate a prejudiciului. De asemenea, ar trebui să țină cont de contextul operațional mai larg atunci când se evaluează riscul, deoarece aceeași aplicație de IA utilizată în același scop va prezenta riscuri diferite în funcție de modul în care este integrată în operațiunile comerciale (de exemplu, amploarea supravegherii umane , măsuri de protecție suplimentare , cum ar fi monitorizarea). Poate o combinație de sector și utilizare / aplicație ca criterii pentru a stabili abordarea bazată pe risc.    

Vătămarea imaterială nu este un concept legal cunoscut și ar putea însemna orice, de la pierderi economice la inhibarea încrederii, și ar putea duce la incertitudine juridică, descurajând investițiile și inovația. Pentru a aduce claritate practică inovatorilor AI ar fi cel mai bine să se ia în considerare un concept alternativ - „restricționarea semnificativă a exercitării drepturilor fundamentale”, care credem că ar fi mai ușor de interpretat și aliniat cu cadrul legislativ existent."
Vodafone Group (United Kingdom),"Vodafone welcome the opportunity to respond to the European Commission Roadmap Inception Impact Assessment (IIA) on the proposal for a legal act of the European Parliament and council laying down the requirements for AI to operate within the single market. These comments, alongside our full response to the AI white paper consultation falls within the wider plan we have established for supporting Europe through the Coronavirus crisis and...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550700_en,9,F550700,09 September 2020,Matt Allison,Company/business,Vodafone Group,Large (250 or more),,United Kingdom,Artificial intelligence – ethical and legal requirements,"Vodafone welcome the opportunity to respond to the European Commission Roadmap Inception Impact Assessment (IIA) on the proposal for a legal act of the European Parliament and council laying down the requirements for AI to operate within the single market. These comments, alongside our full response to the AI white paper consultation falls within the wider plan we have established for supporting Europe through the Coronavirus crisis and helping to rebuild our economies and societies thereafter. In addition to our five point plan to respond to the immediate health crisis, Vodafone has developed a long term package of measures to assist with the recovery from the protracted economic crisis we are entering into. 
Adoption of AI and data driven tools is a vital part of this strategy and Vodafone wholeheartedly supports the objective of the European Commission to encourage the development of an ecosystem of excellence and an ecosystem of trust for AI development and adoption in Europe. We consider that increased use of AI and data driven technology is a necessary precondition for establishing a resilient European digital society.
On the key areas of regulation proposed by the Commission to establish a clear and predictable legal framework for AI operating within the single market, Vodafone has the following holds the following high level views: 
• Regulation of high-risk AI: We broadly support the approach outlined by the Commission to avoid duplication of existing regulatory obligations, and ensure that any new requirements are proportionate and strictly targeted at AI applications that pose a high risk. 
• Voluntary labeling: We raise particular concerns with the lack of focus given to incentives to develop Trustworthy AI (voluntary labeling, certification, industry codes) and ask for more clarity on how such a labeling scheme would be established and maintained.
• Product Liability: we note that the existing EU horizontal and sector-specific legislative framework governing liability has proven to be robust and reliable. Any new requirements should be targeted at providers of high-risk AI applications & must not impose excessive high burdens on industry deploying AI that presents a low risk to EU citizens. 
• Access to data: we underline the importance of availability of high quality training data for AI, to ensure that European businesses can continue to innovate and succeed in this field, and call for joined up policy making in view of the EU Data Strategy and legislative actions outlined therein. 
Our views on the specific policy options contained in the roadmap can be found in the attached PDF."
Deutsche Gesetzliche Unfallversicherung e.V. (Germany),"Aus Sicht der Deutschen Gesetzlichen Unfallversicherung e.V. (DGUV) ist ein Rechtsrahmen, mit dem Fälle des Einsatzes von Künstlicher Intelligenz (KI) angemessen behandelt werden können, grundsätzlich wünschenswert, aber es gilt vorrangig zu prüfen, ob der bestehende allgemeine, d.h. nicht spezifisch auf KI ausgerichtete, Rechtsrahmen nicht in den meisten Fällen ausreichend ist, um auch Fälle des Einsatzes von KI angemessen zu behandeln. In...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550657_en,9,F550657,09 September 2020,Ann-Kathrin Schäfer,Other,Deutsche Gesetzliche Unfallversicherung e.V.,Large (250 or more),,Germany,Artificial intelligence – ethical and legal requirements,"Aus Sicht der Deutschen Gesetzlichen Unfallversicherung e.V. (DGUV) ist ein Rechtsrahmen, mit dem Fälle des Einsatzes von Künstlicher Intelligenz (KI) angemessen behandelt werden können, grundsätzlich wünschenswert, aber es gilt vorrangig zu prüfen, ob der bestehende allgemeine, d.h. nicht spezifisch auf KI ausgerichtete, Rechtsrahmen nicht in den meisten Fällen ausreichend ist, um auch Fälle des Einsatzes von KI angemessen zu behandeln.
In der Stellungnahme der Deutsche Sozialversicherung Arbeitsgemeinschaft Europa e.V. (DSVEV) zum Weißbuch zur Künstlichen Intelligenz wurde bereits festgehalten, dass der von der Europäischen Kommission vorgeschlagene „risikobasierte“ Ansatz im Prinzip zu befürworten ist, wenn von Fragen nach der Haftung, die unabhängig vom Risiko für den Einzelnen oder die Allgemeinheit zu beurteilen sind, abgesehen wird. Soweit die Sozialversicherung und die durch sie finanzierten Leistungen betroffen sind, ist zunächst keine Notwendigkeit für eine generelle Regelung durch Anpassung des bestehenden EU-Rechtsrahmens unter Berücksichtigung von KI erkennbar. Durch KI aufgeworfene Fragen sind weder neu noch mithilfe von allgemeinen Grundsätzen zu beantworten, sondern bedürfen je nach konkretem Fall komplizierter Abwägungen und Kompromisse. Vor diesem Hintergrund bietet jedenfalls eine generelle Regelung keinen Mehrwert oder keine zusätzliche Rechtssicherheit. Mithilfe der Auslegung und Fortentwicklung des bestehenden allgemeinen Rechtsrahmens können bereits Lösungen gefunden werden. Es mag ergänzend ein ethischer Rahmen, der weder entwicklungshemmend noch technologiefeindlich ist, denkbar sein und einen verantwortungsvollen Umgang mit KI fördern. Ausgeschlossen ist nicht, einzelne Vorschriften zu überprüfen und auf die Vornahme von Änderungen hinzuwirken.
Kommt man in dem Zusammenhang zu dem Ergebnis, dass der bestehende allgemeine Rechtsrahmen nicht ausreichend ist, scheinen die Optionen 3 und 4 in Bezug auf Produktsicherheit und –haftung vorzugswürdig zu sein."
Zentralverband Elektrotechnik- und Elektronikindustrie e.V. (ZVEI) (Germany),The Zentralverband Elektrotechnik- und Elektronikindustrie e.V. (ZVEI) welcomes the opportunity to provide feedback to the Inception Impact Assessment of the European Commission for a proposal for a legal act of the European Parliament and the Council laying down requirements to stimulate the development and uptake of Artificial Intelligence (AI) and new technologies. AI will be a core enabling technology for many sectors of European industry...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550620_en,9,F550620,09 September 2020,Philipp Goedecker,Business association,Zentralverband Elektrotechnik- und Elektronikindustrie e.V. (ZVEI),Medium (50 to 249 employees),94770746469-09,Germany,Artificial intelligence – ethical and legal requirements,"The Zentralverband Elektrotechnik- und Elektronikindustrie e.V. (ZVEI) welcomes the opportunity to provide feedback to the Inception Impact Assessment of the European Commission for a proposal for a legal act of the European Parliament and the Council laying down requirements to stimulate the development and uptake of Artificial Intelligence (AI) and new technologies.
AI will be a core enabling technology for many sectors of European industry. Therefore, ZVEI supports a European approach. A patchwork of national rules and initiatives in 27 EU Member States must be avoided.
ZVEI welcomes a debate about the risks and opportunities but calls for a very cautious approach when regulating an essential transversal technology. The immense opportunities must not be ignored, innovation and regulation must facilitate the development and uptake of AI. ZVEI would like to bring forward four points:
1) There is currently no need for a new, horizontal regulation for AI technologies, because there is no evidence yet of any fundamental regulatory gaps. Particularly, in the case of AI embedded in products and machines, AI-characteristics (opacity, complexity and scalability) are limited by existing regulation and functional constraints. 
2) The EU-legislator should not regulate specific technologies but should instead target the effects of AI applications in a technology-neutral way. Otherwise, there is a risk of hampering innovation and having to constantly adapt laws to technological progress. After careful assessment of regulatory gaps, AI applications where personal privacy or where life and limbs are at stake should be critically evaluated in a case-by-case approach. Hereby the risk level should be objectively determined in a short range for the beginning by the criticality of the application itself. Transparent and comprehensible criteria are needed to classify AI-based products and services. Legal uncertainty would be a huge barrier to the use of AI, in particular for SMEs and MidCaps, and would hence hamper the use of AI in Europe.
3) We do not see a need for legislative action on product safety. In the General Product Safety Directive, the safety requirements are technology-neutral and expand without preventing technical innovation and thus cover AI applications.
4) ZVEI does not believe that a readjustment of the Product Liability Directive and national liability regimes is needed at this stage. The Product Liability Directive is formulated in a technology-neutral way and the courts have applied it over the years to a wide range of products, many of which did not exist when the Directive was adopted, like AI now.
ZVEI favours a combination of policy option 1 and 3b in the presented Inception Impact Assessment. Policy option 3c (covering all AI) would raise a prohibitive barrier in a important sector of industrial AI and will finally will bring Europe’s industry to fall behind international developments, especially in competition with US and Chinese companies.
-The basis should be a “Soft Law”-approach, which builds upon existing initiatives and guidelines on trustworthy AI across a wide range of experts within the industry. This will not only leave room for cutting-edge AI-solutions, but also allow a precise assessment of the real risks of AI and potential regulatory gaps. The use of “regulatory sandboxes” could help to find this balance. 
-In a second step, if necessary, specific requirements could be established for clearly defined “high-risk”-applications - if they are not covered by existing regulation. It is crucial to focus on ""high risk applications"" and avoid hampering harmless AI-applications. In the industrial context (B2B), AI offer enormous economic potential and is in general uncritical -non-personal machine data is often used to optimise production processes or increase efficiency along the value chain-. This is already covered by a technology open legislation where AI applications do not require further legislation."
NL AIC (Dutch AI Coalition) (Netherlands),"NL AIC welcomes the opportunity to provide feedback to the European Commission’s Inception Impact Assessment on the “Artificial intelligence – ethical and legal requirements” legislative proposal. 1. We support the Commission’s mission to foster the development and uptake of safe and lawful AI that offers legal certainty, a favourable investment climate and an innovation optimum across the Digital Single Market, while respecting fundamental...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550619_en,9,F550619,09 September 2020,Mauritz Kop,Other,NL AIC (Dutch AI Coalition),Large (250 or more),,Netherlands,Artificial intelligence – ethical and legal requirements,"NL AIC welcomes the opportunity to provide feedback to the European Commission’s Inception Impact Assessment on the “Artificial intelligence – ethical and legal requirements” legislative proposal. 
1. We support the Commission’s mission to foster the development and uptake of safe and lawful AI that offers legal certainty, a favourable investment climate and an innovation optimum across the Digital Single Market, while respecting fundamental rights, ensuring inclusive societal outcomes, protecting citizen’s wellbeing and safeguarding our common Humanist moral values.
2. We believe that the EU should step up and take the lead to set global norms and standards that will shape the international Law of AI & Data system. 
3. The EU should use interoperability in combination with data portability as a policy lever. AI & data driven products and services created within the EU or elsewhere in the world should abide by EU benchmarks, together with associated IEC, ISO and NEN standards, before they can obtain a CE-marking and enter the European markets. 
4. AI’s dynamic and elusive nature asks for agile, flexible governance solutions. Designing a system that can quickly adapt to changing circumstances should be a key starting point. 
5. In our view Option 4, ‘a combination of any of the options above taking into account the different levels of risk...’, would best serve the EC’s objectives. Since both innovation incentive & reward mechanisms, as well as safety/security risks vary per industry and per technology, policy makers should differentiate more explicitly between economic sectors when they design their digital governance solutions. We suggest a differentiated risk-based approach that contains industry specific boundary setting requirements and sector-specific AI regimes.
6. We prefer a broad definition of AI (subject matter) that includes synergies with other disruptive tech such as DLT and quantum computing. A broader scope (Option 3c) means more impact (though perhaps more initial costs/investments) and increased long term benefits.
7. To make AI and machine learning thrive, we have to re-examine the applicability and scope of (intellectual) property rights to data, and construct territorially applicable antitrust laws. Forum shopping should be avoided. There should be a right to process (e.g. access, share, analyse, re-use) data for machine learning purposes. We advise against introducing new layers of innovation stifling exclusive rights. A robust public domain, that includes open, democratized data should be promoted in general. 
8. The EU must also provide incentives to build and augment datasets, algorithms and inference systems, by layering traditional and alternative innovation incentive & allocation options such as prizes, subsidies, fines, benchmarks and competitions. 
9. In our view, guidance is an important part of the implementation and enforcement phase of the Law of AI, as explaining its requirements encourages trust, legal certainty and freedom to operate in the data-driven economy.
10. Adjacent to regulation we can see an important role for harmonized AI Impact Assessments such as the Dutch AIIA & Code of Conduct that combines technical, legal and ethical standards, HLEG’s ALTAI and CoE’s Recommendations. Self-regulation alone should never be enough: industries simply do not have the same incentives to promote public good as governments do.
11. Synchronous to a coordinated, differentiated industry-specific approach regarding incentives and risks, the EU should actively shape technology for good and embed norms, standards, principles and values into the architecture of our technology, by means of Trustworthy AI by Design. 
12. Lastly, we believe it is crucial for the EU to work together with countries that share our European digital DNA, based on common interests and mutual values. It is essential to incentivise systematic transatlantic cooperation. Sovereignty will ensure strong partnerships amongs equals."
László Balázs (Hungary),"Tisztelt Európai Uniós Tisztségviselők! A mesterséges intelligenciával (a továbbiakban: MI) összefüggésben az alábbi álláspontot képviselem erkölcsi, morális és jogi formulák tekintetében. Először kénytelen, kelletlen vagyok párhuzamot vonni a biológiai determinizmus és az MI kettősében. Napjainkban pusztító, pandémiás időszak vonulatában a biológiai esszenciális reziduumok jelenléte egyértelműen detektálható. Az anyatermészet a túlszaporulat...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550618_en,9,F550618,09 September 2020,László Balázs,EU citizen,,,,Hungary,Artificial intelligence – ethical and legal requirements,"Tisztelt Európai Uniós Tisztségviselők!

A mesterséges intelligenciával (a továbbiakban: MI) összefüggésben az alábbi álláspontot képviselem erkölcsi, morális és jogi formulák tekintetében.
Először kénytelen, kelletlen vagyok párhuzamot vonni a biológiai determinizmus és az MI kettősében. Napjainkban pusztító, pandémiás időszak vonulatában a biológiai esszenciális reziduumok jelenléte egyértelműen detektálható. Az anyatermészet a túlszaporulat és a népesség kritikus tömeggé növekedése okán fel kellett, hogy állítson egy olyan védvonalat, amivel kísérletet tehet a ""természetes"" közegek, folyamatok visszaállítására, helyrehozatalára. Mindenképp kár ez, vagy érthető reakció arra a felelőtlen kondíció halmazra, amit az emberiség ""követett el"" egy egész homeosztázis, mikrobiom ellen? Utóbbit adekvátabbnak érzem.

Gondolván a kultúránk, társas kultúrák és a vele együtt járó, olykor azokat túllépő tudományos eredményekre úgy vélem, hogy a moralitás, mint az emberiség fejlődésével együtt fejlődő, alakuló archaikus maradvány, nem szabhat gátat annak a metódusnak, amit a tudomány területén dolgozó, kiváló szakemberek elképzeltek. Igazán megközelítve, a morális értékek, jogi szabályozások, közjogi szervezetszabályozó eszközök nem mások, mint ugyanannyira mesterséges - ellenben közösségi igény alapján szerveződött - klisék, mint a tudomány által szerveződött, irányítva alakult, fejlődött ""termékek"", gondolati elemek fizikai síkon való megvalósulása.

Fentieket összegezve kijelenthető, hogy a morális, jogi normák a tudomány eredményeinek, termékeinek tökéletes reprezentánsai. Csupán az előbbiek az emberiség filozofikus kogníciója, míg utóbbiak a tanulás, a tapasztalat és empirizmus mentén szerveződött kognitív kivetülések, tárgyiasulások.

A MI tekintetében fentiek dacára, kijelenthető, hogy senki és Semmi (Heidegger után szabadon) nem kérdőjelezheti meg annak létjogosultságát, főleg annak ismeretében, hogy már maga az emberi lét alapvető gyakorlati elemei, mentális kivetülései és egyéb kognitív alaki reprezentánsai ugyancsak a mesterséges vonalon keletkeződtek. Filozófiai értelemben lehet ennek viszonylatában disputákat folytatni, ellenben, mint minden disputa, ez is csak azt az eredményt hordozná magában, hogy az időt nyújtsa a cselekvés vesztére, kárára.

Az egészségügynek, az atomiparnak, a környezettudatosságnak és számos tudományos, de az emberiség jövőjét garantáló tudásnak, gyakorlatnak, jelentős szüksége van a MI-ra. 

Le kell csupaszítani a MI-vel szemben kialakult sztereotípiákat, aberrált gondolati elemeket, előre vetített negatív érzelmeket; meg kell teremteni a marketing magasabb fokú jelenét, mely végre nem az ""olcsó sörök"" kategóriáját foglalja el, hanem az emberiség elé tár egy sokkal mélyebb, tartalmasabb, és nehezebb területet, a tudományt és MI-t.

Tisztelettel és köszönettel:
Balázs László"
NL AIC (Netherlands),Removed:This feedback was removed as it did not comply with the European Commission's rules for publishing feedback and suggestions. Any feedback that users report to us as inappropriate will be examined and removed if necessary. Please take a look at the rules for feedback and suggestions to learn more about the guidelines for this site.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550611_en,9,F550611,09 September 2020,Mauritz Kop,Other,NL AIC,Large (250 or more),,Netherlands,Artificial intelligence – ethical and legal requirements,
NL AIC (The Netherlands) (Netherlands),Removed:This feedback was removed as it did not comply with the European Commission's rules for publishing feedback and suggestions. Any feedback that users report to us as inappropriate will be examined and removed if necessary. Please take a look at the rules for feedback and suggestions to learn more about the guidelines for this site.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550610_en,10,F550610,09 September 2020,Mauritz Kop,Other,NL AIC (The Netherlands),Large (250 or more),,Netherlands,Artificial intelligence – ethical and legal requirements,
BEUC - The European Consumers Voice (Belgium),BEUC welcomes the opportunity to comment on the Commission’s Inception Impact Assessment for the upcoming proposal for a legal act laying down requirements for Artificial Intelligence. BEUC particularly welcomes that the Commission – contrary to its White Paper published in February 2020 – envisages a new policy option which foresees an EU legislative instrument establishing mandatory requirements for all AI applications and not only for those...,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550609_en,10,F550609,09 September 2020,Ernani Cerasaro,Consumer organisation,BEUC - The European Consumers Voice,Small (10 to 49 employees),9505781573-45,Belgium,Artificial intelligence – ethical and legal requirements,"BEUC welcomes the opportunity to comment on the Commission’s Inception Impact Assessment for the upcoming proposal for a legal act laying down requirements for Artificial Intelligence. BEUC particularly welcomes that the Commission – contrary to its White Paper published in February 2020 – envisages a new policy option which foresees an EU legislative instrument establishing mandatory requirements for all AI applications and not only for those considered as ‘high-risk’. 
Therefore, in terms of the options proposed in the Inception Impact Assessment, and starting with the consideration that option 0 (no regulation) should be discarded, we consider that the most suitable option is option 3 (c) (proposing a legislative act covering all AI applications), and urge the Commission to move in this direction. 
AI and ADM systems impact the daily lives of consumers but operate within a worrying regulatory vacuum. For this reason, BEUC has underlined many times the importance and urgency of intervening to fill this gap and welcomes that the Commission is envisaging a legislative proposal (please see our publications on AI at http://www.beuc.eu/search?keys=artificial%20intelligence). 
As also outlined in our response to the public consultation on the Commission’s White Paper on AI (in attachment and to which we refer for any further information) we think that such a legislative proposal should be as comprehensive as possible. For this reason we would not limit it only to certain sectors or applications. We think such an option is the most respectful of consumers’ demands as well as of the need for businesses to operate within a clear regulatory framework. 
In particular, we believe that the new regulatory framework for AI and ADM must properly address existing consumer concerns and ensure that this technology is developed and deployed in a manner that embeds strong and tangible safeguards during its whole lifecycle. 
The results of a recent survey on consumer perceptions on AI (September 2020 – http://www.beuc.eu/publications/beuc-x-2020-078_artificial_intelligence_what_consumers_say_report.pdf ), where our member organisations collected opinions of consumers from nine different EU countries about AI, indicate that a majority of respondents do not think that current regulation is adequate to effectively regulate AI-based activities and have low trust in authorities to exert an effective control over AI. This lack of trust is even more significant when it comes to the transparency of AI systems. For example, a large part of consumers agreed that companies use AI to manipulate their decisions or that is not clear who is accountable if AI is not secure or causes harm. 
The survey also shows that although consumers believe that AI can bring benefits, they have serious concerns related to personal data protection, unintended consequences and malicious uses. These are transversal and general concerns, even impacting on fundamental rights such as privacy, which do not necessarily depend on the single sector where AI is deployed nor on the specific system being used. 
This confirms that – when drafting any legislative proposals – the Commission should envisage a broad scope of application which should cover all AI and ADM based technologies so that there will be no vacuums anymore. This would certainly help to build trust in consumers and facilitate business developments ensuring legal certainty. 
For any further analysis, we refer to the attached or linked documents  and remain at the disposal of the Commission for answering any queries."
"International Association of Scientific, Technical and Medical Publishers (STM) (Netherlands)","STM welcomes the ambitions of the European Commission to lead globally in promoting the uptake of Artificial Intelligence whilst ensuring that the highest levels of excellence and trust are respected and delivered to European consumers and businesses. As already noted in our response to the open consultation on the European Commission’s White Paper, given the extensive legislative framework already provided for by the European acquis, the...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550608_en,10,F550608,09 September 2020,Claudia Russo,Business association,"International Association of Scientific, Technical and Medical Publishers (STM)",Micro (1 to 9 employees),98356852465-08,Netherlands,Artificial intelligence – ethical and legal requirements,"STM welcomes the ambitions of the European Commission to lead globally in promoting the uptake of Artificial Intelligence whilst ensuring that the highest levels of excellence and trust are respected and delivered to European consumers and businesses.

As already noted in our response to the open consultation on the European Commission’s White Paper, given the extensive legislative framework already provided for by the European acquis, the first approach should be to consider the applicability of existing rules, including but not limited to the areas of IP, privacy (GDPR) and competition law. It may still be too early to tell what gaps there are and therefore if a new type of intervention is needed. 

Moreover, the evolution and application of AI systems are still in their early stages. Innovation is changing the landscape daily so it is difficult to assess what risks will arise or be mitigated. It would be prudent to take a flexible approach, providing effective and transparent criteria that can be applied by innovators and industry to determine risk, under similar principles as Article 22 of GDPR.

For these reasons, a new legislative instrument is likely premature. Instead, the Commission should focus on non-legislative activities. Efforts should concentrate on building on existing initiatives and protocols and coordinating with stakeholders to ensure alignment, minimise burdens and streamline activity. In particular, standards and initiatives should be developed over time by practitioners and communities of use. The Commission should work to channel appropriate funding and support towards those.

To enable the development and deployment of excellent AI systems, it is necessary that those are trained and fed with excellent, high-quality proprietary content, datasets, metadata, curated items or databases. Appropriate incentives and funding to curate pre-existing or purpose-built IP for this purpose should be provided, working with the owners and creators of such content to make sure that systems and tools are built with integrity. The owners and creators of high-quality content should be viewed as key partners with policymakers and system developers to promote the reliability and accuracy of AI systems.

Compliance with and enforcement of existing Union rules on fundamental rights and product safety will also help gain users’ trust, which will bring to a corresponding increase in the demand and use of AI systems. Efforts should also be dedicated to promoting positive, understandable examples of AI applications to build public understanding and support and underpin sustainable long-term government investment in AI.

STM has already contributed to the open consultation on the Commission’s White Paper on AI, and will be looking forward to further engaging with the European Commission and other European institutions."
Google (Belgium),"Google welcomes the opportunity to provide further input to the European Commission’s deliberations around AI governance. The promise of AI to deliver societal benefits cannot be realised without well-founded public trust in AI’s use. If done well, establishing oversight mechanisms will reassure the public that there are controls in place, while also providing useful clarity and directional guidance for industry — both of which are vital for a...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550556_en,10,F550556,09 September 2020,Sylwia GIEPMANS-STEPIEN,Company/business,Google,Large (250 or more),03181945560-59,Belgium,Artificial intelligence – ethical and legal requirements,"Google welcomes the opportunity to provide further input to the European Commission’s deliberations around AI governance. The promise of AI to deliver societal benefits cannot be realised without well-founded public trust in AI’s use. If done well, establishing oversight mechanisms will reassure the public that there are controls in place, while also providing useful clarity and directional guidance for industry — both of which are vital for a thriving and innovative AI ecosystem. The challenge is to ensure that any interventions in the development and use of AI — especially those that are mandatory and impose upfront costs  — are suitably tailored and appropriately balanced so as to have the desired effect with minimal unwanted repercussions.  

The attached document is intended as a companion to Google’s detailed submission to the earlier White Paper consultation (https://www.blog.google/documents/77/Googles_submission_to_EC_AI_consultation_1.pdf), responding to the specific options laid out in the Commission’s AI inception impact assessment published in July."
European Digital Rights (EDRi) (Belgium),"Aims: 1. EDRi argues that promoting AI uptake should not be an end in itself, rather a detailed framework to ensure all AI is lawful and fundamental rights compliant. Problem definition: 2. The definition of “remote biometric identification” is overly narrow. All mass surveillance uses of biometrics invoke severe fundamental rights implications, and therefore should be in scope. 3. Greater attention is needed to the potential...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550551_en,10,F550551,09 September 2020,EDRi Policy,Non-governmental organisation (NGO),European Digital Rights (EDRi),Small (10 to 49 employees),16311905144-06,Belgium,Artificial intelligence – ethical and legal requirements,"Aims:
    1. EDRi argues that promoting AI uptake should not be an end in itself, rather a detailed framework to ensure all AI is lawful and fundamental rights compliant. 

Problem definition:
    2. The definition of “remote biometric identification” is overly narrow. All mass surveillance uses of biometrics invoke severe fundamental rights implications, and therefore should be in scope.
    3. Greater attention is needed to the potential impact of AI applications on human rights.
    4. Dataset bias is only one source of AI bias, not overlooking bias in programming of the systems, and the discrimination resulting from deployment of AI systems in already discriminatory contexts, e.g. facial recognition and predictive policing in the context of proven systemic racial discrimination. 
    5. Discrimination is not “immaterial harm”; it can have highly material consequences: threats to liberty and safety when AI is deployed for policing, migration control; safety and financial implications when sensitive identity traits are inferred in the delivery of essential public services; or in employment.
    6. Dual uses of AI pose numerous threats to data protection and fundamental rights and must be addressed. 

Impact assessment
    7. The impact on fundamental rights must be given primary attention over assumed economic impact. All presumed benefits of AI, particularly when invoked in public sector must be demonstrated with scientific criteria. 
    8. Societal level harms such as impact on democracy must be included, with a specific reference to uses of AI for content moderation and the impact on democracy.
    9. AI has an environmental impact in terms of encouraging wasteful development and consumption. When AI systems are proposed as solutions to climate change, evidence must be presented.
    10. Fundamental rights impact must be further detailed in an HRIA, in particular with respect to rights to privacy, freedom of assembly and non-discrimination. The HRIA must articulate how fundamental rights will be de facto protected within the  proposed regulatory framework.

Policy Options:
    11. EDRi recommends that the policy options are amended to include legislation which defines the scope of lawful AI and introduces prohibitions for uses which violate fundamental rights, including untargeted biometric surveillance, predictive policing, migration control and other uses detailed in EDRi’s AI recommendations and case bank of impermissible uses. The prohibition of certain uses of AI is necessary to achieve the stated  aim of preventing harm.
    12. For legal uses of AI, EDRi favours the application of safeguards to all uses of AI (3C) . EDRi recommends a rejection of the risk-based categorisation and the sectoral delineation of ‘high risk’, which will create a gap in fundamental rights protections. Mandatory, external HRIAs, at all stages should evaluate the impact of all AI systems on a case-by-case basis to determine safeguards, with a range of options (including prior conformity assessment, notification to oversight body,  prohibition).
    13. For public sector uses of AI, the EU must introduce mechanisms of democratic oversight. This includes consultation with marginalised communities and people most affected by particular deployments. Democratic oversight must extend to  decision-making power for those affected.
    14. The Commission must take specific steps to ensure enforcement of fundamental rights in upcoming legislation, and individual and collective redress.
    15. EDRi rejects options 0-2. Individuals impacted are not ‘customers’ and often not consumers of AI, but subjects to AI systems. Soft law, industry-led or voluntary schemes will be insufficient to protect their rights.

Find furhter information in EDRi’s recommendations on artificial intelligence regulation and ban on biometric mass surveillance position. EDRi attaches use cases of AI deployments in Europe which require prohibition in law."
European Association of Urology (Belgium),"The European Association of Urology, a membership organisation of more than 18 000 urologists from all over Europe, sees value in the use of Artificial Intelligence (AI) both in terms of the activities of our professional association (e.g and decision support and development of evidence based clinical guidelines), and in our clinical roles as medical professionals (e.g. in the early detection of cancer, treatment of tumours and other...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550523_en,10,F550523,09 September 2020,Sarah Collen,Non-governmental organisation (NGO),European Association of Urology,Medium (50 to 249 employees),703095536854-37,Belgium,Artificial intelligence – ethical and legal requirements,"The European Association of Urology, a membership organisation of more than 18 000 urologists from all over Europe, sees value in the use of Artificial Intelligence (AI) both in terms of the activities of our professional association (e.g and decision support and development of evidence based clinical guidelines), and in our clinical roles as medical professionals (e.g. in the early detection of cancer, treatment of tumours and other urological conditions, robotic surgery and for use in clinical trials). 

In urology, we already have experience of this important interaction between the uptake / use of novel technology and medical practice in the field of robotic surgery.
 
In the use of AI technologies, medical professionals will often be users and/or deployers of these tools and will often be responsible for the ‘human oversight’ when they are used in care settings. It is therefore essential that these new technologies have checks and balances in place that ensure that they are safe and effective for their intended use, just as they would need to be in place for new medical devices or pharmaceuticals.

Many of the AI tools we use in a clinical setting are likely to fall under ‘high risk’ devices mentioned in option 3b. Indeed, many are likely to have important legal and physical impacts on our patients (supporting decisions on treatments, for example) and the general public (when it comes to decisions regarding risk based screening, for example). These technologies will have an important impact on the medical profession, requiring the need for new skills and training, and a clear legal framework outlining responsibility and liability when things go wrong. Just like any new technology or pharmaceutical, it must be clear what functions any new AI tool has been proven to be effective and safe in delivering. In the case of AI, the limitations of the tool will directly relate to the limitations of the data driving the tool in the first place. The limitations of the data used must be explained in a clear and transparent way.

A mandatory, stand alone, legal standard for high risk AI defined in 3b using a conformity assessment procedure  (mentioned in the White Paper on AI) would give legal clarity on a number of these issues. For medical devices, this may also be achieved by updating of the relevant standards (ieg IEC 82304)  linked to the Medical Devices Regulation. 

In terms of application of such legislation in the health sector,  it must make provision for feedback from experts from healthcare professionals, patients and the general public. The medical world is rightly highly regulated already. It is a sector well used to asking ethical questions. The risks and benefits will need to be defined by all actors, including healthcare professionals and patients, payers and industry.  There will  be interaction with data protection, pharmaceutical and medical device legislation and the boundaries and complementarity must be carefully defined.  It will be essential to understand the human oversight and control/ responsibility over which aspects of the AI device and this information must be clearly described to the user by the manufacturer. 

For this reason, there must be provision for opinions from healthcare professionals and experts imbedded into the AI conformity assessment  process in the health sector. The Medical Devices Regulation, for example,  has a included the creation of Medical Expert Panels through the JRC who will play a role in the assessment process of new medical devices. This model could be considered as a model to be replicated in any proposed AI legislation. 

The new regulatory approach must go hand in hand with a broader package of education, training and skills for medical professionals so that these tools can be safely deployed in the most effective manner, as outlined in the AI White Paper. European medical societies such as the EAU can support these initiatives."
Handelsverband Deutschland (HDE) (Germany),"Der HDE begrüßt das ausgeglichene Inception Impact Assessment der Kommission, das die Interessen der betroffenen Wirtschaftsakteure – insbesondere von KMU – ausdrücklich mitberücksichtigt und deren potenzielle Belastung durch etwaige Regulierung dem Nutzen gegenüberstellt. Auch der explizite Fokus auf legislative Kohärenz und Konsistenz in den Bereichen Haftung, Produktsicherheit und Grundrechtsschutz ist positiv zu bewerten. Dieser...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550505_en,10,F550505,09 September 2020,Fabian FECHNER,Business association,Handelsverband Deutschland (HDE),Small (10 to 49 employees),31200871765-41,Germany,Artificial intelligence – ethical and legal requirements,"Der HDE begrüßt das ausgeglichene Inception Impact Assessment der Kommission, das die Interessen der betroffenen Wirtschaftsakteure – insbesondere von KMU – ausdrücklich mitberücksichtigt und deren potenzielle Belastung durch etwaige Regulierung dem Nutzen gegenüberstellt. Auch der explizite Fokus auf legislative Kohärenz und Konsistenz in den Bereichen Haftung, Produktsicherheit und Grundrechtsschutz ist positiv zu bewerten. Dieser eingeschlagene Weg muss mit der Folgenabschätzung und dem Gesetzgebungsvorschlag konsequent weiter beschritten werden. Denn: Wir bewegen uns beim Thema KI in einem wettbewerblichen Spannungsfeld und müssen dem Innovationsraum Europa einen Freiraum für technologische Entwicklungen und wirtschaftliches Wachstum bieten, anstatt Fortschritt unbegründet zu erschweren. Das Verständnis von KI sollte unserer Einschätzung deshalb unter einer gestalterischen Prämisse stehen: Wir erschaffen Künstliche Intelligenz; wir gestalten, trainieren und entwickeln die Systeme weiter.

KI ist keine weitere technische Entwicklung, die einer Sonderregulierung bedarf. Es ist vielmehr eine Basis-Innovation, die zahlreiche Geschäftsmodelle verändern und neue ermögli-chen wird. Deshalb ist der HDE überzeugt, dass es keiner gesonderten KI-Gesetzgebung bedarf, sondern der bestehende Rechtsrahmen, wie die DSGVO, das Gesetz gegen unlauteren Wettbewerb (UWG) oder Vorschriften des Allgemeinen Gleichbehandlungsgesetzes (AGG), Verbraucher*innen hinreichend schützt. 

Was in der analogen Wirtschaft mit menschlichen Entscheidungen gilt, sollte auch in der digitalen Wirtschaft mit datenbasierten Entscheidungen mitgedacht werden. Existierende Vorschriften sollten daher überprüft und nur bei nachgewiesenem Bedarf gezielt an die von KI-Systemen ausgelöste Entwicklung angepasst werden. Somit haben wir als HDE eine klare Präferenz für die Regulie-rungsoptionen 1 und 2 aus dem Inception Impact Assessment - bzw. eine Kombination davon. 

Ein freiwilliges Kennzeichnungssystem könnte für die notwendige Transparenz und Orientierung sor-gen, ohne die betroffenen Unternehmen übermäßig zu belasten.  Dabei muss gewährleistet sein, dass vor allem KMU in der Breite extern generierte „KI as a service“ auch praktisch nutzen können, da sie vielfach nicht in der Lage sein werden, KI-Systeme selbst zu entwickeln.

Sollte aus politischen Gründen entgegen der Position des HDE dennoch eine Regelung für erforder-lich gehalten werden, so muss diese anwendungsbezogen und risikobasiert sein. Vor dem Hinter-grund der aufgeführten wirtschaftlichen Auswirkungen sollte sich der Gesetzgeber daher maximal für die Optionen 3a oder 3b entscheiden. Sollte man sich für eine risikoorientierte Regulierung entschei-den, ist es absolut notwendig, dass „KI-Anwendungen mit hohem Risiko“ klar, zukunftsfest und rechtssicher definiert und abgegrenzt werden. Grundsätzlich halten wir den Ansatz, sich bei der Risi-kobewertung vor allem auf den Sektor zu konzentrieren für richtig, allerdings wirft die vorgeschlage-ne Risikobewertung Fragen und Probleme bei der Abgrenzung auf: Ist die Liste der betroffenen Sek-toren abschließend? Ist die Liste der kritischen Verwendungszwecke abschließend? Was genau sind „Auswirkungen auf die Rechte einer natürlichen Person“? Dieser Begriff scheint extrem offen. Wer-den die beiden Faktoren „Sektor“ und „Auswirkung“ immer kumulativ angewendet? Welche weiteren Ausnahmen von der Zwei-Faktor-Bewertung – neben KI bei der Einstellung von Beschäftigten – gibt es noch?

In Bezug auf Optionen 3a (Beschränkung des Rechtsinstruments auf bestimmte KI-Anwendungen wie biometrische Identifizierungssysteme) möchten wir zudem zu bedenken geben, dass bestimmte biometrische Identifikationssysteme zu maßgeblichen Innovationen im Handel beitragen, wie z.B. das Bezahlen per Fingerabdruck. Diese sollten im Sinne der Innovationsförderung sowie der Erleich-terung von Prozessen für den Kunden und Anbieter unter bestimmten Bedingungen weiterhin mög-lich sein."
CECE - Committee for European Construction Equipment (Belgium),"CECE welcomes the opportunity to comment on the European Commission’s Inception Impact Assessment on a proposal for a legal act laying down requirements for Artificial Intelligence. Regarding the different policy options proposed, we would like to share the following comments: - POLICY OPTION 1 For the construction machinery sector, we do not see any benefits of additional requirements for AI-enhanced subsystems in our products, since this is...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550504_en,10,F550504,09 September 2020,Caio Lobo,Business association,CECE - Committee for European Construction Equipment,Micro (1 to 9 employees),60534525900-25,Belgium,Artificial intelligence – ethical and legal requirements,"CECE welcomes the opportunity to comment on the European Commission’s Inception Impact Assessment on a proposal for a legal act laying down requirements for Artificial Intelligence. Regarding the different policy options proposed, we would like to share the following comments:

- POLICY OPTION 1
For the construction machinery sector, we do not see any benefits of additional requirements for AI-enhanced subsystems in our products, since this is already covered by the Machinery Directive 2006/42/EC; we therefore prefer option 1.
 
For the products of our industry – mobile machinery of all sizes – the Machinery Directive 2006/42/EC, having technology neutrality as one of its core principles, already covers safety for those machines using AI-enhancements for operation.
 
According to the Machinery Directive 2006/42/EC, the manufacturer has to take the necessary measures to eliminate any risk throughout the foreseeable lifetime of the machinery, which includes the phases of transport, assembly, dismantling, disabling and scrapping. This includes any machine learning capabilities.
 
- POLICY OPTION 2
For the products under the scope of the Machinery Directive 2006/42/EC, the CE marking already indicates that the risks associated with state-of-the-art AI-enhancements have been sufficiently mitigated, therefore additional labelling is not necessary.
 
- POLICY OPTION 3A + 3B
We reserve our position on option 3 depending on the criteria to be defined for the category of ‘high-risk’ applications. We expect stakeholders (especially the industry) to be  thoroughly consulted when those criteria are defined.
 
- POLICY OPTION 3C
A legislation covering all types of AI use poses the threat of hampering innovation and putting unjustified burden on many narrow AI-enhanced products; where the AI-enhanced function may have tight operational limits, operates in a low-risk application, or is subject to close human oversight during its entire learning phase.
 
- POLICY OPTION 4
No specific statement for policy option 4."
Philips (Netherlands),Philips welcomes the opportunity to provide feedback on the roadmap for AI ethical and legal requirements. Please see our feedback in the attachment.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550483_en,10,F550483,09 September 2020,Aleksandra Appelfeld,Company/business,Philips,Large (250 or more),035366013790-68,Netherlands,Artificial intelligence – ethical and legal requirements,Philips welcomes the opportunity to provide feedback on the roadmap for AI ethical and legal requirements. Please see our feedback in the attachment.
Anonymous,"AI is a fast growing technology that can and will be very useful to predict and optimise resources. The City of Stockholm welcomes the EUs ambition to ensure an appropriate ethical and legal framework based on the Unions values. It is however necessary to ensure that the AI we use is safe, lawful and in line with EUs existing and fundamental rights. AI must be trustworthy eg regarding protection of personal data, non-discrimination, product...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550477_en,10,F550477,09 September 2020,,,,,,,Artificial intelligence – ethical and legal requirements,"AI is a fast growing technology that can and will be very useful to predict and optimise resources. The City of Stockholm welcomes the EUs ambition to ensure an appropriate ethical and legal framework based on the Unions values. It is however necessary to ensure that the AI we use is safe, lawful and in line with EUs existing and fundamental rights. AI must be trustworthy eg regarding protection of personal data, non-discrimination, product safety and liability. 

A changing world brings with it new challenges; globalization, digitalisation, the need for sustainable development, skills supply and a strong demographic development with demands for a rapid expansion of the city's infrastructure, housing and welfare sector and an aging population. The expectations on public authorities are high; citizens expect the same level of service that the private sector can offer. Consequently local authorities need to constantly improve and streamline services and working methods. AI and automation offers new tools to tackle the challenges we face;eg it has the opportunity to acquire and use new information at a pace that humans cannot thus helping us in keeping up with the development of knowledge. 

Development and usage of AI brings about new challenges linked to new digital technology. A number of ethical and legal issues related to AI need to be addressed; in the absence of coherent EU guidance, so-called ""untrustworthy"" AI could arise because there is strong commercial pressure on the issue. The City of Stockholm supports the Commissions review or risks connected to AI and that these are also communicated. Some concerns/potential risks regarding AI are for example:

• Non-transparent decision-making
• Different types of discrimination (gender, race)
• Invasion of citizens’ privacy 
• Usage of AI for criminal purposes

There is also a need to be observant of the social aspects; there may be an increased risk of loneliness and isolation if AI-based, automated welfare services are used to replace the service that currently are performed with the help of personal contact.

There is a strong global competition within the field of digitalisation and AI. The EU must act as one, based on European ethical values, to promote AI development in Europe. In this context it is important to emphasize the need to find viable ways for introducing and using secure AI that contribute to local, regional, national and European development, in an ethically and legally sustainable manner.

In the development of regulations for AI there is a need to clearly specify which types of legal requirements that are mandatory for the different authorities, organisations and companies(etc) concerned, especially with regard to high-risk applications and quality assurance of AI systems.

New technology such as AI is dependent on the good management of data; the amount, the quality and the availability of data is key to the successful implementation of AI. Open data needs to be correct, consequent and coherent. AI systems and algorithms can hide bias which might lead to high risks for people’s safety. Safety and reliability tests of AI systems are burdensome for local public authorities. There is need for the EU to enforce obligatory measure for companies giving them obligations to report which algorithms are used in systems which they deliver. 

The Commission states that different options for AI risk management will be evaluated. ""Soft legislation"" would mean building on ethical principles that have already been developed by the EU through the HLEG (High-Level Expert Group on Artificial Intelligence) and by various industries and organizations. “Hard legislation” would mean significantly greater requirements for documentation and follow-up by both supplier and customer. The City of Stockholm would therefore like to urge the Commission to make an assessment of how costs incurred for various actors can be set against the security aspect/effect of a stricter legislation."
Bundesärztekammer / German Medical Association (Germany),"Comments by the German Medical Association (Bundesärztekammer): Further to our response to the public consultation on the White Paper on Artificial Intelligence (AI), the German Medical Association would like to comment on the Inception Impact Assessment: Regulatory options The Inception Impact Assessment considers several options for regulating AI applications at EU level. Despite the undisputed opportunities AI can provide, e.g. in...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550387_en,11,F550387,08 September 2020,Rudolf REIBEL,Non-governmental organisation (NGO),Bundesärztekammer / German Medical Association,Medium (50 to 249 employees),89648243865-50,Germany,Artificial intelligence – ethical and legal requirements,"Comments by the German Medical Association (Bundesärztekammer):

Further to our response to the public consultation on the White Paper on Artificial Intelligence (AI), the German Medical Association would like to comment on the Inception Impact Assessment:

Regulatory options

The Inception Impact Assessment considers several options for regulating AI applications at EU level.

Despite the undisputed opportunities AI can provide, e.g. in diagnosis, treatment or patient monitoring, the use of AI in healthcare can also cause serious and irreversible harm to the life and health of patients, for instance in the case of recommendations of the wrong medicine, erroneous assessments in cancer screening, injuries during surgery, or errors in prioritisation of patients.

To address such risks, the Commission should propose binding regulation (option 3b in the Inception Impact Assessment), designating any applications used in healthcare as high-risk. We believe that such regulation should be sector-specific and must be detailed and include enforcement mechanisms in order to ensure equally effective patient protection in the EU.

Additional introduction of a voluntary labelling scheme could be envisaged for other areas, such as lifestyle applications.

The White Paper and Inception Impact Assessment already include a number of important aspects to be addressed by an EU regulatory framework on AI, such as:

- the quality of training data sets,
- the keeping of records and data, including the possibility of retracing AI-driven decisions,
- information duties,
- robustness and accuracy of AI systems, and
- human oversight over final decisions.

We also agree with the approach outlined in the White Paper to adapt the EU Product Safety Directive to the characteristics of AI applications, as the existing legislation does not sufficiently address new risks linked to the complexity, opacity, autonomy and openness of AI applications.

In addition to these aspects, an EU regulatory framework on AI should address the following aspects, which are particularly relevant for physicians and their patients:

Liability of practitioners using AI applications

Patients should be effectively protected from harm incurred from the use of AI. At the same time, a liability regime must take account of the fact that physicians using AI applications cannot be expected to have expert IT skills. Therefore, a physician who demonstrates due diligence in selecting, installing and maintaining an AI application, or who diligently selects and supervises a provider to fulfil this task, should not be held liable for harm or damage caused by this AI system. The same should apply if the damage is caused by a third party, e.g. a hacker who interferes with the AI system in a criminal or illicit way, if there is no negligence on the part of the physician.

Moreover, liability rules should not interfere with the physician’s therapeutic autonomy. Unless clinical guidelines state otherwise, physicians should not be held liable for their decision to use or not to use an AI application, or for their decision not to follow a recommendation provided by AI.

Conformity assessment

Applications that can create a risk for patient safety should be subject to a strict and independent conformity assessment before being placed on the market. Ex-post safeguards like liability for damages are insufficient, as the harm caused to patients may be irreversible.

The assessment procedure should be designed to include the consultation of representatives of medical practitioners and patients, to enhance their user-friendliness and promote their acceptance, and to ensure their conformity with practitioners’ professional duties and clinical guidelines, where applicable.

Ownership of data generated using AI applications

Practitioners using AI applications should be permitted to continue to use data generated by them when changing AI application providers."
Atos SE (France),"Artificial intelligence – ethical and legal requirements Atos Feedback – 8 Sep 2020 Atos welcomes the opportunity to respond to the Inception Impact Assessment proposed by the European Commission on the proposed legal act on Artificial Intelligence. Atos supports implementing policies aiming at mitigating the risks associated with AI applications. We believe that a non-legislative approach would not meet this objective, and conversely that...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550383_en,11,F550383,08 September 2020,Dominique Grelet,Company/business,Atos SE,Large (250 or more),249876817241-03,France,Artificial intelligence – ethical and legal requirements,"Artificial intelligence – ethical and legal requirements
Atos Feedback – 8 Sep 2020

Atos welcomes the opportunity to respond to the Inception Impact Assessment proposed by the European Commission on the proposed legal act on Artificial Intelligence. 
Atos supports implementing policies aiming at mitigating the risks associated with AI applications. We believe that a non-legislative approach would not meet this objective, and conversely that mandatory requirements, especially if applied indiscriminately to all applications, are not economically and technically effective.

Please find below our comments on each presented option.



EU “soft law” (non-legislative) approach (option 1)

We believe that a totally non-binding approach would not be sufficient to ensure sufficient security.
In the framework of current existing legislation, we recommend imposing a standard for high-risk applications to ensure that they comply with the 7 principles for an ethical AI defined by the Commission. This could be done by first defining a common risk repository and then classifying applications evaluated within this repository,


Setting up a voluntary labeling scheme (option 2)

Atos supports the creation of voluntary labels. 
The creation of labels (for example one label for each of the seven principles of the European Commission for an ethical artificial intelligence), based on an evaluation template defined by the Commission, can be envisaged, making it possible to highlight the characteristics of an application on the AI axes of trust proposed by the Commission. 
The label would be awarded after analysis by a competent European structure - to be created, if necessary - and which could also define and manage the standards for applications identified as critical. 

In particular, Atos recommends this label be used as a selection criterion in the context of public or private procurement processes, in order to be able to rule out solutions that do not respect the commitments linked to the label, and therefore do not offer all the desired guarantees for the user.

This approach would make it possible to reveal the potential threats posed by existing solutions and potentially become a growth lever for complying solutions, becoming a competitive asset for their developers. Conversely, in the absence of global standards, not adopting this labelling approach could prevent the efforts made by both European and non-European AI actors on ethical dimensions, from being valued.


Regulations and requirements relating to high-risk AI, specific applications or all AI (options 3 and 4)

Atos advises against imposing specific requirements for all AI applications as presented in option 3c. Atos recommends taking into account the notions of the impact (or severity) of a damage and the probability that this damage will occur.

It should be noted that regulation is necessary but not sufficient to enhance the value of ethically compliant assets beyond the Union. Standards and labels could make it possible to promote the specificities of these solutions in other geographies or contexts not subject to European regulations."
CEA (France),"CEA welcomes the opportunity to provide feedback on the Commission’s Inception Impact Assessment for a European legal act aimed at addressing the ethical and legal issues raised by AI. We welcome the initiative objectives, in particular the intention to create a harmonised framework in order to reduce burdensome compliance costs derived from legal fragmentation. It is worth noting, a trustworthy AI as explained in HLEG on AI is at the same...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550327_en,11,F550327,08 September 2020,Armand NACHEF,Academic/research Institution,CEA,Large (250 or more),52774696782-43,France,Artificial intelligence – ethical and legal requirements,"CEA welcomes the opportunity to provide feedback on the Commission’s Inception Impact Assessment for a European legal act aimed at addressing the ethical and legal issues raised by AI. We welcome the initiative objectives, in particular the intention to create a harmonised framework in order to reduce burdensome compliance costs derived from legal fragmentation.

It is worth noting, a trustworthy AI as explained in HLEG on AI is at the same time a lawful, an ethical, and a robust AI. It takes into account all the concerns reflected in the trustworthy AI assessment list such as technical robustness, safety, security, privacy, traceability, explainability, auditability, in addition to diversity, non-discrimination, fairness, and respectability of fundamental rights. Actually, there is no need for an entirely new legislation, as current European legislation and standards already address many of these concerns. However, they may have some gaps that need to be filled.

Below are our comments on the outlined legislative options.

- Option 1 - non-legislative approach to facilitate and spur industry-led intervention:
option 1 is probably convenient for low-risk AI solutions. However, there is a need of a minimum legislation that classifies the solutions according to their level of risk. Self-reporting of compliance with the HLEG ethical guidelines must remain verifiable and auditable by law. The Commission's support and encouragement of industry-led intervention towards trustworthy AI is very important, however in no case can this replace the enforcement of legislations that define the responsibilities and obligations of AI solution stakeholders. 

- Option 2 - legislative instrument setting up a voluntary labelling scheme:
the diversity and multiplicity of uses of AI applications may make it very hard to have a simple labelling for applications with variable risks. On the other hand, a multitude of labelling depending on the use cases could be difficult to understand by the consumer. Particular attention should be paid to the concept of labelling that may lead to dangerous issues: labelling must always be carried out against a charter verifiable by a third party. Self-labelling involves too much risk with regard to its verification. CEA is not in favour of this option.

- Option 3a: legislation for a specific category of AI applications only, notably remote biometric identification systems:
biometric identification systems must be subject to strong legislation. However, CEA considers it is more efficient to put in place a legislative instrument that applies to all AI applications and that modulates according to the AI application risk aspects.

- Option 3b: legislation establishing mandatory requirements for “high-risk” AI applications.
“High-risk” AI applications should not be binary; there must be a gradation of risks as in all sectors with a safety or security aspect. Different rules adapted to the application risk levels (like those in the IEC 61508 standard) are needed.

- Option 3c: the EU legislative act could cover all AI applications.
CEA supports option 3C. Laws and standards cover all human activity, but this does not prevent creativity, innovation and freedom of expression. On the contrary, the absence of laws and therefore an increase of incidents combined with a legal vacuum may impede the AI development and deployment.

In summary, CEA supports option 3C; however, legislation should consider an AI application like any software application. We cannot blame the AI: following the use case, the application providers, issuers, operators, or users are responsible for a malfunctioning of the applications.

Finally, changes in the system may regularly occur, thus the requirements of trustworthiness will be too light without a continuous risk assessment. There is a real need for more R&D in the risk area in order to conceive and create continuous risk assessment processes."
CLEPA (European Association of Automotive Suppliers) (Belgium),"Automotive suppliers play a central role in the development of connected and automated vehicles. AI applications are becoming more and more common in cars: automated driving is the most well-known example, but a broad range of other applications are also concerned, such as many vehicle safety functions, comfort functions, advanced driver-assistance systems warnings, connectivity systems, infotainment systems, etc. CLEPA welcomes the AI White...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550322_en,11,F550322,08 September 2020,William Moreau,Business association,CLEPA (European Association of Automotive Suppliers),Small (10 to 49 employees),91408765797-03,Belgium,Artificial intelligence – ethical and legal requirements,"Automotive suppliers play a central role in the development of connected and automated vehicles. AI applications are becoming more and more common in cars: automated driving is the most well-known example, but a broad range of other applications are also concerned, such as many vehicle safety functions, comfort functions, advanced driver-assistance systems warnings, connectivity systems, infotainment systems, etc.
CLEPA welcomes the AI White Paper, and believes that an appropriate legislative framework can boost the development and uptake of AI by providing market participants more legal certainty and by ensuring consumer trust. We support the risk-based approach outlined in the Paper as it is more likely to ensure proportionality.
We stress the importance of not hindering innovation unnecessarily. Requirements should always remain proportionate to the risks and leave room for testing/experimenting. A balance must be achieved to ensure that the goals of this new initiative do not jeopardise the development of safer vehicles.
CLEPA supports setting up horizontal fundamental principles on AI to increase trust and ensure the necessary level playing field between market players. Nevertheless, automotive suppliers would prefer a sector-based approach for the upcoming regulatory framework and its compliance mechanism. Our sector is very specific and should not be covered by a one-size-fits-all cross-sectoral legislation which would not be adapted to the way automotive products are developed, produced, tested, and put on the market. Indeed, our sector is already subject to strict ex-ante conformity controls, such as the type approval process. AI-related requirements for our sector should be included into that existing framework rather than as a new set of requirements controlled separately. Certification, testing, and market surveillance should not be duplicated. Aside from the additional costs and administrative burden, it would create a risk of inconsistencies arising between the requirements under type approval and those under the AI framework, as both would cover safety and AI applications in automotive are deeply integrated in the vehicles’ systems.
Workstreams should be coordinated to avoid duplication and/or conflicting requirements. Discussions on automated driving are ongoing at the UNECE. The EU’s recently revised General Safety Regulation also introduced new safety measures, some of which may rely on AI. The delegated and implementing acts that will set the technical requirements for these measures are currently being drafted. The EU legislative framework on AI and the UNECE requirements for Automated Driving Systems should be aligned, with future UNECE requirements to be considered valid AI-related requirements, instead of adding another regulatory layer.
Regarding the policy options outlined in the Impact Assessment, we support leaving room for industry-led initiatives (option 1). We are also open to the creation of voluntary labelling scheme(s) (option 2), however, it is difficult to fully support such an initiative without knowing how it would be implemented practically. Before any type of labelling scheme can be introduced, transparent rules and metrics based on international standards should be agreed upon. The HLEG’s assessment list provides an interesting basis, but is not sufficiently adapted to the automotive sector’s specificities. National labelling schemes should be avoided.
We believe that option 3.2 (EU legislative instrument limited to high-risk applications) would be the most compatible with the existing regulatory framework for automotive products. We support mandatory requirements for safety-critical AI applications related to automated driving (SAE level 3 and above), so long as they are integrated into the type approval system, as mentioned above. On the other hand, non-safety-related applications (e.g. comfort functions, driver assistance systems, infotainment…) should clearly be considered low-risk."
"AMETIC AMETIC (ASOCIACIÓN MULTISECTORIAL DE EMPRESAS DE LA ELECTRÓNICA, LAS TECNOLOGÍAS DE LA INFORMACIÓN Y LA COMUNICACIÓN, DE LAS TELECOMUNICACIONES Y DE LOS CONTENIDOS DIGITALES) (Spain)","Scope ○ We caution the Commission on considering to significantly expand the scope of the future AI regulation to the open ended category of “automated decision making” This would go against the initial, thoughtful direction proposed in the AI whitepaper that proposes to focus on the risk-based, double-criterion for sectorial and application/use-based AI technologies. If AI were defined as “automated decision making” for the purpose of the...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550315_en,11,F550315,08 September 2020,Antonio CIMORRA,Business association,"AMETIC AMETIC (ASOCIACIÓN MULTISECTORIAL DE EMPRESAS DE LA ELECTRÓNICA, LAS TECNOLOGÍAS DE LA INFORMACIÓN Y LA COMUNICACIÓN, DE LAS TELECOMUNICACIONES Y DE LOS CONTENIDOS DIGITALES)",Small (10 to 49 employees),013076816891-46,Spain,Artificial intelligence – ethical and legal requirements,"Scope 
○ We caution the Commission on considering to significantly expand the scope of the future AI regulation to the open ended category of “automated decision making” This would go against the initial, thoughtful direction proposed in the AI whitepaper that proposes to focus on the risk-based, double-criterion for sectorial and application/use-based AI technologies. If AI were defined as “automated decision making” for the purpose of the future AI regulation, it would create unproportional, unjustified regulatory obligations that would not only deter development and deployment of AI-based applications in Europe, but also automated systems that do not pose any risk nor harms. 
○ Definition of immaterial harm: We reiterate the concerns around introducing the open-ended concept of “immaterial harm” into the future AI legislation. We propose as an alternative to refer to “significantly restricting the exercise of fundamental rights”.

Policy options
○ Option 0 (baseline): We do believe that there is merit in ensuring that the existing EU regulation is properly implemented with regards to AI before putting in place any new prescriptive AI-specific rules. 
○ Option 1 (industry-led intervention): No matter what policy options are pursued, lending support to the industry in establishing and implementing norms of responsible practices and sharing best practices is worthwhile. 
○ Option 2 (legislation on voluntary labelling): We remain skeptical on the impact of a labelling scheme on the uptake of trustworthy AI in Europe. An administrative burden on SMEs to comply with the onerous labelling obligations -- if drafted on the basis of the update Assessment List for Trustworthy AI from the EU AI HLEG-- could significantly outweigh the benefits of such a scheme.
○ Option 3 (legislation with mandatory requirements): Overall, the opportunity cost of not using AI should be part of the assessment when considering any future legislation aiming to reduce  risk and harms from the use of AI applications. Legislation should ensure legal certainty, be proportionate and increase trust in AI without unduly hindering AI-driven innovation.
- Remote biometric identification systems may be a good example of an application to which mandatory requirements could be applied in a risk-based framework.
- We support a well-defined risk-based approach to the AI regulation that takes into account both the severity and likelihood of harm. A sector and use/application base criteria -- as proposed by the EC’s whitepaper -- at large seem to be a good starting point.
- We strongly caution against an EU legislative act for all AI applications, that would make no distinction between the AI applications that can pose significant risk/harm and those with no or lower risk profile. Such a legislative instrument would be significantly unproportional to the problems so far identified by the European Commission, create significant barriers for AI adoption (additional costs, delay, administrative burden) in Europe, result in opportunity costs in some applications due to lack of AI implementation, and risk lowering the bar for those AI applications that are very likely to raise significant risks. 
Enforcement
○ We support the ex post enforcement for when problems arise as the most appropriate and proportionate mechanism, except in fields where ex-ante assessments are already established practice. In those situations, we recommend aligning any ex-ante assessment with existing procedures.
○ If the Commission insists on the ex-ante enforcement, we strongly caution against a third party ex-ante assessment and recommend instead self-assessment procedures based on clear “due diligence” guidance from the regulators. A practical approach would be for regulators to provide detailed templates and guidance on how to carry out and document the risk assessment, but delegate responsibility to those using and most familiar with the AI system to conduct an accurate assessment."
ACV-CSC Belgium (Belgium),"The ACV-CSC-Belgium Congress on the Future of Work - #Arbeidmorgen, #Queltravaildemain, #Arbeitmorgen - gathered in October 2019 more than 850 delegates for the adaption of its final conclusions. Thousands of members of ACV-CSC-Belgium participated before in a process of preparation and elaboration of the political guidelines and lines of action for this congress. Issues as the digital and the socioecological transitions were at the top of the...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550259_en,11,F550259,08 September 2020,Thomas MIESSEN,Trade union,ACV-CSC Belgium,Large (250 or more),80866452991-55,Belgium,Artificial intelligence – ethical and legal requirements,"The ACV-CSC-Belgium Congress on the Future of Work - #Arbeidmorgen, #Queltravaildemain, #Arbeitmorgen - gathered in October 2019 more than 850 delegates for the adaption of its final conclusions. Thousands of members of ACV-CSC-Belgium participated before in a process of preparation and elaboration of the political guidelines and lines of action for this congress. Issues as the digital and the socioecological transitions were at the top of the agenda of this congress on the Future of Work. The document in attachment resumes its political guidelines. The chapters #2 to #6 focus very much on AI and technology, and their impacts for labor. The chapters #19 and #20 concern the working conditions in the global supply chains and the giants of the Web. A fundamental baseline of the demands of this congress document is that strong regulation is needed if we really want to shape the future world of work and our democracy positively: Without rights, rules and responsibilities, there is no way forward. That's evidently also the position we defend together with the Trade Unions from all Europe united in the European Trade Union Confederation (ETUC), more specifically and most recently on AI in the ""Resolution on the European strategies on artificial intelligence and data"" approved by its Executive Committee on the 2nd of July 2020:  https://www.etuc.org/sites/default/files/document/file/2020-07/Adopted%20-%20ETUC%20resolution%20on%20%20the%20European%20strategies%20on%20artificial%20intelligence%20and%20data%20-%20EN.pdf"
Verbraucherzentrale Bundesverband (Federation of German Consumer Organisations - vzbv ) (Germany),Please see the attached statement,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550245_en,11,F550245,08 September 2020,Miika Blinn,Consumer organisation,Verbraucherzentrale Bundesverband (Federation of German Consumer Organisations - vzbv ),Medium (50 to 249 employees),2893800753-48,Germany,Artificial intelligence – ethical and legal requirements,Please see the attached statement
Access Now Europe (Belgium),"Access Now opposes the uptake of AI as an objective for a potential regulatory intervention. Our opinion on a legislative proposal will be based on the assessment of whether it ensures adequate safeguards for the protection and promotion of fundamental rights including societal impacts. All points outlined here are dealt with more substantially in our White Paper response, uploaded here. Access Now recommends regulatory option 4 to combine...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550212_en,11,F550212,08 September 2020,Daniel Leufer,Non-governmental organisation (NGO),Access Now Europe,Micro (1 to 9 employees),241832823598-19,Belgium,Artificial intelligence – ethical and legal requirements,"Access Now opposes the uptake of AI as an objective for a potential regulatory intervention. Our opinion on a legislative proposal will be based on the assessment of whether it ensures adequate safeguards for the protection and promotion of fundamental rights including societal impacts. All points outlined here are dealt with more substantially in our White Paper response, uploaded here.

Access Now recommends regulatory option 4 to combine options 3.1 and 3.3. The EU legislative instrument should have one part to cover all AI applications (3.3) in order to enforce a basic level of transparency and due diligence, and a further component to focus on specific categories of AI applications (3.1) for which there should be an outright ban. We expand on these distinctions below.

On the provision for all AI applications (3.1), we note that all private companies have existing responsibilities to carry out human rights due diligence. Large companies have resources to do this, and through the establishment of national centres of expertise, SMEs can be helped to carry out due diligence procedures for all AI applications. 

For all public sector usage of AI applications, human rights impact assessments (HRIAs) should be carried out, and the results and technical details made available in public registers of AI systems. Such registers should contain publicly accessible information about all AI systems being used or proposed for use in the public sector. Further, a mechanism must be established for contesting the results of impact assessments. In all cases, the possibility of scrapping or not using the system in question must be on the table, if the result of a HRIA shows that the system undermines the fundamental rights of those affected by it.

The legislative instrument must also contain provisions for a ban on certain applications of AI. As Access Now has repeatedly stated, a ban is necessary where mitigating any potential risk or violation is not enough and no remedy or other safeguarding mechanism could fix the problem. We provide details in our uploaded document.

Additional points:
The document overstates the case when it says that AI can “contribute to a wide array of economic and societal benefits across the entire spectrum of industries and social activities.” We have no evidence that AI can make meaningful contributions “across the entire spectrum” and overselling the positive impact of this technology is ultimately harmful and undermines trustworthiness as those expectations cannot be met. 
On the definition of ‘AI’, we believe that the important thing is to regulate the impacts of the technology, rather than the specific technical processes underlying machine learning or neural networks, for example. Where the specific functioning of a given system requires some special consideration, it should be given, but otherwise we must look at AI as a form of automation and apply generally applicable measures.
We support the acknowledgement that SMEs must also fall under the scope of legislation due to the scalability of AI applications. We further note that some of the most harmful developments in AI have come from SMEs and ‘innovative startups,’ such as Clearview AI and PimEyes, both of whom develop surveillance systems which are incompatible with fundamental rights.
The document mentions that “not a lot of currently valid evidence is available at this stage” for the effects of AI systems. This is not the case. Access Now has already provided the Commission with such evidence, and a new report from Algorithm Watch adds more in relation to Covid-19:  'Automated Decision-Making Systems in the COVID-19 Pandemic.'
The document mentions targeted consultations organised with “technical experts, conformity assessment bodies, standardisation bodies and experts on biometric data.” We request that consultations also be arranged with civil society organisations and with representatives of groups likely to be adversely affected by these systems."
Hutchison Europe (Belgium),Please see attached document.,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F550209_en,11,F550209,08 September 2020,John BLAKEMORE,Company/business,Hutchison Europe,Large (250 or more),3779891566-57,Belgium,Artificial intelligence – ethical and legal requirements,Please see attached document.
David D'Haese (Belgium),"Dear, I am a teacher in AI at the AP University College in Antwerp particularly concerned with ethical issues. My idea is that Europe should postpone any legislation concerning ethics in AI, as enforcement of such a future law is expected to be not practical and possibly even counterproductive. Instead, I would imagine that devising and evangelising a clear set of moral rules comparable to Asimov's three 'laws' of robotics would have a real...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F549988_en,11,F549988,07 September 2020,David D'Haese,EU citizen,,,,Belgium,Artificial intelligence – ethical and legal requirements,"Dear,

I am a teacher in AI at the AP University College in Antwerp particularly concerned with ethical issues. My idea is that Europe should postpone any legislation concerning ethics in AI, as enforcement of such a future law is expected to be not practical and possibly even counterproductive. Instead,  I would imagine that devising and evangelising a clear set of moral rules comparable to Asimov's three 'laws' of robotics would have a real impact and pave to way for future legislation. Europe is currently considered one of the few remaining moral leading institutions in the world and with the propagation of such rule-set, it would reïnforce its position."
European Trade Union Confederation (Belgium),"IIA provides additional but still general information on options the EC intends to consider for legal act on AI. IIA still lacks to address the specificity of the workplace. Imbalance of power between employers and workers should lead EC to consider robust AI frame to create quality jobs, invest in workers AI literacy, promote and increase safeguarding of workers rights, of workers protection, consider risks/benefits related to OSH and ensure...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F548980_en,12,F548980,03 September 2020,Ignacio DORESTE,Trade union,European Trade Union Confederation,Large (250 or more),06698681039-26,Belgium,Artificial intelligence – ethical and legal requirements,"IIA provides additional but still general information on options the EC intends to consider for legal act on AI. IIA still lacks to address the specificity of the workplace. Imbalance of power between employers and workers should lead EC to consider robust AI frame to create quality jobs, invest in workers AI literacy,  promote and increase safeguarding of workers rights, of workers protection, consider risks/benefits related to OSH and ensure trade unions and workers reps participate actively shaping AI at work. The framework should address these labour approaches in ambitious and proactive manner because workers are particularly concerned by AI

AI is key issue for work and society. It brings opportunities and challenges. In the field of work AI supports often or replaces humans in dangerous, strenuous, and repetitive tasks. Yet there are risks of intrusive surveillance, breach of privacy and data protection and fundamental rights. ETUC thus supports the objective of the potential legal act of fostering development of safe and lawful AI that respects and enforces rights

Liability regime of AI applications at work deserves proper attention where burden of proof should lie on employers to balance limited access to information to workers. Liability should rest on AI designers and business not on AI

ETUC calls for EU legislative instrument with mandatory requirements for all AI, option 3c. Regulating AI cannot be given to private actors. This would lead to wide differentiation on protection, with bias for putting on the market AI based on productivity and competitiveness. EC should fill this gap and enact new EU law implemented through national legislation and/or where relevant collective agreements. Respect of human rights instruments and CFREU should lead any legislative proposal. Ethics Guidelines for Trustworthy Artificial Intelligence should be included in regulation

AI applications introduced at the workplace and impacting workers rights and working conditions should be classified as high-risk

Regarding preliminary assessment of expected impacts, legislation in general and any legally binding act on AI in particular should be addressed in positive manner, as a medium/long term investment in society and its people, where public interest and interests of society outweigh interests of few groups. IA impact assessment should address economic, social, and environmental dimensions on same footing and with same details and accuracy. ETUC believes an EC framework would serve businesses and the workforce, providing legal predictability and certainty and sound level playing field for all. ETUC opposes to exceptions to scope of legal act on the size of the company. Particularly for AI systems applying to employment, level playing field in matters of the guaranteeing fundamental rights and labour rights should be pursued

Concerning expected social impacts, and because of imbalance of power existing in an employment relationship, legal framework should address needs for workers to guarantee through appropriate legislation and collective agreements respect and enforcement of their rights when AI is introduced/implemented. This is crucial to prevent discrimination, abuse of privacy and guarantee data protection, security and OSH

AI will have impact on labour market in terms of the replacement of some jobs, while creating new ones. Challenge is to shape an inclusive transition to fair digital future by minimising the risks and creating opportunities for workers. Precautionary principle should be applied to avoid digitalisation further splits society and exacerbates more unequal distribution of wealth

Regarding the likely impacts on fundamental rights, ETUC strongly believes that only binding requirements will strengthen respect of existing fundamental rights for all AI. The current assessment of the impacts of the EU different options on fundamental rights is vague and superficial. Should be addressed in equal manner as economic."
Software AG (Germany),"Software AG highly welcomes the Commission's objective to increase trust in AI thus fostering not only its use but also its development in Europe. We share the Commission's view that while AI can do much good, some of its uses and applications may cause both material and immaterial harm. Like the Commission we believe that trust is a precondition for the success of AI and that this objective can be best reached at Union level. As stated by the...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F547524_en,12,F547524,01 September 2020,Fabian SCHMIDT,Company/business,Software AG,Large (250 or more),253418726919-22,Germany,Artificial intelligence – ethical and legal requirements,"Software AG highly welcomes the Commission's objective to increase trust in AI thus fostering not only its use but also its development in Europe. We share the Commission's view that while AI can do much good, some of its uses and applications may cause both material and immaterial harm. Like the Commission we believe that trust is a precondition for the success of AI and that this objective can be best reached at Union level. As stated by the Commission, a public intervention can be one way to increase trust in AI both for citizens as well as for businesses. However, we share the Commission's view that there is a natural conflict between the benefits of a regulation on the one hand and its compliance costs on the other: the larger the scope, the higher the costs. As the Commission itself points out, this natural conflict may lead to the situation where some desirable AI systems may not be developed at all. To prevent the public intervention from such an unintended outcome, a balanced approach is needed.

Against this context, Software AG endorses option 3a. From our point of view, option 3a fulfills best the requirement for a balanced approach increasing trust in AI without being prohibitive. For the same reason, Software AG rejects option 1 as well as option 3c. While the former is inappropriate to significantly increase trust in AI, the latter would massively hamper the development and uptake of AI in Europe. Regarding the specific category of AI applications covered by Option 3a, we believe that all those AI applications should be considered that are of outstanding importance to citizens and therefore essential for their trust in AI. In our opinion, this is in particular true for AI applications that entail risks for fundamental rights (e.g. remote biometric identification systems). We share the Commission´s view, that whilst no new rights are needed, some characteristics of AI may hamper the effective enforcement of existing EU law meant to protect fundamental rights. In the implementation of option 3a, we prefer the scenario of co-regulation, where the legislative instrument would consist in high-level principles to be complemented by industry-led norms (e.g. stand-ards or codes of conduct). In our opinion, a mayor advantage of co-regulation is its friendliness for SMEs. As the Commission rightly points out, given the high scalability of digital technologies, SMEs must also be covered by the public intervention.

Apart from the protection of fundamental rights, we see neither the need nor the point for a dedicated regulation for AI. We believe that the vast majority of AI applications do not bear any risks at all and that for the very few high-risk applications adjustments to the existing legal and regulatory framework are absolutely sufficient - if they are not covered by Option 3a anyway. The revisions of the Machinery Directive and of the General Product Safety Liability Directive being prepared offer the opportunity to do so. As emphasized by the Commission, any fragmentation of the Single Digital Market must be prevented. This would not only hamper the uptake of AI in Europe, but above all it would put European AI providers at a serious competitive disadvantage. Software AG therefore welcomes the announced set up of a European governance structure on AI to improve cooperation between (national and European) regulatory authorities thus ensuring an effective and consistent enforcement of rules for AI across Europe."
ANEC (Belgium),"As the European Commission’s assessment of product safety and liability legislation shows, there are gaps in present legislation and new AI related aspects such as explicability require new legal provisions, especially for enforcement purposes. We therefore support Option 3.c: EU legislative instrument establishing mandatory requirements for all applications. The new rules have to cover risks posed by AI systems in a proportionate manner, with...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F547341_en,12,F547341,31 August 2020,Chiara GIOVANNINI,Consumer organisation,ANEC,Micro (1 to 9 employees),507800799-30,Belgium,Artificial intelligence – ethical and legal requirements,"As the European Commission’s assessment of product safety and liability legislation shows, there are gaps in present legislation and new AI related aspects such as explicability require new legal provisions, especially for enforcement purposes. We therefore support Option 3.c: EU legislative instrument establishing mandatory requirements for all applications.
The new rules have to cover risks posed by AI systems in a proportionate manner, with more stringent rules for high-risk applications. The EU regulatory approach on safety should be based and explicitly refer to the precautionary principle. 
We think that new rules should be adopted to make the appropriate risk assessment of all AI systems, taking into account of the nature of the hazard and the likelihood of its occurrence. Based on the assessment results, different rules can be applied in a proportionate manner. 
In order to assess whether the AI system is posing a high or low risk, criteria such as likelihood of the harm occurring, immediacy of the harm, the foreseeable use of the AI system (and not only the intended use which is not covering the potential effects of machine learning) have to be taken into account too. In addition, provisions have to deal with how uncertainties and assumptions impact the risk assessment. Once the risk is identified, mitigating measures have to be adopted (by industry, public authorities). Standards can be used to support the risk assessment. Any assessment, audit, certification, market surveillance activities have to cover the evolving nature of the AI system. For this, access to the AI system algorithms, codes and data sets must be ensured to understand and assess the risks.
About the level of risk, in our view, it is not a question of the kind of AI application as such, but of how to assess the risks posed to consumer protection by AI systems. In addition to cyber risks, personal security risks, risks related to the loss of connectivity and mental health risks, the risks to the environment should not be forgotten. 
We believe that product liability rules should be updated to ensure consumers are protected when they face problems with their digital goods.
We also believe that new consumers rights should be enshrined, for all AI systems, and not only high-risk applications, as follows:
-Right to Transparency, Explanation, and Objection
-Right to Accountability and Control
-Right to Fairness
-Right to Safety and Security
-Right to Access to Justice
-Right to Reliability and Robustness
We think that consumers interacting with AI systems must be able to keep full and effective self-determination/autonomy over themselves. This means securing human oversight over processes in AI systems. AI systems must not create asymmetries of power or information, such as between businesses and consumers. AI systems must not endanger the environment. 
We also suggest adopting the definition of AI provided by the EC HLEG on AI in the ethical guidelines. And to add a definition of ADM-Systems (Automated Decision Making). 
Legislation is needed to determine how and by whom biometrics technology can be used and the guarantees for citizens and consumers. Considering the high risk of abuse, discrimination and violation of fundamental rights to privacy and data protection, the European Union must develop a strong, privacy-protective approach for biometrics systems before they are largely used in public spaces.
Consumer information is useful in order to help transparency. However, labels are only as good as the requirements and enforcement systems on which they are based. Once clear legal rules and enforcement mechanisms are in place, the role of a label could be considered. 
Another important element to address is the inherent information asymmetry associated with AI or an evolving/machine learning system, making the function of a label different from a label linked to traditional, non-AI products (e.g. Ecolabel)."
IBM (Ireland),"IBM welcomes the opportunity to respond to the Commission’s Inception Impact Assessment on the proposed legislative initiative on AI. We welcome the policy Objective and Aims of the initiative, in particular the intent to ensure coherence and complementarity with other possible initiatives, e.g. affecting the Machinery Directive, the General Product Safety Directive or the product liability regime. We support targeted policies that address...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F543855_en,12,F543855,19 August 2020,Barry O'BRIEN,Company/business,IBM,Large (250 or more),7721359944-96,Ireland,Artificial intelligence – ethical and legal requirements,"IBM welcomes the opportunity to respond to the Commission’s Inception Impact Assessment on the proposed legislative initiative on AI. We welcome the policy Objective and Aims of the initiative, in particular the intent to ensure coherence and complementarity with other possible initiatives, e.g. affecting the Machinery Directive, the General Product Safety Directive or the product liability regime. 

We support targeted policies that address companies’ accountability for developing and operating trustworthy AI. Below are our comments on the legislative options outlined.

Option 1: “soft law” approach.
We support this Option for low-risk AI applications.

Option 2: legislation setting up a voluntary labelling scheme.
Voluntary labelling schemes can be helpful to consumers or end-users in some markets but we do not believe a single, one-size-fits-all labelling scheme would be effective across such a broad field as AI, given the hugely diverse range of products and services that will be deployed across all sectors.

Option 3a: legislation establishing mandatory requirements for a specific category of AI applications only, notably remote biometric identification systems.
We support the need for a public dialogue on the use of facial recognition technologies, which could lead to targeted legislation.

Option 3b: legislation establishing mandatory requirements for “high-risk” AI applications.
Legislation should focus on high-risk applications, particularly applications where human autonomy or judgment are substantially ceded to an AI system. There should be a single risk assessment framework to identify high-risk AI, regardless of sector and without lists of exceptions. 
Any mandatory requirements for high-risk AI systems should be addressed to the actors best placed to address the risks. Similarly, liability is best allocated to the actor closest to the risk, as liability is highly context-specific. In a B2B context, contractual liability works well and should be maintained, allowing parties negotiate an efficient allocation of risk that takes account of the specific use case.

Option 3c: legislation covering all AI applications.
We do not support this option as it would significantly hamper the uptake and development of AI in the EU, against the stated Objective and Aims of the initiative.

Option 4: A combination of the options above taking into account the different levels of risk that could be generated by a particular AI application.
We believe the Objective and Aims can best be met with a combination of Options 1, 3a and 3b, implemented through a co-regulatory approach and supported by globally recognized standards and industry-led codes of conduct.

In relation to a European governance structure on AI, we believe that in sectors where established structures already exist (medical devices, aviation etc.) these existing bodies are best placed to cover high-risk AI in their sectors, having the necessary sectoral expertise, operational relationships and track-record with relevant stakeholders. There may be value in a new European mechanism that provides best practice sharing and guidance across sectors, but its scope must be limited and its relationship to existing regulatory bodies clearly defined, so as to avoid fragmentation, inconsistency and the risk of stifling innovation.

In summary, we agree with the need for a consistent EU-wide regulatory framework for trustworthy AI. This will be essential to give stakeholders the confidence to develop and adopt AI-based solutions and realize the enormous benefits they offer.  Building trust requires acknowledging valid concerns that exist regarding accountability, transparency, fairness, privacy and security, and putting in place appropriate regulatory mechanisms to manage those risks, while continuing to promote ongoing innovation and experimentation – getting that balance right requires a precision regulation approach that is clear and targeted."
Anonymous,"• Certain rules or meaningful principles are needed to complement the existing legislative & regulatory framework (particularly those targeted at the avoidance of bias imposing a minimum of transparency & fairness obligations which will likely result in increased “explainability” efforts). In light of the existing fundamental rights and data protection regime, it is certainly desirable to only legislate with regard to actual concrete gaps...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F543779_en,12,F543779,19 August 2020,,,,,,,Artificial intelligence – ethical and legal requirements,"• Certain rules or meaningful principles are needed to complement the existing legislative & regulatory framework (particularly those targeted at the avoidance of bias imposing a minimum of transparency & fairness obligations which will likely result in increased “explainability” efforts). In light of the existing fundamental rights and data protection regime, it is certainly desirable to only legislate with regard to actual concrete gaps (based on a thorough gap analysis) instead of crafting an additional comprehensive regime. New legislation should be limited to a necessary minimum to close existing gaps and not create a competitive disadvantage for ai-driven innovation in the EU. Moreover, any legislation governing AI and data usage should be principled based, providing enough leeway for companies to determine the most appropriate measures and ways to comply with those standards. 
• Use cases should be differentiated and prioritized with regard to their potential to cause harm. A differentiated approach is key, considering that many of the cases do not impact a person (physically and morally) directly and personal data is either not used or, at a minimum, anonymized. We therefore suggest structuring any legislative proposal along a decision tree, making it possible to follow simple decision paths, based on pre-defined categorization of use cases. If all use cases had to be assessed against an exhaustive list, unnecessary bureaucracy and convoluted assessments would result; the purpose of creating “trustworthy AI” would be ill-served.
• If not, companies subject to more restrictive regulations, such as in the EU, will be put at a disadvantage. We encourage the EU to aim for a reasonable balance between trustworthy aspirations and competitive realities."
VDMA (Germany),"VDMA (German Mechanical Engineering Industry Association) welcomes the opportunity to provide feedback to the Inception Impact Assessment of the European Commission for a proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence. AI will be a core enabling technology for many sectors of European industry. Therefore, VDMA supports an European approach. A patchwork of national...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F543638_en,12,F543638,17 August 2020,Kai PETERS,Business association,VDMA,Large (250 or more),976536291-45,Germany,Artificial intelligence – ethical and legal requirements,"VDMA (German Mechanical Engineering Industry Association) welcomes the opportunity to provide feedback to the Inception Impact Assessment of the European Commission for a proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence.

AI will be a core enabling technology for many  sectors of European industry. Therefore, VDMA supports an European approach. A patchwork of national rules and initiatives in 27 EU Member States must be avoided.

VDMA welcomes a debate about the risks and opportunities, but calls for a very cautious approach when regulating an essential transversal technology. The immense opportunities must not be ignored and regulation must facilitate the development and uptake of AI. VDMA would like to bring forward four important points:

1) There is currently no need for a new, horizontal regulation for AI technologies, because there is no evidence yet of any fundamental regulatory gaps. In particular, in the case of AI embedded in products and machines, AI-characteristics (opacity, complexity and scalability) are limited by regulation and functional constraints. A precise analysis of the actual autonomy and risks is a prerequisite for assessing the need for legislation.

2) The EU-legislator should not regulate technologies but should instead target the effects of AI application in a technology-neutral way. Otherwise, there is a risk of hampering innovation and having to constantly adapt laws to technological progress. If future legislation is considered to be needed, the right approach would be to focus on high risk applications of AI. It is of crucial importance to develop a methodology to identify these high risk applications, to define the scope and to develop a legally sound definition of AI. Legal uncertainty would be a huge barrier to the use of AI, in particular for SMEs, and would hamper the use of AI in Europe.

3) We do not see a need for legislative action on machine safety. In the EU Machinery Directive ,the safety requirements are formulated in a technology-neutral manner and also apply to machines with AI elements. Factories with AI are therefore just as safe as without AI, as all safety requirements must be fulfilled in the same way.

4) VDMA does not believe that a readjustment of the Product Liability Directive and national liability regimes is needed at this stage. The Product Liability Directive is formulated in a technology-neutral way and the courts have applied it over the years to a wide range of products, many of which did not exist when the Directive was adopted. This legal framework for liability claims applies both to damage caused by a defective conventional product and to damage caused by a robot or other automated system. Therefore, they provide a legal framework within which AI problems can be solved. We also believe that further analysis, observation and examination are necessary before a proven liability regime is changed.

Conclusion: VDMA favours a combination of policy options (1 and 3b): The basis should be a “Soft Law”-approach. This will not only leave room for cutting-edge AI-solutions , but also allow a precise assessment of the real risks of AI and potential regulatory gaps. The use of “regulatory sandboxes” could help to find this balance. In a second step, if necessary, specific requirements could be established for clearly defined “high-risk”-applications - if they are not covered by existing regulation. It is crucial to focus on ""high risk applications"" and avoid hampering harmless AI-applications. In particular the industrial use of AI is in general uncritical and does not require more legislation.

Policy option 3c (covering all AI) would raise a prohibitive barrier to a wide range of AI-applications, including those which are harmless, yet beneficial. This would mean that Europe will fall behind international developments."
Dessislava Fessenko (Bulgaria),"Please review the attached PDF file. Feedback is provided therein. In a nutshell: I wish to hereby submit the views that: 1. Mandatory regulation is needed. As evident from areas such as data privacy, fake news, cyber security, tech firms (be it start-ups or large one, the latter appearing to drive and currently dominate the AI turf) cannot always be trusted to come up with and play by fair and equitable, consumer-friendly voluntary...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F541831_en,12,F541831,10 August 2020,Dessislava Fessenko,EU citizen,,,,Bulgaria,Artificial intelligence – ethical and legal requirements,"Please review the attached PDF file. Feedback is provided therein. In a nutshell:

I wish to hereby submit the views that:

1. Mandatory regulation is needed. As evident from areas such as data privacy, fake news, cyber security, tech firms (be it start-ups or large one, the latter appearing to drive and currently dominate the AI turf) cannot always be trusted to come up with and play by fair and equitable, consumer-friendly voluntary standards.

2. The mandatory requirements should tackle first and foremost ethical and legal issues at the inception of AI solutions (e.g. regarding standards of programming, approach to decision rules, quality of input data, second and third layers of safety nets to be available in the course of operations of an AI solutions) and, as a second line, legal issues around application of AI solutions ( non-discriminatory application, avoidance of intrusion into privacy/personal life, re-allocation of liability, etc.). At the end of the day, end users would not buy an AI solution unless they are absolutely convinced from the outset – including based on regulatory mechanisms warranting this – in the uncompromised flawlessness of its conception and design from its nuts and bolts to its cognitive elements."
European Association of Communications Agencies (EACA) (Belgium),"EACA welcomes the opportunity to give feedback on this roadmap where we would like to reiterate the points made during the Commission’s public consultation on its White Paper on Artificial Intelligence: On the trustworthy use of Artificial Intelligence From our industry’s point of view, concerns with AI are an extension of concerns with data use overall. AI exacerbates the risks involved in data use because of opaque decisioning, opaque...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F540776_en,12,F540776,04 August 2020,Nina Elzer,Business association,European Association of Communications Agencies (EACA),Micro (1 to 9 employees),397482431021-09,Belgium,Artificial intelligence – ethical and legal requirements,"EACA welcomes the opportunity to give feedback on this roadmap where we would like to reiterate the points made during the Commission’s public consultation on its White Paper on Artificial Intelligence: 

On the trustworthy use of Artificial Intelligence   

From our industry’s point of view, concerns with AI are an extension of concerns with data use overall. AI exacerbates the risks involved in data use because of opaque decisioning, opaque use or opaque responsibility. However, the risks that are often associated with AI can be mitigated. For example, in the case of fundamental rights, through compliance with regulations, adherence to data processing standards for robustness, accuracy and security, or ethics guidelines and policies for data sets, goals and algorithms, application of decisions. Discriminatory outcomes can be mitigated through the use of bias detection software on data sets, goals and algorithms as standard. To be able to explain the rationale, record keeping for data sets, goals, algorithms is important, as well as recording decision making at the same time as decisions taking, and testing outcomes with different input data. The risk of low AI accuracy can be mitigated through the adherence to data processing standards; explicit statements of accuracy expectations; explicit statements of responsibility for accuracy (at company/team/individual level). 

On the consideration of different policy options

We think that the concerns expressed by the Commission or the High Level Expert Group can be fully addressed through applicable EU legislation. The challenge is the definition of high-risk sectors or industries. It is the purpose of the AI model use that is key, not the industry. It is impossible to predict the long term impact of behaviour, therefore it is highly difficult to assume that we can know which industries are or will be high-risk in the future. 

If new compulsory requirements had to be introduced, these should be limited to high-risk applications whereas a proper definition of high risk needs to be agreed. The challenge is the definition of high-risk sectors or industries. It is the purpose of the AI model use that is key, not the industry. It is impossible to predict the long term impact of behaviour, therefore it is highly difficult to assume that we can know which industries are or will be high-risk in the future. 

Regarding the possibility of a voluntary labelling system, we would not be opposed to such a system. However, we believe that is unlikely to work Any of the requirements suggested in the White Paper and in this consultation will add cost, effort and paperwork without providing a competitive advantage – thereby lacking an incentive."
Anonymous,"1. Opportunität eines Regulierungsrahmens für KI Der DIHK unterstützt die Idee der EU-Kommission, einen Regulierungsrahmen zu schaffen, der aber offen sein muss für weitere Entwicklungen. Die Fortschritte und weitere Marktdurchdringung sind bei KI-Anwendungen momentan nicht einzuschätzen. Daher dürfen gesetzliche Regelungen keine unnötigen Hemmnisse für die Weiterentwicklung bei KI aufbauen und sollten vielmehr innovationsfördernd wirken. Die...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F540758_en,12,F540758,04 August 2020,,,,,,,Artificial intelligence – ethical and legal requirements,"1. Opportunität eines Regulierungsrahmens für KI

Der DIHK unterstützt die Idee der EU-Kommission, einen Regulierungsrahmen zu schaffen, der aber offen sein muss für weitere Entwicklungen. Die Fortschritte und weitere Marktdurchdringung sind bei KI-Anwendungen momentan nicht einzuschätzen. Daher dürfen gesetzliche Regelungen keine unnötigen Hemmnisse für die Weiterentwicklung bei KI aufbauen und sollten vielmehr innovationsfördernd wirken. Die Gefahr einer Fragmentierung des Binnenmarkts durch nationale KI-Regelungen in grenzüberschreitenden Sektoren spricht auch für eine Harmonisierung auf EU-Ebene. Es darf sich allerdings lediglich um einen Rahmen handeln, der klare und allgemeinen Leitplanken für KI regelt. 

Bei der KI-Regulierung sollte besonders für KMU vermieden werden, dass komplexe und bürokratische Regeln entstehen. Die Rechtssicherheit der Unternehmen sollte bei der Regulierung eine Priorität sein – und nicht vor allem auf den Schutz der Verbraucher fokussiert sein, wie das KI-Weißbuch an mehreren Stellen zu verstehen gibt. Dabei sollten die rechtlichen Regelungen die Risiken, die KI-Anwendungen verursachen können, berücksichtigen. Das betrifft einmal die Höhe des Risikos, aber andererseits auch die Frage der ungleichen Marktmacht im B2B-Bereich. 

Bei der Überlegung einer Differenzierung zwischen B2B und B2C muss berücksichtigt werden, dass gerade viele kleinere und mittlere Unternehmen genauso „schutzwürdig“ im Bereich KI sein können wie Verbraucher. 

2. Risikobasierten Ansatz verfolgen

Der von der EU-Kommission gewählte risikobasierte Ansatz ist im Sinne eines verhältnismäßigen regulatorischen Eingriffs sinnvoll. Auch die Datenethikkommission in Deutschland hat einen solchen ihrem Bericht zugrunde gelegt. Die Kommission schlägt vor, KI-Anwendungen als „hohes Risiko“ einzustufen, wenn sowohl der Sektor als auch die beabsichtigte Verwendung erhebliche Risiken bergen. Dennoch scheint dieser Ansatz keine bessere Risikoeinschätzung im Einzelfall zu ermöglichen, denn die Risiken und Risikobereiche werden nicht vorhersehbar sein – dadurch könnten nicht alle Risiken erfasst werden. 

Teilweise wird vorgebracht, dass risikobehaftete Sektoren in einer Liste aufgezählt werden sollten, umso mehr Rechtssicherheit zu erhalten. Allerdings könnte eine Liste von „risikoreichen Sektoren“ ganze Sektoren unter Verdacht stellen, obwohl in jedem Sektor Anwendungen, Produkte und Dienste mit unterschiedlichsten Risikoanforderungen bestehen. Eine Liste von „risikoreichen Sektoren“ würde damit allen gelisteten Sektoren die Nutzung von KI auch für unkritische Funktionen/Dienste erheblich erschweren, etwa durch erhöhten Trainingsaufwand von ethisch unbedenklichen Anwendungsfällen. Dies wäre mit erheblichen Schäden für die Konkurrenzfähigkeit und Beschäftigung des EU-Standorts verbunden. Eine Bestimmung der risikoreichen Anwendungen nach Sektoren erscheint also nicht geeignet, um die Vielfalt der KI zu erfassen. Daher sollte eine Beurteilung des Risikos anhand allgemeiner Kriterien erfolgen. Sie sollten allerdings sehr klar festgelegt, eng gefasst und zukunftsfest sein. 

3. Zertifizierung/Standardisierung

Die Entwicklung von KI sollte grundsätzlich den gleichen Sicherheitsstandards genügen, wie dies bei anderen Industriegütern oder Dienstleistungen heute schon geregelt ist. Um Schutzziele mit den Entwicklungszielen in Einklang zu bringen, muss auch hier das Grundprinzip Wettbewerb unter Einhalten von Sicherheitsstandards gelten. Eine Möglichkeit wäre, grundsätzliche Anforderungen ähnlich dem Prinzip der CE-Kennzeichnung für KI-Anwendungen und KI-Produkte zu definieren und Unternehmen diese nach dem Selbstverpflichtungsprinzip (Konformitätsbewertungsverfahren) unter behördlicher Überwachung umsetzen zu lassen. 

Ob die Prüfung, Zertifizierung oder auch Standardisierung von Algorithmen jedoch möglich ist, erscheint fraglich. Das Ergebnis wäre eine Momentaufnahme, die bei der schnellen technischen (...) (siehe beigefügtes Dokument)"
BusinessEurope (Belgium),"BusinessEurope welcomes the positive tone of the Commission’s White Paper acknowledging the many opportunities that AI can bring to Europe’s economy and society. We support the Commission in its venture to build ecosystems of excellence and trust in Europe for Artificial Intelligence (AI). As an all-encompassing technology, this involves cross sectoral coordination across all areas of Europe through a number of legislative and non-legislative...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F540645_en,12,F540645,03 August 2020,patrick GRANT,Business association,BusinessEurope,Small (10 to 49 employees),3978240953-79,Belgium,Artificial intelligence – ethical and legal requirements,"BusinessEurope welcomes the positive tone of the Commission’s White Paper acknowledging the many opportunities that AI can bring to Europe’s economy and society. We support the Commission in its venture to build ecosystems of excellence and trust in Europe for Artificial Intelligence (AI). As an all-encompassing technology, this involves cross sectoral coordination across all areas of Europe through a number of legislative and non-legislative actions. No Member State alone can support our global competitive standing in this strategic technological area. Rather than relying on a few Member States or cities to lead, the diversity of resources which Europe can bring forward jointly in this process is what will propel it to be a global competitive player in AI. In return, the full economic, environmental, workplace and societal opportunities AI derives can be evenly spread across the continent - leaving no one behind through the ongoing digital revolution.

We welcome the Commission’s pragmatic approach to excellence and trust in AI outlined in its recent White Paper. The two are likely to reinforce one another: a range of measures tackling legal challenges could support uptake by improving societal trust and offer greater clarity for consumers and businesses alike.

As a key political cornerstone of the Von der Leyen Commission, which will be fundamental to shape how AI develops in the EU, the utmost importance must be given to its transparent and open consultation before further operational steps by policy makers are taken. We repeat our call for an extension until the end of 2020 on this consultation in this regard due to the ongoing COVID-19 crisis. This will allow the fundamental debate required with stakeholders to take place. Adjusting timelines to the realities we are living within would ensure that quality prevails over speed. We suggest extending the period for input to the end of the year to ensure inclusive engagement so that useful proposals evolve from this consultation.

As a key societal stakeholder and European social partner (see latest digitalisation agreement), BusinessEurope outlines its reaction in the document attached as a response to the Commission’s ongoing consultation."
Anonymous,"I would like to express my support for the 2nd sub-option of the Option #3, as it covers all the necessary pillars of an effective AI regulation. Voluntary labeling process outlined in the option #2 might have been effective, but not in the current stage where we already have extensive use of AI applications for malicious purposes (especially outside EU). On the other hand complete regulation of AI is also not desirable as it steps in the way...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F539970_en,13,F539970,30 July 2020,,,,,,,Artificial intelligence – ethical and legal requirements,"I would like to express my support for the 2nd sub-option of the Option #3, as it covers all the necessary pillars of an effective AI regulation. Voluntary labeling process outlined in the option #2 might have been effective, but not in the current stage where we already have extensive use of AI applications for malicious purposes (especially outside EU). On the other hand complete regulation of AI is also not desirable as it steps in the way of development and advancement of AI technologies."
Bart De Witte (Germany),"As we had great concerns that the first release of the guidelines of trustworthy AI was released without going deeper into the first component, which is lawful AI. In regards to the fundamental right as described in the EU charter for fundamental rights, we can cluster two infringements that the current GRDP regulations do not cover. 1. Right to the integrity of the person: Digital Twins represent a concept, where AI-models can “map” data...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F539630_en,13,F539630,28 July 2020,Bart De Witte,EU citizen,,,,Germany,Artificial intelligence – ethical and legal requirements,"As we had great concerns that the first release of the guidelines of trustworthy AI was released without going deeper into the first component, which is lawful AI.

In regards to the fundamental right as described in the EU charter for fundamental rights, we can cluster two infringements that the current GRDP regulations do not cover.

1. Right to the integrity of the person: 

Digital Twins represent a concept, where AI-models can “map” data from humans into digital duplicates of the self. Whereas the original idea of a digital twin focussed on the replication of an object in data, progression within the field of AI, can create AI-models based on observed behavior and biological data rather than just the information itself. This means that a digital twin can be a model of the human self or an evolving set of data relating to the original model. As the model used in a digital twin does not need to be a data-driven model, one can argue that they are not under the protection of GDPR. Most current data-driven business models in social media (eg. Facebook) or AI-Startups (eg. replika.ai) can be GDPR compliant, but, as the subjects have no agency on the AI-model that equals their digital replica, these companies are violating the Right to Integrity of the Person. Digital twins are an extension of ourselves. They reflect who we are as individuals, how we spend our time, who and what we like and dislike, our preferences and quirks, all of what makes us human. our fundamental rights need an upgrade, so humans have agency over their digital selves. As the digital world is a replication of our physical world (Armin Nassehi, Professor of Sociology at LMU Munich) the prohibition of the reproductive cloning of human beings as described in Article 3, needs to be extended to the concept of digital cloning. 

Secondly, data in healthcare is not a commodity, but data is human life. The current view, driven by data-driven business models are paving the way for a new stage of capitalism whose outlines we only partly see: the capitalization of human life without limit. With the current model there will be no part of human life, no layer of experience, that is not extractable for economic value. Human life will be there for mining by corporations without reserve. This process of capitalization will be the foundation for a highly unequal new social arrangement. Article 1 describes the prohibition on making the human body and its parts as such a source of financial gain (Nick Couldry, LSE);  if humans can be digitally cloned, future policies need to assure that data that is extracted out of the human body can not be used as a source of financial gains. 

2. Article 35 describes that everyone citizen of the EU has the right of access to preventive health care and the right to benefit from medical treatment under the conditions established by national laws and practices. It also described that in the definition and implementation of all the Union's policies and activities a high level of human health protection needs to be ensured. The current data-driven business models in healthcare are leading to privatization and centralisation of medical knowledge (medical knowledge is represented in AI models). In order to be compliant with Article 35, the EU need to establish policies that guarantee, that all AI-models used in healthcare are open models that are accessible to all. Only in this way one can guarantee a high level of human health protection for all, as described in article 35."
Global Digital Foundation (Ireland),"Policy analysts and policymakers are responding to AI as both a threat to human rights and as a potential savour of humanity from discrimination. This response rests on two questionable ideas. The first is that AI’s supposed human-like intelligence could give it a mind or a ‘will’. The second is that decisions affecting socio-economic outcomes are, in reality, the instrumentalisation of unfair hierarchies—and that AI could make this problem...",https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F539194_en,13,F539194,24 July 2020,Paul MACDONNELL,Non-governmental organisation (NGO),Global Digital Foundation,Micro (1 to 9 employees),352788324603-77,Ireland,Artificial intelligence – ethical and legal requirements,"Policy analysts and policymakers are responding to AI as both a threat to human rights and as a potential savour of humanity from discrimination. This response rests on two questionable ideas. The first is that AI’s supposed human-like intelligence could give it a mind or a ‘will’. The second is that decisions affecting socio-economic outcomes are, in reality, the instrumentalisation of unfair hierarchies—and that AI could make this problem worse. This paper argues that, while AI affecting safety—e.g. in transport or healthcare—should be regulated and certified prior to implementation, AI that may affect human rights or social outcomes cannot be regulated in this way. This is because the likely causes of bad human rights or socio-economic outcomes following the use of AI will be both multivariate and exogenous to AI technologies in a way that threats to safety will not. Proposals to regulate AI for ‘fairness’ ex ante rest on a univariate ‘social bias’ explanation for differential social outcomes and are, hence, likely to be both ineffective and divisive.

Therefore Option 1 a 'soft law' approach is the best way forward."
