Organization,Feedback reference,Submitted on,User type,Organisation size,Country of origin,text,language
DECO (Portugal),F551020,10 September 2020,Consumer organisation,Medium (50 to 249 employees),Portugal,"PARC - Assunto: Proposal for a legal act of the European Parliament and the Council laying down requirements for Artificial Intelligence Requerente: Comiss o Europeia - CNECT.A.2 I. Coment rios na generalidade : Congratulamo -nos, antes de mais, pela oportu nidade de comentar o presente documento de avalia o de impacto inicial r eferente a iniciativa legi slativa do Parlamento Europeu e do Conselho que estabelece os requisitos em mat ria de Intelig ncia Artificial (IA). Como bem referido neste documento, a IA uma tecnologia que pode contribuir relevantemente para uma diversidade de benef cios econ micos e sociais em todo s os setores industriais e sociais , fornecendo vantagens competitivas importantes para as empresas e potenciar os mais variados benef cios sociais e ambientais . Entre outros , a IA acarre ta novos desaf ios em mat ria de responsabilidade civil, designadamente em reas como a legisla o na seguran a dos produtos , a qual pode futuramente ser desenvolvida para fornecer um ma ior grau de certeza jur dica. Levanta ainda um significativo n mero de quest es ticas e legais , uma vez s fazer sentido a apos ta no desenvolvimento e ado o da IA se esta for segura e l cita , respeitando direitos fundamentais dos cidad os . Com efeito, algu mas das suas utiliza es e aplica es podem caus ar dan os f sicos e morais , nomeadame nte no que respeita com a sa de , seguran a e integridade f sica de pessoas , bem como ocasionar viola o da privacidade ou restri es liberdade de express o , por exemp lo. II. Coment rios na espe cialidade : De acordo com um inqu rito realizada por organiza es de c onsumidores em nove pa ses1 da UE e publicad o este m s , os consumidores acreditam que a intelig ncia artificial (IA) pode trazer benef cios. No entanto, q uando solicitado s a avaliar o valor agregado de uma s rie de servi os espec ficos que j hoje usam tecnolo gia de IA - por 1 Este i nqu rito foi realizado simultaneamente por organiza es de consumi dores de nove pa ses da UE (Test Achats /Test Aankoop - B lgica; Forbrugerr det T nk - Dinamarca; UFC -Que Choisir - Fran a; vzbv - Alemanha; Altroconsumo - It lia; Federacja Konsumentow - Pol nia; Deco Proteste - Portugal ; OCU - Espanha e Sveriges Konsum enter - Su cia) ao longo de novembro e dezem bro de 2 exemplo, assistentes virtuais dom sticos ou an ncios em sites de com rcio eletr nico - a maioria dos entrevistados n o est convencida . Os consumidores tamb m expressaram v rias preocupa es, como a quest o de que a IA poderia levar a um au mento de viola o e abuso d os seus dados pessoais. Na verdade, quando se trata de tecnologias particularmente intrusivas, como reconhecimento de voz, muitos consumidores - 68% na Alemanha e 71% na B lgica - confiam pouco na prote o de sua privacidade. Um grande n mero de entrevistados disse n o achar que a legisla o atual seja adequada para regular efetivamente as atividades baseadas em IA. Apenas u m quinto dos entrevistados disse que as regras atuais os protegem dos danos potenciais que a IA representa. Os planos da UE p ara uma lei sobre IA est o, portanto, muito em linha com as expectativas das pessoas. Este inqu rito demonstro u ainda que que o s consumidores confiam no potencial da IA, mas desejam permanecer no controle. Mais de dois ter os dos entrevistados expressaram que os utilizad ores deve m ter o direito de dizer n o tomada de decis o automatizada. Outras respostas ao inqu rito referem que: O conhecimento sobre IA ainda relativamente baixo, com 21% dos consumidores dizendo que nunca ouviram falar ou n o t m ideia de sua presen a. Os consumidores esperam que os servi os baseados em c lculos de m quina ajudem a prever acidentes de tr nsito (91%), sa de (87%) ou problemas financeiros (81%). Os consumidores relatam ter experimentado mau servi o , tendo 41% dos entrevistados, por exemplo, re latado uma m experi ncia no que diz respeito s informa es fornecidas para propostas de empr st imos com base em decis es automatizadas. Produtos e servi os com tecnologia de IA (de assistentes de voz a bots de chat ) est o cada vez mais presentes na vida dos consumid ores. Ainda assim, 43% dos entrevistados sentem -se mal informados sobre IA ou nun ca ouviram falar sobre isso. E embora os consumidores acreditem que a IA pode trazer benef cios, eles tamb m afirmam que ta is benef cios ainda n o ocorreram. Muitos tamb m levantam s rias preocupa es, com at cinco em cada dez afirmando que a IA levar discrimina o injusta. 3 Consideramos preocupante que a maioria dos consumidores n o confie que sua privacidade seja protegida ao utilizarem ferramentas de IA, como rel gios inteligentes ou assistentes de voz. Mais ainda, o s consumi dores relatam estar preoc upados com o risco de que empresas e governos possam implantar IA para manipular suas decis es e que a IA leve a uma discrimina o injusta. Os legisladores da UE precisam levar essas preocupa es a s rio e garantir que os con sumidores estejam protegidos e possam confiar nessa tecnologia , estando salvaguardados de riscos como a discrimina o ou manipula o.",pt
TECH IN FRANCE (France),F551014,10 September 2020,Company/business,Micro (1 to 9 employees),France,"1 Septembre 2020 R ponse de TECH IN France l Etude d impact initiale sur l intelligence artificielle de la Commission europ enne 2 Par la contribution l tude d impact initiale sur l Intelligence artificielle (IA) ouverte, TECH IN France souhaite poursuivre son implication vis - -vis des travaux et des r flexions conduits par la Commission europ enne dans le cadre de sa strat gie d d i e l IA. Ainsi, le souhait de la Commission europ enne de cr er un syst me europ en m me de garantir la confiance des citoyens et stimuler l adoption des usages IA, tout en assurant celle des entreprises dans le d ploiement de leurs produits et appl ications IA et la capacit d innovation en Europe , nous appara t une strat gie ambitieuse et adapt e aux enjeux de d veloppement du potentiel num rique en Europe. De nombreuses entreprises membres de TECH IN France se sont d ailleurs exprim es publiquement au cours des derniers mois en faveur du principe de l laboration d une r gulation. Dans cette optique, TECH IN France et ses adh rents souhait ent r it rer ici l attention port e l adoption d une approche pragmatique et quilibr e dans l a d finition d un nouveau cadre r glementaire par la Commission europ enne. Ce principe d quilibre dans l laboration d une r gulation europ enne de l IA apparait comme essentiel pour cr er les conditions de l innovation via le d veloppement d un cosyst me de l excelle nce, d s le stade de la recherche et de l innovation, incitant une adoption rapide des solutions IA par les entreprises, notamment les TPE et les PME ; et pour tre m me de stimuler l innovation , en donnant aux entreprises la s curit juridique n cessa ire. Ce nouveau cadre r glementaire devra galement viter de faire peser sur les entreprises des contraintes disproportionn es par rapport leurs comp titeurs internationaux, et devra r pondre leurs besoins de comp titivit dans la bataille mondiale de l IA et des donn es. Dans le cadre de cette tude d imp act, il est propos de revenir plus pr cis ment sur les diff rentes options de r gulation de l IA envisag es par la Commission europ enne et pr sent es au sein du Livre Blanc sur une approche europ enne de l intelligence artificielle en f vrier dernier. Il nous apparait ainsi important de pr ciser nouveau les l ments et points de vigilance , formul s par TECH IN France au sein de sa r ponse la consultation sur le Livre Blanc. Remarques g n rales sur le cadre de r gulation de l IA La Commission europ enne propose de d velopper et graduer la r gulation europ enne en mati re d IA selon une approche bas e sur le niveau de risque . Elle pr cise d ailleurs dans son Livre Blanc de f vrier 2020 que le principe de proportionnalit doit guider l laboration de ce nouveau cadre r glementaire pour l IA, qui devrait atteindre ses objectifs avec efficacit sans tre excessivement normatif , au risque de cr er une charge disproportionn e, en particulier pour les PME. Il est en effet indispensable que les l gislations venir soient proportionn es et ne soient pas trop complexes mettre en uvre par les PME, afin de ne pas les p naliser. La norme doit pouvoir jouer un r le porteur de d veloppement conomique et non pas c ontre -productif. Dans ce cadre, il semble essentiel que le champ d app lication, les notions et les crit res d application d une r gulation sp cifique soient d finis clairement et de mani re pragmatique , afin de permettre aux entreprises soumises la r gulation de b n ficier de la meilleure visibilit sur les r gimes juridiq ues applicables. Ces l ments sont donc des conditions indispensables toute s curit juridique et la dynamique d innovation des entreprises . 3 Champ d application du cadre r glementaire IA : la d finition de l IA Afin de d terminer le champ d applica tion de la r gulation d finir, la Commission europ enne pr cise dans sa strat gie qu il s agit de d finir en amont de mani re claire la notion d intelligence artificielle . Il est int ressant de rappeler qu il n existe ce jour aucune d finition arr t e et accept e par l ensemble de l cosyst me, que ce soit par les experts, les acad miques ou les entreprises. Pour ce faire, la Commission voque les l ments principaux composant l IA : les donn es et les algorithmes et semble ainsi retenir une d finit ion vaste de l IA, qui appelle selon TECH IN France des points de vigilance. Il nous apparait tout d abord important de pr ciser ici qu une d finition claire de l IA et facilement compr hensible de tous, est une condition de l efficacit de la r gulation . D finir l IA en essentialisant les donn es et les algorithmes implique de facto que l IA couvre un p rim tre tr s large. En ce sens, il conviendrait de d finir plus pr cis ment le p rim tre ligible relevant de l IA par rapport celui de l algorithmie e n g n ral. En effet, tout traitement de donn es, y compris massif, ne rel ve pas n cessairement du p rim tre de l IA. Par ailleurs, certaines d finitions existantes de l IA (dont une r alis e par la Commission europ enne en 2018 dans sa communication L IA pour l Europe ), certaines op rent une distinction entre les syst mes d IA apprenants , qui font preuve d un comportement intelligent en analysant leur environnement et en prenant des mesures, avec un certain degr d autonomie, pour atteindre des objectifs sp cifiques et les syst mes d IA classiques, qui peuvent tre purement logiciels, agissant dans le monde virtuel mais aussi dans des dispositifs mat riels . Suivre une telle logique dans une d finition de l IA permettrait de r aliser des dis tinctions de r gulation selon les cat gories d IA, en r alisant un focus sur les syst mes apprenants , r duisant ainsi le champ d application de l intervention r glementaire d finir et conduisant ne pas cr er une r glementation excessive. Cr er un cosyst me de la confiance : les options de r gulation de l IA Sur l option 0 et l importance du principe de coh rence ( consistency ) La Commission europ enne dans son option 0 envisage la possibilit de ne pas cr er une r glementation propre aux applications et syst mes d IA , avec des r gles et des exigences sp cifiques , dans la mesure o des l gislations existantes sont d j applic ables l IA. Il apparait en effet utile qu une valuation des l gislations existantes et de leur capacit s appliquer de mani re pertinente aux technologies d IA, soit r ali s e au pr alable ; cela avant d envisager toute r glementation d di e. Surtout , il semble important de rapp eler qu en cas de nouvelle r glementation, le principe de coh rence ( consistency ) est essentiel. En effet, la coh rence est n cessaire entre une nouvelle 4 r gulation de l IA et les nombreux textes europ ens ou nationaux exis tants, qui s appliquent pleinement comme l a d ailleurs relev la Commission europ enne, tels que le RGPD, la directive relative la s curit g n rale de produits, la directive sur l galit de traitement entre les personnes sans distinction de race ou d origine ethnique, la directive sur l galit de traitement en mati re d emploi et de travail ou encore la directive relative aux droits des consommateurs. Il s agit donc de veiller ce que l laboration de toute autre forme de nouvelle r glementation soi t coh rente avec les textes existants . En pratique, les entreprises ont acquis une exp rience cons quente en mati re de conformit (process, outils, documentation, autor gulation ), notamment dans le cadre de la mise en uvre du r glement g n ral sur la protection des donn es (RGPD). Ainsi, en ce qui concerne les d cisions automatis es, le RGPD impose des restrictions, mais aussi le droit des individus d tre inform s quant la logique sous -tendant ces d cisions. De m me, le r glement pr voit, notamment en son article 22, un cadre pr cis en mati re de traitement des donn es personnelles. Il sera donc n cessaire pour toute nouvelle r gulation en mati re d IA de ne pas se chevaucher avec les dispositions d j pr vues par le RGPD . Surtout, ce principe d e coh rence, garantie d une harmonisation des l gislations, permettra galement aux entreprises de conserver le cadre juridique auxquelles elles se sont adapt es depuis maintenant plusieurs mois ; l ment n cessaire la s curit juridique et donc la cr ation d un environnement favorable la confiance et l innovation. Sur l option 1 , une approche de soft law La Commission europ enne dans son option 1 propose de ne pas dicter d instrument l gislatif ou r glementaire mais de faciliter, privil gier et promouvoir l intervention et les initiatives de l industrie en mati re d IA. Des approches volontaires seraient ainsi privil gi es, reposant sur de bonnes pratiques, le d veloppement de standards et principes Tout soutien l industrie et l encourageme nt la d finition et au partage de bonnes pratiques doit tre selon nous encourag . Sur l option 2 et le principe de lab lisation volontaire Le sch ma de lab lisation volontaire d fini par un instrument l gislatif, envisag dans l option 2 pourrait tre un l ment contribuant renforcer la confiance des utilisateurs dans les syst mes d IA, en facilitant ainsi l adoption. Ce syst me de compliance devrait n anmoins selon nous laisser aux entreprises la flexibilit de choisir les outils les plus pertinents pour attester de leur compliance . Des outils concrets tels que les codes de conduite, les certifications, le concept de privacy by design/ by default , permettraient aux entreprise s de b n ficier de cette flexibilit . L adoption par les entreprises, notamment les start -ups et les PME, de ce syst me de lab lisation d pendra de cette flexibilit . Sur les options et 4 , une a pproche fond e sur le risque L approche europ enne rete nue dans les options 3 b) et 4 de l tude d impact initiale se fonde sur la notion de risque , qui doit permettre de graduer la r ponse r glementaire. Cette approche semble pertinente, notamment car elle permet a priori de ne pas d courager le d veloppem ent et l utilisation de l IA , en appliquant une logique r glementaire s ajustant la diversit des applications IA ; et semble adapt e des technologies en volution comme l IA et le machine learning . Elle 5 permettrait galement de ne pas r guler de mani re excessive les applications IA pr sentant peu de risques pour l int grit physique ou les droits fondamentaux des individus par exemple, ce qui est le cas pour la plupart des applications IA. L approche cumulative pour d terminer le degr de risque : une approche pragmatique Pour d terminer le niveau de risque de l application IA, les crit res pris en consid ration doivent tre clairs et intelligibles , comme le pr cis ait d j l e Livre Blanc de la Commission europ enne, les l ment s permettant d' tablir qu'une application d'IA est haut risque devraient tre clairs, faciles comprendre et applicables toutes les parties concern es . Ainsi, l approche cumulative consistant prendre en compte le secteur dans lequel l IA est utili s e, mais aussi l utilisation qui en est faite au sein de ce m me secteur, appara t raisonnable et pragmatique. Cette combinaison de crit res permettant de d terminer si une application IA est haut risque ou faible risque, permet de ne pas stigmatiser certains secteurs , qui par nature seraient consid r s comme haut risque, alors que l utilisation en question faite de l application comporterait en r alit un faible risque, voire dans certains cas contribuerait diminuer le risque. Il semble n anmoins important en pratique que la distinction entre les deux types de risques envisag e par la Commission europ enne soit clarifi e pour garantir la s curit juridique des entreprises , et notamment viter de placer les petits acteurs conomiques dans des situations juridiques complexes. En effet, les crit res peuvent tre vus comme encore assez flous, ce qui pourrait laisser craindre que la notion de risque soit interpr t e de mani re extensive . Des l ments compl mentaires pourraient ainsi tre p ris en compte lors de l valuation du risque (permettant aux entreprises de la r aliser plus facilement), comme le fait d envisager les dommages potentiels, mais aussi les opportunit s pour la soci t et les citoyens , et donc de mesurer le co t de ne p as utiliser en pratique l IA. Une telle mise en balance apparaitrait utile pour ne pas d courager l utilisation de l IA d s lors qu elle pr senterait des risques, qui peuvent, dans de nombreux cas, tre att nu s en pratique. De m me, la d termination du ni veau de risque pourrait prendre en compte, au-del de la gravit potentielle d un dommage, sa probabilit . Par ailleurs, les cas exceptionnels mentionn s par la Commission europ enne dans son Livre Blanc, qui seraient consid r s par nature comme haut - risque, et ce, quel que soit l valuation des risques selon les crit res cumulatifs r alis e, peut tre per ue comme cr ant un v ritable flou dans la d termination du risque et l application de la r glementation sp cifique, et donc comme un facteur important d ins curit juridique . Il conviendrait galement de relativiser les attentes de performance en mati re d IA, car bien que tout puisse tre fait pour minimiser les risques et les erreurs, les algorithmes servant au syst me d IA peuvent tre biais s ou co mporter des erreurs, cela relevant du caract re inh rent de l algorithme, consistant fournir des r sultats statistiques et des probabilit s bas s sur des donn es. La Commission europ enne rappelle d ailleurs que les biais et discriminations ne sont pas p ropres la machine et sont inh rents toute soci t et activit conomique. Enfin, il semble qu une nomenclature plus pr cise de la donn e permettrait galement aux entreprises d appr cier plus finement la notion de risque et d laborer des strat gies d e normalisation adapt es. 6 Exigences obligatoires pour les applications d IA haut risque La Commission europ enne dans son option voque des exigences et obligations l gales impos es aux d veloppeurs et aux utilisateurs professionnels de l IA, qui ne s appliqueraient que dans les cas d applications IA consid r es comme haut risque. Au vu des obligations envisag es dans le L ivre B lanc, il convient d tre vigilant quant l laboration de ces r gles et quant leur interpr tation pratique : il est important que cela soit r alis avec pragmatisme et que les exigences soient applicables en pratique par les entreprises, au risque de freiner drastiquement l innovation. Conformit et m ise en app lication La Commission europ enne envisage que les applications d IA fassent l objet d une valuation de conformit pr alable visant s assurer que les exigences obligatoires , dans le cas d appl ication haut risque sont bien respect es. Ce prior assessment pourrait inclure des proc dures de test, d inspection ou de certification, voire des v rifications des algorithmes et des datas sets utilis s dans la phase de d veloppement. Les entre prises peuvent s inqui ter de la mise en place d une telle proc dure de conformit ex ante. En effet, de nombreuses questions concr tes mergent, auxquelles il sera important d apporter des pr cisions. Par exemple, quid de l application r troactive d une t elle proc dure des produits d j mis sur le march ? Des alternatives efficaces cette valuation de conformit pr alable, et pouvant tre mises en uvre plus facilement par les entreprises, pourraient tre envisag es, sur la base par exemple de ce qui existe dans le cadre du RGPD en mati re d valuation des impacts sur la protection des donn es ( impact assessment ). De m me, la combinaison d valuations par les entreprises des risques ex ante et ex post , pourrait permettre d valuer la conformit aux exigences obligatoires, sans imposer de charges suppl mentaires trop lourdes aux entreprises, s appuyant par exemple sur des pratiques juridiques ou thiques. Par ailleurs, une d marche de certification devr ait davantage viser les processus mis en uvre dans la phase de d veloppement , comme c est le cas par exemple dans les industries sensibles, que les produits finis. En ce qui concerne les valuations de risques li es la s curit des produits, la l gisla tion actuelle appara t suffisamment souple pour prendre en consid ration la majorit des risques existants li s l utilisation de ces technologies mergentes. C est pourquoi la notion de risque li e l IA ne doit pas tre envisag e sous un angle plus large, ce qui pourrait avoir pour cons quence de cr er des contraintes trop importantes et donc de freiner l innovation . Il est noter que les d veloppeurs de solution s IA font r guli rement des mises jour de leurs produits. Une autor gulation en la ma ti re existe donc et m rite d tre soulign e . Elle est d ailleurs fondamentale pour les entreprises dont les clients sont de plus en plus exigeants en mati re de s curit , et cette confiance que le client peut accorder dans le produit encourage les bonnes pratiques dans le m tier. Par ailleurs, dans le cadre des r flexions sur la mise en place de nouvelles proc dures d valuation des risques pour les produits, la r flexion devrait s engager selon deux axes, qui sont fonction du type 7 d IA en question. En effet, pour les syst mes d IA apprenant sur des jeux dits statiques , le produit final en r sultant n a pas vocation voluer davantage apr s sa mise sur le march . En revanche, pour les syst mes d IA qui continuent d apprendre sur des jeux d essais, i ls peuvent parfois voluer au point de parvenir des ruptures si fortes dans le comportement du syst me que le produit final peut en tre modifi . Ainsi, dans le premier cas, il ne serait pas n cessaire de mettre en place de nouvelles proc dures d valuat ion des risques, puisque le produit fini n aura pas vocation tre modifi ou alt r . Mettre en place cette proc dure pourrait m me constituer un frein l innovation . Il convient en effet de relativiser l volutivit des algorithmes d IA dans ce cas puis que les technologies sont stabilis es . [A propos de TECH IN France] Cr e en 2005, TECH IN France est une association professionnelle de loi 1901 qui a pour but de rassembler et de repr senter les diteurs de logiciels, de services internet et de plateformes en France. Porte -parole de l industrie num rique, TECH IN France compte 400 entreprises adh rentes : de la startup la multinationale en passant par la PME et les grands groupes fran ais ; soit 8 milliards d euros et 90 000 empl ois. TECH IN France s est donn e pour mission de mener une r flexion permanente sur l volution de l industrie num rique et promouvoir l attractivit du secteur.",fr
Syntec Numérique (France),F550993,10 September 2020,Trade union,Small (10 to 49 employees),France,"1 Analyse d impact sur la r glementation de l intelligence arti ficielle El ments de contribution de Syntec Num rique Syntec Num rique soutient la Commission dans son ambition de stimuler le d veloppement et l'adoption de l'IA et des nouvelles technologies, tout en veillant ce que les risques potentiels soient trait s de mani re ad quate. Afin de garantir la coh rence avec la l gislation sectorielle existante , la future proposition de r glementation de l IA devra tenir compte de la r glementation europ enne existant e et qui couvre d j l application de l IA (protection des droits fondamentaux, des consommateurs et s curit des produits) . Compte tenu de la diversit des applications et des technologies de l'IA, nous recommandons la Commission d'adopter une approche cibl e et fond e sur les risques. Une telle approche devrait tre bas e sur des d finitions claires. Elle doit prendre en compte le risque pos par le d ploiement d'un syst me d'IA, le domaine d'application, le type de d p loiement et la nature des risques. Dans son analyse d impact , la Commission pr sente quatre sc narios, allant d'une approche juridique non contraignante des exigences juridiques pour tous les types d'AI. Concernant les outils r glementaires, l analyse d impact tout comme le livre blanc de la Commission, identifie nt des m canismes potentiels ex ante et ex post pour la conformit et l'application. APPROCHE NON -CONTRAIGNANTE (OPTION Dans l o ption 1 , la Commission propose une approche totalement non -contr aignante. Une approche totalement non contraignante telle que propos e dans l'option 1 pourrait ne pas suffire assurer une s curit et une clart juridique suffisante, et pourrait encore entra ner une fragmentation r glementaire. Dans le cas des applica tions d'IA haut risque, il peut tre n cessaire d'adopter une nouvelle l gislation dans certains secteurs, d' tendre ou clarifier la l gislation existante (par exemple dans des secteurs comme les dispositifs m dicaux o il existe d j une r glementation tendue concernant les applications haut risque). Ces applications d'IA haut risque doivent par cons quent tre clairement d finies par des normes juridiques fond es sur une valuation r glement e, impartiale, et externe. Au fil du temps, l IA sera largement d ploy e dans tous les secteurs. Une nouvelle l gislation ne doit tre envisag e que pour des cas sp c ifiques haut risque, lorsqu'il est d termin que les cadres existants ne peuvent pas tre clarifi s ou adapt s de mani re ad quate. Toute nouvelle proposition l gislative sur l'IA doit tre coh rente avec les cadres juridiques existants afin d' viter les r gles divergentes et l'incertitude juridique, qui pourraient avoir un effet n gatif sur l'adoption de l'IA dans l UE. Ils doivent galement pr ciser clairement les risques suppl mentaires que toute nouvelle l gislation cherche traiter. INTRODUCTION D UN LABEL VOLONTAIRE (OPTION Pour l utilisation plus g n rale de l IA, le cadre l gislatif existant devrait suffire. Un label volontaire, comme propos par l'option 2, nous semble ce stade pr matur et n cessite une r flexion plus approfondie sur la mani re dont un tel cadre pourrait s'adapter aux domaines d application et cas d utilisation de l'IA. Il serait par ailleurs n cessaire qu un tel label ne soit pas un crit re d exigence dans le cadre de la commande publique ou priv e, ou un crit re excluant u ne partie des acteurs de l IA. Propos e par le groupe d experts IA de la Commission, l auto - valuation pourrait tre une premi re tape court terme . A ce stade, la proposition d un label reste vague et il semble difficile de bien saisir tous les aspects de sa mise en uvre court terme. Il faudrait au pr alable travailler l laboration de standards. En revanche, plus long terme, sa mise en place peut tre envisag e et pourrait tre privil gi e toute nouvelle r glementation. Un tel label pourrait permettre de donner des orientations utiles aux d veloppeurs et d identifier 2 des acteurs moins visibles, tout en accroissant la confiance dans les syst mes d IA. Dans cette logique, il permettrait galement de r duire les co ts de conformit pour les entreprises op rant dans toute l'UE . En pratique, ce label devrait tre adapt aux diff rents secteurs ou applications . La proposition soul ve ce titre des questions sur le mod le d valuation d es labels ainsi que sur l autorit qui valuerait et d livrerait les labels . Concernant le mod le d valuation , il pourrait tre envisag de cr er un mod le s appuyant sur les principes d velopp s par la Commission europ enne pour une IA thique et de confiance , savoi r : facteur humain et contr le humain ; robustesse et s curit ; respect de la vie priv e et gouvernance des donn es ; transparence ; diversit , non -discrimination et quit ; bien- tre soci tal et environnement al ; responsabilisation. REGLEMENTATION ET EXIGENCES RELATIVES A L 'IA A HAUT RISQUE , A DES APPLICATIONS SPECIFIQUES OU A TOUTE L IA (OPTION S 3 ET Dans l option 3 , la Commission propose la mise en place d une l gislation comporta nt un ensemble d exigences obligatoires pour des applications tr s sp cifiques , des applications haut risque ou toutes les applications. Dans l option 4, l a Commission propose un mod le plusieurs niveaux avec des types de risques. Les options 3 et 4 d pendent enti rement du champ d application, qui reste encore d finir (d finition d es utilisations haut risque , comment et quand une application ou u n cas d'utilisation devrait tre valu , et l'absence de d finition des syst mes d'IA ). La m ani re dont les exigences sont fix es , mesur es et appliqu es (ex ante ou ex post) d pend directement du champ d'application. Nous d conseill ons donc toute proposi tion qui imposerait des exigences sp cifiques toutes les applications d'IA, comme pr sent dans l'option 3c ). L valuation des risques devrait tenir compte du contexte de l' valuation, dans la mesure o une m me application d'IA utilis e dans le m me but pour diff rentes op rations commerciales pr sentera des risques diff rents selon la mani re dont elle est int gr e. Il faudrait par cons quent privil gier une approche au cas par cas. Ainsi, l valuation des risques devrait tenir compte de la probabilit d'un dommage et non pas seulement de sa gravit . Aussi, il faudrait prendre en compte les avantages de l'utilisation de l'IA et le co t d'opportunit de la non - utilisation de l'IA. La r glementation ne doit pas d courager l'utilisation dans de tels cas. De nombreux sc narios de ce type peuvent relever de secteurs d j r glement s, auquel cas toute mesure devrait autant que possible tre coordonn e et faire partie des proc dures d' valuation de la conformit d j pr sentes dans plusieurs secteurs . Certains de ces outils ne sont pas toujours aussi efficaces pour diff rents types d'applications d'IA et peuvent entra ner des co ts ou des complications potentiellement importants pour les organisations, tant pour le d veloppement que pour le d ploiement de l'IA. Syntec Num rique est le syndicat professionnel des entreprises de services du num rique (ESN), des diteurs de logiciels et des soci t s de conseil en technologies. Il regroupe plus de 2 000 entreprises adh rentes qui r alisent 80% du chiffre d affaires total du sec teur (plus de 56 Md de chiffre d affaires, 510 000 employ s dans le secteur). Il compte 30 grands groupes, 120 ETI, 1 000 PME, 850 startups et TPE ; 11 D l gations r gionales (Hauts de France, Grand Est, Auvergne Rh ne -Alpes, Provence Alpes C te d Azur, O ccitanie, Nouvelle Aquitaine, Pays de la Loire, Bretagne, Bourgogne -Franche - Comt , Centre Val de Loire, Normandie) ; 20 membres collectifs (p les de comp titivit , associations et clusters). Pr sid par Godefroy de Bentzmann depuis juin 2016, Syntec Num ri que contribue la croissance du secteur et la transformation num rique de notre pays travers la promotion des nouveaux usages du num rique, le soutien l emploi et la formation, l accompagnement de ses adh rents dans leur d veloppement et la d fens e des int r ts de la profession. syntec -numerique.fr",fr
Związek Pracodawców Branży Internetowej IAB Polska (Poland),F550987,10 September 2020,Business association,Small (10 to 49 employees),Poland,"Zwi zek Pracodawc w Bran y Internetowej IAB Polska ul. Pu awska 39/77 02 -508 Warszawa tel. +48 22 415 54 44 fax + 48 22 212 87 74 Wk ad Zwi zku Pracodawc w Bran y Internetowej IAB Polska w ramach k onsultacj i Komisji Europejskiej dot. sztucznej inteligencji Zakres: Przede wszystkim ostrzegamy Komisj Europejsk przed rozszerzeniem zakresu przysz ej regulacji w sprawie Sztucznej Inteligencji (AI) na szeroko zdefiniowan kategori ""automatycznego podejmowania decyzji"". Takie dzia anie by oby sprzeczne z pierwotnym kier unkiem zaproponowanym w Bia ej Ksi dze w sprawie Sztucznej Inteligencji, gdzie skupiono si na zastosowaniach AI wysokiego ryzyka, tzw. kryterium sektorowym. Gdyby Sztuczna Inteligencja zosta a zdefiniowana jako ""zautomatyzowany proces decyzyjny"", to spowo dowa oby to powstanie nieproporcjonalnych, nieuzasadnionych obowi zk w regulacyjnych. Zniech ci oby to nie tylko do opracowywania i wdra ania w Europie aplikacji opartych na rozwi zaniach AI, ale tak e zautomatyzowanych system w, kt re nie stwarzaj adneg o ryzyka ani te nie wywo uj szk d. Definicja szk d niematerialnych: Ponawiamy nasze obawy zwi zane z wprowadzeniem koncepcji ""szkody niematerialnej"" (immaterial harm) do przysz ych przepis w dotycz cych AI . Jako alternatyw proponujemy odniesienie si do poj cia ""znacznego ograniczenia korzystania z praw podstawowych"", kt re by oby bardziej zbli one do istniej cych ram prawnych. Warianty podej cia do polityki regulacji: Wariant 0 (scenariusz podstawowy): Uwa amy, e nale y zapewni w a ciwe wdro enie obowi zuj cych regulacji UE w odniesieniu do AI przed wprowadzeniem jakichkolwiek nowych przepis w prawnych dotycz cych Sztucznej Inteligencji. Obecnie AI nie dzia a w pr ni i podlega licznym istniej cym przepisom, w tym RODO, regulacjom w zakresie wyrob w medycznych oraz katalogowi praw podstawowych. Wariant 1 (interwencja kierowana przez przemys - samoregulacja): Bez wzgl du na to, jakie polityczne warianty strategiczne polityki s realizowane, warto wspiera przemys w ustanawianiu i wdra aniu norm w zakresie odpowiedzialnych praktyk i dzieleniu si nimi. Wariant 2 (regulacje dotycz ce dobrowolnego etykietowania): Pozostajemy sceptyczni co do wp ywu systemu oznakowania dla sygnalizowania, e konkretne produkty i us ugi oparte na Sztucznej Inteligencji s godne zaufania w Europie. Obci enie administracyjne M P zwi zane z przestrzeganiem uci liwych obowi zk w dotycz cych oznakowania - je li zostanie ono opracowane na podstawie zaktualizowanych rekomendacji dla godnej zaufania AI i przygotowanych przez unijn Grup Ekspert w Wysokiego Szczebla ds. Sztucznej Inteligencji - mog oby znacznie przewy szy korzy ci p yn ce z takiego systemu. Wariant 3 (regulacja z obowi zkowymi wymogami): Koszt alternatywny niewykorzystania Sztucznej Inteligencji powinien by cz ci oceny przy rozwa aniu wszelkich przysz ych Zwi zek Pracodawc w Bran y Internetowej IAB Polska ul. Pu awska 39/77 02 -508 Warszawa tel. +48 22 415 54 44 fax + 48 22 212 87 74 przepis w maj cych na celu zmniejszenie ryzyka i szk d wynikaj cych z wykorzystania aplikacji opartych o Sztuczn Inteligencj . Ewentualna przysz a regulacja powinna gwarantowa pewno prawn , by propor cjonalne i zwi ksza zaufanie do Sztucznej Inteligencji, nie utrudniaj c przy tym w nieuzasadniony spos b wprowadzania innowacji opartych o AI. 3a: Systemy zdalnej identyfikacji biometrycznej mog by dobrym przyk adem rozwi zania, do kt rego mo na by zas tosowa obowi zkowe wymogi w oparciu o analiz ryzyka. 3b: Popieramy dobrze zdefiniowane, oparte na ryzyku podej cie do wdro enia regulacji w sprawie Sztucznej Inteligencji, uwzgl dniaj ce zar wno powag , jak i prawdopodobie stwo wyst pienia szkody. Uwa am y, e dobrym punktem wyj cia wydaj si by kryteria sektorowe oraz kryteria podstawowe dotycz ce wykorzystania/stosowania - zaproponowane w bia ej ksi dze KE. 3c: Zdecydowanie ostrzegamy przed przyj ciem jakiegokolwiek aktu prawnego UE dotycz cego regulac ji wszystkich zastosowa Sztucznej Inteligencji , w kt rym brak by oby rozr nienia mi dzy zastosowaniami AI, kt re mog stwarza znaczne ryzyko/szkodliwo , a tymi, kt re takiego ryzyka nie stwarzaj lub maj ni szy profil ryzyka. Taki instrument legislacy jny by by nieproporcjonalny w stosunku do problem w zidentyfikowanych dotychczas przez Komisj Europejsk , stwarza by znaczne bariery dla przyj cia Sztucznej Inteligencji (dodatkowe koszty, op nienia, obci enia administracyjne) w Europie, generowa by dod atkowe koszty w niekt rych zastosowaniach ze wzgl du na brak wdro enia rozwi za opartych na AI, a tak e stwarza by ryzyko obni enia wymaga regulacyjnych dla tych zastosowa Sztucznej Inteligencji, kt re mog stwarza znaczne ryzyko. Egzekwowanie prawa : Popieramy egzekwowanie prawa ex post w przypadku pojawienia si problem w jako najbardziej odpowiedni i proporcjonalny mechanizm, z wyj tkiem dziedzin, w kt rych oceny ex ante s ju utrwalon praktyk (np. procesy medyczne). W takich sytuacjach zalecamy dostosowanie wszelkich ocen ex -ante do istniej cych procedur i praktyk sektorowych. Je eli Komisja nalega na egzekwowanie prawa ex -ante, stanowczo ostrzegamy przed dokonywaniem oceny ex -ante przez jakikolwiek podmiot trzeci i zalecamy opracowanie procedur samooceny opartych na jasnych wytycznych dotycz cych ""nale ytej staranno ci"" organ w regulacyjnych. W praktyce polega oby to na dostarczeniu przez organy regulacyjne szczeg owych wytycznych dotycz cych sposobu przeprowadzania i dokumentowania oceny ryzyk a, przy jednoczesnym przekazaniu odpowiedzialno ci za przeprowadzenie dok adnej oceny osobom korzystaj cym ze Sztucznej Inteligencji i najlepiej znaj cym go.",pl
The Polish Confederation Lewiatan (Poland),F550907,10 September 2020,Non-governmental organisation (NGO),Medium (50 to 249 employees),Poland,"- 1 - Warszawa , 10 wrze nia 2020 r. KL/420/300 /ED/2020 Konsu ltacje Komisji Europejskiej dotycz ce etycznych i prawnych wymog w dla sztucznej inteligencji Zakres: Jasna i szeroko rozumiana definicja sztucznej inteligencji b dzie mia a kluczowe znaczenie dla skuteczno ci wszelkich przysz ych ram regulacyjnych. Dl atego przestrzegamy przed zdefiniowaniem Sztucznej Inteligencji, jako tzw. automatycznego system podejmowania decyzji. Tak rozumiana definicja Sztucznej Inteligencji by aby sprzeczna z kierunkiem regulacji zaproponowanym przez KE w Bia ej K si dze. Co wi cej , mog aby doprowadzi do powstania nieuzasadnionych obowi zk w regulacyjnych, z kt rych wiele mo e znacznie utrudni rozw j i rozpowszechnienie korzystnych zastosowa Sztucznej Inteligencji w Europie. Zwracamy uwag na nieprecyzyjny charakter poj cia ""szk ody niematerialnej"". Niestety, definicja ta mo e oznacza wszystko, od strat gospodarczych do bolesnych emocji, i mo e prowadzi do niepewno ci prawnej, zniech caj c do inwestycji i innowacji. W zamian proponujemy, aby przysz e regulacje odnosi y si do po j cia ""znacznego ograniczenia korzystania z praw podstawowych"". Poj cie to jest zbli one do istniej cych ram prawnych. Podej cie do regulacji Sztucznej Inteligencji: Przede wszystkim , jeste my przeciwni jakimkolwiek nowym regulacjom. Stoimy na stanowisku , e ju obecnie Sztuczna Inteligencja podlega wielu istniej cym przepisom, takim jak cho by RODO. Dlatego te przed stworzeniem jakichkolwiek nowych regulacji, nale y zapewni prawid owe wdro enie obecnych przepis w prawnych UE w tym zakresie. Niezale nie od teg o jakie podej cie regulacyjne jest stosowane, nale y za pewni wsparcie przemys u we wdra aniu norm w zakresie odpowiednich praktyk w zastosowaniu Sztucznej Inteligencji. Ponadto , jeste my przeciwni tzw. systemowi etykietowania. Uwa amy, e nie spe ni on zak adanej funkcji, a przyczyni si z znacznym stopniu do jeszcze wi kszego obci enia administracyjnego M P, a tak e na o y na tych przedsi biorc w nowe obowi zki dotycz ce oznakowania. Koszty dostosowania si do tego typu systemu mog yby znacznie przewy szy korzy ci z niego p yn ce. Wa ne jest, aby przy konstruowaniu jakichkolwiek nowych regulacji zachowa elastyczno interpretacji prawnej i wsp pracowa z osobami zajmuj cymi si rozwojem AI w celu opracowania przepis w, kt re b d wy konalne z technicznego punktu widzenia. AI to zestaw technologii zdolnych do uczenia si , wnioskowania, dostosowywania i wykonywania zada - 2 - w spos b inspirowany przez umys ludzki. Technologia ta stale si rozwija i ulepsza. Potencjalne korzy ci z rozwoju A I s olbrzymie. Przepisy powinny uwzgl dnia szybkie tempo post pu technologicznego. Komisja s usznie stwierdzi a potrzeb dobrze zdefiniowanego, opartego na ryzyku podej cia do regulacji AI, kt re nie stosuje logiki jeden rozmiar dla wszystkich w niezl iczonych aplikacjach AI. Dobrym przyk adem rozwi zania , do kt rego mo na by zastosowa obowi zkowe wymogi w oparciu o analiz ryzyka jest chocia by system zdalnej identyfikacji biometrycznej. Nale y pami ta , e ka da ocena ryzyka powinna mie charakter ho listyczny, odzwierciedlaj cy nie tylko potencjalne szkody, ale r wnie mo liwo ci spo eczne. Sztuczna inteligencja to zestaw technologii zdolnych do uczenia si , rozumowania, dostosowywania i wykonywania zada w spos b zainspirowany przez ludzki umys . Tec hnologia ta stale si rozwija i doskonali. Potencjalne korzy ci p yn ce z jej rozwoju s ogromne. Przepisy powinny uwzgl dnia szybkie tempo post pu technologicznego. Maj c to na uwadze, nale y wprowadzi szereg dostosowa , aby zapewni , e wszelkie potenc jalne regulacje b d ukierunkowane na w a ciwe przypadki u ycia, zwi ksz pewno prawn i nie zniech c do rozwoju i rozpowszechniania AI. Egzekwowanie prawa: Uwa amy, e najlepsze podej cie do aplikacji AI wysokiego ryzyka to ocena rozwi za ex -post . Rozumiemy oczywi cie, e s dziedziny, w kt rych ocena ex -ante stanowi utrwalon praktyk , np. medycyna, jednak e w tych dziedzinach postulujemy, aby ocen ex -ante po czy z ocen stosowanych praktyk sektorowych. W przypadku, gdy KE planuje wprowadzi mechanizm egzekwowania prawa ex -ante, zalecamy, aby to nie podmioty trzecie, ale tw rcy rozwi za dokonywali samooceny. Organy regulacyjne powinny przy tym wypracowa wytyczne dotycz ce poj cia nale ytej staranno ci . Warto r wnie zwr ci uwag , aby proc es samocertyfikacji nie by zbyt uci liwy, szczeg lnie w zakresie wymog w dotycz cych dokumentacji. Inaczej istnieje ryzyko, e z uwagi na nadmierne wymogi prawne, proces ten mo e zniech ci M P do podejmowania dzia a na rzecz wprowadzania innowacji. Z powa aniem, Maciej Witu cki Prezydent Konfederacji Lewiatan",pl
APDSI - Associação para a Promoção e Desenvolvimento da Sociedade da Informação (Portugal),F550875,10 September 2020,Non-governmental organisation (NGO),Micro (1 to 9 employees),Portugal,"mbito: N o nos parece adequado expandir o mbito do futuro regulamento de IA para a categoria aberta de ""tomada de decis o automatizada"". Isso iria contra a ideia inicial refletida no Livro Branco da IA, que prop e concentrar-se e basear-se no risco e no duplo crit rio para as tecnologias de IA setoriais e de aplica o/utiliza o. Se a IA fosse definida como ""tomada de decis o automatizada"" para efeitos da futura regulamenta o, este conceito criaria obriga es regulamentares que dificultariam o desenvolvimento e a implanta o de aplica es baseadas em IA na Europa bem como de sistemas automatizados que n o representam qualquer risco ou dano. Op es pol ticas: Op o 0 (base): Acreditamos que h m rito em assegurar que o regulamento existente da UE devidamente implementado no que diz respeito IA, antes de se estabelecerem quaisquer novas regras prescritivas espec ficas para a IA. Atualmente, a IA n o funciona no v cuo legislativo, est sujeita a uma s rie de regras existentes, incluindo o RGPD, o regulamento sobre os dispositivos m dicos, e o acervo dos direitos fundamentais. Op o 1 (interven o liderada pela ind stria): Independentemente das op es de pol ticas p blicas que sejam seguidas, til dar apoio ind stria na defini o e implementa o de normas que estabele am pr ticas respons veis e partilha das mesmas. Op o 2 (legisla o sobre rotulagem volunt ria): Parece-nos uma ideia interessante mas somos c ticos em rela o efic cia da ades o a este instrumento que pode tornar-se um encargo administrativo para as PME que poderia pesar mais e prevalecer significativamente, em rela o aos benef cios que traria. Op o 3 (legisla o com requisitos obrigat rios): No geral, o custo de oportunidade da n o utiliza o da IA deve fazer parte da avalia o quando se considera qualquer legisla o destinada a reduzir o risco e os danos decorrentes da utiliza o de aplica es de IA. A legisla o deve garantir a seguran a jur dica, ser proporcional e aumentar a confian a na IA, sem prejudicar, indevidamente, a inova o conduzida pela mesma. 3a: Os sistemas de identifica o biom trica remota podem ser um bom exemplo de uma aplica o qual poderiam ser aplicados requisitos obrigat rios numa abordagem baseada no risco. 3b: Apoiamos uma abordagem bem definida, baseada no risco, ao regulamento sobre IA, que tenha em conta tanto a gravidade como a probabilidade de dano. Crit rios de base de utiliza o/aplica o e setoriais - tal como proposto pelo Livro Branco da Comiss o Europeia - parecem em geral ser um bom ponto de partida. 3c: Advertimos contra um ato legislativo da UE para todas as aplica es poss veis de IA, que n o fa a distin o entre as aplica es de IA que possam representar um risco/perigo significativo e as que n o comportam riscos ou t m um perfil de risco inferior. Tal instrumento legislativo seria significativamente desproporcional aos problemas at agora identificados pela CE, criaria barreiras significativas ado o de IA na Europa, resultaria em custos de oportunidade em algumas aplica es devido falta de implementa o de IA, e arriscar-se-ia a baixar a fasquia para aquelas aplica es de IA que s o muito suscet veis de levantar riscos significativos. Aplica o da regulamenta o: Apoiamos a aplica o ex post, para quando os problemas surgirem, como sendo o mecanismo mais apropriado e proporcional, exceto em campos onde as avalia es ex ante j s o pr tica estabelecida. Nestas situa es, recomendamos o alinhamento de qualquer avalia o ex-ante com os procedimentos existentes. Uma abordagem pr tica, mais eficiente que a avalia o ex-ante por terceiros, consistiria em que os reguladores fornecessem modelos detalhados e orienta es sobre como realizar e documentar a avalia o de risco, delegando por m, a responsabilidade queles que utilizam o sistema de IA e est o mais familiarizados com este, a fim de realizar uma avalia o precisa.",pt
Romanian Business Leaders - Repatriot (Romania),F550710,09 September 2020,Non-governmental organisation (NGO),Large (250 or more),Romania,"O defini ie clar i pe larg n eleas a IA este esen ial pentru eficacitatea viitorului cadru de reglementare. La fel cum Cartea alb a Comisiei privind IA a descris principalele elemente ale IA ca date i algoritmi, la fel i aceast evaluare a impactului ini ial ncearc s sugereze un domeniu de aplicare prea larg pentru reglementarea viitoare a IA. De exemplu, n cazul n care AI ar fi definit ca luarea de decizii automatizat , ar pierde focalizarea dorit bazat pe risc i ar include sisteme automate care nu prezint niciun risc. Orice viitoare reglement ri AI ar trebui s evite obliga iile de reglementare dispropor ionate i nejustificate, deoarece altfel ar avea efecte negative asupra dezvolt rii i implement rii aplica iilor bazate pe IA n Europa. Noile norme prescriptive ar trebui luate n considerare numai n domeniile n care reglementarea existent este n mod clar insuficient . Industria european a IA ar beneficia mai mult dac Comisia European ar oferi principii directoare pentru auto-reglementare i cooperare ntreprinderile europene trebuie s dezvolte tehnologii avansate n mod responsabil i noi bariere de reglementare ar fr na dezvoltarea. Un sistem de etichetare voluntar ar putea crea o povar administrativ grea pentru inovatorii AI care sunt adesea IMM-uri cu resurse limitate. n consecin , costurile unui astfel de sistem ar putea dep i rapid beneficiile ncuraj rii adopt rii AI n ntreaga Europ . Am dori, n special, s avertiz m c o schem de etichetare se bazeaz pe lista de evaluare pentru AI de ncredere din Grupul de exper i la nivel nalt al UE n domeniul IA, deoarece natura sa limiteaz inerent varia ia ntre set ri pentru diferite cazuri de aplicare. Comisia s colaboreze ndeaproape cu industria AI pentru a elabora un meniu de scheme de etichetare pentru diferite set ri ale aplica iilor AI. Costul de oportunitate al neutiliz rii IA va fi foarte mare dac interven ie de reglementare n aplica iile de IA nu sunt f cute ""inteligent"". n deliberarea posibilelor op iuni, este vital s reflect m nu numai prejudiciile poten iale, ci i oportunit ile sociale. Beneficiile AI vor dep i adesea riscurile, mai ales dac riscurile pot fi atenuate ntr-un mod atent, cu garan ii puternice. Regulamentul nu trebuie s descurajeze inovarea, dezvoltarea i nici s limiteze utilizarea AI. Propor ionalitatea i concentrarea clar a oric rei reglement ri vor contribui la asigurarea certitudinii juridice pentru inovatorii AI i vor spori ncrederea n AI, f r a mpiedica n mod nejustificat inova ia bazat pe AI. Viitoarea reglementare AI ar fi bine s se refere doar la aplica ii AI cu risc ridicat , bine definite. A sublinia sublinia necesitatea propor ionalit ii atunci c nd definim aplica iile cu risc ridicat ale IA. Proced nd astfel, este important s reflect m la probabilitatea de a face r u i nu doar posibila gravitate a prejudiciului. De asemenea, ar trebui s in cont de contextul opera ional mai larg atunci c nd se evalueaz riscul, deoarece aceea i aplica ie de IA utilizat n acela i scop va prezenta riscuri diferite n func ie de modul n care este integrat n opera iunile comerciale (de exemplu, amploarea supravegherii umane , m suri de protec ie suplimentare , cum ar fi monitorizarea). Poate o combina ie de sector i utilizare / aplica ie ca criterii pentru a stabili abordarea bazat pe risc. V t marea imaterial nu este un concept legal cunoscut i ar putea nsemna orice, de la pierderi economice la inhibarea ncrederii, i ar putea duce la incertitudine juridic , descuraj nd investi iile i inova ia. Pentru a aduce claritate practic inovatorilor AI ar fi cel mai bine s se ia n considerare un concept alternativ - restric ionarea semnificativ a exercit rii drepturilor fundamentale , care credem c ar fi mai u or de interpretat i aliniat cu cadrul legislativ existent.",ro
Deutsche Gesetzliche Unfallversicherung e.V. (Germany),F550657,09 September 2020,Other,Large (250 or more),Germany,"Aus Sicht der Deutschen Gesetzlichen Unfallversicherung e.V. (DGUV) ist ein Rechtsrahmen, mit dem F lle des Einsatzes von K nstlicher Intelligenz (KI) angemessen behandelt werden k nnen, grunds tzlich w nschenswert, aber es gilt vorrangig zu pr fen, ob der bestehende allgemeine, d.h. nicht spezifisch auf KI ausgerichtete, Rechtsrahmen nicht in den meisten F llen ausreichend ist, um auch F lle des Einsatzes von KI angemessen zu behandeln. In der Stellungnahme der Deutsche Sozialversicherung Arbeitsgemeinschaft Europa e.V. (DSVEV) zum Wei buch zur K nstlichen Intelligenz wurde bereits festgehalten, dass der von der Europ ischen Kommission vorgeschlagene risikobasierte Ansatz im Prinzip zu bef rworten ist, wenn von Fragen nach der Haftung, die unabh ngig vom Risiko f r den Einzelnen oder die Allgemeinheit zu beurteilen sind, abgesehen wird. Soweit die Sozialversicherung und die durch sie finanzierten Leistungen betroffen sind, ist zun chst keine Notwendigkeit f r eine generelle Regelung durch Anpassung des bestehenden EU-Rechtsrahmens unter Ber cksichtigung von KI erkennbar. Durch KI aufgeworfene Fragen sind weder neu noch mithilfe von allgemeinen Grunds tzen zu beantworten, sondern bed rfen je nach konkretem Fall komplizierter Abw gungen und Kompromisse. Vor diesem Hintergrund bietet jedenfalls eine generelle Regelung keinen Mehrwert oder keine zus tzliche Rechtssicherheit. Mithilfe der Auslegung und Fortentwicklung des bestehenden allgemeinen Rechtsrahmens k nnen bereits L sungen gefunden werden. Es mag erg nzend ein ethischer Rahmen, der weder entwicklungshemmend noch technologiefeindlich ist, denkbar sein und einen verantwortungsvollen Umgang mit KI f rdern. Ausgeschlossen ist nicht, einzelne Vorschriften zu berpr fen und auf die Vornahme von nderungen hinzuwirken. Kommt man in dem Zusammenhang zu dem Ergebnis, dass der bestehende allgemeine Rechtsrahmen nicht ausreichend ist, scheinen die Optionen 3 und 4 in Bezug auf Produktsicherheit und haftung vorzugsw rdig zu sein.",de
László Balázs (Hungary),F550618,09 September 2020,EU citizen,,Hungary,"Tisztelt Eur pai Uni s Tiszts gvisel k! A mesters ges intelligenci val (a tov bbiakban: MI) sszef gg sben az al bbi ll spontot k pviselem erk lcsi, mor lis s jogi formul k tekintet ben. El sz r k nytelen, kelletlen vagyok p rhuzamot vonni a biol giai determinizmus s az MI kett s ben. Napjainkban puszt t , pand mi s id szak vonulat ban a biol giai esszenci lis reziduumok jelenl te egy rtelm en detekt lhat . Az anyaterm szet a t lszaporulat s a n pess g kritikus t megg n veked se ok n fel kellett, hogy ll tson egy olyan v dvonalat, amivel k s rletet tehet a ""term szetes"" k zegek, folyamatok vissza ll t s ra, helyrehozatal ra. Mindenk pp k r ez, vagy rthet reakci arra a felel tlen kond ci halmazra, amit az emberis g ""k vetett el"" egy eg sz homeoszt zis, mikrobiom ellen? Ut bbit adekv tabbnak rzem. Gondolv n a kult r nk, t rsas kult r k s a vele egy tt j r , olykor azokat t ll p tudom nyos eredm nyekre gy v lem, hogy a moralit s, mint az emberis g fejl d s vel egy tt fejl d , alakul archaikus maradv ny, nem szabhat g tat annak a met dusnak, amit a tudom ny ter let n dolgoz , kiv l szakemberek elk pzeltek. Igaz n megk zel tve, a mor lis rt kek, jogi szab lyoz sok, k zjogi szervezetszab lyoz eszk z k nem m sok, mint ugyanannyira mesters ges - ellenben k z ss gi ig ny alapj n szervez d tt - klis k, mint a tudom ny ltal szervez d tt, ir ny tva alakult, fejl d tt ""term kek"", gondolati elemek fizikai s kon val megval sul sa. Fentieket sszegezve kijelenthet , hogy a mor lis, jogi norm k a tudom ny eredm nyeinek, term keinek t k letes reprezent nsai. Csup n az el bbiek az emberis g filozofikus kogn ci ja, m g ut bbiak a tanul s, a tapasztalat s empirizmus ment n szervez d tt kognit v kivet l sek, t rgyiasul sok. A MI tekintet ben fentiek dac ra, kijelenthet , hogy senki s Semmi (Heidegger ut n szabadon) nem k rd jelezheti meg annak l tjogosults g t, f leg annak ismeret ben, hogy m r maga az emberi l t alapvet gyakorlati elemei, ment lis kivet l sei s egy b kognit v alaki reprezent nsai ugyancsak a mesters ges vonalon keletkez dtek. Filoz fiai rtelemben lehet ennek viszonylat ban disput kat folytatni, ellenben, mint minden disputa, ez is csak azt az eredm nyt hordozn mag ban, hogy az id t ny jtsa a cselekv s veszt re, k r ra. Az eg szs g gynek, az atomiparnak, a k rnyezettudatoss gnak s sz mos tudom nyos, de az emberis g j v j t garant l tud snak, gyakorlatnak, jelent s sz ks ge van a MI-ra. Le kell csupasz tani a MI-vel szemben kialakult sztereot pi kat, aberr lt gondolati elemeket, el re vet tett negat v rzelmeket; meg kell teremteni a marketing magasabb fok jelen t, mely v gre nem az ""olcs s r k"" kateg ri j t foglalja el, hanem az emberis g el t r egy sokkal m lyebb, tartalmasabb, s nehezebb ter letet, a tudom nyt s MI-t. Tisztelettel s k sz nettel: Bal zs L szl",hu
Handelsverband Deutschland (HDE) (Germany),F550505,09 September 2020,Business association,Small (10 to 49 employees),Germany,"zur EU-Legislativi nitiative K nstliche Intelligenz ethische und rechtliche Anforderungen Stand: September 2020 [EU-Transparenzregisternummer: 31200871765 -41] Kurzs tellungnahme Handelsverband Deutschland (HDE) e. V. Fabian Fechner | fechner.europa @hde.de | +32 ( 2 737 03 76 | Br ssel Dara Kossok -Spie | kossok -spiess@hde.de | +49 ( 30 72 62 50 -33 | Berlin Seite 2 Hintergrund Der Handelsverband Deutschland (HDE) bedankt sich f r die Gelegenheit zur Stellungnahme zur EU - Initiative zum Thema K nstliche Intelligenz ethische und rechtliche Anforderungen im Rahmen des am 2 Juli 2020 von der Euro p ischen Kommission ver ffentlichten Fahrplans . Mit der angedachten Initiative m chte die EU -Kommission garantieren , dass K nstliche Intelligenz (KI) sicher und rechtm ig ist und mit den Grundrechten in der EU im Einklang steht . W hrend KI eine sich rasch entwickelnde und strategisch wichtige Technologie sei, die enorme Chancen bietet , w rden einige Einsatzm glichkeit en jedoch spezifische, erhebliche Risiken f r die Anwendung ver- schiedener EU -Vorschriften zum Schutz der Grundrechte sowie zur Gew hrleistung der Sicherheit und der L sung von Haftungsfragen bergen. Das bergeordnete Ziel bestehe laut Kommission darin, den Einsatz vertrauensw rdiger KI in der EU zu f rdern. Position des HDE K nstliche Intelligenz ist bei weitem kein Ph nomen der Science Fiction mehr: Der kommerzielle Ein- satz von KI zeichnet sich deutlich ab und wird weiter rapide voranschreiten. Ein vi elversprechendes Anwendungsfeld f r KI -Technologien ist der Einzelhandel - sowohl der Online -Handel als auch der station re Handel. Denn aufgrund ihrer Schnittstellenfunktion befinden sich H ndler*innen im kompli- zierten Beziehungsgeflecht zwischen Kunden, Herstellerinnen, Logistikern und Plattformen. Um im Wettbewerb zu bestehen, gilt es, die Kundenbed rfnisse optimal zu erfassen und m glichst effizient und passgenau zu erf llen also die richtigen Entscheidungen zur idealen Einbindung der Akteure zu treff en. KI -Systeme k nnen hierbei hochkomplexe, mit gro en Datenmengen verbundene Aufga- ben in Echtzeit bearbeiten und eine den Anforderungen entsprechende optimale L sung generieren. Der Kunde in der digitalisierten Welt fordert ma geschneiderte Angebote, stel lt sich selbstbewusst in den Mittelpunkt und will seine individuelle Handelswelt erleben. So sind 65% der Deutschen vor allem Anbietern treu, die ihr Angebot gezielt auf die Bed rfnisse und Vorlieben des Kunden zuschneiden. Um dieser Nachfrage zu entsprech en planen 45% der H ndler in den kommenden drei Jahren k nst- liche Intelligenz einzusetzen. Demnach ist KI ein Erfolgsfaktor der Digitalisierung und f r zuk nftige Gesch ftsmodelle des H andels. Die Anwendungsbereiche von KI im Handel sind vielf ltig : Intelligente Systeme k nnen den komplet- ten Gesch ftsprozess von der Zentrale ber die Logistik zur Filiale und Kundenerfahrung begleiten. Standartbeispiele hier sind das Bestandsmanagemen t mit Hilfe intelligenter Systeme in der Zentrale (unabh ngig ob H ndler*innen online oder station ren Vertriebsweg w hlen), smarte Tourenplanung bei der Logistik, die digitale Umkleidekabine am Point of Sale bis zur visuellen Produktsuche im Kun- denkontakt . Der Handelsverband Deutschland ist berzeugt: Intelligente Anwendungen sind eine Chance f r den zukunftsf higen Handel. Dar ber hinaus unterst tzen wir ausdr cklich das Ziel der Kommission, den Handelsverband Deutschland (HDE) e. V. Fabian Fechner | fechner.europa @hde.de | +32 ( 2 737 03 76 | Br ssel Dara Kossok -Spie | kossok -spiess@hde.de | +49 ( 30 72 62 50 -33 | Berlin Seite 3 Einsatz vertrauensw rdiger KI in der EU -Wirtschaft zu f rdern. Hier liegt der Schl ssel f r den Erfolg dieser Technologie auf unserem Kontinent. a) K nstliche Intelligenz mitdenken statt Einzelf lle zu regulieren K nstliche Intelligenz ist keine weitere technische Entwicklung, die einer Sonderregulierung be darf. Es ist vielmehr eine Basis -Innovation, die zahlreiche Gesch ftsmodelle ver ndern und neue erm gli- chen wird. Deshalb ist der HDE berzeugt, dass es keiner gesonderten KI -Gesetzgebung bedarf, sondern der bestehende Rechtsrahmen, wie die DSGVO, das Gese tz gegen unlauteren Wettbewerb (UWG) oder Vorschriften des Allgemeinen Gleichbehandlungsgesetzes (AGG), Verbraucher*innen hinreichend sch tzt. Was in der analogen Wirtschaft mit menschlichen Entscheidungen gilt, sollte auch in der digitalen Wirtschaft mit datenbasierten Entscheidungen mitged acht werden. Existierende Vorschriften sollten daher berpr ft und nur bei nachgewiesenem Bedarf gezielt an die von KI -Systemen ausgel ste Ent- wicklung angepasst werden. Somit haben wir als HDE eine klare Pr ferenz f r d ie Regulierungsop- tionen 1 und 2 aus dem Inception Impact Assessment - bzw. eine Kombination davon. Ein freiwilliges Kennzeichnungssystem k nnte f r die notwendige Transparenz und Orientierung sor- gen, ohne die betroffenen Unternehmen berm ig zu belasten. Dabei muss gew hrleistet sein, dass vor allem KMU in der Breite extern generierte KI as a service auch praktisch nutzen k nnen, da sie vielfach nicht in der Lage sein werden, KI -Systeme selbst zu entwickeln. Sollte aus politischen Gr nden entgegen der Position des HDE dennoch eine Regelung f r erforder- lich gehalten werden, so muss diese anwendungsbezogen und risikobasiert sein. Vor dem Hinter- grund der aufgef hrten wirtschaftlichen Auswirkungen sollte sich der Gesetzgeber daher maximal f r die Optionen 3 a oder 3b entscheiden . Sollte man sich f r eine risikoorientierte Regulierung entschei- den, ist es absolut notwendig, dass KI -Anwendungen mit hohem Risiko klar, zukunftsfest und rechts- sicher de finiert und abgegrenzt werden. Grunds tzlich halten wir den An satz, sich bei der Risikobe- wertung vor allem auf den Sektor zu konzentrieren f r richtig, allerdings wirft die vorgeschlagene Ri- sikobewertung Fragen und Probleme bei der Abgrenzung auf: Ist die Liste der betroffenen Sektoren abschlie end? Ist die Liste der kritischen Verwendungszwecke abschlie end? Was genau sind Aus- wirkungen auf die Rechte einer nat rlichen Person ? Dieser Begriff scheint extrem offen. Werden die beiden Faktoren Sektor und Auswirkung immer kumulativ angewendet? Welche weiteren Ausnah- men von der Zwei -Faktor -Bewertung neben KI bei der Einstellung von Besch ftigten gibt es noch? In Bezug auf Optionen 3a (Beschr nkung des Rechtsinstruments auf bestimmte KI-Anwendungen wie biometrische Identifizierungssysteme ) m chten wir zudem zu beden ken geben, dass b estimmte bio- metrische Identifikationssysteme zu ma geblichen Innovationen im Handel beitragen, wie z.B. das Bezahlen per Fingerabdruck . Diese sollten im Sinne der Innovationsf rderung sowie der Erleichterung von Prozessen f r den Kunden un d Anbieter unter bestimmten Bedingungen weiterhin m glich sein. Handelsverband Deutschland (HDE) e. V. Fabian Fechner | fechner.europa @hde.de | +32 ( 2 737 03 76 | Br ssel Dara Kossok -Spie | kossok -spiess@hde.de | +49 ( 30 72 62 50 -33 | Berlin Seite 4 b) KI ist nicht gleich KI Um eine sachliche Debatte zu erm glichen, brauchen wir neben dem risikobasierten Ansatz aber auch eine Unterscheidung intelligenter Systeme in schwache und starke Systeme. Schwache KI -Sys- teme unterst tzen Menschen bei Entscheidungsfindungen in einem bestimmten Bereich, z.B. in Sprach - oder Bilderkennungssystemen, w hrend starke KI -Systeme und eine sogenannt e Superintel- ligenz menschliche Intelligenz imitieren sollen inklusive der F higkeit, Wissen vielf ltig zu kombinie- ren und bereichs bergreifend anzuwenden. Es existieren bislang keine derartig starken KI -Systeme. Nichtsdestotrotz wird ein Gro teil der Dis kussion um digitale Ethik und ethische KI vor dem Hin- tergrund der dystopischen Auswirkungen einer Superintelligenz gef hrt. Genauso wie es grob fahrl ssig ist, die Erfolge von Algorithmen im kommerziellen Bereich einfach so auf andere Problemfelder wi e das Handeln von Menschen zu bertragen, ist es innovationshemmend und deplatziert aus Regulatorik f r sensible gesellschaftliche Vorg nge auf einfach Empfehlungsal- gorithmen und Mustererkennung zu schlie en. Personalisierte Produktempfehlungen, Sonderang ebote und Rabatte ber cksichtigen individuelle W nsche und Bed rfnisse der Kunden und k nnen so relevante Angebote ausspielen. Dies ist ein Mehrwert f r Verbraucher*innen, den wir in der Un bersichtlichkeit und Menge an Informationen des Internets, sch tze n und sch tzen sollten. Intelligente Produktdarstellung und Websitegestaltung stellt relevante Inhalte f r den Kunden in bersichtlicher Weise dar, indem z.B. Produktbewertungen nach Themen gefiltert werden c) Ohne (qualitativ hochwertige) Daten keine KI Intelligente Anwendungen sind eine Chance f r den Handel sowohl online als auch station r mit Tech am Point of Sale zu berzeugen. K nstliche Intelligenz generiert Erkenntnisse durch Mustererken- nung auf Basis gro er Datenmengen (Big Data) und selbsterlernter A lgorithmen. Mit zunehmender Menge an Trainingsdaten steigt die Genauigkeit der Schlussfolgerungen und Prognosen. Wichtig hier- f r ist neben der hierf r n tigen Datenmenge auch die ausreichende Datenqualit t, mit der KI -Sys- teme trainiert werden. Wir teilen somit die Einsch tzung der Kommission, dass Sch den durch KI vor allem durch die Ver- wendung von Daten schlechter Qualit t oder verzerrte Daten verursacht werden k nnen und sehen ebenfalls die Gefahr, dass fehlerhaft programmierte oder anhand verzerrender Da ten trainierte KI - Systeme diskriminierende und stigmatisierende Wirkung entfalten k nnen . Um K nstliche Intelligenz zu nutzen und insbesondere weiterzuentwickeln, muss daher Daten konomie im europ ischen Raum gelebt werden. Datenschutz ist ein hohes Gut, w as es f r Verbraucher*innen und H ndler*innen in der EU zu bewahren gilt. Dieser europ ische Datenschutz muss jedoch in sich gr tm glich koh rent sein und ein berechtigtes Interesse des H ndlers zulassen. Bereits heute beruht gro e Marktmacht auf ihrer D atenmacht, denn Daten sind der Rohstoff digitaler Gesch ftsmodelle und Trainingsger te f r KI. Im globalen Wettbewerb darf Datenschutz deshalb nicht Handelsverband Deutschland (HDE) e. V. Fabian Fechner | fechner.europa @hde.de | +32 ( 2 737 03 76 | Br ssel Dara Kossok -Spie | kossok -spiess@hde.de | +49 ( 30 72 62 50 -33 | Berlin Seite 5 zum Wettbewerbsnachteil f r europ ische Unternehmen werden. So ist beispielweise eine L sch- pflicht f r mitt els Text und Data Mining generierten Trainingsdaten, wie sie derzeit bei der Umsetzung der europ ischen Urheberrechtsrichtlinie in deutsches Recht diskutiert wird, ein Hemmnis f r die (Weiter -) Entwicklung und Anwendung von KI -Systemen. W hrend wir den Au fbau eines EU -Datenraumes als Voraussetzung f r das Gelingen der KI -Politik daher ausdr cklich begr en, m chten wir anmerken: Eine grunds tzliche Verpflichtung, Daten zu teilen, umfasst auch aus eigenen Datenbest nden neu generierte Daten. Dieses Know -How sollte gesch tzt und nicht offengelegt werden, um Innovation in der EU zu f rdern. Wir sehen daher prim r einen Bedarf zum Austausch von Daten, die von ffentlichen Einrichtungen zur Verf gung gestellt werden. d) Schutz von Gesch ftsgeheimnissen Der zukunft sf hige Handel agiert auf allen Kan len: Ob online oder offline gestalten Algorithmen mo- derne Handelsunternehmen mit: Sie erm glichen eine Anpassung des Produktangebots an die indi- viduellen Bed rfnisse und W nsche der Kunden, erlauben eine Absch tzung des Zahlungsausfallri- sikos und optimieren Absatzprognosen und Lieferrouten. Damit sind insbesondere im Handel Algo- rithmen zum wichtigen Differenzierungsmerkmal geworden. Regulatorische Inkoh renzen k nnen hierbei zu Wettbewerbsnachteilen der europ ischen H ndl er mutieren, wenn unterschiedliche gesetzliche Ma st be an Offline, Online und Smart, also KI betrie- ben, gelegt werden. Zum einen bietet der bestehende Rechtsrahmen Verbrauchern einen angemes- senen Schutz. Zum anderen k nnen wir im Digitalen nicht das Preis geben von Gesch ftsgeheimnis- sen verlangen, die in der Offline -Welt gesch tzt w ren. Denn Wettbewerbsbeschr nkungen und -verzerrungen drohen, wenn die Kerninhalte von Algorith- men offengelegt werden m ssten. Wer diese offenlegen muss, verliert de n Anreiz f r Weiter - und Neuentwicklungen und damit den Anschluss an die globale Konkurrenz. Zudem kann die Effizienz einer solchen berpr fung angezweifelt werden, da Algorithmen oft vielschichtig sind, sich h ufig n- dern und Zufallsz ge enthalten. Wir favorisieren daher einen prinzipienbasierten Ansatz, der ethische Grunds tze einer fairen Algorithmennutzung festlegt, wie sie von der unabh ngigen Expertengruppe f r K nstliche Intelligenz der EU -Kommission in den ethischen Leitlinien f r KI erarbeitet wurden. Wir m chten die Kommission auffordern , diese berlegungen bei der Ausgestaltung etwaiger Durchset- zungsmechanismen zu ber cksichtigen . Fazit: Wertegebundene Innovation Der HDE begr t das ausgeglichene Inception Impact Assessment der Kommission, das die Interes- sen der betroffenen Wirtschaftsakteure insbesondere von KMU ausdr cklich mitber cksichtigt und deren potenzielle Belastung durch etwaige Regulierung dem Nutzen gegen berstellt. Auch der expli- zite Fokus auf legislative Koh renz und Konsistenz in den Bereichen Haftung, Produktsicherheit und Handelsverband Deutschland (HDE) e. V. Fabian Fechner | fechner.europa @hde.de | +32 ( 2 737 03 76 | Br ssel Dara Kossok -Spie | kossok -spiess@hde.de | +49 ( 30 72 62 50 -33 | Berlin Seite 6 Grundrechtsschutz ist positiv zu bewerten. Dieser eingeschlagene Weg muss mit der Folgenabsch t- zung und dem Gesetzgebungsvorschlag konsequent weiter beschritten werden. Denn: Wir bewegen uns beim Thema KI in einem wettbewerblichen Spannungsfeld und m ssen dem Innovationsraum Europa einen Freiraum f r technologische En twicklungen und wirtschaftliches Wachstum bieten, anstatt Fortschritt unbegr ndet zu erschweren. Das Verst ndnis von KI sollte un- serer Einsch tzung deshalb unter einer gestalterischen Pr misse stehen: Wir erschaffen K nstliche Intelligenz; wir gestalten, trainieren und entwickeln die Systeme weiter. Algorithmen sind nur Werkzeuge. Sie haben keine Vorurteile, Menschen aber schon. Und es sind gerade d iese Menschen, die die von Algorithmen gelieferten Ergebnisse interpretieren und dar ber entscheiden, wie man mit den Fehlern von Algorithmen umgeht. F r diese menschlichen Entschei- dungen sind in der analogen Welt bereits weitreichende gesetzliche Regelung en getroffen, die auch in der digitalen Welt gelten. Wir brauchen ein Mitdenken der digitalen Welt statt digitaler Sonderrege- lungen, um sowohl Innovation in Zukunft zu bef rdern als auch unerw nschte Nebenprodukte zu an- tizipieren.",de
ACV-CSC Belgium (Belgium),F550259,08 September 2020,Trade union,Large (250 or more),Belgium,"| DITION SP CIALE DE SYNDICALISTE | N 916 | 20 JANVIER 2020 | BIMENSUEL DIT PAR LA CONF D RATION DES SYNDICATS CHR TIENS | CHAUSS E DE HAECHT, 579 | 1031 BRUXELLES | BUREAU DE D P T BRUXELLES X | P 912043 CONGRES 2019 CONGRES 2019Rapport Congr s CSC 10-12 octobre 2019 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 20202Cela fait d j cinq ans que le d bat belgo-belge a commenc ressentir les effets de la terreur qui s est r pandue sur la sc ne internationale en raison des potentielles destructions d emplois li es une nouvelle vague d innovations techno- logiques. Beaucoup de partenaires impliqu s dans ce d bat ont saisi cette occasion pour mener une r flexion en profon- deur sur l avenir du travail. Ce fut galement le cas la CSC. Nous avons rapidement compris que ces funestes proph - ties nourries par la technologie devaient tre quelque peu nuanc es et que d autres m gatendances p seraient tout autant, voire davantage, sur l avenir du travail. Citons par exemple l volution des besoins et des attentes des travail- leuses et des travailleurs et des consommateurs. Ou encore, les immenses d fis climatiques et environnementaux. Sans oublier l effet conjugu de la poursuite de la mondialisation de l conomie et du contrecoup de la d mondialisation : le repli sur son propre pays, sur son propre peuple. Ce repli s exprime d ailleurs avec une acuit particuli re dans l actuel d bat sur la migration, mais aussi dans la critique de plus en plus virulente l encontre de l interventionnisme euro- p en et international. Bref, l avenir du travail d pend d un grand nombre de transitions et de la coh sion qui les unit. Ou plut t, l avenir du travail devra tre d termin en tenant compte de multiples transitions. Parce que l avenir ne r pond pas un sc nario pr visible. L avenir, cela se fa onne. Les travailleurs ne doivent pas subir passivement ces transitions. En tant que mouvement syndical, nous unissons les travail- leurs pour qu ils contribuent fa onner cet avenir, quelle que soit leur place dans la soci t . C est ce que nous avons fait l an dernier sur la sc ne internationale, lors du centenaire de l Organisation internationale du travail (OIT), qui tait juste- ment plac sous le signe de l avenir du travail. De m me, ces transitions furent le th me central du congr s statutaire de la CSC qui s est tenu en octobre Dans ce num ro sp cial de Syndicaliste, nous vous pr sen- tons un rapport circonstanci de ce congr s sur le th me des transitions. Vous y trouverez les lignes de force approuv es l issue des d bats, les r solutions d actualit et d activit , ainsi que les discours. Vous y trouverez galement un aper u de l ambiance qui r gnait pendant le congr s et des diff rents d bats. Jamais auparavant nous n avions consacr autant de temps aux d - bats en profondeur sur nos orientations pour l avenir avec les militantes et militants pr sents. D une ampleur in dite, ils ont largement d pass nos pr visions de temps et nous permettent d aboutir une vision, ou plut t une mission qui b n ficie d une large adh sion. Cette mission consiste main- tenant traduire chacune des lignes de force et des r solu- tions dans notre travail quotidien, aux diff rents niveaux o nous sommes actifs. Marc Leemans, Marie-H l ne Ska, pr sident de la CSC secr taire g n rale de la CSC Avant-propos Le congr s national est le lieu par excellence o s exerce la d mocratie interne la CSC. Organi- s tous les quatre ans, il r unit des repr sentantes et repr sentants de toutes les organisations. Sa mission? D terminer le programme g n ral de la CSC et l attitude de notre organisation face aux questions importantes. Du 10 au 12 octobre 2019, avec le congr s #queltravaildemain, la CSC avait rendez-vous avec l avenir et les principaux d fis qu il nous r serve: innovation tech- nologique, transition cologique, mergence de nouveaux mod les conomiques, poursuite de la globalisation 2 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 20203Ch res amies, Chers amis, Bienvenue Ostende. Bienvenue nos amis trangers. Comme l accoutum e, une fra che brise de mer souffle sur notre congr s. Avec l oxyg ne n cessaire pour nous inspirer. Un congr s syndical constitue un moment important dans une organisation militante. Il s agit de fixer nos orientations, de traduire notre vision et de d finir nos revendications. Ce congr s, nous l avons soigneusement pr par . Avant m me de prendre la plume, nous avons cout plus de 400 militants et militantes pendant deux samedis, propos de la mani re dont les changements impactent, jour apr s jour, leur travail, leur vie. Ce congr s constitue aussi un moment pour argumenter, couter, d battre, conclure. Un moment de rencontre et de partage entre militantes et militants. Ce congr s de transition porte sur l avenir du travail dans un monde en mutation. Quelles sont nos r ponses ces grandes tendances? En 2010, notre congr s d avenir en abordait d j trois. Pre- mi rement, l volution d mographique, avec le vieillissement DISCOURS D OUVERTURE PAR MARC LEEMANS, PR SIDENT DE LA CSC La technologie peut videmment faire dispara tre le travail, mais les emplois sont plus nombreux dispara tre dans les entreprises qui n innovent pas. Marc Leemans, pr sident de la CSC AUDE VANLATHEM 4 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020de la population. Deuxi me- ment, la mondialisation, avec la crise financi re. Troisi me- ment, le changement clima- tique. Mais pas un mot sur les volutions technologiques. La situation a ensuite totale- ment bascul . Depuis 2015, nous sommes entr s dans une nouvelle re industrielle, apr s la machine vapeur, l lectri- cit , le moteur combustion et l ordinateur. L Europe s est mise parler de la quatri me vague. D embl e, nous avons t confront s des sc narios alarmistes; le terme disrup- tion est devenu le nouveau mot la mode. Mais nous refusons d hurler avec les loups. Les volutions technologiques n entra nent pas syst matiquement une d - t rioration g n rale de la situation des travailleurs, pas plus qu elles ne les am liorent automatiquement. Le r le des pouvoirs publics, du monde politique, des partenaires so- ciaux et des syndicats est n anmoins crucial et d une impor - tance d cisive. La technologie peut videmment faire dispara tre le travail, mais les emplois sont plus nombreux dispara tre dans les entreprises qui n innovent pas. Ce n est pas la digitalisation qui a entra n la faillite de Thomas Cook, mais pr cis ment son absence. Ce n est pas la digita- lisation qui incite Proximus licencier ses travailleurs g s, mais le fait de ne pas avoir in- vesti temps dans la formation tout au long de la vie. Ce congr s sur la transition n est donc pas un congr s sur les technologies. Pour trois raisons. Premi rement, ce n est pas la technologie qui pose probl me, mais la redistribution du gain technologique. Pourquoi avons-nous relativement bien surv cu la troisi me r volu- tion industrielle? Parce que nous avons t en mesure de redistribuer les gains de la productivit . Gr ce aux n gocia- tions salariales, aux cotisations, la s curit sociale, aux ser - vices publics... Pas totalement. Pas comme nous l aurions souhait . Mais assez pour assurer un revenu, une redistribu- tion du travail et des fonds publics suffisants, ce qui a permis de cr er de nouveaux emplois, dans de nouveaux secteurs et de nouvelles entreprises. Deux questions se posent aujourd hui. Comment pouvons- nous pr server ces m canismes de redistribution l avenir? Si nous sommes parvenus compenser les pertes d emplois li es la technologie gr ce une croissance continue, un tel mod le de croissance est-il encore viable? Ces questions se- ront d battues par la 1 re section du congr s. Ce n est pas la technologie qui doit d cider des droits des travailleurs. Marc Leemans, pr sident de la CSC Le protectionnisme n a jamais t compl tement radiqu . Ce comportement mine l approche internationale des grands d fis soci taux. Marc Leemans, pr sident de la CSCQui sont les congressistes? 858 congressistes 360 femmes 498 hommes 608 militantes et militants CSC 250 permanentes et permanents CSC 170 membres du personnel de la CSC nationale 92 invit es et invit s internationaux venus des quatre coins du monde La plus jeune congressiste: Florence Muys, 21 ans Le congressiste le plus g : Gabriel Del Rio, 82 ansRAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 20205J en viens au deuxi me motif pour lequel notre r flexion doit d passer le cadre d un simple congr s technologique: c est nous qui faisons l avenir. Ce n est pas la technologie qui doit d cider des droits des travailleurs. De m me que Facebook ne peut d terminer ce qu il vous reste de vie priv e. Ce sont des choix politiques et soci taux. Et donc aussi des choix pour les partenaires sociaux. En tant que syndicat, nous de- vons contribuer imposer ces choix. Ce n est pas la technolo- gie qui pose probl me, mais la mani re dont on en abuse pour revenir aux anciennes formes de travail que nous avons toujours combattues: le travail la pi ce ou la t che, sans aucune protection, l tre humain n tant qu un simple pro- longement de la machine. Ce n est pas la technologie qui pose probl me, mais l mergence des mod les conomiques bas co ts, d Uber Amazon, en passant par Deliveroo. C est pourquoi, nous n voquerons pas l avenir de la technologie dans le cadre de ce congr s, mais bien l avenir du travail. Ce congr s s inspire fortement du centenaire de l Organisation internationale du travail, plac sous le th me du Futur du travail . Devons-nous donner une place plus importante aux entreprises qui respectent les individus, la soci t et le d ve- loppement durable, aux niveaux national et international? Souhaitons-nous continuer infl chir ces volutions? Ces questions seront d battues par la 2 me section du congr s. Troisi me motif pour que notre r flexion d passe le simple cadre de la transition technologique: d autres transitions pr figurent le monde du travail et elles auront probablement un impact plus important. La persistance des flux migratoires et la diversit accrue des soci t s. Dans quelle mesure nos soci t s et nos march s du travail ont-ils des difficult s g rer ces situations? Qu en est-il de l avenir de la mondialisa- tion? Apr s la crise financi re de 2008, un consensus mondial s est d gag sur le fait que les probl mes conomiques exi- geaient une plus grande coop ration europ enne et interna- tionale. Plus de r gles, plus de surveillance, plus de gouver - nance. Dix ans plus tard, un nombre croissant de pays se replient sur eux-m mes. Le protectionnisme n a jamais t compl tement radiqu . Ce comportement mine l approche internationale des grands d fis soci taux. En 2015, les Na- tions unies les ont traduits en Objectifs de d veloppement durable pour Le changement climatique, surtout, doit tre combattu de toute urgence. M me le sommet de New York sur le climat a t un chec. Il est hallucinant de consta- AUDE VANLATHEM Une premi re au congr s: deux femmes la pr sentation: Caroline Hielegems et Romane Heinen.RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 20206 ter qu aujourd hui, c est une jeune Su doise qui doit faire la le on aux responsables politiques. Elle est soutenue dans le monde entier au travers des actions des jeunes en faveur du climat. Ces questions seront d battues par la 3 me section du congr s. Toutes ces transitions sont interconnect es. Nous n y chap- pons pas. Mais nous ne devons pas seulement nous adapter. Nous devons galement contribuer les orienter et les r a- liser. Nous devons nous renouveler en tant qu organisation. Comment utiliser la digitalisation? Comment appliquer nous- m mes la condition de neutralit climatique? Comment adapter notre action aux nouvelles formes de travail, aux nouveaux mod les conomiques? Ces questions rel vent des r solutions d activit s dont nous avons discut hier avec nos organisations au sein de la commission des r solutions. Nous consacrerons galement du temps aux t moignages des syndicats trangers sur leurs r actions face aux nouveaux mod les conomiques. Nous entendrons galement des t - moignages sur nos propres r alisations concr tes. Hier, cette commission des r solutions a galement finalis les r solu- tions d actualit . La situation politique est diff rente de celle du congr s pr c dent. Nous avions d j un gouvernement f d ral l poque. Nous tions conscients du danger qui nous mena ait. Nous savions alors que nous devrions nous opposer pendant cinq ans une politique de droite. Ce furent des ann es difficiles, maill es de revers et de succ s. En parlant de succ s, vous tes tr s certainement d j dans les starting-blocks pour les lections sociales de mai Nous aussi, du reste. Ce congr s marquera le coup d envoi de notre campagne. Ce n est jamais une mission facile pour la CSC. Nous avons une grande avance sur les autres syndicats. Ces lections impliquent de travailler dur pour encore pro- gresser dans les entreprises o nous sommes d j actifs. Autre l ment tout aussi important: nous devons gagner du terrain en recherchant des candidats dans des entreprises o nous ne sommes pas encore pr sents. Car qui nous sommes et ce que nous sommes, ce que nous signifions concr tement pour nos affili s et la soci t dans son ensemble se traduit d abord et avant tout dans votre tra- vail vous, nos militants. Dans les entreprises et les institu- tions, dans les secteurs priv s et publics, dans le marchand et le non-marchand, dans les villes et les communes, vous don- nez le meilleur de vous-m mes jour apr s jour. Souvent face des vents contraires. Avec de fr quents malentendus. Mais avec la force de conviction que votre engagement volontaire et non r mun r est absolument n cessaire pour rendre jus- tice aux citoyens ordinaires. Dans une perspective d avenir. Nous nous r unissons la C te pour mener ce d bat d mo- cratique tourn vers l avenir. Pour un congr s, la plus haute instance de la CSC, qui insuffle de l oxyg ne nos positions. Je d clare donc ce 36 me congr s f d ral officiellement ouvert. Pour les lections sociales, nous devons gagner du terrain en recherchant des candidats dans des entreprises o nous ne sommes pas encore pr sents. Marc Leemans, pr sident de la CSC AUDE VANLATHEM Conform ment la tradition, Marc Leemans, pr sident de la CSC, a ouvert le congr s.RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 20207 LES LIGNES DE FORCE AUDE VANLATHEM8#Une transition juste Le monde du travail se caract rise par des bouleversements profonds, survenant un rythme croissant. L innovation technologique n est qu un de ces changements. Elle clipse quelque peu la conjonction et le lien avec les autres bou- leversements: la transition cologique, l mergence de nou- veaux mod les conomiques et la poursuite de la globali- sation avec, l oppos , un repli sur soi. Quelle que soit la transition, elle doit tre juste et sociale ( just transition ). Par cons quent, travers toutes ces transitions, il convient en particulier de respecter les travailleurs et les travail- leuses, y compris les non-actifs et tous ceux qui l on refuse aujourd hui un emploi d cent et la protection sociale. Et ce, quel que soit le type de transition: soci tale, cologique, co- nomique ou technologique. La transition juste ne se limite toutefois pas accompagner les travailleurs et les travailleuses travers les changements et faire face aux cons quences. Il s agit tout d abord de piloter d mocratiquement la transition, tant sur le plan poli- tique que soci tal, avec une forte contribution de la soci t civile et en reconnaissant les citoyennes et citoyens, les tra- vailleurs et travailleuses, et la soci t civile comme acteurs et actrices de changement, sur la base de la strat gie la plus orient e r sultats . Les interlocuteurs sociaux doivent jouer un r le essentiel ce niveau, avec pour fil conducteur constant notre test des 4G : a. l galit de genre (test de Genre); b. une attention sp cifique pour les jeunes (test des G n ra- tions); c. une attention sp cifique pour la diversit et l galit (test de l Galit ); d. la contribution aux ODD (ou SDG), les Objectifs des Nations unies (ONU) pour le d veloppement durable (test des SDG).INTRODUCTION RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 AUDE VANLATHEM LAYLA AERTS En pr alable au congr s, des sessions de r flexion ont t organi - s es les 15 et 22 septembre 2018 Bruxelles. L apport des militants de la CSC a servi de base la r daction des lignes de force.9 1 CONGRES 2019Un march de l emploi en transition RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202010 La section 1 devait se pencher sur les 9 premi res lignes de force. Elles portaient tout d abord sur la transition juste, sur la technologie au service de l humain et de la soci t , mais aussi sur les travailleurs et les travailleuses la barre. En- suite, la section a r fl chi la redistribution des b n fices de la technologie et la mani re de taxer ces m mes b n - fices. Elle a galement pris position sur la mani re de per - mettre aux gens de travailler moins et examin les limites du march . Enfin, elle s est positionn e sur l accompagnement travers les transitions et la participation au d veloppement durable. Pour la LIGNE DE FORCE 1 , le congr s a stipul que s il est question de transition, celle-ci doit avant tout tre juste et sociale, en insistant particuli rement sur le c t social. La transition doit aussi r server une attention sp cifique aux jeunes, ce qui a t confirm en s ance pl ni re. L ensemble doit tre soumis au test des 4 G : test de Genre, test des G n rations, test de l Galit et test des SDG (Objectifs du d veloppement durable).La LIGNE DE FORCE 2 porte sur la technologie au service de l humain et de la soci t . La CSC souhaite que la technolo- gie soit socialement orient e. Le congr s a insist sur le fait que la soci t , l conomie et l emploi belges doivent tre les premiers en r colter les fruits. Les pouvoirs publics doivent en outre privil gier les technologies qui soutiennent les per - sonnes fragilis es. Le congr s a galement mis cet aspect en avant. La LIGNE DE FORCE 3 met l accent sur la concertation indis- pensable pour encadrer les transitions technologiques. Le congr s a soulign qu il est important pour le syndicat de suivre les volutions technologiques de pr s et de s attaquer aux impacts n gatifs ventuels. Le r le du l gislateur a t mis en avant au cas o il ne serait pas possible de conclure une CCT ad quate sur la transition. Des valuations et des ajustements doivent intervenir r guli rement apr s l intro- duction de la technologie. La formation est tr s importante ce niveau. Enfin, nous devons suffisamment armer nos d l - gu s pour cette concertation sur la transition. Le congr s en- tend en outre accorder une attention sp cifique aux groupes qui ont moins de possibilit s de participation ou aux groupes o la concertation sociale n est pas implant e. Dans la LIGNE DE FORCE 4 , nous avons r fl chi la mani re de redistribuer quitablement les b n fices de la technologie et d adapter notre syst me fiscal. Les paules les plus larges doivent ici supporter les contributions les plus lourdes. Le congr s a mis l accent sur des n gociations salariales collec - tives libres, au-del de l indexation automatique. Le mod le solidaire de concertation sociale doit tre garanti. Il faut arriver un imp t progressif part enti re sur les grandes fortunes. Les revenus du patrimoine doivent tre trait s de mani re semblable aux revenus du travail. Pour ce faire, il faut introduire un imp t sur les plus-values mobili res. En ce qui concerne les biens immobiliers, la fiscalit doit tre r form e progressivement, en tenant compte des effets sur le march du logement et le secteur de la construction. La Belgique doit redevenir la locomotive d une taxe sur les tran- sactions financi res. Il faut mieux taxer les soci t s et mettre fin l vasion et la fraude fiscales. La LIGNE DE FORCE 5 souligne qu il ne faut pas taxer la tech- nologie elle-m me, mais bien les b n fices issus de la tech- nologie. Une part garantie doit tre r serv e la s curit Rapport de la discussion Section Le march de l emploi en tr ansition 10 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 AUDE VANLATHEM11Rapport de la discussion Section Le march de l emploi en tr ansition 11sociale. Les activit s et services organis s par le biais de pla- teformes num riques doivent tre soumis un r gime fiscal normal. La LIGNE DE FORCE 6 plaide pour une r duction g n ralis e et progressive du temps de travail, avec le maintien du sa- laire et des droits de s curit sociale. Le congr s a d cid que le conseil g n ral devait laborer une feuille de route end ans les deux ans et lui a donn mandat d examiner ce qui doit tre fait pour viter la perte de droits. La LIGNE DE FORCE 7 porte sur le fonctionnement du march lui-m me. Il importe d imposer des r gles claires et contrai- gnantes. Le congr s a d cid qu il fallait faire barrage la tendance croissante la privatisation au sein des organismes publics, de l enseignement et du non-marchand. Ces derniers doivent en outre b n ficier de moyens suffisants pour conti- nuer fonctionner correctement. Le dumping social doit tre combattu. Dans la LIGNE DE FORCE 8 , le congr s a r fl chi la mani re dont nous pouvons armer les travailleurs et les travailleuses face au changement technologique. La CSC a pour mission d accompagner les restructurations d entreprises, mais aus- si de tout mettre en uvre pour les viter. Il faut renforcer les droits de ceux qui sont menac s par un licenciement collectif et mettre l accent sur l assistance d experts et sur la concertation. Les possibilit s d viter des licenciements secs, comme le RCC, doivent tre sauvegard es, renforc es et effectivement utilis es. Il faut mettre en place un fonds de transition pour apporter une assistance en cas de restructu- rations. La section du congr s consacr e au march de l emploi en transition a termin ses travaux en se penchant sur la LIGNE DE FORCE 9 et la mani re dont le d veloppement durable doit intervenir. La plan te doit tre respect e. L conomie locale joue un r le central ce niveau. Il faut freiner la toute-puis- sance de tr s gros acteurs du march . Les nouvelles formes de travail ne peuvent pas porter atteinte la s curit sociale et ne peuvent pas se situer en dehors du droit du travail. Il faut liminer la discrimination des jeunes sur le march de l emploi sur le plan des salaires et des allocations sociales. RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020#La technologie au service de l humain et de la soci t La CSC souhaite que la technologie soit socialement orient e, de sa conception son introduction durable, dans les entreprises ( et la soci t . L tre humain et la dignit humaine doivent garder une place centrale, tout comme la pr occupation pour le climat, l environnement, la biodiversit et la raret des ressources natu - relles. a. Les consid rations thiques doivent tre prises en compte tout au long du cycle de vie d une technologie, et ce d s un stade pr coce: pas de technologies ni d applications techno - logiques qui pourraient constituer une menace pour l tre humain, l environnement et le climat, o que ce soit dans le monde. b. Le soutien la recherche, au d veloppement et au d ploie - ment de nouvelles technologies doit se fonder sur des prio - rit s sociales, conomiques et environnementales tous les niveaux politiques. Il faut en outre pr voir des garanties pour que la soci t , l conomie et l emploi belges soient les pre - miers en r colter les fruits. c. Les pouvoirs publics doivent davantage privil gier et soute - nir les technologies et surtout celles que le march laisse de c t , commencer par le bien- tre, les soins de sant , l en - seignement, la culture, la formation et l aide aux personnes handicap es et autres personnes fragilis es. L objectif doit toujours tre de maximiser la qualit et l accessibilit . d. Il faut absolument viter que la transition technologique m ne l exclusion sociale (voir # . e. Les choix soci taux sur la technologie que nous souhaitons doivent se traduire en droits et r gles, avec des garanties quant leur force ex cutoire, y compris l gard d acteurs internationaux. f. L octroi des droits de propri t intellectuelle doit tre r - gl autrement: les co ts de l innovation technologique ne peuvent pas incomber aux pouvoirs publics, alors que les b n fices qui en d coulent vont au secteur priv . Des appli - cations cruciales sur le plan soci tal ou cologique doivent tre rendues plus vite accessibles au plus grand nombre. g. Pour toutes ces raisons, un Conseil de la science, de l inno - vation et de la soci t doit tre cr au niveau f d ral, ainsi qu au niveau europ en, en renfor ant le r le de la soci t ci - vile et des syndicats. notre niveau, nous devons assurer une collaboration troite avec des conseils r gionaux similaires. h. Au sein du gouvernement f d ral et de la Commission eu - rop enne, il doit toujours y avoir un responsable charg de piloter la technologie et l innovation technologique en fonc - tion des choix thiques et soci taux et des exigences colo - giques. Ces responsables doivent collaborer troitement avec les Conseils susmentionn s (voir g). ( Par entreprises , on entend aussi les institutions, les services publics et les administrations. Ceci vaut pour toutes les lignes de force. 11VERSLAGBOEK TRANSITIECONGRES ACV # 10-12 OKTOBER 2019 # VAKBEWEGING NR. 916 # 20 JANUARI 2020 12#Les travailleurs et les travailleuses la barre Les transitions dans les entreprises et les institutions doivent tre orient es et encadr es en se fondant sur une concerta- tion tourn e vers l avenir. La CCT n 39 du Conseil national du travail (CNT) relative la technologie doit tre transpos e en une CCT sur la transition que les commissions paritaires sont charg es de concr tiser et de compl ter avec un cadre n go- ci quivalent pour le secteur public et l enseignement. Si les employeurs ne sont pas pr ts introduire de telles CCT, le l gislateur doit intervenir et imposer des obligations contrai- gnantes en termes de concept, d objectif, de contenu et de proc dures. Voici le fil conducteur, tant pour le secteur priv que pour les pouvoirs publics: a. extension tous les employeurs, y compris les plus petits; b. pas seulement ax e sur l innovation technologique, mais aussi sur la transition cologique; c. pas seulement ax e sur les cons quences, mais aussi sur la n cessit et la nature de l innovation proprement dite ou sur l absence d innovation, tant du point de vue des travail - leurs et travailleuses que des utilisateurs et utilisatrices, avec une attention particuli re aux cons quences sur l em - ploi; d. test de faisabilit pr alable pour valuer l impact sur la qualit du travail et la qualit de vie, et pour se concer - ter sur la mani re dont l innovation peut contribuer cette qualit avec une valuation et un ajustement r guliers suite l introduction d une technologie (voir #; e. dans le m me temps, viter que l innovation technologique conduise de nouvelles exclusions et, au contraire, favori - ser l inclusion, notamment par la formation (voir #13 et #; f. avec l implication active et des comp tences renforc es pour les organes de concertation au niveau des entreprises, des institutions, des administrations, et pour les services de pr vention; g. armer l ensemble de nos d l gu es et d l gu s pour cette concertation sur la transition, par le d veloppement de programmes de formation et de mat riel d appui et par l acc s des expertes et experts externes reconnus par les syndicats; h. avec un r le important pour la concertation sectorielle afin d encadrer, de promouvoir et de soutenir ce processus, en particulier pour les plus petites entit s; i. des garanties et un contr le du respect effectif de ces prin - cipes. Il est important que notre syndicat suive les volutions tech - nologiques de pr s, que nous jouions un r le dans l analyse de risques, que nous cherchions des alternatives pour viter un ventuel impact n gatif sur l emploi, ainsi que pour accompa - gner les travailleurs et travailleuses touch s.Le congr s donne pour mandat d laborer des propositions concr tes de mod les de participation, qu ils soient nou- veaux ou adapt s, destin s aux travailleurs et aux travail- leuses sans possibilit de participation ou de concertation sociale. Et ce, en tant particuli rement attentif aux travail- leurs et aux travailleuses sans repr sentation syndicale, aux plateformes num riques et aux personnes qui ne sont pas li es leur employeur par un contrat de travail ou une nomi- nation d finitive. #La redistribution des b n fices de la technologie Ce n est pas tant la technologie qui menace l emploi, que le d mant lement des m canismes de redistribution des b n - fices de la technologie. La CSC met tout en uvre pour re- distribuer ces b n fices quitablement. Ce faisant, elle opte r solument pour le maintien et le renforcement des m ca- nismes de redistribution, savoir: a. une fiscalit progressive: les paules les plus larges sup- portent les contributions les plus lourdes; b. la sauvegarde et le renforcement de la s curit sociale; c. des quipements collectifs d excellente qualit ; d. la restauration du droit des n gociations salariales col- lectives libres et responsables, au-del de l indexation au- tomatique. Sur le plan de l Union mon taire europ enne, la coordination de la concertation sur les salaires doit aussi rester du ressort des interlocuteurs sociaux; e. la sauvegarde de notre mod le solidaire de concertation sociale pour tous les travailleurs et travailleuses, avec une priorit pour les accords interprofessionnels et les CCT sectorielles; f. la redistribution du travail (voir #. En outre, il faut tre particuli rement attentif aux personnes pr caris es sur le march de l emploi et dans la soci t . Outre la norme de pauvret , la CSC veut aussi une norme d galit : la Belgique doit se hisser parmi les trois premiers pays d Europe en termes de tension entre les revenus faibles et les revenus lev s. Il ne s agit d ailleurs pas seulement de la r partition des revenus. Plus que jamais, nous devons nous concentrer sur la r partition des richesses car c est l que les in galit s sont les plus grandes. cet effet, la CSC entend: a. utiliser la taxe sur les comptes-titres comme une tape pour arriver un imp t progressif part enti re sur les grosses fortunes (mobilier et immobilier, en Belgique et l tranger), li un cadastre des fortunes; b. un imp t des personnes physiques plus redistributif qui globalise tous les revenus. En particulier en imposant de 12 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202013mani re semblable les revenus du patrimoine et les reve- nus du travail (un euro = un euro), y compris l introduction d un v ritable imp t sur les plus-values mobili res; c. r former progressivement et en profondeur la fiscalit immobili re, avec une analyse pr alable des effets sur le secteur de la construction, le march du logement et le droit au logement; d. am liorer l imp t des soci t s: supprimer les exon rations et autres d penses fiscales inefficaces, freiner le passage abusif du statut de travailleur ou de travailleuse celui de soci t ; e. supprimer les tarifs inf rieurs 30% pour les dividendes; f. instaurer un imp t europ en sur les transactions finan- ci res, avec la Belgique nouveau comme locomotive au sein de l Europe; g. mettre fin l vasion et la fraude fiscales sur les actifs et les revenus du patrimoine, en utilisant les technologies les plus r centes et en y affectant le personnel, les moyens et les comp tences n cessaires pour les services publics concern s; h. appliquer un traitement fiscal quivalent aux entreprises de l internet (voir #. #Une meilleure taxation des b n fices de la technologie Lorsque la transition technologique saborde le financement d un tat de qualit et d une s curit sociale forte, il faut trouver une r ponse appropri e, aux niveaux national, euro- p en et international: a. en taxant quitablement les b n fices technologiques, avec une part garantie pour la s curit sociale; et donc pas tant en taxant la technologie elle-m me; b. en r percutant toutefois les co ts soci taux et environne - mentaux des technologies nocives et en promouvant de meilleures technologies; et ceci en tenant compte du cycle complet d une technologie; c. avec un imp t des soci t s quivalent pour les entreprises de l internet, et des crit res adapt s pour d terminer quelle est la part de chaque pays dans le b n fice; d. les paiements et les placements dans les nouvelles crypto- monnaies doivent tre trait s de la m me mani re sur le plan l gal, en termes d imposition et de cotisations; e. le travail, les activit s et les services effectu s pour ou sur des plateformes num riques, qu il soit reconnu ou non par les pouvoirs publics, doivent tre soumis aux m mes taxes et cotisations que tout autre travail.#Un temps de travail au service de l humain et non des machines Le congr s plaide pour une r duction g n ralis e et progres- sive du temps de travail. Le congr s appelle nos n gociateurs et n gociatrices en- dosser un r le de pr curseur en faveur de la poursuite de la r duction collective du temps de travail. Cette r duction doit tre mise en uvre avec maintien du salaire et des droits de s curit sociale, et avec des embauches compensatoires obligatoires dans des emplois faisables et de qualit . On contribue ainsi l emploi, la qualit du travail et de la vie, une augmentation des salaires des travailleurs et travail- leuses temps partiel qui maintiennent leur temps de travail, et une r partition quilibr e du travail non r mun r entre les femmes et les hommes. L ampleur de cette r duction du temps de travail, la formule choisie et le rapport avec d autres revendications doivent tre d termin s dans le cadre d un dialogue avec les membres, et en fonction des possibilit s sectorielles et locales, en tenant compte du contexte cono- mique et international. Dans ce cadre, nous tirerons des le- ons d exp riences men es tant en Belgique qu l tranger. RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 AUDE VANLATHEM14 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020Le congr s donne mandat au conseil g n ral pour laborer des propositions concr tes end ans les deux ans, en ce com- pris une feuille de route. Ce processus doit s accompagner: a. d une action permanente contre l allongement du temps de travail (en particulier contre les mesures gouverne - mentales qui prolongent le temps de travail et contre leur application par les employeurs) et pour une r duction indi - viduelle ou s lective du temps de travail, dans des cadres n goci s collectivement, en veillant suffisamment ce qu elle s applique tant aux femmes qu aux hommes; b. d une politique de limitation du temps de travail pour les personnes qui ne rel vent pas du champ d application de la dur e maximale du travail; c. d une politique de carri re qui permette aux travailleurs et travailleuses d adapter celle-ci, tout moment, aux possi - bilit s et besoins personnels, y compris avec la sauvegarde et l am lioration du cr dit-temps, de l interruption de car - ri re et les mesures de fin de carri re. La r duction du temps de travail doit tre soutenue par une r duction plus importante des cotisations sociales pour les op rations de r duction du temps de travail avec maintien de salaire, d di es la cr ation d emplois de qualit . Dans le m me temps, on doit largir cette r duction des op rations visant sauver des emplois. Les deux aspects n cessitent un financement alternatif suffisant pour la s curit sociale. Nous souhaitons un contr le actif pour viter tout abus en ce qui concerne les r ductions de cotisations, pour garantir les em - bauches compensatoires et pour combattre la perte des droits. Le congr s donne mandat d examiner, pour chacune des branches de la s curit sociale, ce qui peut et doit ventuel- lement tre fait pour viter la perte des droits dans les diff - rentes formules de r duction du temps de travail. #Des limites pour le march Les m canismes de march ne peuvent pas s appliquer par - tout. L o le march op re, il importe d imposer des r gles claires et contraignantes. Cela implique concr tement que: a. les services publics et non marchands doivent tre de grande qualit , abordables et accessibles pour tous et toutes avec une attention particuli re pour les personnes les plus fragiles; b. l enseignement ainsi que les structures collectives desti - n es venir en aide aux personnes vuln rables ne doivent pas tre abandonn es aux forces du march et doivent tre exclusivement confi es l tat et au secteur non marchand; c. les autorit s belges et les instances europ ennes doivent continuer d fendre les missions fondamentales de l tat, de l enseignement et du secteur non marchand contre les pressions internationales auxquelles notre mod le social est expos par le biais des accords commerciaux et d inves - tissements, mais aussi de l Organisation mondiale du com - merce (OMC). Dans le m me temps, l Union europ enne doit cesser de contraindre les tats membres la privatisation et la commercialisation; d. pour les missions de service public qui sont lib ralis es, les entreprises publiques et le secteur non marchand doivent pouvoir pleinement jouer leur r le et disposer des moyens n cessaires; les autorit s politiques comp tentes doivent pr voir de solides garanties, y compris des r gles contrai - gnantes, un contr le et des sanctions ad quats, pour la qualit des services et des emplois, pour le service univer - sel, pour toutes les citoyennes et tous les citoyens, y com - pris en des lieux moins rentables, pour l accessibilit et le maintien des droits; e. pour ce qui concerne la lib ralisation de missions de ser - vice public, un retour en arri re doit pouvoir tre envisag lorsque les cons quences sont n gatives pour les travail - leurs et travailleuses et la soci t , ou ne sont pas celles escompt es tant sur le plan social, sur le plan de l emploi ou encore en termes de qualit du service rendu; f. dans le cas o des missions de service public sont confi es d autres acteurs, il importe d avoir des garanties concer - nant l environnement, la qualit de l emploi et la lutte contre le dumping social, y compris des garanties relatives au suivi du respect des droits humains tout au long de la cha ne de production et de distribution (voir #. AUDE VANLATHEM15 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020Tant les pouvoirs publics et le secteur non marchand que les acteurs du march doivent garantir des structures collectives de qualit et la port e de tous les groupes de la population. En aucun cas, l introduction d une logique de march ne doit conduire une r duction des services collectifs ou rendre leur acc s plus difficile. #L accompagnement des travailleurs et des travailleuses travers les transitions Si les transitions ne conduisent pas n cessairement une baisse de l emploi global, elles sont en tout cas l origine d un important glissement au niveau de l emploi, et donc de nombreuses restructurations d entreprises. La CSC s engage plus que jamais cr er un meilleur cadre pour l anticipation et pour l accompagnement de ces res- tructurations, en accordant beaucoup plus d attention qu au- jourd hui la pr vention. Nous voulons renforcer les droits des travailleurs et des tra- vailleuses qui sont menac s par un licenciement collectif. a. Les repr sentantes et repr sentants des travailleurs et travailleuses doivent avoir droit l assistance d expertes et experts externes, propos s ou accept s par ces repr - sentantes et repr sentants, aux frais de l employeur. Cela doit leur offrir la possibilit de proposer des alternatives fond es. Une attention particuli re doit tre accord e aux PME, avec un r le sp cifique pour les permanentes et per - manents syndicaux. b. Des proc dures d information et de concertation doivent tre pr vues pour le personnel touch chez les sous-trai- tants, les fournisseurs, les entreprises de travail int ri- maire et d autres prestataires de services, les ind pen- dantes et ind pendants, etc. Ces informations doivent s accompagner d informations d taill es aux travailleurs et aux travailleuses de la soci t -m re propos de l im- pact de la restructuration sur ce personnel, comme base pour la concertation sur la contribution de cette soci t - m re au plan social pour les autres travailleurs et travail- leuses touch s. c. Un cadre adapt doit tre pr vu pour les restructurations et les r organisations dans les entreprises publiques, les services publics et dans les tablissements d enseigne- ment o il n y a pas de cadre, comme nous le connaissons dans le secteur priv pour le transfert de tout ou partie de l entreprise (CCT n 32 bis du CNT). d. Le contournement des droits des travailleurs et des tra- vailleuses par les entreprises en cas de licenciement col-lectif en talant les licenciements sur plusieurs p riodes doit tre rendu impossible. e. Les possibilit s de r duire la capacit du personnel sans licenciements secs doivent tre sauvegard es, renforc es et effectivement utilis es, avec une attention particuli re aux effets n gatifs pour le travailleur ou la travailleuse: - am lioration et unification des syst mes de ch mage conomique pour les ouvri res et ouvriers et les em- ploy es et employ s; - r introduction des r ductions ONSS en cas de r duc - tion collective du temps de travail, en vue d viter des licenciements; - emplois de fin de carri re et RCC pour les entreprises en difficult et en restructuration; - conventions collectives en vue de favoriser la mobilit volontaire l int rieur et l ext rieur de l entreprise. f. En plus de la protection contre le licenciement individuel manifestement d raisonnable (CCT n 109 du CNT), une protection contre le licenciement collectif manifestement d raisonnable doit tre pr vue: obligation de motiver la n cessit de ce licenciement (pas pour augmenter encore les b n fices) et de pr ciser ce qui a t fait pour l vi- ter; tant pour les travailleurs et travailleuses que pour la soci t au sens large; tant lors de l annonce que lors de la mise en uvre effective du licenciement collectif. g. Une aide europ enne doit tre pr vue pour les transitions, non seulement en cas de restructurations induites par la mondialisation, mais pour toute restructuration, y compris celles imputables la transition technologique ou colo- gique. Cette aide pourrait tre organis e condition de transformer le Fonds europ en pour la mondialisation en un Fonds pour la transition, dot de moyens suffisants, y compris pour les restructurations plus modestes, et avec des garanties suffisantes que les employeurs et les pou- voirs publics belges n utilisent pas cette aide pour limiter leurs propres efforts. h. Apr s la loi Renault ( renforcer), la CCT n 24 du CNT et la directive europ enne relative aux licenciements collectifs, il faut laborer d urgence un trait de l OIT qui renforce les droits des travailleurs et des travailleuses en cas de licenciement collectif, pour tout type de restructuration et pour tout type de relation de travail. Ce trait doit venir s ajouter au Trait n 158 de l Organisation internationale du travail (OIT) concernant la cessation de la relation de travail, qui doit d ailleurs tre ratifi d urgence par la Bel- gique. L information et la consultation suite l annonce d un licen- ciement ne suffisent cependant pas. Ce qui pr c de cette annonce est au moins aussi important. Nous voulons une politique plus vigoureuse l gard des entreprises afin de pr venir les difficult s financi res (politique d entreprise pr ventive, meilleure information financi re, enqu te sur les tendances de march ). Cela doit aller de pair avec un droit 16 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 16 l assistance par des expertes et experts externes reconnus par les syndicats et l implication des travailleurs et des tra- vailleuses. Cette politique doit tre men e de front avec une politique de pr vention pr coce l gard des travailleurs et travailleuses: ne pas attendre le licenciement pour s engager dans un processus de formation, mais investir pendant toute la carri re dans les connaissances et les savoir-faire pour le march de l emploi au sens large (voir #13 et #. Il s agit d une alternative aux mesures du gouvernement et aux pro- positions des employeurs qui visent ce que les travailleurs et travailleuses financent eux-m mes leur propre employa- bilit , au d triment du pr avis ou de l indemnit de rupture. #De la croissance au d veloppement durable Nous n chappons pas un d bat sur le mod le actuel de croissance conomique. Le congr s donne mandat pour: a. traduire sous forme de leviers politiques les diff rents instruments destin s mesurer le progr s autrement, afin de renoncer une conception troite de la croissance du revenu national brut (RNB). Cette d marche doit se fonder sur une vision largement soutenue d un mod le alternatif de d veloppement durable qui respecte les limites de la plan te et qui, dans ce cadre, r pond aux objectifs sociaux et cologiques, y compris la n cessit de redistribuer les revenus et la richesse (voir #; b. promouvoir d autres mod les conomiques (coop ratives, conomie sociale, v ritable conomie collaborative, non- marchand ), avec syst matiquement des droits gaux pour les travailleurs et les travailleuses et des garanties gales pour le travail syndical et la concertation sociale; c. en collaboration avec les comit s r gionaux, laborer des propositions pour promouvoir l conomie locale avec moins de consommation de mati res premi res, de pollu- tion et de r chauffement climatique en lien avec le trans- port ( circuit court ); d. en collaboration avec les comit s r gionaux et communau- taires, laborer de nouvelles propositions pour promou- voir la participation au march du travail de personnes qui sont aujourd hui l s es, et ce dans des emplois de qualit ; e. sur le plan national, europ en et international, entre- prendre des actions pour lutter contre les distorsions des forces du march caus es par la toute-puissance de tr s grands acteurs qui, pour les pouvoirs publics, sont deve- nus trop gros pour que l on puisse s en passer ( too big to fail ) et/ou qui liminent la concurrence au d triment des utilisateurs et utilisatrices et des pouvoirs publics. Il faut en outre viter que des normes plus strictes pour les acteurs nationaux et europ ens ne fassent que renforcer la position dominante des grands acteurs en dehors de l Europe; f. tudier comment des formes de travail en dehors du sec - teur public, du non-marchand et de l conomie classique pourraient tre davantage valoris es socialement. Ces formes de travail ne peuvent pas porter atteinte la pro- tection sociale, au droit du travail, au financement collectif par l imp t ou au financement de la s curit sociale; g. r tablir, pr server et am liorer le d couplage existant entre les prestations et le revenu (s curit sociale et as- sistance sociale, cr dit-temps, interruption de carri re, mesures de fin de carri re vacances annuelles, r duction du temps de travail, etc.); h. dans ce cadre, laborer des propositions concr tes, en concertation avec les Jeunes CSC et Jong ACV, pour une mise en uvre au niveau interprofessionnel, sectoriel ou au niveau de l entreprise pour assurer l autonomie finan- ci re et la s curit du revenu des travailleurs et travail- leuses en d but de carri re et des jeunes partir de l ge de 18 ans. Cette volont doit aller de pair avec notre lutte contre la discrimination des jeunes sur le plan des salaires et des allocations sociales. Chacune des nouvelles propositions d velopper doit en outre tre associ e une strat gie syndicale centr e sur les r sultats, notamment en collaboration avec des mouvements de m me tendance. AUDE VANLATHEM17 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202017 2Des emplois en transition CONGRES 2019Qu en est-il des risques sp cifiques pour la s curit et la san- t qui sont li s aux technologies de la nouvelle vague? Qu en est-il de la charge psychosociale croissante li e la digitali- sation? Qu en est-il des possibilit s d enregistrer et de trai- ter un nombre consid rable de donn es sur les travailleurs et travailleuses, les demandeurs d emploi et les allocataires sociaux? Qu en est-il de la protection de la vie priv e? Qu en est-il de l ins curit d emploi croissante li e aux nouvelles formes de travail? La section 2 Des emplois en transition est consacr e tous ces d fis. La ligne de force 10 Lutter contre la pression au travail d - finit une s rie de moyens pour lutter contre le techno-stress et uvrer pour un meilleur quilibre entre vie profession- nelle et vie priv e. la demande de la CSC Transcom, on a ajout la mobilit excessive , car la mobilit repr sente une source de stress croissante. En ce qui concerne le droit la d connexion, le congr s a ajout au projet de lignes de force qu en l absence d organes de concertation, nous demandons le renforcement du r le de la m decine du travail et des services de pr vention, et que les modalit s d application doivent tre pr cis es dans le r glement de travail. Un pas- sage du projet de lignes de force qui voulait inciter les travail- leurs prendre davantage soin d eux-m mes a t supprim . Il donnait en effet l impression que les travailleurs taient personnellement responsables de leur burn-out et de leurs probl mes psychosociaux. Le titre de la ligne de force 11 Contre la super-pr carit est devenu Contre la pr carit et l ensemble de la ligne de force a t adapt dans ce sens. Dans la phrase introductive, on a ajout , la demande de l ACV-Puls, que la CSC d fend pleinement des contrats temps plein. En ce qui concerne le recours aux contrats journaliers successifs, la section a insis- t pour qu il soit interdit. Cet amendement a t approuv l unanimit . Le projet de ligne de force pr voyait encore de ne plus les autoriser que pour des motifs fond s, sous le contr le de la d l gation syndicale . La section a aussi ajou- t que si les mesures visant combattre la pr carit ne sont pas respect es, il faut pr voir des sanctions. Avec la ligne de force 12 Des risques sous contr le , la CSC exige des garanties pour que les nouvelles technologies ne menacent pas la s curit et la sant des travailleurs et des travailleuses ou qu elles ne fassent pas prendre des risques inconsid r s pour la soci t , l environnement ou le climat. Le projet de ligne de force a t compl t dans le sens o si apr s l introduction de nouvelles technologies, celles-ci s av rent nocives pour la sant des travailleurs ou pour l environne- ment, les autorit s doivent pouvoir imposer des conditions ou des restrictions leur utilisation, voire leur retrait. La section a galement ajout qu il fallait veiller l adaptation de la liste des maladies professionnelles, comme la recon- naissance du burn-out et de certains cancers dont la cause pr pond rante s av re professionnelle. Les travailleurs qui sont confront s de nouvelles technologies doivent pouvoir suivre des formations sur mesure et adapt es leur rythme. L examen de la ligne de force 13 La formation tout au long de la vie a donn lieu une discussion sur le nombre de jours de formation auquel les travailleurs et les travailleuses doivent avoir droit. Le projet de ligne de force pr voyait, pour chaque travailleur, un droit individuel cinq jours par an d ici 2022 au plus tard. La section a vot une l g re majorit en faveur d un droit individuel de dix jours par an. La section a ajout au projet de ligne de force que la CSC demande le retrait de la l gislation selon laquelle les travailleurs et les travailleuses doivent consacrer une partie de leur indemnit de pr avis des mesures qui favorisent l employabilit . Un nouveau point distinct insiste sur le fait que, d s le d but de la concertation en mati re de transition, dans le cadre de la CCT n 39, il faut laborer imm diatement un programme de formation qui permet d viter des licenciements. On a ga- lement ajout la ligne de force qu il fallait reconna tre les comp tences acquises et pr voir des conseillers externes en formation. Le risque d une fracture num rique doit tre cart en ins- taurant une politique qui englobe tout le monde. Tel est l l - ment essentiel de la ligne de force 14 Le num rique pour tous et toutes . Un point a toutefois t ajout au projet de ligne de force, qui pr voit qu ind pendamment de la num - risation, les pouvoirs publics doivent continuer offrir des services non-num riques sans co t suppl mentaire pour la ou le b n ficiaire . La ligne de force 15 Protection de la vie priv e au travail plaide pour une am lioration du cadre l gal et conventionnel afin de prot ger efficacement la vie priv e des travailleurs et des travailleuses et des demandeurs d emploi. La section a Rapport de la discussion Section Des emplois en transition 18 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 20201919ajout au projet de ligne de force que nous devons veiller ce que l assistance individuelle des repr sentants syndicaux soit garantie et que la l gislation sur la protection de la vie priv e ne restreigne pas l action syndicale. Apr s le d part d un travailleur ou d une travailleuse de l entreprise, toutes les informations priv es la ou le concernant doivent tre effac es, a estim la section. Cet l ment a t int gr la ligne de force d finitive. La section a galement ajout qu il fallait garantir le secret m dical dans l utilisation des nou- velles technologies. La ligne de force 16 Les travailleurs et les travailleuses ne sont pas des robots stipule que les travailleurs et les travail- leuses doivent tre mieux prot g s contre un contr le appro- fondi au travail. La section a renforc le passage qui disait qu il fallait mettre des limites et convenir de proc dures transparentes en ce qui concerne l information et la surveil- lance des prestations des travailleurs par les clients et les patients . Il doit s agir d une interdiction. La section a ajout au projet de lignes de force que les allocataires sociaux ont galement droit la protection de leurs donn es priv es lors de contr les et de transmissions de donn es entre diff - rentes instances. Il faut galement d velopper une approche critique par rapport l utilisation des nouvelles technologies, ainsi qu une thique dans l usage d internet. La ligne de force 17, L action l gard des travailleurs et travailleuses actifs non-salari s , entend renforcer la lutte contre la faible protection de ceux et celles qui travaillent comme ind pendants d pendants et contre la mani re dont ce syst me menace la qualit des emplois des travailleurs et travailleuses. La section a ajout explicitement l intro- duction de la ligne de force qu il faut d noncer et combattre l utilisation abusive de ces statuts par les employeurs. Il faut instaurer une r glementation compl mentaire si les plate- formes num riques perturbent la vie sociale ou le march . la demande de la CSC Alimentation et Services, on a ajout explicitement que le travail domestique via les plateformes num riques devait tre interdit, de mani re viter qu il ne retourne dans le circuit du travail au noir. Le point de d part reste d obtenir un statut de salari pour toute personne qui travaille en situation de d pendance. Rapport de la discussion Section Des emplois en transition 19 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020#Lutter contre la pression au travail En tant que CSC, nous voulons pr venir le stress li aux tech- nologies et caus par une mobilit excessive, le combattre et uvrer pour un meilleur quilibre entre vie professionnelle et vie priv e, par les moyens suivants: a. prot ger r ellement le temps priv face aux demandes et aux revendications du milieu professionnel, par des dispo- sitions compl mentaires, adapt es l entreprise, l insti- tution ou au groupe de fonctions; b. traduire le droit la d connexion sous la forme d un plan de d connexion contraignant aupr s de chaque employeur, qui doit tre tabli, valu annuellement et corrig par les organes de concertation comp tents: une d connexion technique efficace l o c est n cessaire; si- non, des modalit s de travail coh rentes et un comporte- ment exemplaire de la part des sup rieurs hi rarchiques. En l absence d organes de concertation, nous demandons un renforcement du r le de la m decine du travail et des services de pr vention. Les modalit s d application sont pr cis es dans le r glement de travail; c. une approche du burn-out et des risques psychosociaux au travail, avec le soutien de bureaux d expertise syndi- caux, au travers d une analyse des causes li es au contenu du travail, aux circonstances de travail, aux conditions de travail, l organisation du travail et aux relations de travail (cinq crit res); cela doit passer par la concertation sociale; d. une approche qui oblige les employeurs investir davan- tage dans la pr vention; e. le suivi permanent et la limitation des cons quences n - gatives sur les conditions de travail suite l introduction des applications de type industrie 0; f. le tout dans un cadre l gal qui pr voit des sanctions pour l employeur, sur la base d une concertation au sein du CNT pr voyant des concr tisations aux niveaux des secteurs et des entreprises. #Contre la pr carit La CSC veut d fendre pleinement des contrats de qualit temps plein et dur e ind termin e et combattre la pr ca- rit , par les moyens suivants: a. augmenter le co t des contrats temporaires, y compris des contrats int rimaires sauf les contrats de remplacement, et augmenter encore davantage le co t des contrats pr - caires par des cotisations sociales accrues (celui qui pol- lue le march du travail paie); b. d velopper une approche similaire pour les travailleurs et les travailleuses temps partiel involontaire, renforcer 1920 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020l application de la CCT n 35 et limiter la grande flexibilit qui leur est impos e; c. limiter le recours aux contrats pr caires un pourcen- tage de l emploi fixe global dans l entreprise d finir sur le plan sectoriel, avec des possibilit s de d rogation en accord avec la d l gation syndicale, et l interdire dans le secteur public; d. imposer le principe fonction gale, salaire gal pour l ensemble des contrats temporaires partir du premier jour et pour l ensemble des conditions de travail, la fois au niveau interprofessionnel, sectoriel et de l entreprise. Au CNT, nous demandons que la CCT n 43 soit tendue aux contrats d une dur e inf rieure un mois; e. interdire les contrats d appel et les contrats z ro heure, quelle que soit la relation de travail; f. interdire le recours aux contrats journaliers successifs; g. interdire aux employeurs et aux plateformes num riques de recourir des travailleurs et travailleuses occasionnels s ils ne disposent pas d une assurance contre les accidents du travail, s ils ne paient pas de s curit sociale et s ils ne pr voient pas une protection du travail minimale; h. assujettir les nouveaux statuts de travail flexibles instau- r s par le gouvernement aux r gles ordinaires en mati re de fiscalit , de droit du travail et de s curit sociale; i. lutter contre le dumping social tant en Europe qu en dehors de celle-ci, y compris l encontre des ind pen- dantes et ind pendants enregistr s l tranger, au moyen d une base de donn es europ enne et d une inspection coordonn e au niveau international, avec des moyens de contr le suffisants pour la d l gation syndicale. La CSC et ses organisations s engagent faire installer des organes de concertation sociale dans toutes les entreprises multi- nationales. Ces organes doivent tre install s au niveau de la structure du capital de l entreprise; j. accorder une attention particuli re aux travailleurs et tra- vailleuses pr caires dans la l gislation sur le bien- tre et la sant au travail en leur garantissant la protection l gale; k. toutes ces propositions doivent tre assorties de sanc - tions en cas de violation des r gles tablies et les organes de concertation doivent pouvoir traiter ces mati res; l. le principe travail gal, salaire gal doit tre appliqu tous les travailleurs et travailleuses, y compris aux sans- papiers. Le Conseil national du travail doit veiller l op - rationnalisation de toutes les conventions de l OIT, y com- pris la 189 sur le travail domestique. Pour les travailleurs et les travailleuses sans papiers, il convient de pr server le droit d introduire des plaintes, de mener des proc dures afin de prot ger leurs droits. #Des risques sous contr le La CSC exige des garanties pour que les nouvelles technolo- gies ne menacent pas la s curit et la sant des travailleurs et des travailleuses ou qu elles ne fassent pas prendre des risques inconsid r s pour la soci t , l environnement ou le climat. Aussi, la CSC demande que: a. pr alablement l introduction d une nouvelle technolo- gie et/ou de nouvelles substances, les risques potentiels soient examin s minutieusement, de mani re ind pen- dante, et document s en toute transparence, et que les technologies pr sentant des effets n gatifs potentiels sur la sant soient au maximum proscrites d s la premi re phase de recherche et d veloppement. Si apr s leur intro- duction, ces technologies s av rent nocives pour la sant et la s curit des travailleurs et des travailleuses ou pr - sentent un risque pour l environnement, les autorit s de- vraient pouvoir imposer des conditions ou des restrictions leur utilisation, voire leur retrait; b. une commission scientifique europ enne ind pendante soit tenue de donner son autorisation la mise sur le mar - ch de technologies potentiellement nocives, et puisse ainsi imposer des conditions restrictives l usage indus- triel et aux applications qui en sont faites. Le cadre l gal europ en doit galement tre rapidement tendu afin de prot ger la vie priv e, la s curit et la sant des tra- vailleurs et des travailleuses, des consommateurs et des consommatrices et de l environnement, et ce, sur la base des nouvelles connaissances scientifiques; les dossiers 20 AUDE VANLATHEM21 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020des fabricants concernant les cons quences sur la sant et l environnement doivent tre rendus publics; c. les co ts de la recherche et de la pr vention, ainsi que de la concertation europ enne ce sujet, soient financ s par des contributions patronales des fonds europ ens sec - toriels ( cr er) dans le cadre du dialogue social europ en; d. les moyens et les donn es des services de pr vention soient utilis s et rassembl s pour collecter des donn es scientifiques multidisciplinaires permettant d effectuer un monitoring des effets de certaines technologies sur la sant , en tant galement attentif aux diff rences de genre, d ge et de niveau de formation. Sur le plan de la m decine du travail, un dossier de sant doit galement tre conserv pour chaque travailleur et chaque travail- leuse. Les expositions des risques professionnels sur l ensemble de la carri re doivent syst matiquement tre consign s dans ce dossier, des fins de pr vention et de compensation, avec une attention pour l adaptation de la liste des maladies professionnelles: la reconnaissance no- tamment du burn-out et de certains cancers dont la cause pr pond rante s av re professionnelle; e. les risques pour la sant et la s curit soient abord s dans le cadre de la concertation sociale au sein des secteurs et des entreprises, dans un langage compr hensible, afin que des dispositions puissent tre prises pour viter ces risques. Dans ce contexte, la CCT n 39 doit tre adapt e (voir #; f. les moyens financiers et humains n cessaires soient d ga- g s par l entreprise pour l information, la formation et la participation des travailleurs et des travailleuses qui se- ront confront s aux nouvelles technologies. L information et la formation doivent tre la mesure des travailleurs et des travailleuses, adapt es leur rythme et se d rouler dans le temps de travail r mun r ; g. toutes ces mesures soient galement applicables aux tra- vailleurs et aux travailleuses sans contrat de travail ou qui ne sont pas nomm s titre d finitif; h. un r le particulier soit d volu aux services de pr vention et aux organes de concertation comp tents, l autonomie et l ind pendance de la m decine du travail soit renforc e, et toutes les autorit s publiques appliquent une politique de r pression stricte en leur octroyant les moyens n ces- saires l ex cution de leurs t ches. #La formation tout au long de la vie Les transitions profondes requi rent une politique de forma- tion plus ambitieuse. Pour ce faire: a. le volet formation de la loi sur le travail faisable et ma- niable doit tre transform en un droit individuel et ex cu- table pour chaque travailleur et travailleuse. Chaque tra-vailleur individuel et chaque travailleuse individuelle doit progressivement se constituer ce droit de minimum cinq jours pour atteindre dix jours par an d ici 2022, y compris dans les PME, y compris les int rimaires, les travailleurs et les travailleuses de plateformes et crowd workers , en tenant compte des sp cificit s du secteur. Il convient de dissocier ce droit du cong - ducation pay qui rel ve des comp tences des R gions; b. ce droit doit tre coupl une obligation contraignante pour l employeur et susceptible d tre sanctionn e, sous le contr le des syndicats, d organiser l exercice de ce droit, avec une participation gale de tous les travailleurs et tra- vailleuses, et une attention particuli re pour les travail- leurs et travailleuses les plus vuln rables. Les personnes actives dans des secteurs sensibles la concurrence ou la conjoncture, ou les personnes plus faibles sur le march du travail (personnes peu qualifi es, travailleurs et tra- vailleuses temporaires ou temps partiel involontaire ) doivent prioritairement b n ficier d un choix de forma- tions qui renforcent leur position sur le march du travail; c. les employeurs et les pouvoirs publics doivent, d s le d but de la carri re ou de la relation de travail, investir dans un large ventail de formations et dans un accom- pagnement de carri re en pr voyant, en plus du droit la formation, un droit l accompagnement de carri re au moyen de passeports de formation et de bilans de comp - tences. La CSC demande le retrait de la l gislation selon laquelle les travailleurs et les travailleuses doivent utiliser une partie de leur indemnit de pr avis pour financer leur employabilit . Cette d marche doit s accompagner d une transparence sur les fonctions futures et les comp tences requises, et d un r gime de priorit pour les travailleurs et travailleuses internes; d. d s le d but de la concertation en mati re de transition, dans le cadre de la CCT n 39 (voir #, il faut laborer imm diatement des programmes de formation qui per - mettent d viter des licenciements. La formation devrait galement s inscrire dans une logique d anticipation des changements dans l entreprise, le secteur et le march de l emploi. Un soutien doit tre apport aux sans-emploi sur les comp tences num riques; e. une forme plus efficace de cr dit-formation doit venir s ajouter ce droit, dans le cadre du cr dit-temps, pour des reconversions de longue dur e: prolongation et am - lioration du cr dit-temps, prime Onem plus lev e, sup- pl ment de l employeur, y compris dans les PME et pas seulement pour les formations d bouchant sur un m tier consid r comme tant en p nurie ; f. des CCT doivent concr tiser cette politique de formation. Celle-ci doit tre soutenue par des fonds de formation sec - toriels. Il convient de valoriser ces fonds pour en faire des fonds de transition part enti re consacrant des moyens un cadastre permanent de l innovation et des volutions des m tiers dans le secteur. Ces initiatives doivent renfor - 2122 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020cer les travailleurs et travailleuses et les demandeurs et demandeuses d emploi pour l ensemble des secteurs; g. nos d l gu es et d l gu s dans les organes de concer - tation doivent disposer de soutien et d expertise afin d anticiper les restructurations et d laborer des plans de formation dans chaque entreprise, laissant la possibilit aux travailleurs et travailleuses de choisir eux-m mes leur formation en fonction de leurs besoins; h. des garanties doivent tre apport es pour celles et ceux qui travaillent dans les pouvoirs publics et l enseignement; il faut cet effet les moyens et les ressources humaines suffisants; i. dans ce cadre, il faut aussi reconnaitre les comp tences acquises; j. d signer un conseiller ou une conseill re externe en for - mation financ par l employeur, les secteurs et les pou- voirs publics; k. cette politique doit tre promue aux niveaux europ en et international. #Le num rique pour tous et toutes Le risque d une fracture num rique doit tre cart en ins- taurant une politique qui englobe tout le monde. a. Des garanties en mati re d acc s, d ducation et de for - mation l utilisation des nouvelles technologies doivent tre instaur es tous les niveaux, y compris europ en et international, afin que chacun, chacune puisse b n ficier du num rique. b. L interdiction constitutionnelle de la discrimination im- plique galement la cr ation de cadres l gaux pour les pouvoirs publics et les entreprises, afin de rendre et de maintenir les services accessibles, sans en augmenter les co ts, aux personnes qui n ont pas acc s au num rique. c. L alphab tisation num rique, tout comme la formation la lecture et l criture, doit devenir un droit fondamental accessible toutes et tous. Elle doit tre int gr e par d - faut et de mani re accessible dans toute politique visant d velopper les comp tences soci tales de base, avec des investissements n cessaires de la part des pouvoirs publics. Une attention particuli re doit tre apport e aux demandeurs et demandeuses d emploi, quel que soit leur niveau de formation ou leur ge. Les formations dispen- s es dans ce domaine doivent utiliser les derni res ver - sions des logiciels informatiques. d. L introduction de toute nouvelle technologie dans les en- treprises, les institutions et les pouvoirs publics doit tre accompagn e d une politique de pr vention du technos- tress: mat riel et logiciels conviviaux, droit la formation pr alable durant le temps de travail, accompagnement lors de l introduction, assistance rapide et ad quate en cas de dysfonctionnement, manuels lisibles, am lioration continue sur la base de plaintes et d valuations. Cette formation doit se faire dans les trois langues nationales. Cette politique doit tre concert e, y compris dans les PME. e. Ind pendamment de la num risation, les pouvoirs publics doivent continuer offrir des services non-num riques sans co t suppl mentaire pour le ou la b n ficiaire. #La protection de la vie priv e au travail La CSC profite de l attention accrue accord e la protection de la vie priv e des citoyennes et des citoyens pour am liorer le cadre l gal et conventionnel afin de prot ger efficacement la vie priv e des travailleurs et des travailleuses et des deman - deurs et demandeuses d emploi, tout en veillant ce que l as - sistance individuelle des repr sentantes et repr sentants syn - dicaux soit garantie et que la l gislation sur la protection de la vie priv e ne restreigne pas le travail syndical, en instaurant: a. un droit contraignant pour les travailleurs et les travail- leuses de consulter, copier et corriger toutes les donn es d tenues leur sujet par les employeurs, dans des dos- siers personnels, des valuations, des r sultats de tests et toute autre donn e relative leurs prestations; comme base d un droit collectif et individuel l information et la n gociation sur la collecte, le stockage, le traitement, la transmission et le vol des donn es au niveau de l entre- prise. cette fin, les employeurs doivent dresser un inven- taire de tous les documents et ne peuvent utiliser que ce qui figure dans l inventaire. Cela doit tre repris dans une annexe au r glement de travail. Toutes les donn es doivent tre effac es apr s le d part de l entreprise; b. parall lement, un droit contraignant pour les demandeurs et les demandeuses d emploi de consulter, copier et cor - riger les dossiers de candidature et les r sultats de tests, et de faire effacer ces donn es la fin de la proc dure de recrutement et de s lection; c. des obligations contraignantes pour toutes les institutions sur le march de l emploi, y compris un droit pour les de- mandeurs et demandeuses d emploi l information et la consultation des dossiers d tenus, ainsi que le droit l image; d. une protection sp ciale pour les donn es m dicales et toute autre donn e sensible: - interdire sur le lieu de travail les applications utilis es par les employeurs pour acc der aux donn es de bio- surveillance ou aux donn es m dicales des travailleurs et des travailleuses, des demandeurs et demandeuses d emploi, et des candidates et candidats; - ne permettre aux m decins d sign s par les employeurs d acc der aux donn es m dicales du travailleur ou de la 2223 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020travailleuse que si ce dernier ou cette derni re y consent volontairement et sans contrainte ni sanction; - rendre facilement contraignant le droit pour un travail- leur ou une travailleuse de consulter et de copier son dossier m dical aupr s d un ou une m decin du tra- vail, m decin contr le, m decin d assurance, m decin conseil, conseiller ou conseill re en pr vention, ou en- core personne de confiance; - pr voir un droit la discr tion l gard de l employeur dans les contacts avec les m decins du travail et garan- tir le secret m dical dans l utilisation des nouvelles technologies. Ce droit la discr tion doit tre contrai- gnant et contr l ; e. des sanctions faciles imposer et une proc dure de plainte claire. Avec la possibilit , en cas d infractions, de faire appel des expertes et experts externes qui peuvent apporter les preuves num riques suffisantes. L information doit tre mise disposition des travailleurs et travailleuses avec ou sans emploi dans un langage compr - hensible. Ces diff rents l ments ne peuvent pas entraver l change automatique de donn es entre diff rents services et organisations en vue d accorder automatiquement aux citoyennes et citoyens certains droits et avantages. Des me- sures particuli res doivent tre prises propos du transfert d informations personnelles de travailleurs et travailleuses entre diff rents employeurs. #Les travailleurs et les travailleuses ne sont pas des robots La CSC souhaite que les travailleurs et les travailleuses soient mieux prot g s contre un contr le approfondi au travail, tant par la l gislation que par les CCT interprofessionnelles et sec - torielles et les accords conclus au niveau de l entreprise, de l institution ou de l administration, avec une attention par - ticuli re pour les entreprises sans repr sentation syndicale: a. en abordant le th me dans les discussions sur la r gle- mentation du travail et en formant nos militantes et mili- tants, non pas pour emp cher des contr les concert s et justifi s face des abus ou une plus grande s curit , mais pour d fendre la dignit humaine et les droits l informa- tion conform ment la r glementation; b. en am liorant le cadre l gal et conventionnel en mati re de protection de la vie priv e au travail, en fonction des volutions technologiques, notamment la surveillance par cam ras et la collecte de donn es lectroniques, et en l - gif rant concernant la g olocalisation et d autres syst mes de surveillance et de monitoring. Pour ce faire, il faut en limiter l utilisation des fins sp cifiques, restreindre au 23 maximum le nombre de personnes qui ont acc s ces donn es et mieux appliquer les r glementations; c. en interdisant la surveillance des prestations des travail- leurs et des travailleuses par les clientes et clients et par les patientes et patients; d. en conf rant au travailleur et la travailleuse le droit d acc der et de consulter pr alablement des informations compl tes sur toutes leurs donn es personnelles, y com- pris les donn es relatives aux prestations et la producti- vit collect es sur lui ou sur elle, ainsi qu un droit contrai- gnant la correction de ces donn es. Le travailleur ou la travailleuse et son d l gu syndical doivent galement pouvoir consulter, avec l aide d experts ind pendants, les algorithmes utilis s pour traiter les donn es, afin de lutter contre la discrimination; e. en supervisant de fa on paritaire, au niveau de l entre- prise, l affectation et l utilisation des donn es obtenues par vid osurveillance et toute autre forme de surveillance en ligne; f. en imposant des r glementations relatives aux d lais de conservation et la suppression de ces donn es; AUDE VANLATHEM24 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020g. en supprimant automatiquement et obligatoirement tous les syst mes de surveillance caract re personnel en de- hors des heures de travail et de prestation, et en informant les travailleurs et travailleuses de mani re suffisamment claire sur la mani re dont - et les moments o - ils et elles sont contr l s; h. en organisant des campagnes pour sensibiliser et en for - mant les travailleurs et les travailleuses la protection de leurs donn es personnelles; i. en garantissant galement aux allocataires sociaux le droit la protection de la vie priv e lors de contr les, de la transmission de donn es personnelles d un organisme l autre; j. en d veloppant une approche critique par rapport l uti- lisation des nouvelles technologies, ainsi qu une thique dans l usage d internet. #L action l gard des travailleurs et travailleuses actifs non-salari s La CSC entend renforcer la lutte contre la faible protection des travailleurs et des travailleuses des plateformes num - riques et/ou des ind pendants et ind pendantes d pen- dants, et contre la menace que repr sente ce syst me pour la qualit des emplois des travailleurs et travailleuses salari s. Nous devons continuer d noncer et combattre l utilisa- tion abusive de ces statuts par l employeur, en appliquant les mesures suivantes: a. mener une action soutenue pour requalifier le statut de ces travailleurs et travailleuses, s il existe des preuves suf- fisantes de l existence d un lien de subordination; b. instaurer un meilleur cadre juridique national et europ en contre les faux ind pendants, et un meilleur cadre euro- p en contre le dumping social avec de faux ind pendants trangers et des soci t s- crans; c. conform ment au pilier social europ en, il conviendra d assurer une protection gale de l emploi et une s cu- rit sociale ad quate pour celles et ceux qui travaillent sur les plateformes et les ind pendants et ind pendantes d - pendants. Cela comprend galement l assurance accident du travail, les normes en mati re de dur e de travail, les horaires de travail, la s curit et la sant , le droit un re- venu quitable (au moins quivalent au salaire minimum national) et d autres conditions de travail, ainsi que le droit la n gociation et l action collective. L interdiction europ enne de conclure des accords sur les prix doit tre inf rieure au droit de n gociation; d. rendre les plateformes num riques responsables des d - clarations fiscales et parafiscales et du versement du pr - compte professionnel et des cotisations sociales; e. instaurer une r glementation permettant aux syndicats d organiser et de communiquer personnellement avec tous les travailleurs et travailleuses des plateformes et les ind pendants et ind pendantes d pendants des fins d information, de consultation et de n gociation collec - tive; f. instaurer des contr les stricts des employeurs de plate- forme pour lutter contre la fraude fiscale et la fraude aux cotisations sociales engendr es par le travail sur les pla- teformes, et pour prot ger les droits de ces travailleurs et travailleuses; g. soumettre les plateformes num riques aux m mes r gles de fonctionnement, conditions, contr les et agr ments que les autres entreprises et soumettre les plateformes une r glementation compl mentaire si elles perturbent la vie sociale ou le march ; h. pr voir un acc s adapt pour les services d inspection afin de permettre le contr le des conditions de travail des tra- vailleurs et des travailleuses des plateformes num riques et des r gles de fonctionnement de ces plateformes; i. le travail domestique via les plateformes num riques doit tre interdit. C est indispensable pour viter qu il ne re- tourne dans le circuit du travail au noir. La CSC entend rassembler et repr senter tous les actifs tra- vaillant dans un lien de d pendance, y compris ceux qui, contraints ou non, travaillent avec un statut d ind pendant, ou celles et ceux qui n ont m me pas de statut, comme les travailleurs et travailleuses actifs titre compl mentaire sur des plateformes. Avec le projet United Freelancers, la CSC veut organiser et soutenir les travailleurs et travailleuses au- tonomes et les ind pendantes et ind pendants sans person- nel. Chacun aspire en effet de bonnes conditions de travail (bien- tre, sant , s curit ), une r mun ration correcte et un quilibre optimal entre vie professionnelle et vie priv e. Ceci n cessite une forme d action syndicale qui organise ces actifs et leur conf re une place dans notre syndicat, afin de lutter contre le d mant lement social et le dumping social pour tous les actifs. Nous devons, en collaboration avec ces personnes, am liorer leur revenu et leurs conditions de tra- vail. Notre point de d part, c est d obtenir le statut de salari pour tous ceux et celles qui travaillent en situation de d pen- dance. L organisation de tous les travailleurs et travailleuses d pendants doit tre encadr e afin d am liorer les rapports de force pour tous les travailleurs et travailleuses. Le bureau national suivra et orientera le projet United Free- lancers annuellement afin de l valuer fin Cette valua- tion sera pr sent e au conseil g n ral, qui se prononcera sur les orientations. Le congr s demande au bureau national de mener, pr ala- blement l valuation du projet United Freelancers, un d bat interne sur le fond, dans toutes les instances de la CSC. 2424RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202025 3Un monde en transition CONGRES 201926 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020La mission de la troisi me section du congr s tait essentielle: discuter et mettre au point huit lignes de force qui abordaient tout l aspect international de la transition. Des cha nes d appro - visionnement (num riques) au contr le des g ants de l internet, en passant par la durabilit cologique, les migrations et le com - merce quitable, sans oublier le fonctionnement de l Organisa - tion internationale du travail (OIT) et les Objectifs de d veloppe - ment durable (ODD) de l ONU. La LIGNE DE FORCE 18 sur les cha nes d approvisionnement a t renforc e par le congr s, qui a insist sur les produits locaux et les circuits courts. La plus-value cologique qu offrent les circuits courts (moins de transport) doit tre r compens e. La demande d une l gislation nationale contraignante sur les chaines d appro - visionnement a t tendue au niveau europ en par le congr s. Le travail d cent dans les cha nes num riques , tel est l objet de la LIGNE DE FORCE 19 . Le congr s a demand que la CSC sou - tienne les crowd workers , ces travailleurs et travailleuses tr s vuln rables qui acceptent sur une base freelance des missions propos es par le biais d une plateforme num rique, afin que ces personnes puissent s organiser sur le plan syndical. Le congr s s est aussi prononc en faveur d un lobbying international plus actif des syndicats pour lutter contre la prolif ration du travail par le biais des plateformes num riques et pour un contr le effectif des cha nes internationales d approvisionnement des multinationales. Les syndicats doivent faire pression aupr s des pouvoirs publics pour que les instances de contr le disposent des moyens suffisants et des comp tences n cessaires pour agir de mani re efficace. Les syndicats eux-m mes doivent aussi dis - poser d un r le d fini l galement dans cette fonction de contr le. La LIGNE DE FORCE 20 plaide pour plus de prise sur les g ants de l internet . Le congr s a encore davantage mis les points sur les i en demandant l interdiction de la commercialisation de donn es rassembl es par des services publics. Les consomma - teurs doivent toujours pouvoir faire supprimer d finitivement leurs donn es personnelles des bases de donn es des g ants de l internet. Le droit classique de la concurrence doit tre red fini pour lutter contre le monopole de fait des grandes entreprises de l internet. L examen de la LIGNE DE FORCE 21 Dans les limites de la pla - n te sur la transition cologique a donn lieu de longues dis - cussions et une reformulation profonde du projet de texte. La Rapport des discussions Partie un monde en transition 26transition cologique doit elle-aussi tre juste en premier lieu: les grandes entreprises et les grosses fortunes doivent supporter les charges principales et les pouvoirs publics doivent accorder une attention particuli re aux travailleurs et travailleuses les plus pauvres et aux plus pr caris s, qui sont les principales vic - times. En plus des accises sur le k ros ne et d une taxe kilom - trique intelligente sur les trajets en avion, il faut aussi instaurer une TVA sur les billets d avion. Depuis longtemps d j , le PIB ne suffit plus comme indicateur principal du bien- tre. La CSC doit par cons quent entamer la r flexion sur de nouveaux mod les de prosp rit et de protection sociale dans un contexte de crois - sance durablement faible . Nos revendications doivent aussi tre adapt es l imp ratif cologique de la plan te. Suite une r organisation profonde du programme du congr s, qui a laiss plus de temps la discussion dans les sections, les quatre derni res lignes de force ont aussi pu tre examin es en profondeur. La LIGNE DE FORCE 22 consacr e Une politique migratoire juste tait sensible. Le congr s a davantage mis l accent sur une bonne politique de formation permanente et de bonnes conditions de travail et de r mun ration avant de pou - voir recourir la migration pour combler les p nuries sur le mar - ch de l emploi. Si la migration conomique est une option, il faut tenir compte des cons quences d une fuite des cerveaux dans les pays de d part. Les migrants conomiques sont trop souvent les victimes d une l gislation trop peu coordonn e sur le plan inter - national, des lacunes de la l gislation, plus encore lorsque leurs droits de s jour sont pr caires ou inexistants. Cette situation est exploit e sans vergogne par des employeurs malveillants et c est pr cis ment ce niveau qu il faut faire face au d fi gigantesque de donner chacun des droits du travail identiques. Dans le volet international de ce congr s de transition, la LIGNE DE FORCE 23 consacr e au commerce quitable tait indis - pensable. La section du congr s a renforc le projet de texte, en soulignant que les droits des travailleurs et travailleuses et les droits environnementaux doivent au moins tre tout aussi contraignants que les droits des investisseurs. Les multinatio - nales doivent d abord se tourner vers la jurisprudence nationale avant de pouvoir faire appel une cour publique internationale, qui doit galement traiter les plaintes des travailleurs et travail - leuses et des organisations environnementales. Le commerce d armes avec des pays en guerre ou engag s dans des conflits dont la population civile est victime doit tre rendu impossible. RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202027 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020Le centi me anniversaire de l Organisation internationale du tra - vail (OIT) tait l occasion id ale de consacrer la LIGNE DE FORCE 24 l OIT demain . Peu de modifications ont t apport es au projet de ligne de force, qui plaide notamment pour la poursuite du d veloppement des normes fondamentales du travail, autre - ment dit la constitution de l OIT, avec aussi un droit la s curit et la sant au travail, la limitation de la dur e du travail et le droit un salaire minimum d cent. La section du congr s a ajout un plaidoyer en vue d un droit consultatif renforc pour l OIT aupr s des institutions qui d cr tent des sanctions commerciales pour des pays qui violent les normes fondamentales du travail. La LIGNE DE FORCE 25 porte sur les Objectifs de d veloppement durable des Nations unies: Les ODD vers des droits, des r gles et des r sultats . Le cadre des ODD doit aussi tre traduit en un instrument qui permette aux militants d agir sur le terrain. Le plan ODD qui est demand de la part de chaque entreprise et organisation doit aussi comprendre un plan pour les cha nes d approvisionnement dans lequel une partie garantie des mar - ch s publics peut tre attribu e des entreprises d conomie sociale. RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020#Contr ler les cha nes d approvisionnement La CSC entend soutenir la responsabilit partag e des en- treprises et des pouvoirs publics pour le respect des droits humains tout au long de la cha ne de production et de ser - vices, aux niveaux national et international. Pas seulement avec de belles promesses mais avec des r gles, des droits et des engagements fermes: Sur le plan national: a. une l gislation belge relative la diligence raisonnable, l instar de la loi fran aise Devoir de vigilance ( et de la loi n erlandaise Zorgplicht kinderarbeid (, comme tape pr alable une initiative europ enne. Les entreprises actives sur le plan international doivent ainsi tre contraintes, sous peine de sanctions, de pr senter chaque ann e un rapport public sur le respect des droits humains et, en particulier, des normes fondamentales du travail, pour l ensemble de la cha ne; b. un meilleur cadre l gal contraignant, assorti de contr les proactifs et efficaces, pour rendre les entreprises p nale- ment responsables des violations des droits humains et des normes fondamentales du travail l tranger, ainsi que des violations des trait s internationaux sur le climat et l environnement l tranger, y compris chez les sous- traitants et les fournisseurs. Les produits d entreprises qui violent manifestement ces principes doivent tre bannis. Il faut galement renforcer les r gles en mati re d ex cution et la collaboration internationale entre les tribunaux et les services de police en leur pr voyant des moyens financiers et en personnel; c. la diligence raisonnable doit, en Belgique aussi, faire l ob- jet d une concertation sociale dans chacun des secteurs, entreprises, institutions et administrations. Nous utilisons pour ce faire les comit s d entreprise europ ens et inter - nationaux, le dialogue social europ en et les accords- cadres europ ens et internationaux. La CSC doit plaider pour des initiatives dans la cha ne courte; d. le rapport annuel de chaque entreprise doit contenir un rapport sur la cha ne d approvisionnement, valid de mani re ind pendante, et qui doit faire l objet d une dis- cussion pr alable dans les organes de concertation de l entreprise aux niveaux international, europ en et natio- nal. Chaque entreprise doit d signer un Due Diligence Officer (DDO) qui est responsable de l application de la diligence raisonnable sur l ensemble de la cha ne. Cette personne b n ficie d un statut sp cial dans l entreprise, y compris d une protection ad quate contre le licenciement, afin de garantir son ind pendance; e. des conditions en mati re de droits humains et de droits du travail, ainsi que des conditions environnementales, doivent tre int gr es dans tout march public, et des AUDE VANLATHEM28 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020contr les doivent tre effectu s sur le terrain par des ser - vices d inspection qui disposent de comp tences et de personnel suffisants; f. les entreprises belges plus expos es aux risques doivent adh rer aux initiatives sectorielles et mondiales exis- tantes, ainsi qu aux conventions europ ennes d ve- lopper en collaboration avec les interlocuteurs sociaux concern s pour les secteurs risques. Il faut exclure tout caract re facultatif et aller dans le sens d engagements contraignants et respect s; g. les entreprises qui appliquent la diligence raisonnable et garantissent le respect des droits humains et des droits fondamentaux du travail sur l ensemble de la cha ne doivent tre certifi es par une institution ind pendante; h. dans le cadre de leur plan sur les ODD (voir #, toutes les entreprises, institutions, organisations et administrations doivent laborer leur propre plan en mati re de diligence raisonnable avec un examen tape par tape de tous les produits et services achet s; I. il faut valoriser les entreprises qui font l effort de faire appel des produits locaux et des circuits courts; J. il faut rendre responsables les entreprises qui font appel des sous-traitants non thiques.Sur le plan international, avec le soutien total des autorit s belges et de l Union europ enne: a. une convention ambitieuse et contraignante des Nations unies sur les entreprises et les droits humains; b. une nouvelle convention de l OIT pour le travail d cent dans les cha nes d approvisionnement internationales; c. une l gislation europ enne contraignante en mati re de diligence raisonnable. Nous y associons une strat gie syndicale globale pour de meilleures normes du travail et de meilleures normes cli- matiques et environnementales partout dans le monde, par laquelle nous organisons les travailleurs et travailleuses sur l ensemble de la cha ne. Sur le plan national, nous renfor ons ici la collaboration entre les secteurs et les centrales profes- sionnelles. Sur le plan international, nous renfor ons la col- laboration avec les syndicats locaux, les organisations de la soci t civile et les conf d rations syndicales europ ennes et internationales. Nous impliquons galement nos mili- tantes et militants, au travers des actions professionnelles et interprofessionnelles. #Le travail d cent dans les cha nes num riques Le contexte de la globalisation conomique a un impact sur le niveau g ographique, y compris en termes urbains, et n ces- site donc de prendre en compte l urgence cologique, sociale et migratoire. La CSC tend son champ d action aux cha nes de services internationales pour que les travailleurs et tra- vailleuses de ces cha nes, quel que soit leur statut, puissent s affilier au syndicat et d fendre leurs int r ts. a. Les comit s d entreprise europ ens et internationaux, le dialogue social europ en et international, les accords- cadres europ ens et internationaux, ainsi que l obligation d appliquer la diligence raisonnable dans les cha nes d ap- provisionnement doivent devenir la norme dans le monde. Ce principe vaut galement pour les plateformes num - riques. Pour ce faire, l ensemble de la CSC doit renforcer son engagement et son attention pour le syndicalisme europ en et international, avec la participation active des militantes et militants. b. Ce qui peut tre fait dans le transport maritime, avec les conventions maritimes mondiales de l OIT pour imposer des normes minimales pour les marins, doit aussi pouvoir l tre pour les crowd workers qui surfent sur la toile mondiale. c. Dans le prolongement de notre action sur le plan national (voir #, nous insistons aux niveaux europ en et inter - national pour que les plateformes et les sites de crowd work aient une responsabilit comme employeurs, en ce compris leurs obligations en mati re de s curit sociale. 28 AUDE VANLATHEM29 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020Nous cherchons ici collaborer avec d autres syndicats actifs sur ce plan, y compris pour apprendre de leurs stra- t gies syndicales. d. L obligation d appliquer la diligence raisonnable dans la cha ne d approvisionnement (voir # doit galement couvrir toutes les activit s de service dans les cha nes internationales de production et de services. e. Au travers des organes de concertation, nous nous oppo- sons ce que les entreprises utilisent les plateformes num riques ou le crowd work dans un but de dumping social. Pour ce faire, ces organes de concertation doivent obligatoirement tre inform s au pr alable et dans les d lais. f. Tout comme nous le demandons au niveau national (voir #, il faut veiller aux niveaux europ en et international garantir un champ d action quitable, en luttant contre la distorsion de la concurrence par les plateformes num - riques et en rappelant l ordre les pays qui instaurent des r gimes pr f rentiels (sociaux et fiscaux) pour les plate- formes num riques. Cela n cessite que la CSC travaille de concert avec les syndicats europ ens et internationaux une strat gie active de plaidoyer. Plus globalement, une licence to operate (licence d exploi- tation) doit tre instaur e pour toutes les cha nes interna- tionales de production et de services sur le plan europ en, ind pendamment du mod le conomique: un droit condi- tionnel exercer une activit . Les multinationales qui ne veulent pas respecter les normes sociales et cologiques es- sentielles doivent tre prohib es. Pour que ce soit possible, il faut videmment disposer de moyens suffisants et des comp tences n cessaires en mati re de contr le et d ex cu- tion, en int grant obligatoirement les syndicats, qui doivent tre les garants du respect des normes. Il faut que les syn- dicats fassent pression pour que l tat octroie des moyens suffisants ses administrations publiques pour exercer ses missions de contr le. #Une prise sur les g ants de l internet La CSC s oppose l norme emprise des grandes entreprises de l internet sur la soci t , l conomie et la politique, notam- ment en raison du danger pour la vie priv e et la d mocratie politique et conomique. Par cons quent: a. il faut limiter l galement l exploitation, le stockage, le couplage, la transmission et la vente de donn es person- nelles des fins commerciales et politiques. Les donn es des services publics ne peuvent pas tre commercialis es. Le nouveau R glement g n ral europ en sur la protec - tion des donn es (RGPD) n est qu une premi re tape et doit tre appliqu de mani re stricte, notamment par le biais de contr les suffisants et de sanctions dissuasives. Les consommateurs et consommatrices devraient pou- voir supprimer d finitivement leurs donn es personnelles dans les diff rentes bases de donn es des Big 5 , qu elles soient r centes ou anciennes; b. la s curit de l utilisation des donn es doit tre garan- tie par des organes de contr le publics et les infractions doivent tre s v rement sanctionn es; c. les b n fices que les entreprises tirent de l exploitation, du traitement et de la vente de donn es doivent tre im- pos s de mani re juste, efficace, innovatrice et coordon- n e sur le plan international, afin que les recettes fiscales reviennent aux pays dans lesquels les donn es ont t extraites ou utilis es; d. les autorit s f d rales, l Union europ enne et les institu- tions internationales doivent instaurer une l gislation et des contr les suffisants pour s opposer la concentra- tion extr me des pouvoirs conomique et financier des grandes entreprises de l internet, et viter les abus des fins politiques ou de manipulation massive. Avec la CES et via des contacts politiques, nous voulons parti- ciper au d bat sur la red finition du droit de la concurrence, notamment pour lutter contre les abus des grandes entre- prises de l internet. Dans le m me temps, l Europe doit veil- ler d velopper ses propres entreprises de l internet, pour viter de devenir totalement d pendante des grands acteurs internationaux. #Dans les limites de la plan te Dans tout ce qu elle fait, la CSC veut tre un moteur de la tran - sition cologique radicale, tant au niveau global que local. La transition radicale vers une soci t climatiquement neutre est prioritaire ce niveau. Elle exige aussi une participation la politique climatique et nerg tique fond e sur des conclusions scientifiques, tous les niveaux. Cette participation doit garantir que la politique dans tous ses aspects soit empreinte de la n cessit d une transition juste, et tenir compte du fait que les premi res victimes sont les tra - vailleuses et travailleurs les plus pauvres, les plus pr caris s. Le congr s confirme par cons quent les lignes de force des pr - c dents congr s mais demande de concr tiser ces ambitions. a. La CSC traduit l ambition d une Europe climatiquement neutre d ici 2050 sous la forme d une Belgique climatique - ment neutre, avec un plan sp cifique et des ch ances pour chaque tape. La transition sur le plan de l approvisionne - ment nerg tique (exigeant que la sortie du nucl aire pr - vue actuellement par le Parlement f d ral en 2025 tienne 2930 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020compte de la situation des travailleurs et travailleuses concern s), de l industrie, de la cha ne alimentaire, du transport et du logement doit occuper une place prioritaire ce niveau, car c est l que l on peut enregistrer les plus fortes avanc es, en accordant une attention particuli re au r le que l industrie peut jouer cet gard. Au lieu de faire partie du probl me, elle devrait aider trouver des solu - tions. Cela signifie que certains des plus grands pollueurs du monde devront supporter le poids de la transition vers une soci t climatiquement neutre. Une transition qui - table implique galement que les paules les plus fortes, les grandes entreprises et les grandes fortunes supportent le principal fardeau de la transition cologique. Par ailleurs, il est primordial de soutenir l emploi local et l conomie circulaire. b. Chacun doit s impliquer dans la transition cologique: il faut mettre un terme aux r gimes d exception pour l avia - tion et le transport maritime, aux niveaux europ en et in - ternational. - Il faut taxer le k ros ne et instaurer la TVA sur les bil - lets d avion. Il faut instaurer, l chelle europ enne, une taxe kilom trique intelligente sur les trajets effectu s en avions, li e des accords mondiaux pour accro tre sen - siblement l efficacit du transport a rien. Les possibili - t s de r duire le nombre de vols et de miles parcourus doivent tre optimis es. Il y a lieu d introduire au plus vite les nouvelles technologies en mati re de transport a rien. - Les recettes g n r es par ces mesures doivent notam - ment tre investies dans le transport public internatio - nal. - Toutes ces mesures doivent s accompagner d une poli - tique de circuits courts (voir #, d une part, et promou - voir des d placements avec des moyens de transport du - rables, d autre part. Investir dans le d veloppement de services internationaux de chemins de fer et d autobus des prix abordables est une condition sine qua non. Il faut galement prendre des mesures suppl mentaires dans le secteur maritime au niveau international pour r duire davantage les missions de gaz effet de serre et il faut abolir les r gimes d exception cet gard dans le monde entier. c. Chaque secteur et chaque employeur individuel doivent prendre leurs responsabilit s dans la transition cologique. Un plan de transition doit tre tabli tous les niveaux. Ce doit tre un l ment part enti re et obligatoire dans le dialogue social afin de v rifier syst matiquement la mani re dont nous offrons un accompagnement juste aux travailleurs et travailleuses travers cette transition, en particulier par le biais de la formation et de la reconver - sion avec l objectif, entre autres, d accro tre l utilisation des comp tences en fonction de la transition cologique. L tablissement d un plan de transition peut galement tre une opportunit de r duire les co ts non durables (mat riaux, mati res premi res, nergie, transports et d chets) et ainsi lib rer plus de moyens afin d am lio - rer les conditions de travail et les conditions salariales. Cette concertation doit donc devenir une priorit dans toutes les entreprises. cette fin, il faut, outre les infor - mations conomiques et financi res (IEF), les informations sur l emploi (CCT n 9 du CNT) et le bilan social, imposer des informations climatiques et environnementales (ICE) et un bilan public sur le climat et l environnement. Pour ce faire, la CSC doit investir dans la formation, l assistance et le mat riel d accompagnement pour nos d l gu es et d l gu s, ainsi que nos n gociateurs et n gociatrices. Chaque entreprise et/ou secteur doit organiser avec les repr sentants des travailleurs et travailleuses et, dans le cadre de ce plan de transition, une concertation sur la ma - ni re dont l entreprise/le secteur peut prendre des initia - tives industrielles pour s int grer dans l conomie circulaire. Mais une transition juste exige aussi le maintien et/ou la cr ation d emplois de qualit . Les travailleurs et travail - leuses n ont pas payer cette transition avec leur emploi. Cela n cessitera des transformations (globales) grande chelle, en particulier dans les secteurs industriels, le pas - sage d autres mati res premi res et sources d nergie, diff rents processus de production et l organisation des cha nes de production, de nouveaux et autres produits. d. La n cessit d une transition juste doit s accompagner d une exigence d galit tous les niveaux (voir # afin d viter que les revenus les plus faibles supportent les co ts les plus lev s de cette transition, notamment par le biais d une fiscalit environnementale d gressive sans compensation suffisante. Au contraire, ces derniers doivent tre les premiers gagnants, en particulier dans le cadre de la lutte pour l accessibilit des transports en commun et la lutte contre la pr carit nerg tique. e. Il faut acc l rer consid rablement la r alisation d une mobilit d entreprise durable en adoptant un plan glo - bal en mati re de mobilit avec l ensemble des acteurs concern s. Ceci ne peut se faire au d triment de la s curit sociale. En outre, il faut r aliser d urgence des investisse - ments pour des transports publics plus efficaces et mieux d velopp s ainsi que pour les infrastructures y aff rentes. Il faut supprimer progressivement les r gimes fiscaux pour les voitures salaire, et utiliser la nouvelle possibilit l gale de les convertir en un budget mobilit . - Ces mesures doivent s accompagner d une politique de transports publics ambitieuse, abordable et coordonn e. Il faut am liorer l accessibilit et la coordination ( inter - modalit ) des r seaux de transports publics. - La CSC doit jouer un r le de pionnier dans ce changement de mentalit , par exemple en promouvant la semaine de quatre jours et le t l travail. f. Il est n cessaire de mettre en place un r seau de repr sen - 3031 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020tants syndicaux verts dans les entreprises, qui favorisent la r duction de l empreinte cologique, avec un soutien fort de la part de la centrale professionnelle et des r seaux de collaboration Rise, Brise et Arbeid en Milieu. g. Les fonds de formation sectoriels doivent aussi servir accompagner les travailleurs et les travailleuses vers une conomie durable: formation, accompagnement vers de nouveaux emplois, acquisition de comp tences colo - giques Cette action doit tre bas e sur une analyse, sec - teur par secteur, de l impact de la neutralit climatique et des risques que court le secteur s il attend et ne fait rien. Il faut ici accorder une attention sp cifique celles et ceux qui ne peuvent pas participer cette transition cologique. c t de la transition technologique, la CCT n 39 du CNT doit aussi encadrer la transition cologique (voir #. Pour adapter notre conomie aux limites de la plan te, il faut r fl chir d autres indicateurs de d veloppement que le RNB (voir #. La CSC doit aussi entamer la r flexion sur les nouveaux mo- d les de prosp rit et de protection sociale dans un contexte de croissance durablement faible, et adapter ses revendica- tions sociales l imp ratif cologique.#Une politique migratoire juste La globalisation conomique et ses interf rences avec la politique environnementale soumise aux lois du march entra nent l aggravation, d une part, des in galit s sociales, d autre part, du r chauffement climatique. Dans l ensemble du monde du travail, il faut tenir compte du d fi des grandes villes, souvent plaques tournantes du travail pr caire et de la pr carisation des travailleurs et travailleuses issus de l immigration, des demandeurs et demandeuses d asile, des migrantes et migrants. La CSC veut une politique migratoire plus humaine et plus juste tous les niveaux. a. Des droits du travail gaux doivent tre mis en uvre pour tous et toutes. La CSC met en place une action pour soutenir toute personne qui acc de au march du travail. Ce principe vaut pour tous les travailleurs et travailleuses, demandeurs et demandeuses d emploi et nouveaux arrivants, migrantes et migrants provenant de pays tiers, qui arrivent en Bel - gique pour y travailler ou pour d autres motifs. 31 AUDE VANLATHEM32 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020en mati re de s curit sociale en cas d immigration, ainsi qu en cas de retour. e. Les sans-papiers qui s journent et/ou travaillent ici de- puis un certain temps d j doivent tre r gularis s. Cette r gularisation doit intervenir dans un d lai raisonnable, sans arbitraire et donc sur la base de crit res clairs et ob- jectifs avec une commission ind pendante pour traiter les demandes. La protection et la r gularisation des travail- leurs et travailleuses qui d noncent des abus doivent tre r gl es de mani re ad quate. f. Un travail doit tre men tous les niveaux sur les facteurs qui poussent les gens migrer pour des raisons d ins cu- rit , de pauvret ou de r chauffement climatique. Dans le m me temps, il faut mieux encadrer la mobilit au sein de l Europe. Les travailleurs et travailleuses d tach s doivent b n ficier d une attention sp cifique. Le principe travail gal, salaire gal doit tre garanti partout. Il faut aussi lutter contre les faux ind pendants. Une r vision du R - glement europ en 883/2004 doit garantir la perception effec - tive des cotisations de s curit sociale. La cr ation rapide de l inspection sociale europ enne ( European Labour Autho- rity ) s impose, avec un personnel et des moyens suffisants. Aux niveaux national et europ en, les interlocuteurs sociaux doivent tre pleinement associ s ce processus. Les personnes d origine trang re sont encore trop souvent trait es de mani re d sobligeante. Cette situation n cessite une concertation et des actions dans les secteurs et les en- treprises pour promouvoir la diversit et lutter contre la dis- crimination, dans toutes les phases de la relation de travail, du recrutement au licenciement. Elle doit s appuyer sur des CCT sectorielles, des codes de conduite et des tests pratiques. Dans ce cadre, le code de conduite du Conseil national du travail concernant le recrutement et la s lection doit tre largi aux autres phases de la relation de travail. Il faut ici soutenir les d l gu es et d l gu s, ainsi que les n gocia- teurs et n gociatrices. Nous avons besoin d une politique claire et cons quente en mati re de migration conomique. Les employeurs ne peuvent pas d cider seuls qui entre en Belgique en provenance de l ext rieur de l Union europ enne et qui n y entre pas. Il s agit de choix soci taux et politiques. Les p nuries r elles sur le march du travail sont bien sou- vent la cons quence de mauvaises conditions de travail et salariales. Par ailleurs, le fonctionnement du march du tra- vail peut tre am lior par une politique de march de l em- ploi plus efficace et une politique de formation adapt e. On ne peut avoir recours la migration conomique uniquement pour combler les p nuries r elles sur le march du travail. La politique doit aussi tenir compte des cons quences de la migration conomique pour les pays d o partent les travail- leurs et travailleuses de sorte ne pas cr er de fuites de cer - veaux. 32b. Un m canisme de plaintes efficace doit tre pr vu au niveau europ en pour les migrantes et migrants dont les droits humains ne sont pas respect s, ainsi qu un plan pour lutter contre la violence faite ces personnes et leur exploitation par des trafiquants d tres humains, des pa- trons abuseurs et des tats, avec une attention sp cifique pour la violence sexuelle. Il faut permettre que les tra- vailleurs et travailleuses exploit s puissent porter plainte contre les employeurs abuseurs via un m canisme qui les prot ge durant toute la proc dure lorsqu ils d noncent les abus et d posent une plainte. c. Les demandeurs et demandeuses d asile doivent pouvoir participer rapidement au march du travail via des dis- positifs r gionaux: l octroi plus rapide de permis uniques; des trajectoires d accueil et d int gration; des formations linguistiques; des formations et une orientation profes- sionnelle; une reconnaissance et une quivalence rapides des dipl mes et comp tences acquis l tranger. Ce pro- cessus doit se poursuivre apr s la reconnaissance du sta- tut de r fugi et s appliquer tout autant aux personnes qui immigrent dans le cadre du regroupement familial. d. Les migrantes et migrants doivent avoir des droits gaux et l acc s la s curit sociale: par la conclusion d accords bilat raux suppl mentaires avec les pays d origine ext - rieurs l Union europ enne afin de pr server les droits AUDE VANLATHEM33 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020La CSC continuera s opposer toutes les tentatives visant dresser les populations les unes contre les autres, surtout contre les personnes d origine trang re, et continuera d fendre une politique bas e sur le respect, la diversit et l int gration. Le congr s exige que l engagement pris par la Belgique au sein des Nations unies d laborer un plan inter - f d ral contre le racisme soit enfin concr tis apr s 18 ans. #Le commerce quitable Nous restons convaincus qu une autre politique commerciale est possible, dont les objectifs seraient le travail d cent et une transition socialement juste. Dans ce cadre, nous nous battons depuis le tout d but des n gociations pour de meilleurs ac - cords commerciaux et d investissement, en collaboration avec le mouvement syndical europ en et international et des orga - nisations de la soci t civile qui partagent nos valeurs. a. Chaque accord commercial et d investissement doit com- prendre un chapitre durabilit , avec des sanctions en cas de non-respect, afin que la politique commerciale ne subordonne pas les droits environnementaux et ceux des travailleurs et des travailleuses aux droits des investis- seurs, mais qu elle rende ces droits au moins tout aussi contraignants. Le respect des normes fondamentales du travail de l OIT doit occuper ici une place centrale. b. La politique europ enne en mati re de commerce et d in- vestissements, ainsi que les accords conclus au sein de l Organisation mondiale du commerce, doivent v ritable- ment prot ger les entreprises europ ennes et leurs tra- vailleurs et travailleuses contre toute forme de dumping (social, conomique, climatique et environnemental). c. Les trait s existants en mati re de commerce et d inves- tissements, ainsi que les n gociations en cours ou qui doivent d buter, doivent tre corrig s en profondeur s ils sapent le droit des tats de r glementer et ne prot gent pas assez les droits des travailleurs et des travailleuses. d. Dans toutes les phases du processus de n gociation, la transparence doit tre garantie, y compris sur le mandat donn aux n gociateurs et n gociatrices europ ens, avec l implication des parlements et de la soci t civile, et en particulier des syndicats. e. Ce processus doit tre engag en collaboration avec les syndicats et les autres acteurs de la soci t civile des pays avec lesquels des n gociations sont en cours. f. cette fin, nous d fendons aussi l laboration, par l Union europ enne, de programmes de coop ration technique destin s accro tre la capacit des syndicats du Sud, afin d assurer une implication r elle, en collaboration avec les syndicats europ ens et entre ceux-ci. g. Nous continuons nous opposer la privatisation de la justice qui consiste confier des litiges avec des multina- tionales l arbitrage priv . Il faut au contraire mettre en place une Cour publique, pas uniquement pour les litiges entre les multinationales et les pays, mais aussi pour la protection des droits des travailleurs et travailleuses et des consommateurs et consommatrices, ainsi que du cli- mat et de l environnement, contre les abus de multinatio- nales. Les conditions suivantes doivent tre respect es: des d cisions claires et transparentes, l ind pendance et l impartialit des juges, la transparence, l galit entre les parties au proc s et la possibilit pour les syndicats et d autres organisations de la soci t civile de jouer un r le. Il est demand que la Cour r agisse rapidement et que les litiges ne durent pas des ann es. Pr alablement toute saisine de cette Cour, les multina- tionales doivent avoir puis les voies de recours ordi- naires (juridictions domestiques). h. Toutes les missions publiques doivent tre pr serv es des forces du march (voir # et donc rester en dehors des accords de commerce et d investissements. i. La CSC labore, en collaboration avec ses organisations, un plan d action, un itin raire et une feuille de route clairs pour int grer le th me du commerce quitable dans le travail quotidien du syndicat et pour l amener sur le ter - rain. j. Aucun nouvel accord sur le commerce des armes de guerre et des technologies connexes ne doit tre conclu avec des pays ou des parties engag es dans une guerre ou un conflit dont la population civile est victime. #L OIT demain La CSC reste tr s attach e l Organisation internationale du travail (OIT) et continue s y investir massivement. Cent ans apr s sa cr ation, l OIT joue toujours un r le irrempla able dans la promotion et la pr servation des droits des travail- leurs et des travailleuses dans le monde entier, sous quelque statut que ce soit. cet gard, la CSC mise en priorit sur l obtention et la pr servation de droits contraignants, en par - ticulier: a. le suivi et la mise en uvre de la D claration du cente- naire de l OIT sur l avenir du travail, aux niveaux national, europ en et mondial; b. le renforcement de l OIT en tant qu institution, y compris par le renouvellement et le renforcement de son arsenal l gislatif, de ses moyens et la s curisation des m canismes de plaintes, afin que l OIT b n ficie de plus de capacit d action en termes de contr les ind pendants et de sanc - tions effectives; c. une OIT plus forte dans le cadre des r formes des Nations unies: la concertation tripartite ne resterait plus seule- ment ancr e dans le fonctionnement de l OIT, elle doit aussi contribuer au fonctionnement global des Nations unies; 3334 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020d. la promotion et la pr servation des normes fondamen- tales du travail (l interdiction du travail des enfants, du travail forc et de la discrimination, la libert d associa- tion, le droit la n gociation collective) dans le monde entier, mais galement l extension syst matique de ces normes. commencer par le droit la s curit et la san- t au travail, la limitation de la dur e du travail et le droit un salaire minimum d cent, titre d amorce d un socle universel de la protection du travail, qui soit contraignant pour tous les pays et d application pour tous les travail- leurs et travailleuses, peu importe leur statut ou la forme de leur travail; e. une nouvelle convention de l OIT sur le travail d cent dans les cha nes internationales d approvisionnement (voir #. Cela doit favoriser la promotion et le respect des ac - cords internationaux entre interlocuteurs sociaux, y com- pris des accords-cadres avec des multinationales, avec un renforcement du r le de l OIT ce sujet; f. une campagne de formation et de sensibilisation de l OIT pour les travailleurs et travailleuses, les employeurs et les autorit s publiques sur l importance des normes fonda- mentales du travail dans le dialogue social international. Pour les jeunes, une campagne de formation et de sensi- bilisation devrait aussi tre mise en place; g. la mise en avant des r alisations et de l importance de l OIT et, au moyen de projets internationaux, le renforce- ment de la position des travailleurs et des travailleuses au niveau mondial pour garantir le respect des normes de l OIT dans la pratique; h. l OIT doit disposer d un droit consultatif en ce qui concerne les embargos sur les produits et le commerce aupr s des instances des pays qui ne respectent pas les normes fon- damentales du travail. #Les ODD vers des droits, des r gles et des r sultats La CSC adh re aux Objectifs de d veloppement durable (ODD) des Nations unies pour 2030 comme r f rence du travail syn- dical pour la prochaine d cennie (voir aussi #. Elle traduit les objectifs internationaux qui correspondent nos missions fondamentales en objectifs sp cifiques pour notre action aux diff rents niveaux politiques, dans les secteurs, dans les entreprises et l interprofessionnel, en y associant des leviers concrets pour les r aliser. Cela n cessite un instrument fort sur le terrain pour permettre aux militants de s y atteler. Nous luttons pour que les dispositions contenues dans les ODD soient traduites tous les niveaux sous la forme d ob- jectifs contraignants, notamment par:a. une triple approche: les Objectifs de d veloppement durable 2030 doivent tre traduits tous les niveaux et court terme sous la forme de droits contraignants, de r gles appliqu es et de r sultats chiffr s; b. sur cette base aussi, des objectifs interm diaires fixer pour Rien n est moins contraignant pour les res- ponsables politiques que les objectifs dont la r alisation incombe seulement un prochain gouvernement; c. l laboration r guli re, en collaboration avec d autres or - ganisations de la soci t civile et du monde acad mique, d un rapport alternatif opposer au rapport officiel de la Belgique sur les Objectifs de d veloppement durable; d. l exigence de contr les et de suivi effectifs des pouvoirs publics concernant des initiatives en mati re de d velop- pement durable, en incluant les moyens n cessaires; e. l laboration, avec les partenaires de la soci t civile, d un plan ambitieux qui d passe les domaines politiques et les secteurs, repose sur une vision long terme et porte sur plus d une l gislature; f. le biais de la nouvelle g n ration qui doit tre amen e devenir le moteur de la transition n cessaire pour la r ali- sation des ODD; g. avec la CES, veiller ce que la nouvelle strat gie euro- p enne moyen terme (Europe s inscrive totalement dans le cadre des Objectifs de d veloppement durable; h. le renforcement de la collaboration dans le cadre de bewe- ging.net et du Moc, et en particulier WSM (We Social Mo- vements), et avec nos alli s nationaux et internationaux, syndicats et ONG, afin de r aliser l agenda des Nations unies pour 2030; i. un plan pour les cha nes d approvisionnement pour toutes les entreprises, institutions, organisations et administra- tions, dans lequel une partie obligatoire des march s pu- blics est attribu e des entreprises d conomie sociale; j. l instauration d une obligation pour toutes les entreprises, institutions, organisations et administrations, d tablir leur propre plan de durabilit pour 2030, avec des enga- gements de r sultats, des objectifs interm diaires et des rapports annuels d avancement, tant en interne ( l gard de leurs travailleurs et travailleuses, des membres ) que vis- -vis du public. 3435 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202035 LES R SOLUTIONS D ACTIVIT S AUDE VANLATHEM36 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020Les activit s de la CSC au cours des quatre derni res ann es ont t voqu es dans une vid o. La secr taire g n rale, Ma - rie-H l ne Ska, a compl t le reportage oralement. Elle a pas - s en revue les principales actions, les initiatives organis es par la CSC et les succ s obtenus depuis le dernier congr s. Vous pouvez tre fiers! Fiers de ce que nous avons r alis ces quatre derni res ann es. La vid o que nous venons de regar - der montre une toute petite partie de ce qui nous a mobilis au cours de la p riode qui nous s pare de notre congr s de Pendant ce temps, des v nements plus invraisemblables les uns que les autres se produisent, v nements que nous aurions qualifi s il y a encore quelques ann es de science-fiction. Ainsi, le monde d aujourd hui est un monde dans lequel: le pr sident des tats- Unis d Am rique se pro - pose de racheter le Groen - land au Danemark comme si le Groenland tait une entreprise! Ce m me pr sident ne comprend par ailleurs pas que la Premi re ministre danoise lui refuse ce joujou. l ancien pr sident Lula est incarc r , tout cela pour l em - p cher d tre candidat une lection. le pr sident du Br sil, poumon vert de notre plan te, ac - cuse les ONG de mettre le feu l Amazonie. en croire certains magazines conomiques, l objectif des entreprises ne doit plus tre de produire des biens utiles mais de devenir des gazelles, entendez d arriver un chiffre d affaires d un milliard d euros. Mais le monde d aujourd hui est aussi un monde qui voit un million six cent milles Hongkongais se mobiliser, paraplu ies ouverts, pour exiger que la d mocratie soit respect e. Le monde d aujourd hui est un monde dans lequel des mil - liers, des dizaines de milliers d hommes, de femmes et d en - fants quittent leur pays en qu te d une vie meilleure, d une vie digne souvent au p ril de leur vie et souvent dans l indiff - rence g n rale. C est une jeune femme, Carola Rackete, capi - taine de navire qui force l entr e du port de Lampedusa pour y d barquer 42 naufrag s, et ce, au c ur de l Europe. Le monde d aujourd hui est aussi un monde qui voit une jeune femme sacr e championne du monde d heptathlon. Elle se pr nomme Nafissatou. Elle est n e d une maman belge et d un papa s n galais. Elle n a pas l ambition de devenir riche, mais elle r alise jour apr s jour son r ve et nous suivons avec d lice ses aventures. C est le monde o , dans un petit pays au c ur de l Eu - rope, des jeunes, emmen s par des femmes d exception, se sont lanc s dans un mara - thon contre les d r glements climatiques en menant des actions r pondant au doux nom de gr ves et o le pr - sident Barack Obama se pr te au jeu des selfies avec Greta Thunberg. Dans une soci t travers e par des failles id ologiques im - portantes o m me la question du maintien de la d mocratie comme syst me politique pertinent est pos e. CONTINUER LUTTER AVEC DES R SULTATS Dans ce monde qui semble perdre le nord, il nous importe, nous, militantes et militants de la CSC de ressortir notre bous - sole, de garder des rep res, de prendre le temps de revenir nos quations de base. Notre boussole s ordonne autour de nos valeurs: justice so - ciale, mancipation, solidarit , ouverture aux autres. Au cours de ces derni res ann es, nous avons d nonc , r - sist , chaque fois que ces valeurs taient mises en question. Nous n avons pas toujours r ussi faire changer les gouver -INTRODUCTION AU D BAT SUR LE RAPPORT D ACTIVIT S PAR MARIE-H L NE SKA, SECR TAIRE G N RALE DE LA CSC Notre boussole s ordonne autour de nos valeurs: justice sociale, mancipation, solidarit , ouverture aux autres. Marie-H l ne Ska, secr taire g n rale de la CSC 3637 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020nements de cap, c est vrai. Mais nous avons lutt , sans rel che et avons obtenu des r sultats. Face aux employeurs qui refusaient d augmenter les sa - laires, nous avons exig du respect pour les efforts des tra - vailleurs, qu ils prennent en compte la r alit parfois dure du travail. Nous avons obtenu un AIP et de nombreux autres accords interprofessionnels, sectoriels et d entreprises. Il nous faudra poursuivre ce combat. Car nous refusons que les employeurs se cachent derri re une loi qui bloque les salaires. Nous disons non un carcan salarial, oui une n gociation plus libre des salaires! Face au gouvernement qui a d cid que certaines personnes pouvaient tre exclues de toute solidarit , nous avons exig des solutions humaines. Avec pour r sultat un statut pour les MMPP. Face au dumping social qui met en concurrence les tra - vailleurs, nous avons exig que soit respect e l galit des travailleuses et travailleurs actifs sur un m me chantier. La r vision de la directive d tachement et le paquet mobi - lit constituent une premi re victoire des travailleurs dans ce long combat. Ces victoires et bien d autres encore, nous les avons obtenues gr ce la mobilisation de chacune et chacun d entre vous. Dans les entreprises vous avez interpell vos coll gues. Sur les march s, vous avez sensibilis les citoyens. Lors des ma - nifestations et gr ves, vous tiez pr sents. Ces victoires nous font chaud au c ur. Merci vous toutes et tous! DES ALTERNATIVES POUR DEMAIN Dans le m me temps, nous avons commenc penser le futur et dessiner des alternatives pour demain. Nous avons tra - vaill rendre l avenir d sirable, dessiner des possibles. C est ainsi que nous avons commenc travailler sur une nouvelle branche de la s curit sociale pour les jeunes de 18 25 ans, leur permettant de sortir de la pr carit , des petits boulots, bref leur permettant de trouver leur chemin dans la vie. Gen ve, nous avons repens l avenir du travail lors du centenaire de l Organisation internationale du travail. Nous avons galement contribu au vote d une convention inter -nationale contre les violences faites aux femmes sur leur lieu de travail. Lors d une large campagne de sensibilisation et d action autour des pensions et des fins de carri re, nous avons construit nos alternatives: droit un all gement de la car - ri re d s 55 ans, possibilit de lever le pied progressivement partir de 60 ans, rel vement des montants de pensions. Ces alternatives, nous les construisons chaque jour. Nous les travaillons ensemble notamment lors des journ es de forma - tion syndicales. Plus de 000 militantes et militants b n - ficient chaque ann e de celles-ci. Mais aussi ici, au congr s. DES QUESTIONS PERTINENTES Partant des r alit s de travail d aujourd hui, nous interro - geons lors de ce congr s avec lucidit : le mod le de d veloppement conomique qui est celui que nous connaissons depuis la fin de la seconde guerre. Ce n est pas une mince affaire! Nous redisons que non, m me dans un monde du travail qui se transforme radicalement, les travailleurs et les travail - leuses ne sont pas des robots. Nous entendons non pas r fl chir la transition cologique (nous l avons fait en , mais bien en tre un des mo - teurs car notre valeur se mesurera aussi l aune de notre apport l avenir des g n rations futures. Reprendre notre boussole, c est se (re)dire que notre soci t est bien plus qu une addition d individus isol s. Ensemble, nous sommes forts. Ensemble, nous gagnons: report de la pension points, n gociations de meilleures conditions de travail (ex: convention internationale contre les violences faites aux femmes), application du droit du travail au person - nel de Ryanair. Et la CSC y est pour beaucoup. LE FUTUR DE LA CSC Penser le futur, c est galement penser le futur de la CSC comme organisation syndicale. Nous avons d j s rieuse - ment diversifi les canaux qui permettent tous les affili s et militants d entrer en contact avec nous. Au cours des quatre ann es venir, nous allons intensifier le travail ce niveau. 3738 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020Dans le m me temps, il nous faut aussi, c est assez logique pour une organisation syndicale qui s est progressivement construite ces 130 derni res ann es, oser remettre sur le m tier nos modes de fonctionnement, nous adapter vos attentes, celles des militantes, des militants, des affili s toujours plus divers. Cet exercice a d but . Il ne peut nous d tourner des combats syndicaux mener, mais il est essentiel pour nous rendre plus forts demain. Nous faisons le choix d une transformation, de nous transfor - mer pour nos publics, de plus en plus divers. Nous faisons le choix de nous transformer, ensemble, avec nos quipes. Ce choix est fond sur notre capacit collective tre pr sents et actifs l o se trouvent nos affili s et militants d aujourd hui et de demain. Nous voulons tre une organisation syndicale qui repr sente l ensemble du monde du travail. Une organisation ouverte sur son environnement, une organisation ancr e dans les r alit s de terrain v cues par les travailleuses et les travailleurs. Une organisation pour tous les travailleurs, pour chacun et cha - cune d entre eux.Parce que le monde du travail se transforme radicalement, nous resterons une organisation syndicale forte et pertinente seulement si nous anticipons l avenir, condition d investir sans cesse de nouveaux terrains syndicaux comme nous ve - nons de le faire en lan ant l exp rience United Freelancers, initiative visant affilier et repr senter les travailleuses et travailleurs de plateforme, les ind pendants d pendants. CONTINUER D FENDRE NOS CONVICTIONS Sans vous, sans votre d termination, sans votre engagement, sans votre militance, nous n aurions pu r aliser ce que nous avons r alis ces derni res ann es. Sans vous, nous n aurions pas, une fois de plus gagn les lections sociales. Lorsque l on se bat pour ses convictions, en se disant que les id es que l on porte sont justes, on peut beaucoup. Nous pouvons et devons jouer un r le d terminant pour sortir du climat de d fiance actuel, du repli sur soi, du chacun pour soi, de la peur de l autre. Notre travail, les rep res que nous tra ons sont autant de pieux plant s sur le chemin de la confiance en l avenir. Nous avons besoin de (re)prendre confiance en nous, de rendre confiance dans l id e que le chacun pour soi n est pas une option. Produire de l action collective comme nous l avons fait pen - dant cinq ans, c est aussi imposer notre vision de la soci t , notre r cit celles et ceux qui nous disent qu il n y a pas d al - ternatives un march sauvage. tous ceux-l , nous comp - tons bien infliger un d menti cinglant. Nous l avons fait, et c est ensemble que nous allons continuer le faire. Nous resterons une organisation syndicale forte et pertinente seulement si nous anticipons l avenir. Marie-H l ne Ska, secr taire g n rale de la CSC Le chacun pour soi n est pas une option. Marie-H l ne Ska, secr taire g n rale de la CSC 38 AUDE VANLATHEM Marie-H l ne Ska.39 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202039R SOLUTION D ACTIVIT S: SOUTIEN DE LA CNE La CNE a tenu soutenir l ensemble des r solutions d acti- vit s par une intervention (en n erlandais!) de S bastien Robeet, secr taire g n ral adjoint. Dans les moments compliqu s que vit la CSC, une r solu- tion d activit n est pas simplement un programme d activit s pour les ann es venir, elle est une boussole pour orienter notre action. Nous sommes, comme CSC, une seule et m me grande maison. La r solution d activit a pour but de donner une ligne de conduite tous les habitants de cette maison, quelle que soit la pi ce dans laquelle ils vivent. Elle permet d ouvrir des portes entre les pi ces, de d couvrir la vie dans chaque pi ce et peut- tre de changer de chambre si cela pla t chacun. Et peut- tre d envisager des r novations, pour per - mettre chaque habitant d y trouver sa place, aujourd hui et demain. Pour que chacun se sente bien, la fa ade sud de la maison doit faire l objet d une attention particuli re dans cette possible r novation. Apr s les images immobili res, je me permets de passer la m taphore qui m a t enseign e lorsque je suis arriv la CSC. La CSC est une organisation qui vit sur deux jambes, une professionnelle et une interprofessionnelle. Lorsque je vois mes enfants apprendre marcher, je me rends compte que l quilibre entre les deux jambes n est pas facile atteindre. Il faut apprendre se coordonner, il faut apprendre faire confiance chacune des jambes. Et lorsque cette confiance est atteinte, la marche devient facile et l enfant peut avancer dans le monde, grandir et devenir plus fort. La r solution d activit est un bel quilibre entre les deux jambes de la CSC. Gr ce cette r solution, nous connaissons les quilibres trouver et nous saurons trouver les nouvelles mani res de marcher dans ce monde en transition. L union fait la force. Leve de ACV, Vive la CSC. Les r solutions d activit s sont adopt es l unanimit (100%).R SOLUTIONS D ACTIVIT S ET D ACTUALIT : INTERVENTIONS R SOLUTIONS D ACTUALIT PROPOSITION D AMENDEMENT SUR LES PENSIONS Un militant a demand d ajouter un point la r solution sur les pensions: Parce que nos pensions sont parmi les plus basses d Europe, nous demandons de relever le montant et de majorer le seuil de pension minimum 500 euros net apr s 40 ans de carri re . En r ponse la proposition pr c dente, plusieurs interventions demandent de prendre le temps de la r flexion. Finalement, la proposition d amendement est rejet e 56,25% des voix (259 pour, 333 contre et 44 abstentions). Mais le congr s donne le mandat suivant au conseil g n ral: La CSC veut une augmentation substantielle du montant des pensions et donne mandat au conseil g n ral de traduire ce point concr tement dans les plus brefs d lais . AUDE VANLATHEM Au nom de la CNE, S bastien Robeet a appuy les r solutions d activit s.40 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 JAN AGTEN - WOLF&WOLFNous l avons fait et nous pouvons en tre fiers! Quatre vic - toires importantes obtenues ces derni res ann es ont t expliqu es par des militants de la CSC. Lidl: la direction r pond aux attentes des gr vistes Wouter Parmentier d ACV Puls et Veerle Seghers, d l gu e syndicale chez Lidl, sont venus expliquer le r sultat de leur lutte pour am liorer les conditions de travail chez Lidl. En avril 2018, un important mouvement de gr ve a touch les magasins de la chaine dans tout le pays. Il r sultait d un ras- le-bol du personnel qui la direction en demandait toujours plus. Apr s plusieurs jours de fermeture de bon nombre de magasins, syndicats et direction sont parvenus un accord. Il pr voyait 42 heures de travail suppl mentaires par semaine. Mais aussi de prendre le temps de n gocier une nouvelle CCT traitant de plusieurs aspects: recours des quipes de nettoyage ext rieure, largissement de l quipe volante qui remplace les travailleurs absents, augmentation des contrats horaires pour les travailleurs temps partiels, cadre sur le travail tudiant, sur la flexibilit et le bien- tre des travailleurs. QUATRE T MOINS DE VICTOIRES SYNDICALES Perc es chez Ryanair Yves Lambot, permanent CNE, est revenu sur l importante victoire obtenue chez Ryanair apr s des mois de gr ves en 2018, qui pour la premi re fois, ont touch six pays en Europe gr ce aux r seaux sociaux qui ont permis de les coordonner. Initi es par le personnel de cabine, elles se sont tendues aux pilotes, bloquant des dizaines de mil - liers de voyageurs. Les travailleurs belges ont r sist la pression au chantage exerc e par la direction qui mena ait de quitter les a roports de Charleroi et Zaventem. l issue des actions, une CCT a t sign e entre les syndicats et la direction. Elle pr voyait que le droit belge serait appliqu d s le 31 janvier 2019 pour les travailleurs. Cette CCT consti - tuait une base pour n gocier les conditions de travail des pilotes et des personnels de cabine. Une premi re en Bel - gique! Une hausse salariale de 25 % pour le personnel le moins bien pay a aussi t obtenue. La compagnie irlan - daise respecte enfin les salaires minimums du secteur de l aviation. Aujourd hui, une petite amorce de d l gation syndicale se met en place et des lections sociales se pro - filent chez Ryanair. C est un travail de fourmi qui dure depuis huit ans , rel ve Yves. AUDE VANLATHEM AUDE VANLATHEM Yves Lambot a pr sent les victoires conquises chez Ryanair. Wouter Parmentier et Veerle Seghers ont t moign des avanc es obtenues chez Lidl.41 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020Nouveau statut pour les demandeurs d emploi vuln rables Karen Van Gaever a une forme d autisme qui lui a t dia - gnostiqu e quand elle avait 20 ans. En 2016, elle re oit un courrier de l Onem lui annon ant qu elle allait perdre ses allocations d insertion car elle ne recherche pas d emploi. Elle fait partie de la cat gorie des demandeurs d emploi re - connus comme ayant des probl mes s rieux, aigus ou chro - niques de nature m dicale, mentale, psychique ou psychia - trique (MMPP). L acc s au march du travail leur est difficile, et pourtant, ils se retrouvent demandeurs d emploi avec le risque d exclusion du ch mage s ils ne font pas les d - marches n cessaires ou s ils ne trouvent pas un emploi. En 2017, les Travailleurs sans emploi de la CSC ont commenc mener des actions de sensibilisation aupr s du ministre de l Emploi, Kris Peeters. Ils ont finalement obtenu un sta - tut qui leur permet de rester prot g et d viter l exclusion des allocataires d insertion. Karen a t le visage d une cam - pagne men e aupr s du ministre qui a reconnu que la situa - tion tait anormale. Le nouveau statut a t introduit le 1er juillet 2019 et prendra effet partir du 1er janvier Mieux prot ger les travailleurs sans-papiers Arriv en Belgique en 2006, ayant travaill au Foyer ander - lechtois, Mounir Tahri, militant sans papiers de la CSC, a t arr t le 9 f vrier 2018 dans les locaux de l association cultu- relle Globe Aroma suite un contr le de papiers. Il a t d te- nu pendant quatre mois au centre 127 bis de Steenokkerzeel, menac d expulsion au Maroc. Pendant toute cette p riode, la CSC a men des actions qui ont abouti sa lib ration le 7 juin. Une issue c l br e dans la joie mais qui ne doit pas faire oublier le sort des travailleuses et des travailleurs sans papiers. Eva Jimenez, responsable du groupe des Travailleurs migrants et sans papiers de la CSC Bruxelles, rappelle qu ils sont au moins 000 en Belgique. Exploit s, ils et elles as- surent les t ches les plus d grad es sur le march du travail en Belgique: le plus souvent, les hommes dans la construc - tion et les femmes dans le care. Pour la CSC, les travailleurs sans-papiers doivent avoir des droits et tre prot g s. Elle demande notamment que la Belgique ratifie la convention 143 de l OIT sur la protection des travailleurs migrants et la convention 190 sur la violence et le harc lement au travail. AUDE VANLATHEM AUDE VANLATHEM Mounir Tahri et Eva Jimenez ont t moign de la pr carit des personnes sans papiers.Riky De Bi vre, permanente la CSC, et Karen Van Gaever sont intervenues sur le nouveau statut pour les demandeurs d emploi MMPP . 42 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202042( Nos valeurs, formul es selon nos propres mots et de mani re positive, d - terminent notre narratif. Nous le d clinons en plusieurs piliers: le respect de l engagement des personnes, des revenus juste, la qualit du travail et de la carri re, un syst me de s curit sociale solide et des services publics de qualit .Introduction D importants d fis internes se pr senteront nous dans les ann es venir. Dans cette introduction et dans les r solu- tions suivantes, nous nous basons sur les conclusions des chantiers et sur les missions de la CSC. Pour continuer nous renforcer et nous adapter aux attentes des membres et des militantes et militants, nous allons: a. veiller la solidarit entre toutes les organisations tout en respectant leur sp cificit et veiller la coordination entre les comit s r gionaux et communautaires tout en respec - tant leur autonomie; b. poursuivre nos efforts tant au niveau des recettes que des d penses afin de d fendre les int r ts de tous les membres; c. consacrer davantage d nergie occuper les nouveaux terrains syndicaux; d. poursuivre la formation et l accompagnement de notre personnel afin qu il continue tre comp tent, militant et motiv au service de nos militantes et militants, ainsi que de nos membres; e. d velopper, renouveler, rajeunir et diversifier notre base militante; f. am liorer encore notre action individuelle et collective en consid rant la r alisation d un meilleur statut pour les ouvriers, employ s et cadres comme une opportunit pour ce faire; g. optimiser et digitaliser notre service aux membres, tout en garantissant une grande accessibilit , y compris pour nos membres fragilis s sur le plan socio conomique ou culturel; h. veiller ce que nos militantes et militants, nos membres du personnel et nos dirigeants incarnent les valeurs de la CSC ainsi que les r alit s du monde du travail et de la soci t ; i. faire syst matiquement usage du narratif CSC ( dans chaque organisation. AUDE VANLATHEMLES R SOLUTIONS D ACT V T S APPROUV ES43 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202043D mocratie interne R solution 1 Nos organisations renforcent leur d - mocratie interne et leur repr sentati- vit travers: a. une am lioration de la pr sence et de la participation effective des militantes et militants dans nos ins- tances notamment via un change de bonnes pratiques et une plus forte repr sentation des jeunes; b. de nouvelles formes d information, de consultation, de communication bien encadr es pour les militantes et militants et pour les membres, no- tamment dans les milieux non struc - tur s syndicalement par des d l - gations. Compl mentairement, nous devons continuer exp rimenter de nouveaux modes de repr sentation dans nos instances. Action professionnelle R solution 2 Les secteurs priv s et publics s en- gagent analyser pour le prochain congr s ( comment organiser au mieux l action professionnelle partir des principes suivants: la feuille de route reste un document approuv qui sert de base la dis- cussion; les structures actuelles des organi- sations ne constituent pas un but en soi; il faut s efforcer de cr er des entit s professionnelles qui peuvent fonc - tionner de mani re suffisamment ef- ficace et durable en termes d chelle, tout en assurant une coh sion lo- gique des secteurs; la meilleure d fense possible des in- t r ts individuels et collectifs de nos membres est au c ur de nos pr oc - cupations. Cette analyse doit tre r alis e dans le cadre d un dialogue avec les mili- tantes et militants dans les centrales et secteurs concern s. Les membres du bureau national (conf d ration et f d - rations) seront associ s ce processus. Nous consacrons par ailleurs davan- tage d nergie : a. un accompagnement renforc de toutes les militantes et de tous les militants d entreprise et un meilleur d veloppement des facilit s syndi- cales; b. la r ussite des lections sociales 2020 en r alisant entre autres: une campagne de recrutement solide suivie d une campagne de vote dynamique avec une colla- boration entre centrales et f d - rations; une r duction du nombre d entre- prises sans candidats CSC; une augmentation de la propor - tion de femmes, de jeunes et de personnes d origine trang re parmi nos candidates et candi- dats afin de parvenir une image fid le de l entreprise/l institution; un engagement encore accro tre la qualit de nos candidates et de nos candidats en accordant une attention particuli re au fait que ces personnes partagent les valeurs de la CSC; c. une attention renforc e envers les travailleurs et travailleuses dans les PME et les entreprises/institutions dont l emploi est dispers , les ind - pendantes et ind pendants sans personnel, les int rimaires, les tra- vailleuses et travailleurs d tach s trangers, les travailleurs et travail- leuses de plateforme digitale, ainsi que celles et ceux qui sont occup s temps partiel ou dans des contrats pr caires; d. la construction de cha nes d appro- visionnement durables et de solida- rit internationale, en discutant du devoir de vigilance et en tablissant des plans de vigilance dans le cadre de la concertation sociale dans les entreprises; e. au renforcement des n gociations sectorielles de sorte que le plus grand nombre possible de travail- leuses et de travailleurs en Belgique puisse tre couvert par une CCT sec - torielle. En concertation avec les centrales pro- fessionnelles et avec le soutien des f d rations, nous d finissons des ob- jectifs et pr voyons un suivi et des rap- ports p riodiques au niveau des efforts et des r sultats. Action interprofessionnelle R solution 3 En collaboration avec les centrales professionnelles, nous voulons repr - senter, organiser et d fendre tous les travailleurs et toutes les travailleuses avec ou sans emploi, afin qu ils fassent entendre leur voix. Nous le faisons en nous appuyant notamment sur l du- cation permanente, la dynamique de groupes sp cifiques, le d veloppement d initiatives th matiques et l organi- sation d une action de proximit . Les militantes et militants sont au c ur de cette action collective. Dans ce cadre, nous voulons: a. l organisation d assembl es et d ini- tiatives syndicales qui rassemblent 44 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202044des militantes et militants d hori- zons divers. Ceci constitue gale- ment l occasion d tre l coute des travailleuses et travailleurs l o ils se trouvent; b. d velopper des actions d ducation permanente et de sensibilisation pour lutter contre les st r otypes, les pr jug s et les discriminations; c. mener un travail de collectivisation des plaintes qui d passent les sec - teurs et proposer des actions collec - tives sur cette base; d. rassembler les publics sp cifiques de travailleurs et travailleuses (avec ou sans emploi) afin de les informer et construire ensemble notre action collective. galit de genre et participation des femmes R solution 4 Depuis notre congr s de 2002, nous avons des objectifs ambitieux en termes d galit de genre qui portent partiel - lement leurs fruits, mais nous voulons aller plus loin et demandons aux organi - sations d tre actives dans les mati res suivantes: a. pour l ensemble de la CSC, tendre vers la participation paritaire entre femmes et hommes dans les instances interprofessionnelles. Pour les ins - tances professionnelles, tendre vers une repr sentation proportionnelle la r alit de l emploi (hommes/femmes) dans les secteur s; b. am lioration de la participation des femmes aux lections sociales de nous veillons ce que, lors de la constitution des listes de candi - dates et candidats, la repr sentation des femmes soit proportionnelle au nombre de travailleuses dans l en - treprise. Dans les entreprises o il y a encore des possibilit s de progr s, nous menons des actions cibl es; c. les hommes et les femmes doivent disposer des m mes chances de pou - voir exercer un mandat. Nous accor - dons une attention particuli re ce que les travailleuses et travailleurs temps partiel puissent effectivement exercer leur mandat. AUDE VANLATHEM45 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202045Au travers du plan d action galit , nous suivons annuellement dans les organi - sations et les instances les volutions au niveau de l galit de genres. Services aux membres et accessibilit R solution 5 Nous am liorons nos services aux membres en: a. mettant les membres au centre pour l application de nos accords qui pr - cisent ce que font les divers services ou organisations; b. optant pour une digitalisation de certains services en tenant compte de la fracture num rique tout en privil giant un r le central pour les militantes et militants et en main - tenant le contact humain avec nos membres. Nous accompagnons nos militantes et militants, ainsi que nos membres dans l utilisation des outils mis en place; c. veillant assurer une accessibilit renforc e pour nos membres dans toutes les organisations en offrant la possibilit de prendre des rendez- vous et en d finissant les canaux les plus pertinents au travers desquels ils peuvent entrer en contact avec nous; d. encourageant un engagement de longue dur e via la possibilit de b n ficier d avantages en phase avec notre travail syndical, nos valeurs et les besoins de nos membres. Dans cette perspective, la CSC accom - pagne chaque membre tout au long de sa carri re. Des avantages com - merciaux ou autres li s un contenu syndical constituent des instruments de recrutement utiles. Ils contribuent une affiliation de longue dur e;e. menant une valuation r guli re des services aux membres et en adaptant si n cessaire nos services en fonc - tion des besoins de nos membres. Recrutement et fid lisation R solution 6 Le recrutement et la fid lisation des membres est une priorit et est l affaire de tous et toutes. Elle doit faire partie de l ADN de notre organisation. Nous devons disposer d un pilotage national afin de travailler de mani re profession - nelle. Nous voulons la fois augmenter le nombre de membres recrut s, r duire le nombre de membres d missionnaires et augmenter notre base militante afin de renforcer notre mouvement syndical dans sa capacit d fendre les droits de tous et toutes. Nous allons: a. veiller ce que l affiliation soit simple et rapide et ce que les membres b - n ficient d s le d part d une bonne vision de nos services, mais aussi de la possibilit de s engager dans le mouvement syndical; b. rappeler les avantages d une affilia - tion et l importance d tre affili notre syndicat; c. donner notamment via internet une information claire sur le co t net de l affiliation en limitant de mani re drastique les diff rentes cat gories de cotisations et en informant de mani re transparente sur les primes syndicales; d. laborer des plans d action par orga - nisation, de mani re disposer, d ici fin 2020, des adresses mail, lieux de travail et num ros de GSM d au mini - mum 80% de nos membres; e. proc der rapidement une simpli - fication, une standardisation et une digitalisation des proc dures admi -nistratives pour nos membres tout en tenant compte de la fracture nu - m rique; f. d velopper une communication ci - bl e, accessible, s lective et proac - tive sur la l gislation, nos services et notre action syndicale; g. proc der des enqu tes de satisfac - tion r guli res aupr s des membres sur notre action et sur nos services et en assurer le suivi; h. d velopper des plans d action pour contacter personnellement et de mani re professionnelle tous les membres d missionnaires, afin de comprendre et r pertorier les m - contentements, les attentes mais aussi les satisfactions, et attirer l at - tention sur ce que la CSC peut signi - fier pour eux; i. soutenir les militantes et militants ainsi que les membres du personnel avec de la formation et les outils ad - quats dans le cadre du recrutement et de la fid lisation des membres; j. pr voir des actions de recrutement l attention de groupes cibles et sur des th mes propos desquels nous nous profilons clairement; k. promouvoir, travers ces diff - rentes actions, l implication de nos membres dans le mouvement syndi - cal en tant que militante ou militant afin de les rendre acteurs de notre soci t et renforcer notre mouve - ment syndical; l. valuer les proc dures existantes et relatives l affiliation de gr vistes lors de conflits sociaux. R solution 7 L affiliation des jeunes est une mission de toute la CSC. Nous favorisons l affi- liation et la militance des jeunes en col- laboration avec les Jeunes CSC et Jong 46 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202046 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020ACV et l action des jeunes des centrales professionnelles. Nous allons: a. donner de la place aux jeunes dans les instances d cisionnelles de nos organisations; b. organiser le service et la commu- nication de mani re encore plus professionnelle l gard des l ves de secondaire et des tudiantes et tudiants (jobistes), des jeunes en fin de scolarit et des jeunes qui d butent sur le march du travail; c. tablir des plans d action dans chaque organisation pour revenir notre repr sentativit de jeunes membres de 2012; d. promouvoir Enter et Go, l affiliation graduelle pour les jeunes, et sensibi- liser, impliquer l ensemble de notre personnel et de nos militants dans cette d marche; e. d finir des plans d action avec de jeunes militantes et militants afin d assurer l accueil syndical et l ac -compagnement des nouveaux tra- vailleurs et travailleuses dans l en- treprise, des tudiantes et tudiants jobistes, des stagiaires en alternance emploi-formation et des int ri- maires, par le biais d une approche syst matique et continue; f. int grer dans notre communication et dans nos positionnements syn- dicaux des revendications qui r pondent aux besoins des jeunes, sur la base de leurs propositions, et les mettre en dialogue avec d autres organisations de jeunesse. Nous valuons ceci annuellement. R solution 8 La CSC veut galement veiller l affilia- tion, la fid lisation et la militance des personnes (pr )-pensionn es: a. en contactant les membres sur le point de partir la (pr )-pension; b. en visibilisant la concertation et nos actions pour ces groupes; c. en d veloppant la collaboration avec d autres organisations de seniors; d. en d veloppant des outils de propa- gande destination de chaque orga- nisation afin de syst matiser en en- treprises et en r gion une approche efficace de ce public. Information et communication R solution 9 Nous am liorons la visibilit et la coh - rence de l image de la CSC au travers des mesures suivantes: a. l application de notre narratif dans toutes nos communications et la diffusion d une image plus positive du syndicat par le biais de divers moyens de communication, m tho- dologies et moyens; b. la poursuite de l harmonisation de nos communications internes et AUDE VANLATHEM Lors d interm des musicaux, Max Vandervorst a fait voyager les congressistes dans le monde de la pataphonie (voir p. .Lors d interm des musicaux, Max Vandervorst a fait voyager les congressistes dans le monde de la pataphonie.47 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202047externes (correspondances, publi- cations et communication digitale) avec le style maison et avec les bonnes pratiques de la communi- cation en gardant l esprit que les membres doivent y occuper une place centrale. Notre message doit tre vulgaris , clair, cibl et en ad - quation avec le public vis ; c. la prise en compte de l volution rapide vers le digital: le num rique sera utilis d s que c est pertinent en tenant compte de la fracture num rique avec une approche via diff rents m dias dans laquelle un contenu est d velopp en parall le pour plusieurs supports. Les sup- ports papier et digitaux jouent des r les compl mentaires; d. la poursuite de notre travail syndi- cal tant sur la communication crite que sur le contact personnel. Pour certains groupes cibles et certaines communications, le contact person- nel ne peut tre remplac par l offre num rique; e. la poursuite du d veloppement de l intranet et du nouveau site internet de la CSC; f. une pr sence (inter)active sur les m dias sociaux gr ce une strat gie claire; g. la fixation des prochaines tapes en mati re de marketing et de gestion de la relation avec nos membres (CRM, Customer relationship mana- gement). Formation et accompagnement des militantes et militants R solution 10 La formation et l accompagnement des militantes et militants sont pilot s de fa on centralis e au niveau national, au niveau des commissions de formation r gionales et au niveau des r unions des formateurs. Nous renfor ons la for - mation et l accompagnement des mili - tantes et militants tant au niveau tech - nique qu au niveau sociopolitique, en: a. offrant aux militantes et militants, temps, un acc s l action associa- tive ou la formation leur permet - tant de d velopper une compr hen- sion critique du monde dans lequel ils vivent, mais galement de d ve- lopper leurs capacit s d expression et d action; b. construisant des parcours de for - mation de base pour les militantes et militants r cents et de formation continue adapt e pour les plus ex - p riment s avec la possibilit , de mani re s lective pour ces derniers, d un enseignement qualifiant du niveau de l enseignement sup rieur sans oublier les besoins sp cifiques des publics plus qualifi s; c. accordant une attention particuli re aux militantes et militants ayant un faible niveau d instruction, celles et ceux qui ne sont pas de langue maternelle n erlandaise, fran aise ou allemande et celles et ceux qui ont des difficult s avec la digitalisa- tion, en offrant galement des cours de langue syndicaux pour celles et ceux qui en ont besoin; d. articulant, c t de l offre standard de formation autour de l exercice des mandats, la formation aux en- jeux d actualit et de prospective en accordant une attention particuli re la transition juste et aux dangers qui p sent sur la d mocratie; e. ciblant la concertation, l action col- lective et l ducation permanente comme moyens d actions impor - tants; f. int grant les applications TIC dans la formation et l apprentissage de l uti- lisation des technologies de l infor - mation dans le travail syndical dans un souci d alphab tisation num - rique et de d veloppement du sens critique; g. examinant comment nous pouvons, via la formation, atteindre et orga - niser les travailleurs et travailleuses sans mandat syndical et maintenir le contact avec eux. Une attention particuli re est accord e au renfor - cement sociopolitique, notamment des groupes de travailleurs et tra - vailleuses les plus fragilis s. Une information au sujet de notre offre de formation doit tre organis e vers le plus grand nombre de nos membres; h. donnant une formation l utilisa- tion des m dias, en particulier les AUDE VANLATHEM48 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 48m dias sociaux; i. accordant une attention particuli re aux militants et militantes travaillant dans des entreprises/institutions dans lesquelles l emploi est disper - s ; j. coop rant davantage et en conve- nant de r gles claires entre les f d - rations interprofessionnelles et les centrales, notamment via les com- missions de formation et les r u- nions de formateurs. Accompagnement du personnel R solution 11 Nous souhaitons que notre personnel reste comp tent, militant et motiv dans son travail, dans son quipe, dans son organisation et au sein de la CSC dans son ensemble. Pour ce faire, nous poursuivons la professionnalisation de la politique du personnel de la CSC en prenant des initiatives dans diff rents domaines de la politique du personnel, via des formes existantes et nouvelles d apprentissage et de d veloppement, une politique active concernant le bien- tre et les agressions et la poursuite de l laboration de la politique interne de la carri re.D veloppement durable la CSC R solution 12 Chaque organisation de la CSC s engage laborer un plan de durabilit pour sa propre action et le budg tiser. Ce plan vise un fonctionnement durable et cli- matiquement neutre d ici 2050 (Accord de Paris) en: a. r alisant partir de 2020 un premier tat des lieux au sein de chaque or - ganisation; b. tablissant des objectifs de progr s ann e apr s ann e avec valuation; c. pr tant une attention toute parti- culi re une politique d achat qui garantisse les droits des travailleurs et travailleuses tout au long du pro- cessus de production. Ce plan de durabilit doit pr voir un calendrier reprenant des mesures d organisation interne dans le domaine des plans d action syndicaux pour la concertation sociale tous les niveaux et ce, en fixant des orientations coh - rentes partant d une vision et d une strat gie CSC globales.Comit s r gionaux et communautaires R solution 13 Nous organisons une bonne interaction et concertation avec les comit s r gio- naux et communautaires en: a. s informant r guli rement et mu- tuellement des positions et orienta- tions prises; b. se coordonnant, dans la mesure du possible, l o ceci est pertinent; c. collaborant pour se renforcer mu- tuellement dans l int r t des droits des travailleuses et travailleurs et/ ou de la protection des travailleuses et travailleurs; d. pr voyant cet effet une plateforme de concertation ad quate afin de r aliser cet objectif. Conclusion Le congr s charge le conseil g n ral et le bureau national de traduire ces r solutions, ainsi que les lignes de force de notre congr s de transition, dans notre action et dans nos inter - ventions. AUDE VANLATHEM49 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202049 AUDE VANLATHEMLES R SOLUTIONS D ACTUALIT 50 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER Respect et transition juste Conform ment son m morandum, la CSC entend que la nouvelle politique du gouvernement f d ral respecte chaque personne et chaque travailleuse ou tra - vailleur. Cette politique doit galement s engager fermement en faveur du d ve - loppement durable, y compris au travers d initiatives n cessaires en mati re de climat et d environnement. cet effet, la CSC poursuit son engage - ment dans la vaste action men e contre le r chauffement climatique et pour la protection de l environnement. l instar de la CES et de la CSI, la CSC veut que la transition soit juste et que l on pr vienne et compense les r percussions n gatives pour les travailleuses et travailleurs. La CSC voit dans les activistes climatiques des alli s pour lutter en faveur d une transition qui est n cessaire. Droit la n gociation La CSC entend sortir du carcan actuel dans lequel est enferm e la politique des salaires. Respecter les travailleuses et travailleurs signifie renforcer leur droit la n gociation collective. La CSC exige la plus grande libert salariale possible. La loi relative la norme salariale de 2017 doit tre supprim e, ainsi que les l ments contraignants de la loi de Cette loi fait reposer la responsabilit de la comp titivit sur les seuls travail - leuses et travailleurs et est contraire au droit fondamental la libert de n go - ciation. Cette loi repose sur une com - paraison erron e du co t salarial. Par ailleurs, la CSC ne permettra sous aucun pr texte que l on touche nouveau l indexation automatique des salaires ou aux bar mes et aux salaires minimums. Cette mati re rel ve en effet de la libert de n gociation. Une Europe sociale et durable La CSC veut une Europe sociale qui pro - t ge les travailleuses et travailleurs et s engage pleinement en faveur du d ve - loppement durable. Pour atteindre ces objectifs, la CSC renvoie son m mo - randum europ en et aux orientations du congr s de la CES. La CSC demande que l Europe s attelle en priorit aux aspects suivants: a. en cho notamment la faillite de Thomas Cook, qu une r glementation fiscale contraignante emp che que les entreprises soient vid es financi re - ment travers des constructions euro - p ennes ou internationales d entre - prises; b. qu elle transpose le pilier social euro - p en en des droits et r gles contrai - gnants. La Commission doit renforcer le dialogue social europ en, trans - poser les accords conclus et modifier la r gle qui consiste supprimer une l gislation lorsque le l gislateur euro - p en en adopte une nouvelle; c. qu elle joue un r le de pr curseur dans la r alisation des Objectifs de d ve - loppement durable des Nations unies pour 2030, avec des objectifs interm - diaires pour 2024, et qu elle s attache r duire l empreinte environnementale europ enne conform ment aux ob - jectifs du Groupe d experts intergou - vernemental sur l volution du climat (Giec) ; d. qu elle cesse de se focaliser unilat ra - lement sur la r duction des d penses et qu elle sorte les investissements publics, sociaux et durables du calcul des soldes budg taires des gouverne - ments; e. qu elle agisse contre les probl mes persistants de dumping social. Pour les travailleuses et travailleurs d ta - ch s, la r vision du r glement n 883/2004 ( constitue une avanc e importante dans la perception des co - tisations sociales. Cette r vision doit tre finalis e dans les meilleurs d lais. ( R glement (CE) n 883/2004 du Parlement eu- rop en et du Conseil du 29 avril 2004 portant sur la coordination des syst mes de s curit sociale. AUDE VANLATHEM51 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202051Ce n est pas suffisant toutefois: comme c est le cas pour les salaires, les cotisa - tions sociales per ues ne peuvent tre inf rieures celles des travailleuses et travailleurs belges. La possibilit de percevoir la s curit sociale dans le pays du travail sera examin e; f. qu elle assure dans chaque tat membre un salaire minimum qui vaut pour toutes les travailleuses et travail - leurs; g. que pour les accords commerciaux du type TTIP et Ceta, l autonomie l gisla - tive des parlements soit pr serv e. Le Brexit est un spectacle hallucinant. La CES et la CSC conjuguent leurs efforts pour une issue qui pr serve et qui cause le moins de dommage possible l emploi et aux droits des travailleurs et travailleuses, y compris des travailleuses et travail - leurs britanniques. Les pouvoirs publics doivent galement tout mettre en uvre pour contrer autant que possible le pr ju - dice ventuel que le Brexit pourrait occa - sionner au march du travail belge. Populisme, racisme et d mocratie La CSC veut une soci t inclusive. Les suc - c s des partis d extr me droite, et leur d magogie, mettent en p ril les droits humains et les m canismes de solida - rit qui caract risent le monde du travail. Elle rejette la polarisation contre les plus faibles, contre les personnes d origine trang re, contre les ayants droit aux prestations sociales. Elle rejette la discrimination sous toutes ses formes. Changer le r cit sur la migra - tion, lutter contre le racisme est plus que jamais d actualit pour la CSC qui contri - buera faire barrage contre cet empoi - sonnement de la soci t . La CSC y sera aussi particuli rement attentive lors du recrutement des candidats aux lections sociales. La peur n est jamais une bonne conseill re. La diversit constitue un enrichissement et non une menace comme le laissent croire les id es racistes et d magogiques. Pour la CSC, la d mocratie est plus qu un processus de vote quelques ann es d intervalle. La d mocratie exige un dia - logue permanent avec la soci t , avec la soci t civile organis e en particulier. La CSC n accepte pas que la d mocra - tie soit min e par des attaques contre une soci t civile critique son gard. C est une strat gie qui s attaque aussi aux scientifiques critiques, aux juges et aux m dias. La CSC rappelle que le r le des partenaires sociaux et, en particu - lier, du mouvement syndical (syndicats et mutuelles) dans la gestion et la mise en uvre de la s curit sociale est indis - pensable. Renforcement de la s curit sociale La CSC veut que la s curit sociale et ses missions soient renforc es plut t que d - mantel es. C est pourquoi elle demande son refinancement de toute urgence. Cet objectif sous-tend une politique forte pour des emplois de meilleure qualit avec des bons salaires et des cotisations normales. Elle requiert galement de mettre un terme aux fuites de cotisa - tions li es la fraude aux salaires et aux cotisations et la prolif ration des sta - tuts professionnels et des avantages sala - riaux sans cotisations ni imp ts normaux. Ces mesures devraient permettre d am - liorer les revenus de remplacement et les soins de sant plut t que de les d man - teler en r duisant les allocations et les remboursements ou en durcissant les conditions d acc s. Plus particuli rement, la CSC: a. s oppose toute proposition qui limite dans le temps ou r duit davantage les allocations de ch mage; b. n accepte pas que l on porte atteinte au m canisme l gal de liaison au bien- tre ni l indexation des allocations; c. souhaite que le d mant lement des r gimes de fin de carri re et le rel - vement de l ge de la pension laissent la place une politique de carri re part enti re qui investisse dans un travail de qualit chaque ge, du d but la fin de la carri re. Nous vou - lons de bons salaires et des contrats dur e ind termin e d s le d but de la carri re, des possibilit s de souffler durant la carri re et des perspectives d une fin de carri re digne et en bonne sant . Cela se traduit par: emplois de fin de carri re partir de 55 ans, RCC m dical partir de 58 ans, autres RCC ou pension anticip e partir de 60 ans, pension l gale partir de 65 ans; d. veut une augmentation substantielle du montant des pensions et donne mandat au conseil g n ral pour tra - duire ce point concr tement dans les plus brefs d lais. En effet, les pensions belges font partie des plus basses en Europe et ne suffisent plus garantir une retraite paisible; e. souhaite renforcer la qualit et le volume de l emploi dans les secteurs relevant de la protection sociale. Pr servation des services collectifs La CSC constate que l obsession r a - liser des conomies ne se focalise pas 52 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202052plut t que la freiner. Il faut plus parti - culi rement un engagement r solu largir l assiette imposable au niveau europ en et que les nombreuses multinationales qui ne contribuent pas ou quasi pas au financement des fonctions collectives soient d sormais assujetties l imp t; c. que la r forme ventuelle de l imp t des personnes physiques renforce le caract re redistributif: avec un r ta - blissement de la progressivit (r ins - tauration des tranches sup rieures) sans favoriser les revenus du patri - moine comparativement aux revenus du travail (un euro est un euro). Solidarit syndicale internationale Les graves violations des droits syndi - caux dans plusieurs pays pr occupent vivement la CSC. Il est totalement inacceptable que des travailleuses et travailleurs et des res - ponsables syndicaux soient emprisonn s ou, pire encore, assassin s parce qu ils organisent et mobilisent leurs coll gues pour d fendre leurs int r ts. Par l interm diaire de l OIT, de la CSI et des f d rations internationales, la CSC met tout en uvre pour organiser des missions charg es d enqu ter dans ces pays et d exercer des pressions sur les gouvernements concern s pour qu ils respectent les conventions de l OIT. Le congr s de la CSC adresse ses chaleu - reuses et solidaires salutations aux col - l gues syndicalistes de ces pays et leur t moigne son immense respect.seulement sur la s curit sociale, mais galement sur les services collectifs, ces derniers manant tant des pouvoirs publics que du secteur priv non-mar - chand. Les services publics sont tout particuli rement vis s. La CSC pr conise un renforcement plut t qu un d man - t lement des services publics. l instar du non-marchand, de nombreux services publics n cessitent des investissements suppl mentaires, pas seulement dans les infrastructures et les quipements, mais aussi dans les effectifs. De bons salaires et de bonnes conditions de travail consti - tuent une condition sine qua non pour des services de qualit . Avec ses centrales des services publics et de l enseignement, la CSC s opposera toute tentative visant d manteler les services publics et le statut du personnel de la fonction publique et de l enseigne - ment, des nominations au syst me des pensions publiques. Mise en uvre du projet d AIP Le projet d accord interprofessionnel et son approbation par la CSC ont jet les bases d une s rie d am liorations pour les travailleuses et travailleurs, d une part au travers d accords conclus au Conseil national du travail et dans les secteurs et entreprises, d autre part avec la liaison au bien- tre des allocations sociales. La CSC r it re son exigence que les discussions sur l affectation de l en - veloppe bien- tre soient men es confor - m ment la loi qui pr voit que les inter - locuteurs sociaux se prononcent avant le 15 septembre de l ann e concern e. La CSC souhaite pr sent que des accords soient galement conclus tr s court terme sur le salaire minimum: - une premi re augmentation de 1,1% du salaire minimum interprofessionnel, dans les meilleurs d lais ; - directement suivie d une deuxi me augmentation substantielle. Justice fiscale La CSC exige plus de justice fiscale en donnant la priorit la recherche de recettes suppl mentaires aupr s de ceux qui, aujourd hui, ne contribuent pas suffi - samment. Il faut prioritairement: a. rechercher des compensations au sous-financement ( hauteur d envi - ron 6 milliards d euros) du tax shift et de la r forme de l imp t des soci t s afin de rendre ces op rations budg - tairement neutres, notamment par l instauration d une imposition des grandes fortunes; b. lutter de fa on cr dible contre la fraude et l vasion fiscales. La Bel - gique doit soutenir cette approche aux niveaux europ en et international Le studio photo en action (voir p. . AUDE VANLATHEM53 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202053 EN MARGE DU CONGR S AUDE VANLATHEM54 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 En marge du congr sNotre mascotte: Zora quelles volutions technologiques faut-il s attendre demain... voire d s aujourd hui? La mascotte de notre congr s tait Zora, un robot qui peut tre utilis dans un h pital, un h tel, une maison de repos, etc. Elle peut tenir des conversations basiques en 25 langues, indiquer le chemin ou montrer un exercice. Plus d infos? Studio photo Le studio photo est l occasion de prendre la pose, seul ou en groupe, pour conserver un beau souve- nir du congr s. Pour d couvrir les photos, r endez- vous sur Focus sur la durabilit Dans le cadre de ce congr s, nous avons essay de prot - ger au maximum l environnement. Le sac du congr s, r utilisable, est en papier tiss recy - cl . Les lani res sont fabriqu es partir de bouteilles en plastique recycl es. Le caf et les jus servis sont issus du commerce qui - table. Des fontaines sont disposition pour remplir les verres d eau. Dans la mesure du possible, les ingr dients utilis s pour confectionner les repas sont produits locale - ment, en veillant tout particuli rement une p che durable. Enfin, la mobilit douce (train, transports en commun, co- voiturage ) a t vivement encourag e pour se rendre Ostende et se d placer durant les trois jours (navette, marche, v lo ). La photographe de service au studio photo tait Katty Petras. AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM55 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 En marge du congr s Interm des musicaux Qui est l homme myst rieux qui a anim notre congr s avec ses interm des musi - caux surprenants? Max Vandervorst: musicien, compositeur, inventeur d instru - ments sauvages et de la pataphonie, donne vie depuis 1988 des instruments qu il fabrique partir d objets recycl s ou trouv s dans les poubelles. J ai tudi la clarinette l acad mie, mais j ai toujours t plus attir par le saxophone. Un beau jour, j ai pos le bec de ma clarinette sur un arrosoir, et c est ainsi qu est n mon premier instrument: le saxosoir. Ce son m a mu, j avais le sentiment d avoir trouv quelque chose de personnel, de pouvoir m exprimer. Progressivement, d autres instruments se sont ajout s et j ai multipli mes spectacles. Son message au public: Donnons de la force au quotidien. Il faut faire quelque chose de l ins - tant pr sent (ici et maintenant), c est mon credo. L imagination est essentielle. Pour en savoir plus sur Max Dinant, vous pouvez visiter la Maison de la pataphonie . D couvrez des instruments improbables faits de cailloux, de bambou, de manches balai, de tuyaux de chauffage, etc. Vous trouverez plus d informations sur les spectacles, livres, CD et ateliers de Max Vandervorst sur Max Vandervorst, musicien pataphoniste. AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM Le saxosoir.56 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 lections sociales: le coup d envoi Le coup d envoi officiel des lections sociales a t lanc au congr s. La Ligue belge d improvisation est partie la recherche du candidat id al pour la CSC. Levi et Jean-Marc, que vous reconnaissez sur les affiches des lections sociales, ont partag leur exp rience sur leur engagement la CSC. Le mat - riel de la campagne de recrutement a galement t pr sent et Marc Leemans a conclu par un appel cha - leureux aux participants du congr s: Soyez la voix qui porte .Message au nom de la CES Pour Ludovic Voet, secr taire conf d ral en charge de la jeunesse la Conf d ration europ enne des syndi - cats (CES), deux menaces guettent l Europe: le repli sur soi et les attaques sur le multilat ralisme. Certains dirigeants jouent sur les peurs des gens, migrants et ch meurs, pour se d douaner de leurs propres checs. Comme syndicats, pour rendre la confiance aux citoyens, nous devons aider l Europe relever des d fis. Il s agit de d velopper un mod le durable avec des investissements publics et priv s pour des emplois de qualit et une transition juste. Il faut atteindre la neutralit carbone en 2050 avec un objectif interm diaire de 50% en Il faut cr er des emplois nouveaux n cessaires pour d ve - lopper une nouvelle politique industrielle europ enne. Il faut fa onner l conomie mondiale avec des accords de commerce et d investissement justes, instaurer un syst me de salaire minimum en Europe, renforcer les syndicats dans les pays o ils sont faibles ou absents et tendre les m mes droits tous les travailleurs Par rapport aux migrations, l Europe doit adopter un pro - gramme global qui engage tous les tats membres. Il faut d fendre la digitalisation avec l humain aux com - mandes. Les militants qui figurent sur les affiches des lections sociales sont venus t moigner au congr s. Ludovic Voet.En marge du congr s AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM57 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020 Faire mouvement avec les Jeunes CSC Le d fi des jeunes est d tre plus que des chiffres et des lignes sur un graphique , affirment Jeanne Maillart et Jeroen Van Ranst, responsables des Jeunes CSC et des Jong ACV. Les jeunes sont la recherche de r ponses dans une soci t en changement. Nous, la CSC, devons pouvoir continuer offrir une alternative. Proposer aux jeunes un autre point de vue sur le monde, et pas celui qui nous divise et nous monte les uns contre les autres. C est ainsi que nous faisons mouvement. Alors que la pr carit est lev e chez les jeunes, notre souhait est qu ils soient autonomes conform ment la ligne de force num ro h. Nous devons reconqu rir le terrain par un plan de recrutement et d affiliation, tre un syndicat dans lequel les jeunes se reconnaissent et ont un r le jouer. Les manifs pour le climat de 2019 sont une oppor - tunit de convergence des luttes. Les jeunes qui se mobi - lisent, c est une excellente nouvelle pour la d mocratie et pour nous. propos des nouvelles formes de travail Comment adapter notre travail syndical et notre action aux nouvelles formes de travail li es au d veloppement des plateformes digitales telles que Uber, Deliveroo, RBNB ? Comment mieux prot ger ces travailleurs que le gouvernement ne consid re pas comme des travailleurs? Ce panel a r uni Amrit Sewgobind, Secr taire syndical du syndicat hollandais FNV et permanent dans le secteur des taxis, Jean-Bernard Robillard, porte- parole du Collectif des coursiers, et Mathias Wou- ters, chercheur sur l conomie de plateforme la KUL. Tous trois se rejoignent pour dire que le droit du travail doit tre appliqu ces nouvelles formes de travail, notamment aux niveaux des salaires minimum et des assurances accidents du travail. Comme syndicat, nous devons am liorer les conditions de travail de tous les travailleurs et r pondre ces nouveaux d fis. Aux manifs pour le climat de ces derniers mois, nous pouvons associer le combat pour la justice sociale. Jeroen Van Ranst. Jeanne Maillart. Jean-Bernard Robillard. Amrit Sewgobind. En marge du congr s AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM58 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020D bat sur l Europe et le populisme V ritable danger pour nos d mocraties, le populisme est partout pr sent en Europe mais prend des formes diff - rentes selon les pays. Pour en parler, trois syndicalistes: le britannique Paul Nowak de la TUC, le finlandais Jarkko Elorantai, pr sident du SAK et le fran ais Laurent Berger de la CFDT et pr sident de la Conf d ration europ enne des syndicats. Pour contrer les dangers du repli sur soi, tous trois croient en l id e d une Europe forte qui d fende les in- t r ts europ ens par rapport aux autres grandes puis- sances conomiques. Nous avons besoin de r glemen- tations internationales et europ ennes fortes pour aller de l avant, contrer les changements climatiques et autres. C est le moment pour l Europe de montrer qu elle est plus qu un march unique. Nous devons monter des alterna- tives ensemble pour obtenir l Europe sociale. Les citoyens et les travailleurs ont la trouille de la mondialisation avec peu ou pas de r gulation, avec pour cons quence le repli sur soi. Le r le de la CES est de porter ces revendications pour d avantage de r gulations. Nous devons remettre la solidarit au c ur de nos discours, repartir de la base du syndicat, de l indignation par rapport aux injustices, et mener des campagnes coordonn es. Les citoyens et les travailleurs ont la trouille de la mondialisation avec peu ou pas de r gulation. La cons quence est le repli sur soi. Paul Nowak, syndicaliste anglais (TUC). Laurent Berger, syndicaliste fran ais (CFDT).En marge du congr s AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM59 RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 2020Message de Sharan Burrow, secr taire g n rale de la CSI Sharan Burrow a remerci la CSC pour son lea - dership l OIT, pour la d fense des droits des travailleurs et la Commission des normes et tire la sonnette d alarme. Elle voit en effet dans les crises actuelles des analogies avec l entre- deux guerres. Elle a pass en revue une s rie de probl mes li s la mondialisation de l conomie qui impactent directement les travailleurs trans - form s en esclaves ou en robots, que ce soit dans les chaines d approvisionnement ou chez Amazone par exemple. Elle rappelle que quatre milliards de personnes dans le monde ne sont pas couvertes par la s - curit sociale et qu il faut continuer la mettre en place dans tous les pays. Que l conomie z ro mission de gaz effet de serre est la seule fa on d assurer notre avenir. Elle rappelle que le dialogue social et la n gocia - tion collective sont indispensables. Tout cela doit passer par la d fense pour un travail d cent pour tous l chelle mondiale en le mettant prioritai - rement l agenda. L OIT a 100 ans C est Luc Cortebeeck, ancien pr sident de la CSC, qui a anim ce panel sur l Organisation internationale du tra - vail (OIT). Et pour cause: il s y est beaucoup investi et est toujours membre du CA depuis L OIT a c l br ses cent ans en juin 2019 Gen ve. La CSC s y implique nor - m ment. Plusieurs militants de la CSC sont intervenus dans ce panel. Michel Vanden Berghe, d l gu chez Als- tom Belgium, a mis en avant le probl me que des entre - prises multinationales signent des chartes non contrai - gnantes en mati re d environnement, de droits sociaux. Quand les d l gu s proposent d en discuter, ils nous disent que a ne fait pas partie de nos pr rogatives. La CSC soutient l id e d un trait des Nations unies pour le respect des droits humains et des travailleurs. Pia Stalpart, secr taire g n rale de la CSC-Alimentation et Services, a soulign l importance de la Convention 189 sur le travail d cent pour les travailleuses et travail - leurs domestiques adopt e par l OIT en Martine le Garroy, permanente la CNE, est revenue sur l immense joie ressentie par les repr sentants des travailleurs l OIT en juin 2019 lors de l adoption de la convention 190 concernant l limination de la violence et du har - c lement dans le monde du travail . Corinne Vargha, directrice des normes l OIT, a mis en avant l important travail de la Commission des normes qui juge chaque ann e 24 pays qui n ont pas respect les droits des tra - vailleurs conform ment aux normes de l OIT. Sharan Burrow. Luc Cortebeeck a mod r le panel sur l OIT. En marge du congr s AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEM AUDE VANLATHEMRAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202060Colloque international sur la diligence raisonnable Le congr s de la CSC a t pr c d le 8 octobre par un colloque international inti- tul Vers une diligence raisonnable en mati re de droits humains suivi, le 9 octobre, d un s minaire international sur le m me th me. Des syndicalistes du monde entier, partenaires de la CSC, se sont pench s sur l importance de r guler les chaines d ap- provisionnement et d aboutir la signature d un trait des Nations unies contraignant concernant les entreprises et les droits humains. Ces deux jours ont soulign la n ces- sit absolue de la solidarit internationale. Nous d velopperons ces th mes dans le Syndicaliste n Le colloque international et le s minaire ont mis en avant l importance de la solidarit internationale. Le colloque international sur la diligence raisonnable a rassembl les partenaires de la CSC du monde entier.En marge du congr s ROGER JOB ROGER JOB ROGER JOBRAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202061 AUDE VANLATHEMDISCOURS DE CL TURERAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202062Ch res amies, Chers amis, Mesdames et Messieurs nos invit s, Nous voici arriv s la fin de notre congr s. Ces trois jours furent l occasion de d bats passionnants. Et j attends la suite avec beaucoup d int r t. Parce que ce congr s sur le th me de la transition tait tourn vers l avenir. Au lieu de le subir dans l inaction, nous devons le d terminer. Afin d orienter les tran - sitions. Nous avons l habitude de r sumer les nombreuses d cisions en quelques revendications phares. Les acteurs de la transition. Aujourd hui, je vous en propose dix et je vous invite compter avec moi. Premi rement, l humain n est pas au service de la technologie, au contraire, c est la technologie qui est au service de l tre humain! Les choix technologiques sont des choix de soci t . Tout comme la technologie doit faire l objet d une concertation. Lors de ce congr s, nous avons rig le principe Pia. Parce que nous sommes indign s. D abord face au scandale li la petite Pia, ce b b dont la vie d pend d un m dicament au co t exorbitant. Ensuite, cause d une entreprise pharmaceutique qui bloque le remboursement d un type de gouttes ophtalmiques, de sorte qu elle encaisse 500 millions de plus au d triment de la s curit sociale. Les pouvoirs publics doivent cesser de financer les vo - lutions technologiques pour ensuite permettre que les entre - prises commercialisent ces volutions dans leur propre int r t. Le soutien la recherche et au d veloppement doit tre assorti de conditions claires sur le plan l gal: notre soci t et notre conomie doivent en r colter les fruits. Deuxi mement, ce n est pas la technologie qui pose probl me en soi, mais la r partition des gains! On peut compenser les pertes d emplois en un endroit par des cr ations d emplois ailleurs. Ce principe s applique na - turellement de mani re g n rale. En accordant syst mati - quement une attention particuli re aux situations sp ci - fiques. Et il s applique condition que nous parvenions redistribuer les gains technologiques, ce que nous avons assez bien r ussi par le pass . Cette r ussite n offre tou -tefois aucune garantie pour l avenir. Car les m canismes de redistribution sont d mantel s partout dans le monde. En effet, les syndicats, garants de la redistribution, sont constamment attaqu s sur leur droit la concertation so - ciale. Voil pourquoi il est capital de pr server ces m canismes de redistribution, mais aussi de les renforcer. Il n est pas normal qu un b n fice de plusieurs milliards, r alis en une nanose - conde gr ce la sp culation boursi re, chappe encore et tou - jours l imp t alors que l on surtaxe un revenu ordinaire gagn la sueur de son front tout au long de la carri re. Un euro, quelle que soit la fa on dont vous le gagnez, doit tre impos de la m me fa on. Troisi mement, guidons les travailleurs dans le d dale de ces transitions! La technologie offre des possibilit s pour am liorer la qualit du travail. En all geant le travail ou en le rendant plus s r. En travaillant moins ou autrement. videmment, la transition aura galement un impact n gatif sur les emplois dans les entreprises. Nous disposons d j d un cadre pour les restructurations. Le meilleur au monde, selon les employeurs. En fait, ils veulent dire que, pour eux, il pourrait tre un peu moins restrictif. Pour la CSC, il faudrait qu il le soit davantage. Les entreprises doivent investir de mani re proac - tive dans la formation tout au long de la vie, pr cis ment pour emp cher les licenciements. Ces investissements, elles ne les consentiront jamais de leur propre initiative. Par cons quent, nous r clamons pour 2020 un droit cinq jours de formation pour chaque travailleur. Pour tout le monde et partout, donc y compris dans les PME. Quatri mement, la technologie peut galement alourdir le tra - vail. Ce n est pas li la technologie, mais au fait que les mod les conomiques low cost r alisent des b n fices sur le dos de leurs collaborateurs, avec le soutien des lobbies qui liminent toute forme de protection, sous pr texte que personne ne doit entraver l innovation . Mais le progr s peut galement tre synonyme de r gression. Ici en Belgique, les plateformes num riques telles qu Uber et Deliveroo ont re u ce qu elles ont voulu comme un duty free : elles ne paient ni imp ts, ni coti - sations. Elles ne contribuent aucunement la protection des travailleurs et la s curit sociale. ma connaissance, c est un DISCOURS DE CL TURE PAR MARC LEEMANS, PR SIDENT DE LA CSC RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202063exemple, en rendant les entreprises actives l tranger p na - lement responsables de violations des droits humains, des normes fondamentales du travail et des accords internationaux sur le climat et l environnement. Y compris chez leurs sous-trai - tants. Cela contribuera d finir des r gles europ ennes et in - ternationales. Et appliquons ces normes et conditions chaque march public. Septi mement, soutenons la transition climatique! Nous voulons aider la concr tiser pour la rendre socialement juste. Pas la ralentir, mais susciter l adh sion n cessaire. Un monde plus cologique ne nuit pas la croissance et l emploi. Au contraire. C est une condition sine qua non. La Conf d ration syndicale internationale n a de cesse d enfoncer le clou: il n y a pas d emplois sur une plan te morte. Nous voulons et pou - vons encore inverser la tendance. Et non, nous ne sommes pas na fs ou n gatifs. Au contraire, nous voulons un avenir pour nos enfants, un avenir positif. Huiti mement, la migration est un ph nom ne irr versible. Les distances deviennent plus courtes, ce qui rend notre monde plus grand, avec une diversit croissante de couleurs, de cultures, de religions, etc. Certains abusent de cette diversit pour polariser la soci t , en flirtant parfois avec le racisme et la x nophobie. Pourtant, il faut viter cette polarisation et la com - battre. Pour nous, tout individu et tout droit humain compte. Neuvi mement, r alisons les ODD! Les Objectifs de d veloppement durable des Nations unies pour 2030 ont t approuv s en Nous serons bient t en 2020 et nous avons d j perdu un tiers du temps. Car la mise en uvre n a pas commenc , ni au niveau belge, ni au niveau r gional. Sauf dans le cadre d initiatives de relations publiques on - reuses orchestr es par certaines entreprises. Nous proposons le triple R: avec le R de respect de droits contraignants; le R de r sultats impos s; le R de r gles mises en uvre. Sinon, nous n y parviendrons jamais. Nous arrivons enfin notre dixi me acteur de la transition: un autre mod le de croissance! La croissance conomique stagne. Souhaitons-nous ou pou - vons-nous retourner dans le pass ? L ancien mod le de crois - sance nuit fortement la qualit du travail, l int gration des plus vuln rables, au climat ainsi qu l environnement. Nous cas unique au monde. M me les employeurs estiment que ce syst me d passait les bornes. Avec les Classes moyennes, nous demandons que la Cour constitutionnelle annule cette d cision. Notre dossier est solide. Nous esp rons que cette fois les juges rendront un verdict clair . Par ailleurs, nous voulons gale - ment que les travailleurs des plateformes soient couverts par une assurance accident du travail et des r gles en mati re de dur e du travail, d horaire de travail et de s curit et sant et ils doivent recevoir un salaire au moins gal au salaire minimum. Mais nous devons galement mettre un terme toute forme de flexibilit excessive. Des contrats ultra pr caires plongent les travailleurs dans une grande ins curit . Les entreprises qui tra - vaillent malgr tout avec ce type de contrat doivent en subir les cons quences: une augmentation des cotisations doit rendre ces contrats plus on reux. Cinqui mement, le patron ne doit pas tout savoir! Il fut un temps o nous renoncions volontiers notre droit au respect de la vie priv e pour se balader sur le terrain de jeu qu est la toile. Ce temps est r volu. Nous sommes maintenant conscients des risques et nous avons recommenc pr server un peu plus notre vie priv e. Alors que les employeurs sont avides de scanner les travailleurs au moyen des derni res technologies. Le droit la vie priv e ne doit pas cesser lorsque vous cherchez un emploi ou que vous p n trez sur votre lieu de travail. C est un droit humain et les entreprises doivent s y conformer. Toute personne qui travaille ou postule un emploi doit avoir le droit absolu de consulter et de corriger toutes les donn es personnelles d tenues par l entreprise. Dossiers du personnel, valuations, prestations, r sultats de tests... Sixi mement, rappelons les multinationales l ordre! Souvenez-vous du drame du Rana Plaza: 556 morts dans l effondrement d une usine au Bangladesh il y a six ans. Ces travailleurs y confectionnaient des v tements tr s bas co t pour des marques internationales on reuses. Ce fut un tournant car cette catastrophe a fait voler en clat le discours non contraignant sur l entreprenariat durable. Ce qu il faut, ce sont de nouvelles r gles et de nouveaux droits: contrai - gnants, li s des contr les et exigibles par les travailleurs. C est le cas de la loi fran aise appliqu e aux multinationales. Cette loi contraint les multinationales rendre compte de l impact qu elles ont ailleurs dans le monde. La Belgique peut suivre cet RAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202064devons donc d velopper notre monde autrement. M me l OCDE le reconna t aujourd hui. Cela exige des instruments pour me - surer diff remment la croissance et le niveau de civilisation d un pays. Cela n cessite un changement des rapports de force. L conomie doit se d faire de la sp culation boursi re des ac - tionnaires. Nous devons remettre notre monde entre des mains responsables. Reprendre le contr le! C est ce que nous d fendons. C est le sens de notre combat. court terme, nous serons confront s des d fis de taille. La nouvelle Commission europ enne entrera en fonction le 1er novembre. Nos R gions ont leur propre gouvernement. Les n - gociations pour un nouveau gouvernement f d ral sont amor - c es. J ai vraiment de la compassion pour les n gociateurs. Mais peut- tre pourrons-nous les aider. Vous l aurez remarqu : depuis le 26 mai, le courrier est toujours distribu , les pensions et les allocations sont vers es, les bus et les trains continuent de circuler, les h pitaux soignent les pa - tients, dans les coles, les cours sont dispens s... Si la Belgique n est pas totalement paralys e, c est parce que notre pays peut compter sur un syst me de protection sociale fort, des services publics et des quipements collectifs solides. Pour maintenir ces syst mes, l avenir aussi, nous devons inves - tir grande chelle. Par exemple, comment allons-nous conti - nuer bien soigner les patients sans effectifs suffisants dans le secteur des soins? Nous voulons que le prochain gouvernement investisse massivement dans la s curit sociale, dans la pro - tection sociale, bref, dans la soci t . Conjointement aux autres syndicats chers coll gues, je vous salue , nous l avons claire - ment indiqu aux informateurs qui, dans l intervalle, ont achev leur mission. Ce que nous attendons du futur gouvernement, c est qu il adopte une politique juste et quitable pour faire face aux nombreuses transitions que nous sommes amen s traver - ser. C est bien diff rent de ce que nous avons connu au cours de la l gislature pr c dente. Comment allons-nous sou - tenir notre conomie dans le cadre du processus d colo - gisation? Comment accom - pagner les secteurs? Com -ment allons-nous soutenir nos travailleurs dont le travail, le revenu et la vie seront influenc s par les transitions? Comment allons-nous doter notre s curit sociale de moyens suffisants et, de pr f rence, de moyens demand s de mani re quitable tous les revenus? Comment allons-nous assurer une pension d cente pour nos vieux jours? Nous voulons organiser une concertation sociale structur e sur toutes ces questions. Cela n cessite donc une approche politique diff rente. Je ne vais pas refaire le proc s de ce gou - vernement. Non bis in idem , disent les juristes. Nul ne peut tre puni deux fois pour la m me infraction. Et l lecteur a d j sanctionn cette politique gouvernementale le 26 mai. Tout ce que je peux faire, c est valuer le chaos laiss . Nous nous heurtons un d ficit de 13 milliards d euros dont la moiti est due une promesse non tenue qui visait rendre budg tairement neutres le tax shift et la r duction de l imp t des soci t s. Dans quelques ann es, notre s curit sociale peut tre confront e un sous-financement de l ordre de 5,9 milliards d euros principalement d aux coupes gratuites op r es de diverses fa ons dans les recettes. Notre monde et notre mode d habitat et de travail ne s cologisent pas. La classe politique choue dans la lutte contre le changement climatique et dans la r alisation des objectifs de d veloppe - ment durable. Et, pire que tout, le m contentement social ne fait que cro tre. Les citoyens ordinaires en ont assez. Ils ne se sentent pas respect s. Ils voient que les in galit s de traite - ment augmentent. Ces in galit s r sultent de la politique que les pr c dents partis au pouvoir auraient souhait poursuivre. Mais le r sultat des lections les a ramen s la raison. Les partis politiques de droite se targuent d avoir enfin compris je cite que les charges et les avantages ne sont pas r partis quitablement. Qu il est urgent de mieux les quilibrer. Cette approche ressemble trangement la n tre. Nous nous ver - tuons depuis des ann es expliquer que les charges ne sont pas r parties quitablement. Il y a deux ans, le professeur britannique Timothy Garton Ash expliquait le succ s du populisme de droite. Selon lui, ce succ s est li aux in ga - lit s. Ce ph nom ne d coule Un euro, quelle que soit la fa on dont vous le gagnez, doit tre impos de la m me fa on. Marc Leemans, pr sident de la CSCRAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202065du fait que les citoyens ordinaires observent que les riches sont syst matiquement avantag s. En outre, Ash estime qu la dis - parit de revenu et de patrimoine s est ajout e une frustration n e de l in galit d attention, de respect et de compr hension. Bon nombre de citoyens ordinaires estiment qu ils sont laiss s pour compte. C est bien l que le b t blesse. Beaucoup de tra - vailleurs ont le sentiment d tre abandonn s leur sort, que l on ne s int resse gu re eux et qu on leur manque de res - pect. Trop ont le sentiment que le monde politique ob it surtout aux ordres des lobbys conomiques et financiers. Voil ce que des citoyens ordinaires d noncent dans l isoloir. C est ce qu ils revendiquent. Du respect pour leur travail. Du respect pour la contribution qu ils apportent au bien- tre collectif. De la com - pr hension pour les difficult s qu ils rencontrent dans leur vie. De l attention pour ce qu ils ont dire. Et c est cette attention, cette compr hension et ce respect que la CSC continuera de d fendre. Cela commence par le respect envers ceux qui travaillent dur ou ont travaill dur et qui chaque mois, chaque ann e, contri - buent sans d tours la s curit sociale, aux services collectifs et la dette de l tat, alors que d autres, aid s par une arm e de conseillers fiscaux, passent entre les mailles du filet. Voil le premier axiome du droit au respect: la fiscalit juste. Une contribution juste et quitable de chacun la soci t ! Cela passe par le respect de la juste r mun ration des per - sonnes qui travaillent dur. Le salaire minimum doit tre relev d urgence. Nous nous sommes mis d accord sur ce point dans le cadre du projet d AIP. La CSC a approuv ce projet, qui a ensuite t adopt par tous les partenaires sociaux au CNT. Cet accord pr voyait d j une premi re augmentation de 1,1% au 1er juil- let de cette ann e. Et pour le 30 septembre, nous devions nous concerter au CNT sur une deuxi me augmentation substantielle. Depuis, la premi re augmentation a t bloqu e. Par cons - quent, les b n ficiaires du salaire minimum perdent 17,5 euros par mois. Dans l intervalle, ce montant repr sente d j 70 euros, ce qui a d j fait conomiser aux employeurs plus de 16 millions d euros. La CSC veut une augmentation plus importante pour les salaires les plus bas. Mais elle ne comprend pas qu on laisse passer une premi re augmentation. Cette perte n est ni justi - fiable ni acceptable. Compr hension pour les travailleurs qui su - bissent des accidents de parcours, respect pour ceux qui partent la pension. Cela signifie que nous devons renforcer notre pro - tection sociale. Cela signifie qu il faut percevoir de nouvelles recettes. Des choix politiques ont mis notre syst me au r gime. On peut parfaitement infl chir ces choix politiques en trouvant de nouvelles recettes. Pour mieux faire face aux besoins en mati re de soins, au co t du vieillissement, la pauvret , etc. Notre soci t peut opter pour une bonne dose suppl mentaire de solidarit . Car c est cela respecter les tres humains et la dignit humaine. C est cela opter pour le changement! Ce sc nario n est pas na f du tout. Nous pensons vraiment qu il est possible de construire une soci t meilleure, ouverte, se - Nous devons mettre un terme toutes les formes de travail flexible excessif. Marc Leemans, pr sident de la CSC AUDE VANLATHEMRAPPORT CONGR S CSC #QUELTRAVAILDEMAIN | 10-12 OCTOBRE 2019 | SYNDICALISTE N 916 | 20 JANVIER 202066 Les citoyens ordinaires ne se sentent pas respect s. Ils voient que les in galit s de traitement augmentent. Marc Leemans, pr sident de la CSC suit attentivement les dynamiques sociales, culturelles et soci - tales plut t que de les affaiblir ou de les r duire au silence. C est pourquoi, nous continuons nous engager fermement coop rer avec la soci t civile largie qui uvre pour un monde meilleur dans les domaines de la lutte contre la pauvret , de l environnement, du climat, de la diversit , de l int gration, du genre, de la culture, de la d mocratie, de la durabilit Ensemble, nous cr ons un monde meilleur. Le r le des syndica - listes est d une importance cruciale cet gard. Vous intervenez parmi vos coll gues de fa on structur e. Vous entendez, voyez et parlez sur le lieu de travail. Vous donnez la parole vos coll - gues sur le terrain, mais aussi l ext rieur. Vous veillez ce que leurs voix ne soient pas seulement entendues bri vement tous les cinq ans. Vous incitez les d cideurs politiques rester sur leurs gardes. M me si cela n cessite parfois de passer l action. Ces interventions sont n cessaires pour une d mocratie forte. Dans d autres pays, des Philippines la Colombie en passant par le Zimbabwe, souvent il est difficile de faire entendre une voix forte. Dans trop d endroits, les syndicalistes sont priv s de libert , leurs familles sont intimid es, ils sont menac s de mort, ils sont assassin s. Parce qu ils d fendent leurs droits fondamentaux. Leur situation m rite notre attention solidaire, notre compr hension, notre respect et notre soutien. Friends of Unions worldwide, we pay you our deepest respect and we salute you! Ch res amies, chers amis, Je terminerai par l expression sinc re de mon respect: le respect que vous m ritez. Au cours des derni res ann es, vous avez une fois de plus donn le meilleur de vous-m me. Gr ce vous, ce congr s fut un v nement enrichissant et chaleureux, avec des d cisions claires. Avec un itin raire clair pour les transitions r aliser. Beaucoup d entre vous s engagent nouveau dans la campagne pour les lections sociales. Pour que se mette en place une politique d entreprise, pour conclure des accords so - ciaux, pour d finir une politique qui rende justice aux citoyens ordinaires. Parce que les citoyens ordinaires sont au c ur de nos pr occupations. Pour tout cela, je vous remercie du fond du c ur. Je d clare le 36 me congr s national de la CSC cl tur .reine, inclusive, pacifique, o ce ne serait pas chacun pour soi, et Dieu pour tous. Nous pr f rons prendre en main la solidarit , ici dans ce monde et dans cette vie. Nous demandons le respect pour ceux qui, chaque jour, s inves - tissent dans les services collectifs, que ce soit dans le non-mar - chand, dans le secteur public ou dans l enseignement. Souvent, la force d une soci t ne se mesure qu la mani re dont elle s organise collectivement. C est la seule fa on d difier un socle, des infrastructures, des fondements communs... Non pas en choisissant la voie du mercantilisme et de la privatisation. L ob - session d un tat plus maigre est souvent synonyme d ob - sit pour les entreprises. Nous demandons que l on soit attentif aux g n rations futures. Au travers de ses actions pour le climat, la jeune g n ration se mobilise. Elle nous motive pour lutter contre le d r glement climatique et pour une transition juste. Mieux que nous, elle r ussit vraiment agacer le camp des conservateurs. Elle est notre alli e dans notre combat pour un monde plus durable. Ensemble, nous continuerons d exiger du gouvernement f d ral et de la Commission europ enne qu ils soient conscients d avoir rendez-vous avec l Histoire avec un H majuscule. C est mainte - nant ou peut- tre plus jamais. Nous demandons le respect pour tous ceux qui s engagent pour une soci t meilleure. Tant que l on s engage spontan ment et discr tement aider les personnes dans le besoin , il n y a pas de probl me. Tant que vous ramassez les immondices et distri - buez de la soupe et, qu en agissant ainsi, vous comblez les trous laiss s par les pouvoirs publics, les secteurs marchands et non marchands , il n y a pas de probl me. Mais lorsque la soci t civile d clare qu un monde meilleur ne se r alise pas unique - ment gr ce un engagement charitable, mais que le politique doit aussi jouer son r le, elle est consid r e comme un pro - bl me politique. Pourtant, notre r le et notre responsabilit consistent aussi faire entendre notre voix entre deux lections. Parce que notre discours diff re de celui que les dirigeants poli - tiques estiment d duire des r sultats des urnes. Nous sommes convaincus qu une d mocratie se renforce si elle 67AVANT-PROPOS 2 DISCOURS D OUVERTURE 3 LES LIGNES DE FORCE: #QUEL TRAVAIL DEMAIN 7 Introduction 8 #1 Un march de l emploi en transition 9 #2 Des emplois en transition 17 #3 un monde en transition 25 R SOLUTIONS D ACTIVIT S 35 Introduction au d bat 36 Discussions sur les r solutions d activit s et d actualit Quatre t moins de victoires syndicales 40 R solutions d activit s approuv es 42 R SOLUTIONS D ACTUALIT 49 R solutions d actualit approuv es 50 EN MARGE DU CONGR S 53 DISCOURS DE CL TURE 61Sommaire AUDE VANLATHEMCOLOPHON R daction de ce num ro: Donatienne Coppieters, Herman Fonck, Renaat Hanssens, Simon P tre, Ive Rosseel, Chris Serroyen, Stijn Sintubin et Patrick Van Looveren. Traduction: Ilse Cambier, Myl ne Demeure, Pascal Dr ze, Anne Scieur, Isabelle Tuteleers, Hilde Van Lancker. Secr tariat de r daction: Donatienne Coppieters et Patrick Van Looveren. Photos du congr s: Aude Vanlathem. Lay-out: Gevaert Graphics. Imprimerie: Hoorens Printing. diteur responsable: Dominique Leyon. R daction Syndicaliste: BP 10 - 1031 Bruxelles - T l.: Courriel: dcoppieters@acv-csc.be - Site internet: CONGRES 2019",fr
Anonymous,F540758,04 August 2020,,,,"Berlin, August 2020 Deutscher Industrie - und Handelskammertag R ckmeldung des Deutschen Industrie - und Handelskammertag s (DIHK ) zu einer Folgen absch tzung der Kommission Artificial intelligence ethical and legal requirements Opportunit t eines Regulierungsrahmens f r KI Der DIHK unterst tzt die Idee der EU -Kommission, eine n Regulierungsrahmen zu schaffen, der aber offen sein muss f r weitere Entwicklungen. Die Fortschritte und weitere Marktdurchdringung sind bei KI -Anwendungen momentan nicht einzusch tzen. Daher d rfen gesetzliche Regelungen keine unn tigen Hemmnisse f r die Weiterentwicklung bei KI aufbauen und sollten vielmehr innovationsf rdernd wirken . Die Gefahr einer Fragmentierung des Binnenmarkts durch nationale KI-Regelungen in grenz berschreitenden Sektoren spricht auch f r eine Harmonisierung auf EU - Ebene. Es darf sich allerdings lediglich um einen Rahmen handeln, der klare und allgemeinen Leitplanken f r KI regelt. Bei der KI -Regulierung sollte besonders f r KMU vermieden werden, dass komplexe und b rokratische Regeln entstehen. Die Rechtssicherheit der Unternehm en soll te bei der Regulierung eine Priorit t sein und nicht vor allem auf den Schutz der Verbraucher fokussiert sein, wie das KI - Wei buch an mehreren Stellen zu verstehen gibt. Dabei sollten die rechtlichen Regelungen die Risiken, die KI-Anwendungen verursachen k nnen, ber cksichtigen. Das betrifft einmal die H he des Risikos, aber andererseits auch die Frage der ungleichen Marktmacht im B2B -Bereich. Bei der berlegung e iner Differenzierung zwischen B2B und B2C muss ber cksichtigt wer den, dass gerade viele kleinere und mittlere Unternehmen genauso schutzw rdig im Bereich KI sein k nnen wie Verbraucher. Risikobasierte n Ansatz verfolgen Der von der EU -Kommission gew hlte risikobasierte Ansatz ist im Sinne eines verh ltnism igen regulatorischen Eingriffs sinnvoll . Auch die Datenethikkommission in Deutschland hat einen solchen ihrem Bericht zugrunde gelegt. Die Kommission schl gt vor, KI -Anwendungen als hohes Risiko einzustufen, wenn sowohl der Sektor als auch die beabsichtigte Ver wendung erhebliche Risiken bergen. Dennoch scheint dieser Ansatz keine bessere Risikoeinsch tzung im Einzelfall zu erm glichen, denn die Risiken und Risikobereiche werden nicht vorhersehbar sein dadurch k nnten nicht alle Risiken erfass t werd en. Teilweise wird vorgebracht, dass risikobehaftete Sektoren in einer Liste aufgez hlt werden sollten, umso mehr Rechtssicherheit zu erhalten. Allerdings k nnte eine Liste von risiko reichen Sektoren Berlin, August 2020 Deutscher Industrie - und Handelskammertag ganze Sektoren unter Verdacht stellen, obwohl in jedem Sek tor Anwendungen, Produkte und Dienste mit unterschiedlichsten Risikoanforderungen bestehen. Eine Liste von risiko reichen Sektoren w rde damit allen gelisteten Sektoren die Nutzung von KI auch f r unkritische Funktionen/Dienste erheblich erschweren , etwa durch erh hte n Trainingsaufwand von ethisch unbedenklichen Anwendungsf llen . Dies w re mit erheblichen Sch den f r die Konkurrenzf higkeit und Besch ftigung des EU -Standorts verbunden . Eine Bestimmung der risiko reichen Anwendungen nach Sektor en erscheint a lso nicht geeignet, um die Vielfalt der KI zu erfassen. Daher sollte eine Beurteilung des Risikos anhand allgemeine r Kriterien erfolgen. Sie sollten allerdings sehr klar festgelegt, eng gefasst und zukunftsfest sein. Zertifizierung/Standardisierung Die Entwicklung von KI sollte grunds tzlich den gleichen Sicherheitsstandards gen gen, wie dies bei anderen Industrieg tern oder Dienstleistungen heute schon geregelt ist. Um Schutzziele mit den Entwicklungszielen in Einkla ng zu bringen, muss auch hier das Grundprinzip Wettbewerb unter Einhalten von Sicherheitsstandards gelten. Eine M glichkeit w re, grunds tzliche Anforderungen hnlich dem Prinzip der CE -Kennzeichnung f r KI -Anwendungen und KI -Produkte zu definieren und Unt ernehmen diese nach dem Selbstverpflichtungsprinzip (Konformit tsbewertungsverfahren) unter beh rdlicher berwachung umsetzen zu lassen. Ob die Pr fung, Zertifizierung oder auch Standardisierung von Algorithmen jedoch m glich ist, erscheint fraglich. Das Ergebnis w re eine Momentaufnahme, die bei der schnellen technischen Entwicklung regelm ig angepasst werden m sste. Zudem ist zu ber cksichtigen, dass insbesondere f r Start -ups und KMU Zertifizierungen eine enorme finanzielle Belastung bedeuten. Hier si nd Nutzen und Mehrwert einer Zertifizierung sorgf ltig gegen ber dem Aufwand abzuw gen. Gro er Handlungsbedarf besteht bei der Anonymisierung von Daten. Denn dies k nnte helfen, die Datennutzung zu verbessern und das Zusammenf hren von Daten verschiedener Anbieter zu erm glichen. Europ ische Standards f r die technische Umsetzung der Anonymis ierung personenbezogener Daten w ren ein gro er Schritt in die richtige Richtung. Die zur Verf gungsstellung eines Pr fsystems, dass automatisch die Stabilit t, Sicherheit und den Bias berpr ft, k nnte Unternehmen einiges an Last abnehmen. Denn schlie lic h muss beim Einsatz von KI das Recht der Betroffenen ""nicht einer ausschlie lich auf einer automatisierten Verarbeitung beruhenden Entscheidung"" gewahrt werden. Fraglich ist, wann eine Entscheidung ausschlie lich auf einer automatisierten Entscheidung beru ht. Die (verl ssliche und tats chliche) Umsetzbarkeit von gesetzlichen Auflagen durch Unternehmen h ngt auch stark von den staatlichen Stellen ab, die die Vorgaben/Regelungen (glaubw rdig) kommunizieren, deren Einhaltung berpr fen und gleichzeitig unter nehmensfreundliche Hilfestellungen/Umsetzungs - bzw. Einhaltungswerkzeuge bereitstellen. Zur Unterst tzung der Berlin, August 2020 Deutscher Industrie - und Handelskammertag Unternehmen sollten entsprechende Entwicklungsleitf den, eventuell sogar ein neuartiger Entwicklungsprozess f r KI -Anwendungen, erarbeitet werden. Daraus ergeben sich folgende Fragen: Wird es eine zentrale Stelle auf EU geben, die in enger Abstimmung mit landesspezifischen Einrichtungen (wie dem BSI) eine Operationalisierung und Koordinierung vornimmt? Und kann dieses hochanspruchsvolle Wissen, wa s in gesetzliche Regelungen bersetzt werden soll, berhaupt von jedem EU -Land einzeln geleistet werden oder macht eine EU -weite B ndelung Sinn? Wie sollen Daten im Rahmen von Edge Computing L sungen effizient vorgehalten werden, wenn sie nicht zentral v erf gbar sind? Wie werden bei einer externen Pr fung Unternehmensgeheimnisse und Datenschutz gewahrt? Wie soll mit KI - Anwendungen umgegangen werden, die bereits entwickelt sind? Datenschutz und KI zum Ausgleich bringen Aus datenschutzrechtlicher Sicht zeigt sich, dass die DSGVO die Nutzung von KI vor Herausforderungen stellt. So hat die EU selbst mit ihrer Verordnung (EU) 2018/1807 vom 2018 ber einen Rahmen f r den freien Verkehr nicht -personenbezogener Daten in der Europ ischen Union deutlich gemacht, wie schwierig die Abgrenzung zwischen personenbezogenen und nicht -personenbezogenen Daten ist. In der Realit t gibt es einen hohen Prozentsatz an gemischten Daten, die aber f r KI -Anwendungen notwendig sind, wegen des Personenbezugs aber der DSGVO unterliegen. Ob eine st rkere Anwendungsm glichkeit von Pseudonymisierung und Anonymisierung von Daten bei der Verarbeitung f r und durch KI m glich ist, w re ein wichtiger Aspekt, um zumindest teilweise nicht dem strengen Regim e der DSGVO zu unterliegen. Die EU -Kommission sieht zurecht eine generelle Sektor - berwachung bei der Frage eines h heren Risikos als kritisch an. Denn nicht jede KI -Anwendung in einem risikohaften Sektor ist an sich ebenfalls risikoreich. So beinhaltet z . B. die Auswertung von abstrakten, anonymisierten Daten f r die berpr fung von Verkehrsfl ssen keinerlei Risiko f r die Verkehrsteilnehmer. KI -Anwendungen mit einem hohen Risiko m ssen wohl ohnehin, wenn sie personenbezogene Daten verarbeiten, z. B. eine r Datenschutz -Folgenabsch tzung unterliegen. Zudem unterliegen sie entsprechenden Informationspflichten nach der DSGVO. Insofern ist nicht ersichtlich, welche weiteren Kennzeichnungen notwendig w ren. Werden keine personenbezogenen Daten verarbeitet, ist n icht erkennbar, worin dann ein hohes Risiko f r Verbraucher/B rger liegen soll. Im Bereich des Deep Learning eine spezielle Machine -Learning -Technik - lernt die KI selbst und direkt aus Beispielen . Zwangl ufig ergibt sich die Frage, wie den Anforderunge n der DSGVO nachgekommen werden kann bzw. ob der von der DSGVO vorgebebene Rahmen kompatibel mit Anwendungsszenarien sich weiter entwickelnder KI ist. Konkrete Unklarheiten sind : (i) Der Zweckbindungsgrund satz (dynamischer Prozess; eine KI entwickelt sich nicht starr nach vorgebebenen Kriterien), (ii) Voraussetzungen informierter Einwilligung (wie m glich, wenn die Zwecke nicht ausreichend feststehen; Umsetzung des Widerrufs bei bereits verarbeitete n Daten in Berlin, August 2020 Deutscher Industrie - und Handelskammertag der KI schwierig), (iii) Informationspflichten ( keine Darstellung der Verarbeitungszwecke im Detail m glich). Auch das L schen von Daten in der KI d rfte schwierig sein. Wie sollen die verarbeiteten Daten herausgelangen und kann die KI ihren Zweck, aus Datens tzen zu lernen, dennoch weiterverfolgen? Tatbest nde der DSGVO m ssten im KI -Anwendungsfeld wohl weit ausgelegt werden, um KI und DSGVO zum Ausgleich zu bringen und die DSGVO nicht zum Innovationshemmnis f r die Entwicklung neuer Technologien werden zu lassen. Dar ber hinaus braucht es weitere Pr zisierungen und eine einheitliche, europaweite Auslegung der DSGVO. Transparenz Grunds tzlich ist die Forderung nach Transparenz zu unterst tzen. Es muss zumindest im B2C - Bereich deutlich gemacht werden, dass KI -L sungen angewendet werden. Eine transparente KI kann f r Beweisf hrungen und Haftungsfragen ggf. Vorteile mit sich bringen. Allerdings findet die Transparenz dort ihre Grenzen, wo es um Gesch ftsgeheimnisse geht. Hier sei auf die Richtlinie (EU) 2016/943 verwiesen. Algorithmen und KI -Anwendungen geh ren eindeutig zu den sch tzenswerten Gesch ftsgeheimnissen von Unternehmen. Mit der geforderten Datentransparenz k nnen Gesch ftsgeheimnisse tangiert werden. Deshalb sollten Unternehmen die bereitzustellenden Informationen ber F higkeiten, Grenzen und ordnungsgem e Funktionalit t auf h herem Abstraktionsgrad bereitstellen k nnen . Vermieden werden muss, dass Datentransparenz zum Einfallstor f r Spionage wird und ggf. so zu Wettbewerbsverzerrungen zwischen First und Late -Mover f hrt. Dass die Transparenz bzw. das Auskunftsrecht der betroffenen Personen nicht schrankenlos sind, sondern die Gesch ftsgeheimnisse oder Rechte des geistigen Eigentums nicht beeintr chtigen darf, sieht bereits Erw gungsgrund 63 vor. Auch hier w re - f r KI -basierte Entscheidungen - eine Klarstellung dahingehend sinnvoll, dass Algorith men nicht offengelegt werden m ssen, weil nach Erw gungsgrund 58 die M glichkeit besteht, pr zise, leicht zug nglich und verst ndlich"" zu informieren. Haftung a. Opportunit t eines Haftungsrechtsrahmens f r KI Die Digitalisierung erm glicht in nahezu allen Wirtschaftszweigen und Branchen KI -L sungen. Gesch ftsmodelle bauen zunehmend auf KI -L sungen auf. Bisherige ordnungs - und rechtspolitische Paradigmen werden dadurch dennoch nicht obsolet. Die Fragen, wer di e Verantwortung f r Sch den, die aus KI -Anwendungen hervorgehen, zu tragen hat, sollten durch Herausbildung europaweit einheitlicher Regeln, insbesondere bei Berlin, August 2020 Deutscher Industrie - und Handelskammertag Produktsicherheits - und Haftungsfragen erfolgen. Dabei sollte auch der Begriff Verantwortung europ isch definiert werden. Die Ausf hrungen unter B.2 zur KI -Definition gelten hier entsprechend. Zugleich gilt, dass vor jeder neuen Regulierung eine Regelungs - oder Rechtsdurchsetzungsl cke nachgewiesen sein sollte. Regulierung darf kein Selbstzweck sei n und in berregulierung m nden. Sie sollte Innovationen f rdern, also innovationsoffen sein, und eine leistungsstarke und international wettbewerbsf hige Wirtschaft erm glichen. Wo werden Regelungsl cken gesehen? Das Aufkommen neuer digitaler Technologie n wie KI, Internet der Dinge und Robotik birgt in Bezug auf rechtliche Fragen, z. B. f r die Produktsicherheit und -haftung, neue Herausforderungen wie Konnektivit t, Autonomie, Datenabh ngigkeit, Opazit t, Komplexit t von Produkten und Systemen, Softwarea ktualisierungen sowie ein komplexeres Sicherheitsmanagement und komplexere Wertsch pfungsketten. Diese Probleme sind auch bisher nicht unbekannt. Beim Einsatz von KI wird es aber gegebenenfalls noch schwieriger, die Risiken zu beschreiben und zu quantifi zieren. Insbesondere die Nachvollziehbarkeit von KI -Systemen und die von diesen oder mit deren Hilfe getroffenen Entscheidungen m ssen beurteilt und ggf. entschl sselt werden. Konnektivit t darf nicht mit Kausalit t gleichgesetzt werden. Ob vor diesem Hi ntergrund eine Notwendigkeit besteht, dass f r KI neue rechtliche Regelungen eingef hrt werden oder bestehende angepasst werden sollten, ist vorsichtig zu beurteilen. b. Produkthaftung Im Rahmen von Industrie 0 k nnen, wie bei der industriellen Fertigung auch, im Herstellungsprozess Fehler auftreten, die sich in der Produktnutzung fortsetzen. Der Schaden, der bei der Nutzung des fehlerhaften Produkts entsteht, ist dann auf das fehlerhafte Produkt selbst zur ckzuf hren. Beim Einsatz autonomer oder selbstlernender Systeme k nnen Sch den durch ein Fehlverhalten dieser Systeme auftreten. Das Produkthaftungsgesetz und das Deliktsrecht sind nur dann fit f r die Digitalisierung, wenn sowohl die Produkte selbst als auch Dienstleistungen m itumfasst werden. KI wird blicherweise aus dem Bereich der Dienstleistungen generiert. Im Dienstleistungsbereich k nnen auch Fragen der gen genden Cybersicherheit zu Problemen f hren. Der Hauptfokus d rfte im Bereich des Nachweises bzw. der Kausalit t lie gen . Hier k nnte daher m glicherweise eine Beweislastumkehr oder zumindest Beweislasterleichterungen entsprechend der Verantwortungs - und Risikosph ren angedacht werden. c. Deliktsrecht Berlin, August 2020 Deutscher Industrie - und Handelskammertag Verursachen autonome oder selbstlernende Systeme Sch den, ist es insbe sondere schwierig, den Anspruchsgegner zu identifizieren. Dieses Rechtsrisiko unterscheidet sich strukturell nicht von anderen Situationen, in denen der Verursachungshergang nicht oder nur schwer aufkl rbar ist. Es ist zu berlegen, ob die Haftung f r au tonome Systeme sich am Beispiel der Halterhaftung ( hnlich der Regelungen im Stra enverkehr), verbunden mit einer Versicherungspflicht, orientieren sollte. Eine in diesem Zusammenhang diskutierte gesetzliche Erweiterung um eine reine Gef hrdungshaftung geh t allerdings zulasten der Unternehmen. Denn die Gef hrdungshaftung geht davon aus, dass sie ohne jeden Bezug auf ein Verschulden oder auf einen Verursachungsbeitrag zur Anwendung kommt. Dies w rde sich nachteilig auf die internationale Wettbewerbsf higkeit auswirken und Unternehmern die Entwicklung und Etablierung innovativer Produkte erschweren. In diesem Zusammenhang ist darauf hinzuweisen, dass schon heute viele Produkte einer besonderen Zulassung vor dem Inverkehrbringen bed rfen, z. B. im Medizin - /Phar ma- oder KFZ -Bereich. d. Zurechnung von Willenserkl rungen Automatisiert agierende Systeme handeln nach voreingestellten Bedingungen, wie Drucker, die ab einem vorgegebenen F llstand der Druckerpatrone eine neue nachbestellen. Virtuelle Assistenten, wie Siri oder Alexa , f hren sprachgesteuerte Bestellungen durch. Autonom agierende Systeme sind in der Lage, aufgrund der ihnen zur Verf gung stehenden Datens tze selbstst ndig zu lernen und damit Willenserkl rungen abzugeben. F r Deutschland gilt gem dem B rgerlichen Gesetzbuch (BGB) der Grundsatz, dass Erkl rungen demjenigen zuzurechnen sind, aus dessen Sph re sie tats chlich stammen. Viele Fragen zum Vertragsschluss lassen sich daher bereits mit den Auslegungsregeln 133, 157 BGB l sen. Automatisi ert agierende Systeme handeln, wie in den Beispielen oben dargelegt, nach voreingestellten Bedingungen und folgen einem vom Menschen vorgegebenen Algorithmus. Die Person, die die KI nutzt, hat den generellen Willen, zu einem zuvor definierten Zeitpunkt ode r bei Eintritt bestimmter Bedingungen eine Willenserkl rung abzugeben. Die Willenserkl rung kann dieser Person zugerechnet werden. Die Erkl rungen eines autonom agierenden Systems sind zwar nicht vorhersehbar, aber auch dieses System kann Willenserkl runge n erst generieren, wenn die Nutzer dies so wollen. Dieser Person ist bewusst, dass das System Erkl rungen abgeben k nnte. Erkl rungen des Systems lassen sich daher der Person zurechnen aus deren Sph redie Erkl rungen stammen. F r die Frage der Zurechnung von Willenserkl rungen, die von automatisiert oder autonom agierenden Systemen abgegeben werden, bieten Regelungen wie im deutschen BGB bereits einen passenden Rechtsrahmen. Eine Regelungsl cke erscheint uns daher nicht zu bestehen. Berlin, August 2020 Deutscher Industrie - und Handelskammertag Wer wir sind: Unter dem Dach des Deutschen Industrie - und Handelskammertags (DIHK) haben sich die 79 Industrie - und Handelskammern (IHKs) zusammengeschlossen. Unser gemeinsames Ziel: Beste Bedingungen f r erfolgreiches Wirtschaften. Auf Bundes - und Europaebene setzt s ich der DIHK f r die Interessen der gesamten gewerblichen Wirtschaft gegen ber Politik, Verwaltung und ffentlichkeit ein. Denn mehrere Millionen Unternehmen aus Handel, Industrie und Dienstleistung sind gesetzliche Mitglieder einer IHK - vom Kiosk -Besit zer bis zum Dax -Konzern. So sind DIHK und IHKs eine Plattform f r die vielf ltigen Belange der Unternehmen. Diese b ndeln wir in einem verfassten Verfahren auf gesetzlicher Grundlage zu gemeinsamen Positionen der Wirtschaft und tragen so zum wirtschaftspol itischen Meinungsbildungsprozess bei. Dar ber hinaus koordiniert der DIHK das Netzwerk der 140 Auslandshandelskammern, Delegationen und Repr sentanzen der Deutschen Wirtschaft in 92 L ndern. Er ist im Register der Interessenvertreter der Europ ischen Komm ission registriert (Nr. 22400601191 -. Ansprechpartner im DIHK Annette Karstedt -Meierrieks Bereich Recht Referatsleiterin Datenschutz Tel.: +49 30 20308 - 2706 E-Mail: karstedt -meierrieks.annette@dihk.de Doris M ller Bereich Recht Leiterin des Referats Recht des Geistigen Eigentums Tel.: +49 30 20308 - 2704 E-Mail: moeller.doris@dihk.de Annelise Badinand Legal Affairs Director European Economic Law, German and International Commercial Law Tel.: +32 -2-286-1663 E-Mail: badinand.annelise@dihk.de",de
UC Berkeley Center for Human-Compatible AI (United States),F2665648,06 August 2021,Academic/research Institution,Small (10 to 49 employees),United States,C H A I P o s i t i o n P a p e r o n t h e E U A r t i ,cy
CrowdStrike (United States),F2665647,06 August 2021,Company/business,Large (250 or more),United States,"R E Q U E S T F O R C O M M E N T R E S P O N S E P r o p o s a l f o r a R e g u l a t i o n o f t h e E u r o p e a n P a r l i a m e n t a n d o f t h e C o u n c i l : L a y i n g D o w n H a r m o n i s e d R u l e s o n A r t i c i a l I n t e l l i g e n c e a n d A m e n d i n g C e r t a i n U n i o n L e g i s l a t i v e A c t s A u g u s t 6 2 0 2 1 I . I N T R O D U C T I O N I n r e s p o n s e t o t h e E u r o p e a n C o m m i s s i o n s r e q u e s t f o r p u b l i c c o n s u l t a t i o n o n A r t i c i a l I n t e l l i g e n c e , C r o w d S t r i k e o f f e r s t h e f o l l o w i n g v i e w s . W e a p p r o a c h t h e s e q u e s t i o n s f r o m t h e s t a n d p o i n t o f a l e a d i n g i n t e r n a t i o n a l , U S - h e a d q u a r t e r e d c l o u d - n a t i v e c y b e r s e c u r i t y p r o v i d e r t h a t d e f e n d s g l o b a l l y d i s t r i b u t e d e n t e r p r i s e s f r o m g l o b a l l y d i s t r i b u t e d t h r e a t s . C r o w d S t r i k e o f f e r s i n s i g h t s i n f o r m e d b y m u l t i p l e p r a c t i c e a r e a s : c y b e r t h r e a t i n t e l l i g e n c e ; p r o a c t i v e , i n c i d e n t r e s p o n s e a n d m a n a g e d s e c u r i t y s e r v i c e s ; a n d a n A I - p o w e r e d s o f t w a r e - a s - a - s e r v i c e c y b e r s e c u r i t y p l a t f o r m a n d m a r k e t p l a c e . A c c o r d i n g l y , t h i s p e r s p e c t i v e i s i n f o r m e d b y C r o w d S t r i k e s r o l e i n p r o t e c t i n g o r g a n i z a t i o n s f r o m d a t a b r e a c h e s a n d a v a r i e t y o f o t h e r c y b e r t h r e a t s . I I . C O M M E N T S A . A I a n d M a c h i n e L e a r n i n g T h e w i d e n i n g a d o p t i o n o f A r t i c i a l I n t e l l i g e n c e ( A I ) / M a c h i n e L e a r n i n g ( M L ) p e r i o d i c a l l y r a i s e s f e a r s a b o u t a u t o m a t e d d e c i s i o n - m a k i n g , s u r v e i l l a n c e , a l g o r i t h m i c b i a s , a n d o t h e r n e g a t i v e e x t e r n a l i t i e s . I n s p e c i c i n s t a n c e s , t h e s e c o n c e r n s m a y w a r r a n t s u s p i c i o n a n d i n t e n s e s c r u t i n y . H o w e v e r , i t i s c r i t i c a l f o r p o l i c y m a k e r s t o u n d e r s t a n d t h a t A I / M L a l s o h a s t h e o p p o r t u n i t y t o d r i v e p o s i t i v e s o c i a l o u t c o m e s ; i s a l r e a d y w i d e l y d e p l o y e d i n i m p o r t a n t i n s t a n c e s d r i v i n g s u c h o u t c o m e s ; a n d c r e a t e s t h e o p p o r t u n i t y f o r i n n o v a t i o n i n a v a r i e t y o f i m p o r t a n t s p h e r e s , i n c l u d i n g i n d u s t r i e s s u c h a s m e d i c i n e a n d e d u c a t i o n . O u r c o m m e n t s w i l l f o c u s o n t h e u s e o f A I / M L w i t h i n c y b e r s e c u r i t y s o l u t i o n s . L e g a c y c y b e r s e c u r i t y s o l u t i o n s u s e d t o r e l y o n s c a n n i n g l e s a g a i n s t s i g n a t u r e s o f p r e v i o u s l y i d e n t i e d m a l i c i o u s l e s . T h i s p r o c e s s w a s o n e r o u s , r e s o u r c e - i n t e n s i v e , a n d c o u l d b e e a s i l y c i r c u m v e n t e d t h r o u g h t h e u s e o f n o v e l o r s l i g h t l y m o d i e d a p p r o a c h e s . N e x t - g e n e r a t i o n s o l u t i o n s , w h i c h l e v e r a g e A I / M L , c a n d e t e c t p r e v i o u s l y u n k n o w n t h r e a t s b a s e d o n t h e i r c h a r a c t e r i s t i c s o r b e h a v i o r s . T h i s o f f e r s m u c h m o r e r o b u s t p r o t e c t i o n a g a i n s t t h r e a t a c t i v i t y . L e v e r a g i n g A I / M L c a n a c h i e v e s u c c e s s a g a i n s t u n k n o w n u n k n o w n s . F o r e x a m p l e , a m a c h i n e l e a r n i n g m o d e l , s h i p p e d t o C r o w d S t r i k e s F a l c o n P l a t f o r m c u s t o m e r s i n S e p t e m b e r 2 0 1 9 , d e t e c t e d w i t h h i g h c o n d e n c e t h e S U N S P O T m a l w a r e , w h i c h w a s c e n t r a l t o a s o p h i s t i c a t e d c a m p a i g n t h a t t a r g e t e d h i g h - v a l u e g o v e r n m e n t o r g a n i z a t i o n s i n l a t e 2 0 2 0 - e a r l y 2 0 2 1 . 1 T h i s i s o n e o f m a n y i n s t a n c e s o f A I / M L t y p i f y i n g t h e b e s t w a y s t o d e f e a t t h r e a t a c t o r s u s i n g n e w o r t a i l o r e d t o o l s , t a c t i c s , t e c h n i q u e s , o r p r o c e d u r e s . B . A I a n d C y b e r s e c u r i t y I n c y b e r s e c u r i t y , A I i s a n a d v a n t a g e , e s p e c i a l l y w h e n a d d e d t o e n t e r p r i s e s e c u r i t y s o l u t i o n s . 2 C y b e r s e c u r i t y t h r e a t s a r e e x c e p t i o n a l l y b r o a d , a n d f o r t o o l o n g i n d u s t r y p l a y e r s h a v e f o c u s e d o n n a r r o w s o l u t i o n s . N o b o x o n a n e t w o r k o r a s i n g l e - p u r p o s e s o f t w a r e a g e n t w i l l a d d r e s s t h e f u l l s c o p e o f t h e p r o b l e m . S e c u r i t y t e a m s d e m a n d c o n t e x t u a l a w a r e n e s s a n d v i s i b i l i t y f r o m a c r o s s t h e i r e n t i r e e n v i r o n m e n t s , i n c l u d i n g w i t h i n c l o u d a n d e p h e m e r a l e n v i r o n m e n t s . I n d e e d , w i t h t h e h e l p o f A I , C r o w d S t r i k e c a n s t o p a n a t t a c k i n i t s t r a c k s b e c a u s e s u c h t e c h n o l o g y w o r k s f a s t e r t h a n c o n v e n t i o n a l s i g n a t u r e - b a s e d o r i n d i c a t o r o f c o m p r o m i s e ( I O C ) - b a s e d p r e v e n t i o n . A s s u c h , C r o w d S t r i k e r e c o m m e n d s t h a t t h e E C c o n s i d e r e x e m p t i o n s t o a n y f u t u r e r e g u l a t i o n s c o n c e r n i n g A I . L i k e i n o t h e r r e a l m s o f E u r o p e a n U n i o n r e g u l a t i o n 3 , d u e t o t h e a d v a n t a g e s A I b r i n g s t o c y b e r s e c u r i t y , w e e n c o u r a g e t h e E C t o c o n s i d e r a c y b e r s e c u r i t y e x e m p t i o n . U l t i m a t e l y , C r o w d S t r i k e u n d e r s t a n d s t h a t a c o n c e r n w i t h A I i s t h e p o s s i b l e h a r m t o i n d i v i d u a l s , b u t f o r A I , l i k e f o r a n y o t h e r t e c h n o l o g y , t h e c o n t e x t i n w h i c h i t i s u s e d , r a t h e r t h a n t h e m e r e f a c t t h a t i t i s i n c o r p o r a t e d , i s m a t e r i a l . R e g u l a t i n g A I f o r t h e s a k e o f t h e t e c h n o l o g y r a t h e r t h a n i t s a p p l i c a t i o n i s n o t t h e b e s t a p p r o a c h t o f o s t e r - i n n o v a t i v e s o l u t i o n s t o d i f c u l t p r o b l e m s . C o n v e r s e l y , w e r e c o m m e n d e m b r a c i n g c o m m o n E U 3 E U r e g u l a t i o n s r e g u l a r l y a c k n o w l e d g e t h e u n i q u e i m p o r t a n c e o f c y b e r s e c u r i t y i n n o v a t i o n . T h e p r o p o s e d e P r i v a c y R e g u l a t i o n i n c l u d e s a c y b e r s e c u r i t y e x e m p t i o n . S i m i l a r l y , t h e G e n e r a l D a t a P r o t e c t i o n R e g u l a t i o n s R e c i t a l 4 9 s p e c i c a l l y i d e n t i e s c y b e r s e c u r i t y a s a l e g i t i m a t e i n t e r e s t f o r t h e p r o c e s s i n g o f p e r s o n a l d a t a . 2 M i c h a e l S e n t o n a s , H o w A r t i c i a l I n t e l l i g e n c e i s B e c o m i n g a K e y W e a p o n i n t h e C y b e r s e c u r i t y W a r , C r o w d S t r i k e B l o g , O c t . 2 4 , 2 0 1 7 , h t t p s : / / w w w . c r o w d s t r i k e . c o m / b l o g / h o w - a r t i c i a l - i n t e l l i g e n c e - i s - b e c o m i n g - a - k e y - w e a p o n - i n - t h e - c y b e r s e c u r i t y - w a r / . 1 S v e n K r a s s e r , S t e l l a r P e r f o r m a n c e s : H o w C r o w d S t r i k e M a c h i n e L e a r n i n g H a n d l e s t h e S U N S P O T M a l w a r e , C r o w d S t r i k e B l o g ( J a n . 2 1 , 2 0 2 1 ) h t t p s : / / w w w . c r o w d s t r i k e . c o m / b l o g / s t e l l a r - p e r f o r m a n c e s - h o w - c r o w d s t r i k e - m a c h i n e - l e a r n i n g - h a n d l e s - t h e - s u n s p o t - m a l w a r e / . a p p r o a c h e s t o p r o t e c t i n g t h e f u n d a m e n t a l r i g h t s o f i n d i v i d u a l s i n a t e c h n o l o g y - n e u t r a l m a n n e r . W h e n c r e a t i n g r e g u l a t i o n s o n t h e s a f e u s e o f A I , t h e E C s h o u l d c o n s i d e r a d o p t i n g l a n g u a g e s i m i l a r t o t h e G e n e r a l D a t a P r o t e c t i o n R e g u l a t i o n s ( G D P R ) r e q u i r e m e n t t h a t o r g a n i z a t i o n s i m p l e m e n t s a f e g u a r d s a p p r o p r i a t e t o t h e r i s k t o p r o t e c t p e r s o n a l i n f o r m a t i o n . T h i s a p p r o a c h i n c e n t i v i z e s o r g a n i z a t i o n s t o t a k e i n t o a c c o u n t m o d e r n , r a p i d l y - e v o l v i n g d a t a b r e a c h r i s k s p o s e d b y c y b e r s e c u r i t y t h r e a t s f r o m e - c r i m e , h a c k t i v i s t , a n d n a t i o n s t a t e a c t o r s u s i n g t a c t i c s s u c h a s r a n s o m w a r e , s u p p l y c h a i n a t t a c k s , o r m a l w a r e - l e s s i n t r u s i o n s . I I I . C O N C L U S I O N T h e E C s p r o p o s e d r e g u l a t i o n p r o v i d e s a t h o u g h t f u l a n a l y s i s o f a c o m p l e x l e g a l a n d p o l i c y a r e a . A s t h e E C u p d a t e s i t s r e g u l a t i o n s , w e r e c o m m e n d c o n t i n u e d e n g a g e m e n t w i t h i n t e r n a t i o n a l s t a k e h o l d e r s . A d v e r s a r i e s i n n o v a t e a t a r e c o r d - p a c e , a n d i t s i m p o r t a n t t o e m p o w e r d e f e n d e r s t o l e v e r a g e g l o b a l d a t a o w s , b i g d a t a a n a l y t i c s , a n d m a c h i n e l e a r n i n g t o p r o t e c t a g a i n s t e v e r - e v o l v i n g t h r e a t s . F i n a l l y , b e c a u s e t h e u n d e r l y i n g t e c h n o l o g i e s e v o l v e f a s t e r t h a n l a w a n d p o l i c y , w e r e c o m m e n d a n d e m p h a s i z e t h a t a n y p r o p o s e d l e g i s l a t i v e u p d a t e s f o c u s o n p r i n c i p l e s r a t h e r t h a n p r e s c r i p t i v e r e q u i r e m e n t s a n d i n c l u d e a m e c h a n i s m f o r p e r i o d i c r e v i s i o n s . I V . A B O U T C R O W D S T R I K E C r o w d S t r i k e I n c . ( N a s d a q : C R W D ) , a g l o b a l c y b e r s e c u r i t y l e a d e r , i s r e d e n i n g s e c u r i t y f o r t h e c l o u d e r a w i t h a n e n d p o i n t p r o t e c t i o n p l a t f o r m b u i l t f r o m t h e g r o u n d u p t o s t o p b r e a c h e s . T h e C r o w d S t r i k e F a l c o n p l a t f o r m s s i n g l e l i g h t w e i g h t - a g e n t a r c h i t e c t u r e l e v e r a g e s c l o u d - s c a l e A I a n d o f f e r s r e a l - t i m e p r o t e c t i o n a n d v i s i b i l i t y a c r o s s t h e e n t e r p r i s e , p r e v e n t i n g a t t a c k s o n e n d p o i n t s o n o r o f f t h e n e t w o r k . P o w e r e d b y t h e p r o p r i e t a r y C r o w d S t r i k e T h r e a t G r a p h , C r o w d S t r i k e F a l c o n c o r r e l a t e s o v e r 3 t r i l l i o n e n d p o i n t - r e l a t e d e v e n t s p e r w e e k i n r e a l t i m e f r o m a c r o s s t h e g l o b e , f u e l i n g o n e o f t h e w o r l d s m o s t a d v a n c e d d a t a p l a t f o r m s f o r s e c u r i t y . W i t h C r o w d S t r i k e , c u s t o m e r s b e n e t f r o m b e t t e r p r o t e c t i o n , b e t t e r p e r f o r m a n c e a n d i m m e d i a t e t i m e - t o - v a l u e d e l i v e r e d b y t h e c l o u d - n a t i v e F a l c o n p l a t f o r m . T h e r e s o n l y o n e t h i n g t o r e m e m b e r a b o u t C r o w d S t r i k e : W e s t o p b r e a c h e s . L e a r n m o r e : h t t p s : / / w w w . c r o w d s t r i k e . c o m / . V . C O N T A C T W e w o u l d w e l c o m e t h e o p p o r t u n i t y t o d i s c u s s t h e s e m a t t e r s i n m o r e d e t a i l . P u b l i c p o l i c y i n q u i r i e s s h o u l d b e m a d e t o : D r e w B a g l e y C I P P / E D r . C h r i s t o p h B a u s e w e i n C I P P / E V P & C o u n s e l , P r i v a c y a n d C y b e r P o l i c y D i r e c t o r & C o u n s e l , D a t a P r o t e c t i o n & P o l i c y E m a i l : p o l i c y @ c r o w d s t r i k e . c o m 2 0 2 1 C r o w d S t r i k e , I n c . A l l r i g h t s r e s e r v e d . C r o w d S t r i k e , t h e f a l c o n l o g o , C r o w d S t r i k e F a l c o n a n d C r o w d S t r i k e T h r e a t G r a p h a r e t r a d e m a r k s o w n e d b y C r o w d S t r i k e , I n c . a n d r e g i s t e r e d w i t h t h e U n i t e d S t a t e s P a t e n t a n d T r a d e m a r k O f c e , a n d i n o t h e r c o u n t r i e s . C r o w d S t r i k e o w n s o t h e r t r a d e m a r k s a n d s e r v i c e m a r k s , a n d m a y u s e t h e b r a n d s o f t h i r d p a r t i e s t o i d e n t i f y t h e i r p r o d u c t s a n d s e r v i c e s . * * *",an
LA POSTE (France),F2665608,06 August 2021,Company/business,Large (250 or more),France,"Ao t 2021 1 Selon Le Groupe La Poste, le Hub France IA et la Villa Numeris , l intelligence artificielle (IA) ouvre des possibilit s multiples pour l innovation et la croissance et nous souhaitons saisir tout son potentiel. Le Groupe La Poste, qui pla ce le num rique et l IA parmi ses axes prioritaires et strat giques de d veloppement dans le cadre notamment du plan strat gique de La Poste 2030, engag e pour vous , le Hub France IA, association pour la promotion de l'Intelligence artificielle en Fran ce, mot eur et f d ratrice des initiatives en IA en France et la Villa Numeris, association promouvant un mod le europ en du digital bas sur l'humain , ont d cid de mettre en commun leur expertise en vue de s associer pleinement aux d bats europ ens sur l IA et l thique . Nous nous r jouissons par cons quent de pouvoir partager nos positions l occasion de la consultation publique de la Commission europ enne sur la proposition de r glement du Parlement europ en et du Conseil tablissant des r gles harmon is es en mati re d intelligence artificielle ( Artificial Intelligence Act) et modifiant certains actes l gislatifs de l Union. Nous saluons tout d abord l ambition et l initiative de la Commission europ enne de positionner l Union europ enne (UE) comme un lead er politique en mati re de technologies et de proposer une troisi me voie europ enne . Apr s avoir influenc le monde en mati re de donn es personnelles avec le RGPD, l UE cherche en effet aujourd hui prot ger les Contribution commune du Groupe La Poste, du Hub France IA et de la Villa Numeris la consultation de la Commission europ enne sur l Artificial Intelligence (AI) Act Ao t 2021 2 ressortissants europ ens en s assuran t que l intelligence artificielle soit d ploy e dans le respect de ses valeurs thiques et de ses droits fondamentaux. Nous convenons que l IA ne r pondra ces attentes que si sa mise en place s accompagne d un cadre exigeant qui pr serve l a confiance d es citoyens et s assure que son utilisation apporte un b n fice la soci t tout enti re. Cependant, nous sommes attentifs la comp titivit des entreprises europ ennes dans ce domaine absolument clef. Il est important que cette initiative trouve un j uste (et d licat) quilibre entre la promotion de l innovation et un texte protecteur des droits fondamentaux. C est pourquoi, nous consid rons qu en l tat de la proposition de r glement, cet quilibre n est pas atteint . Nous identifions un r el risque p our la comp titivit des entreprises si le texte est publi en l tat , en particulier pour les raisons suivantes : La proposition englobe tr s largement tout type de solutions IA dont certaines sont d j largement exploit es et valid es ; L app roche haut risque, bien que tout fait pertinente, consid re un p rim tre tr s large de syst mes qui fait porter des exigences sur des syst mes IA dans des secteurs encore peu mature s ; La mise en conformit est prescriptive pour les syst mes haut ris que et appar a t sur de nombreux points particuli rement complexe et co teu se mettre en uvre ; La proposition est floue sur plusieurs points g n rant de nombreuses incompr hensions la fois sur le porteur de l obligation de certification que sur la mise en uvre de s exigences de conformit . Nous avons quatre principales pistes de recommandations : - La premi re consiste ce que l AI Act prenne davantage en consid ration les finalit s des syst mes d IA concern s . En ignorant ces finalit s ou les usages p r vus de l I A, le texte impose des obligations g n rales disproportionn es un grand nombre de syst mes ; - La deuxi me consiste r orienter la proposition pour privil gier une approche ex post en v rifiant a posteriori la conformit des syst mes aux oblig ations d cri tes dans la proposition de r glement ; - La troisi me consiste ce que le texte soit moins prescriptif en fonction du niveau de risque consid r . Il convient , par exemple , de s appuyer sur les bonnes pratiques d j mises en place par l industrie ; La quatri me consiste affiner les d finitions du texte , en particulier celle de l IA. Il convient que le texte conserve un p rim tre proportionn aux objectifs poursuivis. Nous d taillons ci -dessous nos interrogations, commentaires et recommandations sur l ensemble du texte. Un texte qui devrait plus insister sur les bonnes pratiques mettre en place dans le respect des droits fondamentaux et en vue de promouvoir l innovation et la comp titivit des entreprises Nous saluons l ambition de r guler l intelligence artifi cielle pour proposer une IA digne de confiance et respectueuse des droits fondamentaux. Cependant, le texte reste tr s centr sur la s curit et les garanties apport es par les entreprises pour disposer d une IA de confiance . Mais il est important de s ass urer galement que ces garanties ne nuisent pas la comp titivit Ao t 2021 3 des entreprises europ ennes et ne constituent pas des freins l innovation en Europe : l impact de chaque garantie devrait donc tre valu e et proportionn e . L'objectif principal, pour l a Commission, est donc de d velopper une intelligence artificielle digne de confiance , reposant sur une technologie thique pr servant la comp titivit et aidant la consolidation d une IA souveraine au sein de l Union europ e nne. Nous soutenons l ambition de cette r gulation des IA fond e sur une approche des risques, n anmoins nous souhaitons souligner que cela ne doit pas se faire au d triment de l innovation et d u business de notre cosyst me europ en par rapport la conc urrence mondiale . En effet, certains points du r glement, en l tat de leur formulation, laissent craindre des contraintes de mises en uvre pouvant asphyxier certaines structures, en particulier les startups, mais pas seulement, dans leur d marche d innov ation . Nous craignons en effet que le texte, dans son tat actuel, renforce les acteurs trangers qui ne seront pas soumis cette r glementation. M me si ce texte est louable bien des gards, nous nous inqui tons de sa mise en pratique qui semble comp lexe , en particulier pour les plus petites structures, en l tat actuel des aspects techniques . C est pourquoi, nous sugg rons d insister sur les bonnes pratiques mettre en place dans le respect des droits fondamentaux et en vue de ne pas entraver l inno vation. En effet, il est n cessaire de mieux comprendre et utiliser l IA notamment : o en favorisant une culture de la donn e par de vastes programmes de sensibilisation et de formation ; o en promouvant des mod les d anonymisation profonde permettant de lutt er cont re les discriminations . Un texte qui reste encore impr cis sur des concepts fondamentaux a) Une d finition de l IA trop large et pouvant entra ner de lourdes difficult s de mise en place pour les entreprises L AI Act a vocation s appliqu er c ertains syst mes d intelligence artificielle , expression qui a t pr f r e celle d intelligence artificielle , laquelle renvoie plus une discipline, une science, qu des usages. La technologie est non seulement plurielle, mais elle a vo cation s appliquer des domaines et pour des usages tr s vari s. Le syst me vis est d fini, l article 1, comme : un logiciel d velopp l aide d une ou plusieurs des techniques et approches num r es l annexe I de la proposition et capable, p our un ensemble donn d objectifs d finis par l homme, de g n rer des r sultats tels que des contenus, des pr dictions, des recommandations ou des d cisions influen ant les environnements avec lesquels ils interagissent . Malgr une volont d clar e par la Co mmission de neutralit technologique et d adaptation l volution technologique, que nous comprenons, la d finition retenue de l IA est tr s large et peut tre amen e voluer, ce qui pourrait poser des difficult s d application dans l approche par les r isques . L annexe I num re par ailleurs trois cat gories de techniques algorithmiques, en substance les syst mes (auto -)apprenants, les syst mes logiques et les syst mes statistiques. Cette annexe a vocation tre modifi e et , par cons quent, on peu t note r Ao t 2021 4 que cette d finition est amen e voluer notamment par des actes d l gu s ce qui est source d ins curit juridique . Nous consid rons qu avec une d finition aussi large de l IA, il appara t que de nombreuses applications logicielles risquent d t re inc luses dans le p rim tre du texte , ce qui pourrait induire des co ts r troactifs pour mettre en conformit des syst mes d j en production et nuire l innovation pour la conception de nouveaux syst mes . Or, dans un contexte de comp titivit inter nationale, il est essentiel d encourager le d veloppement technologique. Nous recommandons que la d finition de l IA se limite au point a) relatif l apprentissage automatique. En effet, si l id e de ce tte prop osition de r glement vise faire r guler de nouvelles technolo gies fond es sur les donn es et l apprentissage automatique , il ne convient pas d encadrer des solutions d j prouv es (les approches symboliques ou les statistiques par exemple qui sont d j industrialis es) qui ne pr sentent pas l es m mes d fis des sy st mes d IA apprentissage automatique. b) Un p rim tre pr ciser La pr cision des te rmes est souvent insuffisante. A titre d exemple : natural person ou personne physique : ce terme peut poser des difficult s pratiques, par e xemple dans le secteu r bancaire, quand une TPE, ne comprenant qu une seule personne (le cr ateur) demande un cr dit, la distinction entre personne physique et personne morale est t nue. Nous recommandons que ces termes soient d finis avec beaucoup plus d e pr cisions car la r daction actuelle autorise de multiples interpr tations, ce qui constitue un risque juridique . Un texte qui soul ve des c ommentaires sur l approche fond e sur l valuation du risque et l alignement d obligations proportionn es associ es La Commission a privil gi une o ption d j pressentie par ses pr c dents crits : une approche par graduation des risques. La d marche de la Commission europ enne est la suivante : - Une pr -qualification des risques inh rents l utilisation et au d ploiement de l intelligence artificie lle ; - Un alignement, en miroir de cette pr -qualification, d obligations gradu es et proportionn es. De mani re g n rale, nous accueillons favorablement une approche par les risques qui met sur un pied d gali t les entreprises qui op rent des activit s s imilaires. Il est important d instaurer un traitement quitable en fonction du risque qu une activit donn e suscite, afin d assurer des garanties similaires ind pendamment du fait de savoir qui g re cette acti vit . Tous les syst mes d IA ne sont donc pas concern s par l encadrement envisag au regard de la variabilit des obligations en lien avec le niveau de risque. En outre, les usages vis s sont les usages professionnels. En effet, l utilisateur d un syst m e d IA des fins personnelles et non - professi onnelles est exclu du champ d application du texte (voire la d finition d un utilisateur l article . Ao t 2021 5 On peut noter que les fournisseurs, importateurs et les utilisateurs des syst mes d IA risque lev sont galement directement soumis une s rie d obligations (Articles 16 et peuvent faire l objet d un contr le par une autorit nationale (articles 30 . Enfin , il nous semble aussi important de consid rer le cas de mod les cr s dans le cadre de syst me s qui ne sont pas ha ut risque mais qui pourrai ent tre d tourn s de leurs finalit s pour rentrer dans ce cadre. Concernant les usages vis s, la proposition de r glement devrait se limiter explicitement aux usages concernant les perso nnes physiques. a) Sur les syst mes haut risque (Titre I II Article 6 - Sur la d finition des syst mes IA haut risque (article Nous sommes convaincus que les applications IA consid r es comme haut risque doivent r pondre des crit res d fin is s il existe des menaces av r es pour la sant , la vie ou les droits fondamentaux. La d finition tr s large des syst mes IA haut risque pr vue au titre III semble avoir pour effet de faire peser d importantes obligations de nombreux acteurs ce qui po urrait avoir pour cons quence un ralentissement de l inno vation en Europe. Par ailleurs, il est noter que les dispositions de l article 7 pr voient une volution de l Annexe III tablissant une liste de syst mes IA consid r s haut risque par l adoptio n d actes d l gu s. Nous sommes conscients des volutio ns rapides en mati re d IA et donc des d finitions concern es toutefois, le recours aux actes d l gu s ne semble pas assurer la s curit juridique n cessaire. Nous estimons que cette d finition dem eure trop large ce qui pourra faire peser d importantes o bligations. Nous recommandons de mettre en place une balance b n fice/risque des volutions technologiques en vue de promouvoir l innovation. En effet, en l tat des mesures propos es par ce texte, i l existe un risque de limitation de l innovation, notamme nt li es aux obligations de mises en conformit (cf. Sur l obligation de mener des analyses de risque et de conformit (articles 9, 19 et . Il pourrait tre pertinent de d terminer plusieurs niv eaux de syst me haut risque et n imposer des dispositio ns strictes pour le plus haut niveau. - Sur l' obligation d utiliser des ensembles de donn es sans erreur (article Afin d utiliser l IA de fa on thique, il faut la ma triser et qu elle soit d un haut niveau de qualit . Concernant les obligations, l article 10 impose en particulier une obligation d utiliser des ensembles de donn es sans erreur, ce qui est n est absolument pas r alisable en pratique . Il serait pr f rable de retirer cette obliga tion. Le concept de z ro erreur dans les donn es est con traire avec la notion d IA qui int gre conceptuellement cette capacit de reproduire une analyse humaine. Ao t 2021 6 De la m me mani re, si la constitution de jeux de donn es sans biais est souvent consid r e c omme un enjeu important de l IA , ils restent in vitables . Il est important de mettre en place des proc dures pour les mesurer . Les fournisseurs d IA devront fournir leur meilleur effort pour se pr munir des discriminations pouvant r sulter de l existence d e biais. Par ailleurs, le texte ne semble pas assez pre ndre en compte les donn es n cessaires (plus particuli rement leur qualit ) l IA. - Sur l obligation de mener des analyses de risque et de conformit (articles 9, 19 et Il est fait r f rence au x articles 9, 19 et 43 l obligation, pour les op rateu rs de mener des analyses de risque et de conformit l ensemble des l gislations applicables. Or, du fait des similitudes que ce texte peut avoir avec le RGPD, on peut indiquer qu une analyse d impac t relative la protection des donn es (AIPD) est n cess aire dans les cas notamment o un projet comprend une innovation technologique et en la mati re quel que soit le nombre de conditions remplies, une telle analyse est pr conis e lors de l utilisation d une IA. Nous nous demandons quelle sera l articulatio n de l analyse de risques et de conformit fix e par le texte et l AIPD pr vue l article 35 du RGPD ? Par ailleurs, ces analyses n cessitent d importants moyens techniques et financiers pour chaque entreprise en vue de r pondre ces mesures de fa on opt imale . Les entreprises devront faire face des co ts suppl mentaires qui pourraient avoir un impact n gatif sur l innovation . En pratique, l exigence que la conformit soit v rifi e d s qu une mise jour est r alis e demeure tr s co teuse , impossible en temps r el voire peu pertinente s agissant de certaines mises jour. Les exigences de tra abilit sur toute la dur e de vie du syst me ne sont pas tenables en mati re de co ts et capacit s de stocka ge, et m me incompatible s avec d autres r glementation s comme le RGPD . Nous craignons qu in fine cette obligation ait des effets de bord n gatifs et d couragent les fournisseurs de mettre jour leurs mod les pour qu ils restent efficaces dans le temps co mpte tenu des d marches de remise en conformit n cessair e ces mises jour. - Sur les logs (ou journaux ) g n r s automatiquement (article Selon l article 12 , les fournisseurs d IA haut risque devr ont conserv er les logs (ou journaux ) g n r s automatiquement. Cette obligation nous semble contraignante compte tenu de la volum trie importante des logs qui seraient conserver : conserver les logs de toutes les exp rimentations ayant conduit au syst me final serait beaucoup trop co teux . Il suffit, selon nous, de conserver les logs de l exp rimentation (avec les jeux de donn es correspondants) qui a produit le syst me final. - Sur le contr le humain (article L article 14 pr voit un contr le et une surveillance de l IA humains . Ao t 2021 7 Il convient de noter que toute conception d un algorithme ne peut se faire sans intervention humaine. La supervision du syst me d IA nous para t galement importante pour d tecter les d rives par rapport l usage initialement pr vu de l IA. - Sur les composants IA (article Il est fait r f rence aux composa nts IA dans la d finition des syst mes IA haut risque. Les responsabilit s de chaque op rateur doivent correctement s articuler. Sous l angle de la responsabilit et de la conformit , commen t traiter des briques d IA propos es par des fournisseurs, mai s assembl es par l utilisateur ? Aux termes de l article 26, l importateur de ces composants devra -t-il de la m me mani re s assurer que les analyses de conformit ont t effectu es par le fournisseur ? Nous comprenons et soutenons qu il est n cessaire de disposer d une cha ne de con fiance en la mati re mais il sera impossible de proc der une valuation compl te de ce champ. Nous nous interrogeons en effet, sur la responsabilit de chaque acteur notamment dans le cas de figure o l application labor e par un fournisseur devrait tre modifi e par l utilisateur. Quelle sera galement la responsabilit engag e dans le cadre d une relation entre un fournisseur de brique technologique et un producteur de solution ? b) Sur le marquage CE de conformit (marquage CE) (articles 24 et 4 Le marquage CE de conformit (marquage CE), un marquage par lequel un fournisseur indique qu un syst me d IA est conforme aux exigences nonc es au titre III, chapitre 2, de la proposition de r glement et d autres textes l gislatifs applicables de l Union harmonisant les conditions de commercialisation des produits pr voyant son apposition. En effet, la proposition de r glement pr voit que les syst mes d'IA haut risque portent le marquage CE pour indiquer leur conformit au texte afin qu'ils pui ssent circuler librement dans le march int rieur (article 49 d e la proposition de r glement). Concernant la certification, nous pouvons nous interroger sur l articulation de ces nouvelles exigences en mati re de certification avec les instances de normal isation d j en place (n ormes ISO, marquage CE, directive Machines, etc .). De la m me fa on, les syst mes IA d j en exploitation devront -ils tre certifi s a posteriori ? Si oui selon quelles modalit s ? En effet, la mise en conformit se faisant avant la mise sur le march , qu adviendra -t-il des solutions d j prouv es, qui m me haut risque n aurait jamais pos de probl me particulier depuis leur mise sur le march ? Les co ts n ayant pas t anticip s, ainsi que les contraintes et exigences de r gleme ntation, il semble compl exe d appliquer ces exigences de fa on r troactive. Les fournisseurs de syst mes d'IA haut risque devront veiller ce que leurs syst mes soient soumis la proc dure d' valuation de la conformit (article avant leur mise sur le march ou leur mise en service. Lorsque leur conformit aux exigences a t d montr e la suite de cette valuation de la conformit , les fournisseurs tablissent une d claration UE de conformit conform ment l'article 48 et apposent le marquage CE d e conformit conform me nt l'article Quelle autorit sera charg e d valuer la conformit en la mati re ? Ao t 2021 8 Une r glementation par l exp rimentation L Artificial Intelligence Act encourage les autorit s nationales comp tentes mettre en p lace des Sandbox es (bacs sable ) r glementaires de l IA afin de tester des technologies innovantes pendant une dur e limit e, sur la base d un plan d essai convenu avec les autorit s comp tentes (Articles 53, 54 et . Cette approche est n cessaire afin d viter de brider l innovation par une r glementation inadapt e. Il s emble toutefois n cessaire de conserver une approche pragmatique au cours de la construction de l encadrement juridique de l IA, pour ne pas faire peser trop de contraintes sur les initiatives technologiques europ ennes. Ce droit l exp rimentation appa ra t un outil int ressant pour appr hender un domaine d innovation forte telle que l IA. Toutefois nous souhaiterions obtenir des pr cisions concernant : o les crit res d ligibilit respecter pour les entreprises qui veulent avoir recours ces sandboxes . En particulier, comment les jeunes entreprises seront identifi es (article ? o les donn es u tilis es dans ces bacs sable . Pour une efficacit renforc e, ces sandboxes devr aient impliquer les r gulateurs de bout en bout . Par ailleurs, nous reco mmandons, en parall le des sandboxes, de permettre aux entreprises de b n ficier d un cadre r glementaire assoupli pendant les phases de pr -production ou pilotes de leurs projets. Le s deux m canismes pourraient coexister pour permettre aux plus petites st ructures d innover dans un contexte plus flexible. L autorit nationale comp tente sur l IA (article et le risque de gouvernance europ enne clat e L article 59 pr vo it la d signation d une autorit nationale comp tente sur l IA pour v rifier et mettre en place des proc dures pour l es analyses, la d signation et la notification des organismes d valuation de conformit . Cette nouvelle r glementation s accompagne d u ne gouvernance europ enne de l IA, dont la politique sera dirig e par un Conseil Europ en de l Intelligence Artificielle, compos de repr sentants des tats membres et de la Commission. Ce conseil assurera la coop ration des autorit s nationales de contr l e et coordonnera l analyse de la Commission par le partage d expertise, des recommandations ou des avis Articles 56 . Toutefois, malgr la cr ation de ce Conseil, la notion de gouvernance semble encore assez floue. Un cadre d'application aussi complex e avec de nombreuses autorit s diff rente s pourrait en gendrer un chevauchement des comp tences entre les autorit s. Nous nous interrogeons sur l autorit (article qui sera charg e d valuer la conformit en la mati re. Il serait opportun de mieux d fi nir les missions de cett e autorit l aune des enjeux de comp titivit internationale et de prendre en consid ration les probl matiques relevant de l innovation, de la recherche et du traitement de donn es industrielles ou non personnelles, mais aussi des crit res de confidentia lit . Ao t 2021 9 Il est essentiel que les d cisions et doctrines des autorit s de contr le nationales soient harmonis es afin d viter les risques de fragmentations dans l application du texte . Il existe en effet un risque de non -alignement , de diff rences d interpr tation, qui, de facto entra neront l mergence de services qui ne seront pas gaux entre services d v elopp s dans certains Etats membres. Notamment pour des questions de secret bancaire, nous souhaitons d emander que pour les banques et assureurs les autorit s comp tentes en mati re de supervision bancaire et assurantielle (BCE, EBA, ACPR) soient nomm ment d sign es . La surveillance du march des syst mes IA haut risque (Tit re VIII article L article 64 pr v oit la possibilit pour les autorit s de surveillance du march d exiger l acc s aux donn es, la documentation et au code source des syst mes IA pour le contr le de conformit des IA haut risque. Nous nous dema ndons comment l acc s au code source doi t tre donn . Il semble difficile de donner acc s un code source distance m me une autorit publique ou un organisme notifi . Non pas par crainte de la divulgation de ce code source par ces entit s mais ces mesu res ne semblent pas respecter les dis positions en mati re de cybers curit et paraissent disproportionn es par rapport l utilit de cette d marche. L acc s au code source distance nous semble difficile mettre en place et entraver la s curit du sys t me, en particulier si ce syst me es t haut risque. Aussi , l acc s aux donn es et la documentation n est pas r alisable sous forme d API comme pr cis dans l article 1 pour les m mes raisons de s curit . Des sanctions particuli rement lourdes (Articles 71 La Commissi on s inspire encore du RGPD tant l argement fond sur le risque encouru en cas de non -respect, en proposant des sanctions particuli rement lourdes en cas de non -respect des r gles dict es (Articles 71 . Les sanctions mises en place par le RGPD sont d j assez importantes, cumul es av ec celles -ci, il est probable que les entreprises ne prennent pas le risque d innover surtout au regard d obligations qui ne pourraient tre respect es en l tat (cf code source, donn es exemptes d erreur, etc) . Il sera it pr f rable de r duire ces sancti ons et de mettre en place une autorit de conseil en IA en vue d aider les entreprises mettre en place leurs projets (bo tes outils, analyse des projets, etc .). La responsabilit et l IA Nous nous demandon s quelles seront au total les dispo sitions qui seront pr vues par la proposition qui devrait tre labor e en fin d ann e par la Commission europ enne et comment elle s articulera avec cette proposition de r glement. *** Ao t 2021 10 Nous contacter Pour le Groupe La Poste : Christelle DEFAYE -GENESTE , Directrice des Affaires Europ ennes et Douani res, Repr sentation de La Poste Bruxelles Tel : +33 (6 71 70 37 32 ou +32 (2 231 56 27 christelle.geneste@laposte. fr Ga lle KULIG , Responsable des Affaires Europ ennes Num riques Tel : +33 (6 22 69 98 82 gaelle.kulig@laposte.fr Pour le Hub France IA : Fran oise SOULIE , Conseiller Scientifique francoise.soulie@hub -fran ceia.fr Caroline CHOPINAUD , Directrice Associ e Tel : + 33 ( 6 07 51 74 80 caroline.chopinaud@hub -franceia.fr Pour la Villa Numeri s : David LACOMBLED , Pr sident david@lacombled.com",fr
CFE-CGC (France),F2665597,06 August 2021,Trade union,Large (250 or more),France,"Draft of the EU Commission on a European AI regulation (Artificial Intelligence Act) 21 April 2021 La Conf d ration fran aise de l encadrement - Conf d ration g n rale des cadres (CFE-CGC) est un syndicat fran ais de salari s fond le 15 octobre 1944 sous le nom de Conf d ration g n rale des cadres (CGC), qui pr sente la caract ristique de d fendre les int r ts d une cat gorie professionnelle sp cifique, l encadrement. Cette sp cificit en fait un syndicat cat goriel ouvert aux cadres, ing nieurs, agents de ma trise et forces de ventes tant dans le secteur priv que public. La CFE-CGC est adh rente de la Conf d ration europ enne des cadres (CEC Euro Managers) et, depuis juin 2014, observatrice de la Conf d ration europ enne des syndicats ind pendants (CESI), qui regroupe essentiellement des organisations du secteur public en Europe. La CFE-CGC se d finit comme un syndicat de proposition pr nant avant toute chose le dialogue et la n gociation. La CFE-CGE s int resse depuis 2018 aux impacts de l IA sur l emploi. Nous avons organis des tables rondes et un cycle de conf rence Y voir Clair afin d initier le d bat et de comprendre les enjeux. Ensuite, nous avons travaill l laboration d une charte pour r pondre la question thique pos e par l intelligence artificielle dans le domaine RH. En effet, l intelligence artificielle se d veloppe tr s largement dans le monde professionnel avec des impacts qui restent encore aujourd hui difficiles mesurer. Tous les m tiers se retrouveront terme impact s par l IA, soit de fa on positive avec une r allocation des t ches forte valeur ajout e vers des emplois augment s, soit de fa on n gative avec un risque de suppression de certains emplois, dont toutes les t ches deviendraient automatisables. Il est donc important de mesurer r guli rement ces impacts r els de l IA sur les emplois l chelle de chaque secteur et de chaque entreprise. L IA va aussi modifier les processus industriels de fa on partielle ou totale s ils peuvent tre int gralement d mat rialis s. Nous pensons que l hybridation deviendra la norme dans l industrie du futur, ce que nous commen ons voir avec l int gration de l IA dans la maintenance pr dictive ou dans les relations clients fournisseurs (optimisation des processus logistiques). Ces optimisations apportent des gains de productivit qu il est important de mesurer afin de permettre une r partition quitable entre les facteurs de production. C est dans ce but que nous avons initi avec d autres syndicats europ ens le projet SecoIADeal, financ par Horizon2020. Ce dernier a galement pour objectif de d finir quelles comp tences seront n cessaires aux managers pour la ma trise du big data et de l apprentissage automatique. Pour terminer, nous constatons que l IA bouleverse les processus RH la fois au moment du recrutement et tout au long de la vie du salari dans l entreprise. Il faut donc en priorit d finir un cadre thique ces pratiques. Pour rappel, la CFE-CGC avait d j r pondu la consultation de f vrier 2020 sur la proposition du HLEG. Nous avions propos une approche Social By Design en compl ment de celle dite du X by design. L id e forte tait de sensibiliser les quipes d experts en m ga donn es aux impacts sociaux de leur travail. Nous avions aussi t interview s par un consultant mandat par la Commission europ enne sur la pertinence de l AI Assessment List. Pour nous, cet outil tait une base de travail int ressante finaliser. Aujourd hui, La CFE-CGC salue la proposition de r glement de la Commission europ enne tablissant un cadre de r gulation en mati re d intelligence artificielle. C est pour nous une bonne chose qu un cadre r glementaire vienne encadrer les pratiques dans les entreprises avec l arriv e du management dit algorithmique . Les enjeux sont grands en termes de responsabilit et de libert avec des outils d aide la d cision qui peuvent se r v ler opaques et g n rateurs de biais. Cr er des obligations et des p nalit s associ es, dans la logique de ce qui avait t fait sur le RGPD, permet de responsabiliser les fournisseurs d IA, tout en informant et en prot geant les utilisateurs d IA. Le point 36 du r glement pr conise de classer les applications d IA li es au monde du travail comme haut risque. Il couvre bien l ensemble des situations (candidats, salari s, ind pendants) et tous les risques associ s aux populations discriminables. La Commission europ enne a bien identifi que le lien de subordination cr e une asym trie entre le salari et l employeur avec une possibilit pour les employeurs d imposer ces syst mes d IA de fa on unilat rale ou par un consentement volontaire vici . Cette asym trie est encore plus forte pour les candidats, qui disposent seulement des droits sur leurs donn es accord es par le RGPD. Nous attirons cependant l attention de la Commission europ enne sur l ventualit de se retrouver face des applications identifi es comme doublement haut risque, c est- -dire li es au monde du travail (Annexe 3 point et utilisant des proc d s de reconnaissance biom trique (Annexe 3 point , et dont les obligations pour le fournisseur ou op rateur d IA ne seront pas claires. Par ailleurs, de fa on plus courante, nous serons confront s des applications li es au monde du travail (Annexe 3 point et ayant des obligations sur la transparence des algorithmes vis es par l article 52, car utilisant des syst mes de reconnaissance des motions. Nous trouvons aujourd hui ce type d application pour le recrutement, par exemple1. L optimisation du processus de recrutement se fait par des syst mes de reconnaissance des motions, afin d valuer au mieux les candidats. Nous pouvons imaginer que ce type de syst me va se p renniser pour, entre autres, tester leur r sistance au stress. Ces applications font aussi une analyse de la voix du candidat travers son rythme et son intensit (prosodie). La voix est consid r e comme une donn e biom trique, car elle permet d idendifier la personne, et peut donc tre soumise aux obligations associ es (Annexe 3 point . C est une des limites de l approche par le risque propos e par la Commission europ enne. Il aurait t plus pertinent de s appuyer sur celle du Federal Government s Data Ethics Commission ( Datenethikkommission ), fond e sur la criticit , beaucoup plus pr cise2. En effet, une granularit plus fine des risques aurait permis une simplification du mod le et donc, des obligations associ es. Pour ce faire, il faudrait d finir des sous-niveaux par criticit dans les mod les haut risque afin d ajouter des obligations claires inh rentes aux outils utilisant des donn es biom triques, par exemple. Dans le cas des applications de recrutement avec utilisation de donn es biom triques, on peut supposer que les fournisseurs d IA devront remplir toutes les obligations li es l article 16 et aux obligations de transparence de l article 52 (syst me de reconnaissance des motions). Les obligations li es aux syst mes d IA utilisant la voix d pendront de la finalit recherch e et d finie par fournisseur d IA. Que se passera-t-il pour ceux qui auront omis de d clarer l une des obligations en pr textant la bonne foi ? C est une des limites du mod le auto-d claratif propos par le r glement. Pour la CFE-CGE, l auto valuation des syst mes haut risque par les fournisseurs d IA n est pas suffisante dans la r gulation propos e, m me si les obligations et p nalit s associ es semblent assez contraignantes pour eux. Nous pr conisons que des autorit s tierces veillent la conformit des syst mes d IA avant la mise sur le march , et que ces conformit s soient syst matiquement fournies aux repr sentants des salari s lors des informations ou consultations li es une introduction de syst me d IA dans le monde professionnel. Ces autorit s devraient aussi avoir la possibilit d auditer ces syst mes d IA afin de v rifier la conformit des produits tout au long de leur cycle de vie. Ceci est d j rendu possible par la demande d une autorit nationale comp tente de l article 16 (point j). Il faut donc rendre obligatoires ces demandes pour les applications haut risque concernant le monde professionnel. Pour toutes les applications d j sur le march dans le domaine des RH et du monde du travail en g n ral, celles-ci devront passer par un processus d valuation strict vu les d rives que nous constatons d j en France et en Europe. 1 2 Qu en est-il pour les syst mes d IA d velopp s par un diteur puis d ploy s dans l entreprise par une quipe interne ou par une soci t de services ? Qui sera responsable de l volution, de l optimisation et du r glage du syst me d IA dans le contexte local d une entreprise ? Fournisseur, utilisateur, distributeur ? De plus, pour entra ner le mod le, que cela soit en mode bac sable ou en production, quelles seront les contraintes sur les donn es et qui en sera responsable au dernier niveau ? Fournisseur, utilisateur, distributeur ? On peut supposer que le fournisseur d IA haut risque devra r pondre aux obligations li es la solution g n rique, puis que chaque entreprise utilisatrice (utilisateur d IA) devra son tour remplir ses obligations en termes de donn es et de cycle de vie du syst me d IA. Aujourd hui, cela n est pas clair dans la r gulation propos e. En tout tat de cause, le r sultat attendu pour les fournisseurs d IA dans le chapitre 3 ne sera pas atteint : Les fournisseurs d IA devraient b n ficier d un ensemble d exigences minimal, mais clair, cr ant une s curit juridique et garantissant l acc s l ensemble du march unique. La CFE-CGE consid re que les obligations d information pour les syst mes d IA haut risque sont insuffisantes pour les salari s. L article 13 du r glement propos oblige les fournisseurs d IA communiquer aux utilisateurs des informations sous forme d une notice d utilisation sur son syst me d IA. La d finition d un utilisateur d IA est donn e par l article 3 : Toute personne physique ou morale, autorit publique, agence ou autre organisme utilisant sous sa propre autorit un syst me d IA, sauf lorsque ce syst me est utilis dans le cadre d une activit personnelle caract re non professionnel. Nous supposons que les salari s pourraient tre consid r s comme un utilisateurs de la solution au m me titre que l employeur. Les op rateurs de solution d IA n ont donc pas d obligation pr cise de communiquer les impacts des syst mes d IA sur les salari s et peu de salari s seront inform s de l existence d une notice utilisation. Nous pensons aussi qu il aurait fallu d finir une analyse relative la protection des donn es (AIPD) d di e au jeu de donn es des syst mes d IA. En effet, une AIPD au sens de RGPD couvre les donn es propres la personne, mais qu en est-il des m tadonn es utilis es dans les mod les d apprentissage des logiciels de reconnaissance d motion humaine utilis s par exemple dans les applications de recrutement distance et faisant appel des syst mes d IA ? De m me, les processus d anonymisation sont-ils suffisants pour garantir l int grit des donn es des personnes ? Qu en est-il de la dur e de conservation de ces donn es ou m tadonn es sachant que ces mod les d apprentissage sont plus pertinents et pr cis si les jeux de donn es sont importants ? De plus, quid des proc dures de r clamation pour les salari s aupr s des autorit s comp tentes ? Nous pensons qu il manque aussi dans l article 13 la notion d explicabilit . La transparence des syst mes d IA ne pourra pas tre totale que si une explicabilit des syst mes d IA est apport e. Pour l ensemble des mod les d apprentissage automatique, l explicabilit devra s appliquer sur tous les l ments du syst me d IA : jeu de donn es, algorithme d apprentissage, mod le, pr diction du mod le. Il est vident que certains syst mes d IA bas s sur des r seaux de neurones entra nent une opacit par un effet bo te noire. Il conviendra alors de s appuyer sur les travaux en cours pour trouver la meilleurs strat gie d explicabilit : explicabilit par construction, explications a posteriori. En tout tat de cause, il existe des solutions pour expliquer les mod les propos s et ne pas risquer d exposer les salari s des d cisions arbitraires. La CFE-CGC consid re que la s curit des donn es des salari s est fondamentale. L article 15 du r glement propos vient pr ciser les obligations des fournisseurs d IA en mati re de robustesse et de cybers curit . Cependant, aucune obligation de test d intrusion n est faite ces fournisseurs d IA et on ne leur fournit aucun r f rentiel technique ou qualification de s curit en annexe. Nous consid rons que le r glement ne permet ces fournisseurs d IA de respecter les obligations nonc es dans l article Pour terminer, il est annonc en propos liminaire que les droits fondamentaux des salari s seront renforc s (article 31 de la charte des droits fondamentaux) par le pr sent r glement. En l tat du r glement propos et la suite de l ensemble de nos remarques, la CFE-CGC s interroge sur le renforcement r el de ces droits pour les salari s. Pour nous, les garde-fous n cessaires leur garantie tels que d finis par l article 31 ne sont pas suffisants. Nous esp rons que les travaux port s par le Conseil de l Europe sur l IA viendront compl ter le r glement pour une intelligence artificielle thique.",fr
Martin Haimerl (Germany),F2665596,06 August 2021,EU citizen,,Germany,"Anmerkungen zum Vorschlag f r die EU -Verordnung zur k nstlichen Intelligenz vom April 2021 Prof. Dr. Martin Haimerl Wissenschaftlicher Direktor Innovations - und Forschungs -Centrum Tuttlingen der Hochschule Furtwangen (IFC) Hochschule Furtwangen | Furtwangen University Hochschulcampus Tuttlingen Kronenstra e 16 78532 Tuttlingen E-Mail : Martin .Haime rl@hs -furtwangen.de Inhalt der KI -Verordnung Feedback Anhang I Zu den Verfahren der k nstlichen Intelligenz z hlen nicht nur das maschinelle Lernen, sondern auch: Logik - und wissensgest tzte Konzepte, einschlie lich Wissensrepr sentation, induktiver (logischer) Programmierung, Wissensgrundlagen, Inferenz - und Deduk tionsmaschinen, (symbolischer) Schlussfolgerungs - und Expertensysteme; Statistische Ans tze, Bayessche Sch tz -, Such - und Optimierungsmethoden. Dieser bereite Anwendungsbereich kann dazu f hren, dass viele Medizinprodukte (und auch andere Produkte) , die Software enthalten, in den Anwendungsbereich der KI -Richtlinie fallen , obwohl sie nicht wirklich eine KI - und insbesondere keine Machine Learning -Komponente enthalten . Jeder in Software gegossene Entscheidungsbaum w re demnach ein KI -System. Da die Veror dnung in vielen der Aspekte auf Machine Learning -Verfahren bzw. allgemein auf statistische Ans tze ausgerichtet ist, ist es nicht ersichtlich, warum die gestellten Anforderungen f r alle der gelisteten Verfahren gelten sollen. In vielen F llen w ren sie ei nfach nicht umsetzbar. Eine pauschale bertragung der Anforderungen in der bisherigen Form auf alle diese Varianten erscheint daher nicht als sinnvoll. Hierzu m sste die Verordnung selbst, insbesondere im Bereich der Umsetzungsanforderungen, an die jeweili gen Verfahren angepasst werden. Manche Aspekte, wie die Einschr nkungen/Verbote bestimmter Anwendungsbereiche, sind in der pauschalen Form anwendbar. Die KI -Verordnung greift einige Begriffe auf, ohne dass sie diese entweder gar nicht, nicht passend oder nicht konsistent mit anderen Verordnungen (wie z.B. der EU -Medizinprodukteverordnung (MDR) einf hrt. Dazu geh ren Begriffe wie z.B. Sicherheitskomponente ( safety component ) Beispiel Sicherheitskomponente ( safety component ) Die Verordnung definiert diesen Begriff, indem sie den nicht definierten Begriff einer Sicherheitsfunktion verwendet: Eine Sicherheitskomponente eines Produkts oder Systems ist ein Bestandteil eines Produkts oder Systems, der eine Sicherheitsfunktion f r fehlerfrei und vollst ndig in Bezug auf Daten ( free of error und complete ) Menschliche Aufsicht ( Human Oversight ) Validierung ( Validierung ) SW Update dieses Produkt oder System er f llt oder dessen Ausfall oder St rung die Gesundheit und Sicherheit von Personen oder Sachen gef hrdet; Es bleibt unklar , was eine Sicherheitsfunktion ist. Beispielsweise k nnte es eine Funktion sein, die die Sicherheit von Patienten gef hrdet, wenn sie s ich nicht spezifikationsgem verh lt. Es k nnte aber auch eine Funktion gemeint sein, die eine risikominierende Ma nahme implementiert. Damit bleibt auch der zentrale Begriff der Sicherheitskomponente undefiniert. hnliche Unklarheiten verbleiben bei den anderen genannten Begriffen. Da diese in den anderen Punkten dieser Aufstellung aufgegriffen werden, wird auf diese Punkte verwiesen. Die KI -Richtlinie schlie t explizit Medizinprodukte (gem Medizinprodukteverordnung / Medical Device Regulation MDR) und IVD-Produkte (In-Vitro -Diagnostics Regulation IVDR) mit ein . Dadurch gibt es eine Dopp elung an Anforderungen zwischen der KI - Verordnung und der MDR / IVDR . MDR und IVDR fordern beispielsweise bereits Cybersecurity, ein Risikomanagement, die Post -Market Surveillance, ein Meldesystem, eine technische Dokumentation, ein QM - System usw. Es ist dabei von zentraler Bedeutung, dass keine Inkonsistenzen zwischen den jeweiligen Verordnungen enthalten sin d, die dann dazu f hren w rden, dass manche Vorgehensweisen nicht mehr oder nur unter erheblichem Mehraufwand m glich w ren . In der aktuellen Form sind aber noch eine ganze Reihe an derartigen Inkonsistenzen vorhanden, wie einige der im Weiteren gelisteten Punkte aufzeigen. Die KI-Verordnung gilt unabh ngig davon, f r was die KI im Medizinprodukt eingesetzt wird. In Erw gungsgrund ( wird folgende Anforderung aufgef hrt: Um ein verh ltnism iges und wirksames verbindliches Regelwerk f r KI -Systeme einzuf hren, sollte ein klar definierter risikobasierter Ansatz verfolgt werden. Bei diesem Ansatz sollten Art und Inhalt solcher Vorschriften auf die Intensit t und den Umfang der Risiken zugeschnitten werden, die von KI-Systemen ausgehen k nnen. Weiterf hren d wird in Erw gungsgrund ( angegeben: Als hochriskant sollten nur solche KI -Systeme eingestuft werden, die erhebliche sch dliche Auswirkungen auf die Gesundheit, die Sicherheit und die Grundrechte von Personen in der Union haben; Allerdings wird i n dem Vorschlag f r die KI-Verordnung selbst ein pauschaler branchenweiter Ansatz verfolgt, bei dem die Anforderungen f r Medizinprodukte und andere als Hochrisikoprodukte klassifizierte KI - Systeme unabh ngig von ihrem tats chlichen Risiko pauschal definie rt werden. Das gilt z.B. auch f r KI -Komponenten, die nicht oder nur sehr bedingt mit Risiken in Verbindung stehen wie z.B. eine KI, die Optimierungen des Energieverbrauchs bei einem Medizinprodukt umsetzt. Unter einem risikobasierten Ansatz ist im Kern z u verstehen, dass das Ma der umzusetzenden Qualit tsmanagementanforderungen in Abh ngigkeit von der Risikobewertung umzusetzen ist. Das hei t, dort wo das Risiko bei einem gegebenen Produkt / in Bezug auf eine gegebene Komponente gro ist, dort sind hohe Anforderungen zu erf llen. Dort wo kein oder nur ein geringes Risiko vorhand en sind, d rfen sie unter Ber cksichtigung der Sicherheit des Gesamtprodukts entsprechend angepasst werden. Ein solcher Ansatz ist jedoch in dem vorliegenden Entwurf nicht gegeben. Es wird im Kern lediglich eine pauschale Unterscheidung nach Branchen vorge nommen und nicht gem der Sicherheit der jeweils gegebenen Produkte. Die Anforderungen in der KI -Verordnung gelten nur f r Hochrisiko - Produkte. Es w re zu berlegen, ob jedes KI -basierte Produkt grundlegende Schritte wie eine Zweckbestimmung definieren muss und darauf aufbauend eine Bewertung dokumentieren muss, ob es sich um ein Hochrisikoprodukt handelt oder nicht. Zu dieser Pr fung sollte im Grunde jedes KI -Produkt verpflichtet sein und das sollte auch entsprechend dokumentiert sein. Alle weiteren An forderungen k nnten entfallen, sofern das Produkt als Nicht -Hoch -Risiko -Produkt einzuordnen ist. Der Prozess k nnte durch die Vorlage eines entsprechenden Formblatts unterst tzt werden. Eine solche abgestufte Vorgehensweise w rde auch in dieser Hinsicht einem risiko -basierten Ansatz besser entsprechen, wie er in dem vorherigen Punkt diskutiert wurde. Insgesamt geht es darum, auf Basis einer soliden Begr ndung d en Umfang der umzusetzenden Anforderungen dem Risiko entsprechend anpassen zu k nnen. In den grund legenden Entscheidungsoptionen zur Vorbereitung der Verordnung scheint eine solche Option nicht wirklich vorhanden gewesen zu sein. In der Einleitung wird von Ma nahmen gesprochen, mit denen bei KI - Systemen sowohl der Nutzen als auch die Risiken der KI auf Unionsebene angemessen geregelt werden . Auch in dem White Paper der HLEG AI wird einem ausgewogenen Verh ltnis von Risiken und Nutzen eine wichtige Rolle zugeordnet. Die KI -Verordnung selbst betrachtet nur die Seite der Risiken und erlaubt keine Abw gung gegen ber dem potenziellen Nutzen, der sich aus einem System ergibt. In der EU -Medizinprodukteverordnung (MDR) ist gezielt der folgende Punkt mit aufgenommen: wobei etwaige Risiken im Zusammenhang mit ihrer Anwendung gemessen am Nutzen f r den Patienten vertretbar und mit einem hohen Ma an Gesundheitsschutz und Sicherheit vereinbar sein m ssen. (Anhang I Grundlegende Sicherheits - und Leistungsanforderungen , Kap. 1, Pos. . Das w rde zu Inkonsistenzen f hren, da die KI -Verordnung eine solche Abw gung nicht erlaubt. Gerade in Zeiten der CoViD -Pandemie ist deutlich geworden, dass manchmal Risiken akzeptiert werden m ssen, um einen bestimmten Nutzen erreichen zu k nnen, siehe z.B. beschleunigte Zulassung von Impfstoffen. Auch wenn es sich in dem Beispiel um ein Pharma - und nicht um ein Medizinprodukt handelt, zeigt es, wie wichtig eine solche Gegen berstellung von Risiken und Nutzen ist. Andere Beispiele, die in den Bereich KI hineinreichen, w ren Systeme zur Vorhersage und zum Management der Aus breitung der Infektionen. Es w re sinnvoll , zu erlauben, eine solche Risiko -Nutzen -Absch tzung machen zu k nnen, wenn entsprechende Begr ndungen/Nachweise f r den Nutzen dargelegt werden k nnen alleine schon um Konsistenz mit der MDR zu erreichen. Der A nsatz, hier ber Ausnahmegenehmigungen gehen zu m ssen und dabei die Notwendigkeit eines Konformit tsbewertungsverfahren aussetzen zu k nnen (siehe Erw gungsgrund (68 ): Es ist daher angebracht, dass die Mitgliedstaaten aus au ergew hnlichen Gr nden der f fentlichen Sicherheit, des Schutzes des Lebens und der Gesundheit nat rlicher Personen und des Schutzes des gewerblichen und kommerziellen Eigentums das Inverkehrbringen oder die Inbetriebnahme von KI -Systemen, die keiner Konformit tsbewertung unterzogen w urden, genehmigen k nnten. ), erscheint hier nicht ausreichend. In Art. 9 ( wird eine weitestm gliche Beseitigung oder Verringerung der Risiken durch eine geeignete Konzeption und Entwicklung gefordert, d.h. eine Reduzierung der Risiken as far as po ssible . Eine solche Formulierung f hrt dazu, dass viele KI -Systeme nie fertig entwickelt werden k nnen, da eine weitere Reduzierung von Risiken bei einem mit Risiken verbundenen Produkt i.d.R. m glich ist und dazu f hren w rde, dass Risiken ohne ein wirkl iches Ende immer weiter reduziert werden m ssen . Stattdessen sollte es gen gen, ein der Zweckbestimmung angemessenes Niveau der Risiken zu erreichen. Aus diesem Grund ist in der EU -Medizinprodukteverordnung (MDR) die Anforderung in angepasster Form vorhand en. Dort ist angegeben: Die in diesem Anhang dargelegte Anforderung zur m glichst weitgehenden Minimierung von Risiken ist so zu verstehen, dass Risiken so weit zu verringern sind, wie es ohne negative Auswirkungen auf das Nutzen - Risiko -Verh ltnis m glich ist. (Anhang I Grundlegende Sicherheits - und Leistungsanforderungen , Kap. 1, Pos. . Die Anforderung weitestm glich bzw. as far as possible sollte aus Gr nden der Machbarkeit und aus Konsistenzgr nden zur MDR in der KI - Verordnung entsprechend ang epasst werden. Die Verordnung spricht regelm ig von Validierung ( validation ), meint dabei in der Regel aber nur die Modellvalidierung von KI -Systemen. Diese Begrifflichkeiten treten mehrfach auf in Zusammenhang mit Trainings -, Validierungs - und Testdaten . An manchen Stellen wird auch von Trainings -, Test - und Validierungsverfahren (Erw gungsgrund , von Untersuchungs -, Test - und Validierungsverfahren (Art. , Entwicklung, Erprobung und Validierung (Art. . In Art. 9( wird zudem angegeben Hochrisiko -KI-Systeme m ssen getestet werden, um die am besten geeigneten Risikomanagementma nahmen zu ermitteln. Durch das Testen wird sichergestellt, dass Hochrisiko -KI-Systeme stets bestimmungsgem Der Begriff Validierung bezeichnet im Bereich der Entwicklun g von Medizinprodukten (und auch in vielen anderen Entwicklungsbereichen) einen m glichst objektiven Nachweis, dass das entwickelte Produkt Anwendungszweck in passender Weise umsetzt. Im Bereich der KI wird der Begriff Validierung jedoch in der Regel in einem sehr viel eingeschr nkteren Sinn verwendet. Er bedeutet hier die Optimierung bzw. Adjustierung (Tuning) von nichttrainierbaren Modellparametern (im Sinne eines model tunings ). Die in der KI -Verordnung verwendeten Formulierungen und der stetige Bezu g auf die Datens tze ( Validierungsdaten ) zeigen auf, dass die Verordnung den Begriff in diesem eingeschr nkten Verst ndnis verwendet. funktionieren und die Anforderungen dieses Kapitels erf llen. . In Art. 9( ist aufgef hrt Die Testverfahren m ssen geeignet sein, die Zweckbestimmung des KI -Systems zu erf llen, und brauchen nicht ber das hierf r erforderliche Ma hinauszugehen. und in Art. 9( Das Testen erfolgt anhand vora b festgelegter Parameter und probabilistischer Schwellenwerte, die f r die Zweckbestimmung des Hochrisiko -KI-Systems geeignet sind. In Art. 17 ( sind Techniken, Verfahren und systematische Ma nahmen f r den Entwurf, die Entwurfskontrolle und die Entwu rfspr fung des Hochrisiko -KI-Systems; ( techniques, procedures and systematic actions to be used for the design, design control and design verification of the high -risk AI system; ) gefordert. Bei der Entwicklung von Medizinprodukten (und auch in anderen Bereichen) ist jedoch die Validierung eine Kernaufgabe, o hne die ein Produkt nicht auf den Markt gebracht werden darf. Diese Aufgabenstellung ist in der KI -Verordnung nahezu gar nicht vorhanden. Zumindest ist diese Thematik nicht entsprechend klar dargelegt. Lediglich der Begriff Validierungsdaten ist definier t, jedoch nicht Begriffe wie Validierung oder Validierungsverfahren . Die unterschiedlichen Reihenfolgen und Kombinationen des Begriffs Validierungsverfahren in verschiedenen Abschnitten der KI -Verordnung lassen ein wenig vermuten, dass z.T. die klass ische Validierung hier ein St ck mitgedacht sein k nnte. Das sollte dann aber auch in voller Konsequenz definiert und dargestellt werden. Insgesamt fehlen in der KI -Verordnung Kernelemente der Validierung. Es wird zwar z.B. gefordert, dass Genauigkeitsbere iche Metriken zur Bewertung von KI -Verfahren verwendet und Ergebnisse dar ber dokumentiert werden. Es wird in der KI -Verordnung selbst aber nicht dar ber gesprochen, dass (im Sinne einer Validierung) schl ssig zu begr nden ist, dass diese Metriken geeignet sind, den jeweiligen Anwendungsfall zu bewerten. Auch viele andere Punkte wie Leistungsgrenzen oder Genauigkeitsgraden m ssen zun chst nur angegeben, aber nicht begr ndet werden. Lediglich in Anhang IV ( Technische Dokumentation ) Pos. 2b ist gefordert, dass Entwurfsentscheidungen zusammen mit Gr nden und Annahmen daf r dokumentiert werden m ssen und in Art. 13(, dass eine Kommunikation des Ma es an Genauigkeit, Robustheit und Cybersicherheit gem Artikel 15, f r das das Hochrisiko -KI-System gete stet und validiert wurde und das zu erwarten ist an den Benutzer erfolgen muss. Ein Nachweis, ob das f r die Zweckbestimmung angemessen / ausreichend ist, fehlt auch hier. Die Anforderungen / Hinweise in Art. 9(, 9( und 9( zeigen nochmals auf, dass Begriffe hier nicht passend eingeordnet sind. Testverfahren alleine gen gen nicht, um die Erf llung der Zweckbestimmung wiedergeben zu k nnen. Das ist eine Aufgabe der Validierung. Bezeichnend ist auch, dass Art 17( eine Entwurfspr fung ( design verification ) aber keine Entwurfsvalidierung ( design validation ) enth lt. Insgesamt fehlt damit eine konsequente Einf hrung des Begriffs Validierung (im klassischen Sinn, inkl. Abgrenzung gegen ber dem in der KI verwendeten Begriff im Sinne einer Optimie rung / Adjustierung des Modells) und die f r KI -Systeme damit verbundenen Anforderungen. Gegebenenfalls k nnte auch auf weiterf hrende Verordnungen verwiesen werden, um Inkonsistenzen mit diesen zu vermeiden. Im Artikel 10 ( fordert die KI -Verordnung Die Trainings -, Validierungs - und Testdatens tze m ssen relevant, repr sentativ, fehlerfrei und vollst ndig sein . Die Daten bei Machine Learning sind in den meisten F llen nicht fehlerfrei , insbesondere dann, wenn sie auf Realweltdaten aufbauen . Das gilt sowohl f r die Input - als auch f r die Output -Daten (Gold Standard - Daten) . Selbst bei menschlichen Bewertern (von Menschen durchgef hrten Annotationen der Daten) gibt es in der Regel eine gewisse Fehlerrate (z.B. bei Klassifikationsaufgaben wie bei Bewertungen anhand von radiologischen Bildern oder auch Laborwerten bzgl. einer bestimmten Erkrankung). Zudem sind quantitative Daten, praktisch immer mit einem gewissen Messfehler behaftet , wenn sie durch Messsensorik aufgenommen oder auch durch einen menschlichen Beobachter definiert sind . Weiterhin werden die Daten nie vollst ndig sein. Wenn sie vollst ndig w ren, w rde kein spezieller KI -Algorithmus ben tigt werden , um eine Aussage treffen zu m ssen. Es g be ja immer einen passenden Referenzdatensatz . Machine Learning -Verfahren dienen ja gerade dazu, Generalisierungen anhand von repr sentativen, aber eben nicht vollst ndigen Daten vorzunehmen. Es bleibt damit unklar, w ie Begriffe wie fehlerfrei und vollst ndig in der KI -Verordnung zu interpretieren sind. Die KI Verordnung fordert in Art. 14 (: Hochrisiko -KI-Systeme werden so konzipiert und entwickelt, dass sie w hrend der Dauer der Verwendung des KI -Systems auch mit geeigneten Werkzeugen einer Mensch -Maschine -Schnittstelle von nat rlichen Personen wirksam beaufsichtigt werden k nnen. Weiterhin ist in Art. 14( angegeben: Die menschliche Aufsicht dient der Verhinderung oder Minimierung der Risiken f r die Gesundheit, die Sicherheit oder die Grundrechte, die entstehen k nn en, wenn ein Hochrisiko -KI-System bestimmungsgem oder unter im Rahmen einer vern nftigerweise vorhersehbaren Fehlanwendung verwendet wird, insbesondere wenn solche Risiken trotz der Einhaltung anderer Anforderungen dieses Kapitels fortbestehen. und in A rt. 14(, dass die Eigenschaft die F higkeiten und Grenzen des Hochrisiko -KI-Systems vollst ndig zu verstehen und seinen Betrieb ordnungsgem zu berwachen, damit Anzeichen von Anomalien, Fehlfunktionen und unerwarteter Leistung so bald wie m glich erk annt und behoben werden k nnen; gegeben sein muss. Es bleibt unklar, was mit den Begriffen wirksam und menschliche Aufsicht gemeint ist. Wenn damit gemeint ist, dass ein Mensch in dem Sinne eine berwachung durchf hren k nnen muss, dass er in Realze it die Ergebnisse des Systems abgreifen, verstehen und darauf reagieren kann, dann erscheint das f r viele KI-Systeme unrealistisch. Das w rde z.B. Systeme ausschlie en, bei denen im Regelbetrieb automatisiert bestimmte Steuerungen vorgenommen werden, z.B. automatisierte Adaption von Maschinenparametern in der Fertigung oder Konfiguration von Medizinprodukten. Wenn stattdessen eine wirksame menschliche berwachung auch damit gegeben ist, dass der Gesamt -Outcome des Systems z.B. in dem Sinne berwacht so w erden kann, dass Anomalien ausreichend zuverl ssig entdeckt werden k nnen, dann w re eine solche Forderung eher realistisch. Das bleibt jedoch unklar. Hinzu kommt, dass die F higkeiten und Grenzen des Hochrisiko -KI- Systems vollst ndig zu verstehen sein m ssen , damit Anzeichen von Anomalien, Fehlfunktionen und unerwarteter Leistung so bald wie m glich erkannt und behoben werden k nnen . Ein solch vollst ndiges Verst ndnis f r die Leistungen eines Systems ist selbst bei Produkten ohne KI in der Regel nicht oder nur begrenzt gegeben. Bei der inneren Komplexit t von vielen KI -Systemen erscheint diese Forderung um so mehr unrealistisch, wenn hier wirklich ein vollst ndiges Verst ndnis gefordert ist. Dass ist eben auch bei vielen/den meisten anderen Produkten nicht wirklich gegeben. Erschwerend kommt dazu, dass eine derartige Aufsicht gem Art. 14( dazu dient, Risiken zu reduzieren / zu minimieren, insbesondere wenn solche Risiken trotz der Einhaltung ander er Anforderungen dieses Kapitels fortbestehen . Bei den meisten Produkten werden am Ende gewisse Risiken verbleiben. Dann ist gerade bei Medizinprodukten der Normalfall. Wichtig ist dabei eigentlich, dass keine inakzeptablen Risiken bestehen bleiben. Dass ist die Kernforderung einer Produktentwicklung in Bezug auf ein angemessenes Risikomanagement. Der Begriff inakzeptabel fehlt jedoch hier. Dabei sollte, wie bereits an anderer Stelle angegeben, beim Risikomanagement verzichtet werden, die Risiken weites tm glich reduzieren zu m ssen ( as far as possible , siehe Art. 9( und Kommentar dazu an anderer Position) . Dann bliebe die Anforderung einer Reduktion n mlich bis zum vollen, aber nie zu erreichenden Minimum bestehen. Stattdessen sollte eine Anforderu ng gestellt werden, dass die menschliche Aufsicht (ebenso wie andere Risikominimierungsma nahmen) dazu dienen, die Risiken auf ein der Zweckbestimmung angemessenes Niveau zu bringen. Art. 13( fordert eine Beschreibung f r die erwartete Lebensdauer des Hochrisiko -KI-Systems und alle erforderlichen Wartungs - und Pflegema nahmen zur Gew hrleistung des ordnungsgem en Funktionierens dieses KI -Systems, auch in Bezug auf Software -Updates Es bleibt an dieser Stelle unklar, was Begriffe wie Lebensdauer des Software -Systems und Software -Update umschreibt. Bei klassischen, zum Zeitpunkt eines Releases fixierten Software -Systems w rde man hier den Code inkl. der dazugeh rigen Daten verstehen. Bei KI -Systemen stellt aber auch die Datenbasis eine wichtige Komponente dar, die zudem f r die Leistungsf higkeit des Systems ma geblich ist. Stellen nderungen der Datenbasis bereits ein Software -Update dar, wenn Software -Systeme einen fixen Stand haben bzw. auch wenn es sich um kontinuier lich lernende Systeme handelt? Wie muss ein Update des Datenbestandes dokumentiert werden, wenn es Updates der lokalen Datenbasis beim Benutzer mit eingeschlossen sind? Art. 28( sagt, dass u.a. Benutzer zu einem Anbieter werden und damit Pflichten wie Sicherstellung der Anforderungen an KI -Systeme, Qualit tsmanagementsystem, haben, wenn sie eine wesentliche nderung an dem Hochrisiko -KI-System vornehmen. Es bleibt unklar, was eine wesentliche nderung ist. Ist z.B. eine Erweiterung des Trainingsdat enbestandes, der eine nderung der Genauigkeit der Vorhersagen eines KI -Systems, z.B. in Form Adaptierung des Systems an die Gegebenheiten eines Betriebs, bereits eine wesentliche nderung? Eine generelle Auferlegung all dieser Pflichten an den Benutzer er scheint in diesem Zusammenhang unverh ltnism ig. In Erw gungsgrund ( wird angegeben: Ein fehlender Schutz vor diesen Risiken k nnte die Sicherheit beeintr chtigen oder sich negativ auf die Grundrechte auswirken, wenn das KI -System beispielsweise W hrend im Erw gungsgrund das Problem der Entstehung von Bias in den Resultaten angesprochen wird, sind in der Verordnung in Bezug auf die Bias -Problematik im Wesentlichen nur Untersuchungen der Input - Daten sowie der Effekt des A utomatisierungs -Bias bei kontinuierlich falsche Entscheidungen trifft oder falsche oder verzerrte Ergebnisse hervorbringt. Anforderungen bzgl. Bias -Effekten sind zu finden in Art. 10(, dass in Bezug auf die verwendeten Trainings -, Test - und Validierungsdaten eine Beobachtung, Erkennung und Korr ektur im Hinblick auf m gliche Verzerrungen (Bias) und gem Art. 10( eine Erkennung und Korrektur von Verzerrungen ( bias monitoring, detection and correction ) bzgl. der Daten durchzuf hren ist. In Bezug auf kontinuierlich lernende Systeme soll zudem berpr ft werden, ob eine m gliche Neigung zu einem automatischen oder berm igen Vertrauen in das von einem Hochrisiko -KI-System hervorgebrachte Ergebnis ( Automatisierungsbias ) vorliegt (siehe A rt. 14(), und dass f r diese Systeme auf m glicherweise verzerrte Ergebnisse, die durch eine Verwendung vorheriger Ergebnisse als Eingabedaten f r den k nftigen Betrieb entstehen ( R ckkopplungsschleifen ), angemessen mit geeigneten Risikominderungsma nahmen eingegangen wird . lernenden Systemen angegeben. Eine Adressierung von Bias -Effekten in den Resultaten eines KI -Systems fehlen. Der Artikel 64 der KI -Verordnung verlangt von den Herstellern den Beh rden einen vollst ndigen Remote -Zugriff zu den Trainings -, Validierungs - und Testdaten zu verschaffen, sogar durch eine API. Vertrauliche Patientendaten ber einen Remote -Zugriff zugreifbar zu machen, steht in einem gewissen Ma e im Konflikt mit der gesetzlichen Forderung nach Data Protection by Design. Gesundheitsdaten z hlen zur besonders sch tzenswerten Kategorie personenbezogener Daten. Eine externe API zu den Trainingsdaten zu entwickeln und mit entsprechenden Sicherheitsmechanismen bereitzustellen, bedeutet f r die Hersteller einen erheblichen Mehra ufwand und erscheint unverh ltnism ig . Zudem entsteht durch derartige Backdoors immer eine gewisse Sicherheitsgef hrdung bzgl. des Zugangs zu pers nlichen und vertrauensw rdigen Daten. Bei anderen, oft sogar kritischeren Daten und I nformationen zum Design und zur Produktion von Produkten (z.B. Source -Code oder CAD -Zeichnungen) w rde niemand verlangen, dass die Hersteller den Beh rden einen Remote -Zugriff gew hren m ssen.",de
Kancelaria Radców Prawnych Konieczny Wierzbicki (Poland),F2665567,06 August 2021,Company/business,Small (10 to 49 employees),Poland,"Dzie Dobry, Przesy amy stanowisko Konieczny Wierzbicki Kancelaria Radc w Prawnych sp.p. w ramach konsultacji publicznych nad projektem rozporz dzenia unijnego ARTIFICIAL INTELLIGENCE ACT.",pl
OpenForum Europe (Belgium),F2665562,06 August 2021,Other,Micro (1 to 9 employees),Belgium,"5 A u g u s t 2 0 2 1 I n p u t t o t h e C o m m i s s i o n A d o p t i o n F e e d b a c k o n t h e P r o p o s a l f o r a R e g u l a t i o n L a y i n g D o w n H a r m o n i s e d R u l e s o n A r t i f i c i a l I n t e l l i g e n c e A r t i f i c i a l I n t e l l i g e n c e A c t ) O p e n n e s s , h a r m o n i s e d s t a n d a r d s a n d c l a r i t y a s a w a y f o r w a r d t o E u r o p e a n A I i n n o v a t i o n a n d t r u s t S t r o n g s u p p o r t o f t h e r e g u l a t o r y a p p r o a c h t a k e n O p e n F o r u m E u r o p e ( O F E w e l c o m e s t h e E u r o p e a n C o m m i s s i o n s d r a f t f o r t h e E U R e g u l a t i o n o n A I a n d a p p r e c i a t e s t h e o p p o r t u n i t y t o p r o v i d e a r e s p o n s e a n d w i t h i t h i g h l i g h t s o m e p o i n t s a n d p o s s i b l e i s s u e s . W i t h t h i s r e s p o n s e w e b u i l d o n p r e v i o u s s u b m i s s i o n s b y O F E , i n p a r t i c u l a r t h e o n e p r o v i d e d i n r e l a t i o n t o t h e W h i t e P a p e r o n A r t i f i c i a l I n t e l l i g e n c e i n J u n e 2 0 2 0 , b u t a l s o o n t h e E u r o p e a n s t a n d a r d i s a t i o n s t r a t e g y . O u r i n p u t t o t h i s c o n s u l t a t i o n i s f o c u s e d o n o u r s p e c i f i c a r e a s o f e x p e r t i s e , w h i c h i n c l u d e O p e n S t a n d a r d s a n d O p e n S o u r c e . W e s t r o n g l y b e l i e v e t h a t o p e n n e s s c a n h e l p a c h i e v e t h e t w i n o b j e c t i v e o f p r o m o t i n g t h e u p t a k e o f A I a n d o f a d d r e s s i n g t h e r i s k s a s s o c i a t e d w i t h c e r t a i n u s e s o f t h i s n e w t e c h n o l o g y . O F E s u p p o r t s t h e r e g u l a t o r y a p p r o a c h t a k e n b y t h e E u r o p e a n C o m m i s s i o n w i t h a c l e a r f o c u s o n h i g h - r i s k a r e a s a n d w i t h p r o p o s i n g p r o c e s s e s t h a t a r e l a r g e l y m o d e l l e d o n t h e E u r o p e a n N e w L e g i s l a t i v e F r a m e w o r k ( N L F . W e b e l i e v e t h a t t h e f o c u s o n h i g h - r i s k a r e a s p r o v i d e s f o r c l a r i t y i n t h e m a r k e t p l a c e , a l l o w s f o r d i f f e r e n t i a t i o n o f a p p l i c a t i o n s c e n a r i o s a n d f o r t h e r i g h t f o c u s o f r e g u l a t i o n o f A I t e c h n o l o g i e s . I t b u i l d s o n a r i s k - b a s e d a p p r o a c h w h i c h i s t h e f o u n d a t i o n f o r b r i n g i n g i n n o v a t i v e a n d t r u s t e d A I t o t h e m a r k e t a n d w h i c h i s a l s o a l r e a d y a d d r e s s e d i n i n t e r n a t i o n a l s t a n d a r d i s a t i o n a c t i v i t i e s - s u c h a s I S O / I E C J T C 1 / S C 4 2 . B u i l d i n g o n s t a n d a r d s a s t h e k e y p a t h f o r a c h i e v i n g a n d d e m o n s t r a t i n g c o m p l i a n c e i s a h i g h l y s u c c e s s f u l a n d e f f i c i e n t w a y f o r b r i n g i n g s a f e a n d t r u s t e d t e c h n o l o g i e s t o t h e s i n g l e E u r o p e a n m a r k e t . O F E s u p p o r t s t h i s p a t h t o a d d r e s s t h e n o v e l r e g u l a t o r y c h a l l e n g e A I i s p o s i n g . A t t h e s a m e t i m e w e u n d e r s t a n d t h a t w i t h A I b e i n g t h e s u b j e c t o f s u c h n e w r e g u l a t i o n m o d e l l e d l a r g e l y a c c o r d i n g t o t h e N L F w h i c h d e a l s w i t h p h y s i c a l / t a n g i b l e p r o d u c t s p u t o n t h e E u r o p e a n m a r k e t - e v e r y o n e i n v o l v e d e n t e r s a n e w r e g u l a t o r y t e r r a i n / l e a r n i n g c u r v e a n d t h u s a n i n c l u s i v e a n d f a c t - b a s e d c o l l a b o r a t i o n i s c r i t i c a l . O F E i s r e a d y t o s u p p o r t t h i s j o u r n e y b a s e d o n o u r o r g a n i s a t i o n s e x p e r t i s e i n o p e n p r o c e s s e s a n d o u r e c o s y s t e m w h i c h i n c l u d e a n u m b e r OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 1 o f t h e l e a d i n g g l o b a l p r o v i d e r s o f A I t e c h n o l o g i e s a s w e l l a s p i o n e e r i n g o p e n s o u r c e s o f t w a r e p r a c t i t i o n e r s . D e f i n i t i o n m a y b e m i s i n t e r p r e t e d a n d s h o u l d b e c l a r i f i e d T h e d e f i n i t i o n o f A I a s c u r r e n t l y l a i d d o w n i n A r t i c l e 3 a n d A n n e x I m a y b e m i s i n t e r p r e t e d , b o t h i n t e r m s o f b r e a d t h a n d d e p t h . O F E u n d e r s t a n d s t h a t m i s i n t e r p r e t a t i o n o f s u c h a d e f i n i t i o n i s n o t i n t e n d e d b y t h e E u r o p e a n C o m m i s s i o n . H o w e v e r , w e b e l i e v e t h a t s o m e c l a r i f i c a t i o n a n d i m p r o v e m e n t t o t h e d e f i n i t i o n i s i m p o r t a n t t o a v o i d u n c e r t a i n t i e s i n t h e m a r k e t p l a c e a n d t h u s s u p p o r t a s e a m l e s s i m p l e m e n t a t i o n o f t h e f u t u r e r e g u l a t i o n . T h e c u r r e n t t e x t s t a t e s t h a t A I s y s t e m m e a n s s o f t w a r e t h a t i s d e v e l o p e d w i t h o n e o r m o r e o f t h e t e c h n i q u e s a n d a p p r o a c h e s l i s t e d i n A n n e x I ; A n n e x I ( c ) l i s t s S t a t i s t i c a l a p p r o a c h e s . I n t h i s b r o a d c o m b i n a t i o n , e v e n t h e u s e o f s o m e s i m p l e s p r e a d s h e e t w h e n d e v e l o p i n g s o f t w a r e m i g h t q u a l i f y t h e s o f t w a r e a s a n A I s y s t e m i n t h e s e n s e o f t h i s d e f i n i t i o n . N a r r o w i n g t h e d e f i n i t i o n a n d l i s t e d t e c h n i q u e s t o e x c l u d e s o f t w a r e s y s t e m s t h a t a r e n o t c o m m o n l y u n d e r s t o o d a s A I w i l l p r o v i d e g r e a t e r c e r t a i n t y t o t h e s o f t w a r e e c o s y s t e m . T h e c u r r e n t d e f i n i t i o n c a n a l s o b e m i s i n t e r p r e t e d i n d e p t h : t o i n c l u d e A I s y s t e m s u b - c o m p o n e n t s a n d p r e c u r s o r s . I n p a r t i c u l a r , t h e d e f i n i t i o n a s w r i t t e n c o u l d b e i n t e r p r e t e d t o i n c l u d e A I - r e l a t e d s o f t w a r e c o d e , i n c l u d i n g p r e - t r a i n e d m o d e l s , t h a t a r e n o t f u l l y A I s y s t e m s . A l t h o u g h a p r e - t r a i n e d m o d e l i s s o f t w a r e t h a t i s c o m m o n l y d e v e l o p e d w i t h t e c h n i q u e s l i s t e d i n A n n e x I a n d c a n y i e l d a n o u t p u t f r o m a n i n p u t , i f p r o m p t e d u s i n g a d d i t i o n a l c o d e , i t d o e s n o t c o n s t i t u t e a n A I s y s t e m b e c a u s e i t c a n n o t i n t e r a c t w i t h i t s e n v i r o n m e n t u n a i d e d . B e l o w O F E o f f e r s a p r o p o s a l f o r a n a m e n d m e n t t o t h e d e f i n i t i o n o f A I s y s t e m s - e s s e n t i a l l y a d d i n g t w o c h a r a c t e r i s t i c s f o r A I s y s t e m s w h i c h w e b e l i e v e s h o u l d m a k e t h e d e f i n i t i o n c l e a r . T e x t i n d r a f t r e g u l a t i o n A m e n d m e n t s p r o p o s e d b y O F E a r t i f i c i a l i n t e l l i g e n c e s y s t e m A I s y s t e m ) m e a n s s o f t w a r e t h a t i s d e v e l o p e d w i t h o n e o r m o r e o f t h e t e c h n i q u e s a n d a p p r o a c h e s l i s t e d i n A n n e x I a n d c a n , f o r a g i v e n s e t o f h u m a n - d e f i n e d o b j e c t i v e s , g e n e r a t e o u t p u t s s u c h a s c o n t e n t , p r e d i c t i o n s , r e c o m m e n d a t i o n s , o r d e c i s i o n s i n f l u e n c i n g t h e e n v i r o n m e n t s t h e y a r t i f i c i a l i n t e l l i g e n c e s y s t e m A I s y s t e m ) m e a n s s o f t w a r e t h a t i s d e v e l o p e d w i t h o n e o r m o r e o f t h e t e c h n i q u e s a n d a p p r o a c h e s l i s t e d i n A n n e x I a n d ( a ) D e m o n s t r a t e s i n t e l l i g e n c e i n p a r t i c u l a r t h e a b i l i t y t o l e a r n a n d a d a p t , OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 2 i n t e r a c t w i t h ; ( b ) F o r a g i v e n s e t o f h u m a n - d e f i n e d o b j e c t i v e s , g e n e r a t e o u t p u t s s u c h a s c o n t e n t , p r e d i c t i o n s , r e c o m m e n d a t i o n s , o r d e c i s i o n s ( c ) M u s t b e b a s e d o n a r u l e b a s e o r m o d e l , ( d ) I n f l u e n c e s t h e e n v i r o n m e n t t h a t i t i n t e r a c t s w i t h ; O F E i s r e a d y t o f u r t h e r d i s c u s s a n d w o r k o n i m p r o v e m e n t s . W e w o u l d l i k e t o e n c o u r a g e t h e E u r o p e a n C o m m i s s i o n t o s u p p o r t s o m e a m e n d m e n t s - f o r i n s t a n c e i n t h e f o r m a s p r o p o s e d b y O F E i n t h e c o n t e x t o f t h e c o - r e g u l a t i o n p r o c e s s a n d t h e d i s c u s s i o n s w i t h P a r l i a m e n t a n d C o u n c i l . S c o p e s h o u l d b e c l a r i f i e d f o r o p e n s o u r c e d e v e l o p e r s O p e n s o u r c e d e v e l o p e r s s h o u l d b e f r e e f r o m p r o v i d e r o b l i g a t i o n s u n l e s s t h e y p r o v i d e a f u l l y f u n c t i o n i n g A I s y s t e m f o r p l a c i n g o n t h e E U m a r k e t . O F E b e l i e v e s t h a t t h e p r o p o s a l i s n o t i n t e n d e d t o h a m p e r o p e n s o u r c e d e v e l o p m e n t s , c o m m u n i t i e s a n d o p e n s o u r c e c o d e h o s t i n g p l a t f o r m s i n t h e s p h e r e o f A I s y s t e m s ; h o w e v e r , w e s u g g e s t i t b e c l a r i f i e d . W h e n a n o p e n s o u r c e d e v e l o p e r c o l l a b o r a t e s w i t h f e l l o w d e v e l o p e r s u n d e r e s t a b l i s h e d O S I / F S F l i c e n s i n g o n A I - r e l a t e d c o d e , s u c h d e v e l o p e r s s h o u l d b e f r e e o f o b l i g a t i o n s u n d e r t h e r e g u l a t i o n u n l e s s t h e y p l a c e a f u l l y f u n c t i o n i n g A I s y s t e m o n t h e E U m a r k e t . U n c e r t a i n t y o f p o s s i b l e o b l i g a t i o n s a n d l i a b i l i t i e s c o u l d h a v e a c h i l l i n g e f f e c t o n i n n o v a t i o n , p a r t i c u l a r l y a m o n g E u r o p e a n d e v e l o p e r s w h o a r e c o l l a b o r a t i n g a n d s h a r i n g i d e a s r e l a t e d t o p o t e n t i a l l y b r e a k - t h r o u g h r e s e a r c h a n d c o l l a b o r a t i o n . I n s o f a r a s t h e E U A I A c t i n t e n d s t o s u p p o r t E U i n n o v a t i o n , t h e C o m m i s s i o n s h o u l d c l a r i f y t h a t s h a r i n g o p e n s o u r c e A I c o d e , p r o o f o f c o n c e p t A I r e s e a r c h , o r s i m p l y e x p e r i m e n t i n g w i t h A I m o d e l s s h o u l d b e e x p r e s s l y e x c l u d e d f r o m t h e r e g u l a t i o n . W e s u g g e s t t h r e e c h a n g e s t o c l a r i f y t h i s s c o p e : F i r s t , t h e p r o p o s a l s r e c i t a l 1 6 d e m o n s t r a t e s t h e i n t e n t i o n t h a t t h e A I A c t s h o u l d n o t c u r t a i l R e s e a r c h f o r l e g i t i m a t e p u r p o s e s o n c e r t a i n h i g h - r i s k A I s y s t e m s i f s u c h r e s e a r c h d o e s n o t a m o u n t t o u s e o f t h e A I s y s t e m i n h u m a n - m a c h i n e r e l a t i o n s . H o w e v e r , t h e d e f i n i t i o n b y r e f e r e n c e o f p r o v i d e r - - a s a n a t u r a l p e r s o n t h a t d e v e l o p s a n A I s y s t e m w i t h a v i e w t o p l a c i n g i t o n t h e m a r k e t , d e f i n e d a s f i r s t m a k i n g a v a i l a b l e o n t h e m a r k e t , d e f i n e d a s s u p p l y o f a n A I s y s t e m f o r d i s t r i b u t i o n o r u s e o n t h e U n i o n m a r k e t i n t h e c o u r s e o f a c o m m e r c i a l a c t i v i t y , w h e t h e r i n r e t u r n f o r p a y m e n t o r f r e e o f c h a r g e - - m a y b e OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 3 i n t e r p r e t e d t o i n c l u d e d e v e l o p e r s w h o a r e o p e n l y s h a r i n g A I - r e l a t e d c o d e . C l a r i f i c a t i o n i s w a r r a n t e d t o e n s u r e t h a t s h a r i n g o f A I - r e l a t e d c o d e f o r r e s e a r c h a n d d e v e l o p m e n t p u r p o s e s i s o u t o f s c o p e . S e c o n d , o p e n s o u r c e g i v e s e n d - u s e r s t h e f r e e d o m t o u s e , i n s p e c t , d i s t r i b u t e , a n d m o d i f y s o f t w a r e . W h e n a n A I s y s t e m i s m a d e a v a i l a b l e u n d e r O S I / F S F l i c e n s e s , e n d - u s e r s a r e e m p o w e r e d t o a l t e r t h e s y s t e m f o r t h e i r p u r p o s e s . I n t h e l i m i t e d c a s e s w h e r e A I s y s t e m s a r e a v a i l a b l e o p e n s o u r c e , p r o v i d e r - o b l i g a t i o n s s h o u l d b e p l a c e d o n t h e e n d - u s e r , w h o i s e m p o w e r e d t o i n s p e c t , r e t r a i n , a n d d e p l o y t h e s y s t e m . I n e f f e c t , t h i s a l t e r a t i o n w o u l d i n c e n t i v i z e t h e p r o d u c t i o n o f o p e n s o u r c e A I s y s t e m s i n t h e E U m a r k e t , c o n f e r r i n g a s t r a t e g i c a d v a n t a g e i n A I d e v e l o p m e n t t h a t a l i g n s w i t h E u r o p e a n v a l u e s . T h i r d , d e v e l o p e r s a b i l i t y t o c o l l a b o r a t e o p e n l y o n a w i d e r a n g e o f s o f t w a r e - d e v e l o p i n g a n d s h a r i n g p l a t f o r m s m a y a l s o b e i n a d v e r t e n t l y i m p a c t e d b y t h i s r e g u l a t i o n . I f s u c h p l a t f o r m s a r e u n d e r s t o o d a s d i s t r i b u t o r s t h e y w o u l d n e e d t o e n s u r e t h a t A I s y s t e m s b u i l t o p e n l y o n t h e i r p l a t f o r m a r e c o m p l i a n t . S i m i l a r t o t h e E U C o p y r i g h t D i r e c t i v e , a c a r v e o u t f r o m d i s t r i b u t o r o b l i g a t i o n s f o r c o d e - h o s t i n g p l a t f o r m s c o u l d h e l p o p e n s o u r c e d e v e l o p e r s , e n s u r i n g t h a t t h e i r a c c e s s t o s o u r c e c o d e a n d a b i l i t y t o s h a r e a n d c o - c r e a t e t h e i r A I - r e l a t e d c o d e a r e p r e s e r v e d . T h e p r i n c i p l e s a b o v e a r e a l s o a p p l i c a b l e t o o t h e r t y p e s o f t o o l s a n d p l a t f o r m s . T h e C o m m i s s i o n s h o u l d c l a r i f y t h e P r o p o s a l s s c o p e s o a s t o n o t i n a d v e r t e n t l y i n c l u d e s o f t w a r e d e v e l o p e r s i n t h e r e g u l a t i o n w h i c h i s t a r g e t e d a t A I s y s t e m s d e p l o y e d i n t h e E U , t h e i r p r o v i d e r s , a n d t h e i r p r o f e s s i o n a l u s e r s . S u p p o r t f o r t h e a p p r o a c h w i t h h a r m o n i s e d s t a n d a r d s O F E s t r o n g l y s u p p o r t s t h e a p p r o a c h l a i d d o w n i n A r t i c l e 4 0 t o r e l y o n h a r m o n i s e d s t a n d a r d s f o r d e m o n s t r a t i n g c o m p l i a n c e a n d o p e r a t e u n d e r t h e p r e s u m p t i o n o f c o n f o r m i t y . W i t h t h e d r a f t R e g u l a t i o n t h u s b e i n g m o d e l l e d a c c o r d i n g t o t h e p r o c e s s e s o f t h e N e w L e g i s l a t i v e F r a m e w o r k i t b u i l d s o n t h e w e l l e s t a b l i s h e d a n d w e l l p r o v e n f r a m e w o r k f o r t e c h n i c a l r e g u l a t i o n i n E u r o p e . W i t h t h e C E N C E N E L E C J T C 2 1 t h e i n f r a s t r u c t u r e f o r t h e d e v e l o p m e n t o f h a r m o n i s e d s t a n d a r d s i n E u r o p e i s a v a i l a b l e w h i c h w i l l a l l o w a n e a r l y a n d f a s t s u p p o r t o f t h e r e g u l a t o r y n e e d s . C E N C E N E L E C J T C 2 1 a l s o e s t a b l i s h e s c l o s e l i n k a g e s t o i n t e r n a t i o n a l s t a n d a r d i s a t i o n , i n p a r t i c u l a r I S O / I E C J T C 1 S C 4 2 , w h e r e a n u m b e r o f h i g h l y r e l e v a n t i n t e r n a t i o n a l s t a n d a r d s a r e d e v e l o p e d - s o m e o f t h e m a l r e a d y a v a i l a b l e - o n t o p i c s t h a t h a v e r e l e v a n c e i n t h e c o n t e x t o f t h e p r o p o s e d A I r e g u l a t i o n . T h i s OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 4 i n c l u d e s s t a n d a r d i s a t i o n o n g o v e r n a n c e o f A I s y s t e m s , t r a n s p a r e n c y , t r u s t w o r t h i n e s s a n d e x p l a i n a b i l i t y . A m a j o r s t r e n g t h o f t h e E u r o p e a n s t a n d a r d i s a t i o n s y s t e m h a s b e e n i t s c l o s e l i n k a g e t o i n t e r n a t i o n a l s t a n d a r d i s a t i o n i n c l u d i n g t h e p o s s i b i l i t y t o a d o p t i n t e r n a t i o n a l s t a n d a r d s a s E u r o p e a n s t a n d a r d s a n d t h e p o s s i b i l i t y o f c o - d e v e l o p m e n t . O F E w o u l d l i k e t o e n c o u r a g e t h e E u r o p e a n C o m m i s s i o n t o p r o m o t e a c l o s e l i n k a g e w i t h i n t e r n a t i o n a l s t a n d a r d i s a t i o n a n d t h e a d o p t i o n a n d u s e o f i n t e r n a t i o n a l s t a n d a r d s w h e n e v e r p o s s i b l e . R e g a r d i n g t h e s t a n d a r d i s a t i o n r e q u e s t s f o r t h e d e v e l o p m e n t o f h a r m o n i s e d s t a n d a r d s O F E w o u l d l i k e t o r e c o m m e n d t h e f o l l o w i n g c o n s i d e r a t i o n s : 1 . S t a n d a r d i s a t i o n r e q u e s t s s h o u l d b e a v a i l a b l e e a r l y - i d e a l l y t h e f i r s t s t a n d a r d i s a t i o n r e q u e s t s s h o u l d b e i s s u e d b e f o r e a d o p t i o n o f t h e A I R e g u l a t i o n s o t h a t w o r k c a n s t a r t e a r l y w i t h o u t u n d e r m i n i n g t h e l e g i s l a t i v e p r o c e s s . 2 . S t a n d a r d i s a t i o n r e q u e s t s s h o u l d b e d e v e l o p e d i n c l o s e i n t e r a c t i o n w i t h t h e E S O s a n d t h e e x p e r t s i n t h e r e s p e c t i v e t e c h n i c a l c o m m i t t e e s . 3 . A v o i d s t a n d a r d i s a t i o n r e q u e s t s t h a t a r e t o o p r e s c r i p t i v e . T h e c l e a r s t r e n g t h o f t h e N L F i s t h a t t h e t e c h n i c a l r e a l i s a t i o n o f h o w t o m e e t l e g a l r e q u i r e m e n t s i s d e v e l o p e d b y e x p e r t s p r o v i d e d b y a l l s t a k e h o l d e r s a n d a g r e e d b y c o n s e n s u s . T h i s p r o m o t e s t h a t E u r o p e a n s t a n d a r d s r e f l e c t t h e s t a t e - o f - t h e - a r t . I t a l s o f a c i l i t a t e s t h e a d o p t i o n o f i n t e r n a t i o n a l s t a n d a r d s . 4 . K e e p a c l o s e d i a l o g u e b e t w e e n t h e E u r o p e a n C o m m i s s i o n a n d t h e t e c h n i c a l e x p e r t s t h r o u g h o u t t h e e n t i r e d e v e l o p m e n t p r o c e s s . T h i s i s i m p o r t a n t t o a v o i d m i s u n d e r s t a n d i n g s a n d p r e v e n t t h a t s t a n d a r d s m i g h t n o t m e e t t h e n e e d s a n d e x p e c t a t i o n s a s o u t l i n e d i n t h e r e s p e c t i v e s t a n d a r d i s a t i o n r e q u e s t s . 5 . F a s t c i t a t i o n o f h a r m o n i s e d s t a n d a r d s i n t h e O f f i c i a l J o u r n a l o f t h e E U O J E U . T h i s i s i m p o r t a n t t o m a k e t h e s t a n d a r d s a v a i l a b l e f o r p r e s u m p t i o n o f c o n f o r m i t y . F o l l o w i n g t h e s e c o n s i d e r a t i o n s a b o v e w i l l a l s o b e o f h i g h i m p o r t a n c e f o r s u p p o r t i n g t h a t t h e h a r m o n i s e d s t a n d a r d s c a n b e a v a i l a b l e i n t i m e a n d t h a t t h e t r a n s i t i o n t i m e o f 2 4 m o n t h s w i l l b e s u f f i c i e n t b e t w e e n t h e c o m i n g i n t o f o r c e o f t h e R e g u l a t i o n a n d t h e m o m e n t i t a p p l i e s . A s a n u m b e r o f h a r m o n i s e d s t a n d a r d s w i l l h a v e t o b e a v a i l a b l e , a n d g i v e n t h e s c a r c i t y o f a c t u a l e x p e r t s i n t h e f i e l d o f A I a n d a v a i l a b l e f o r d o i n g t h e s t a n d a r d i s a t i o n w o r k 2 4 m o n t h s i s n o t m u c h a n d i t w i l l b e v e r y i m p o r t a n t t h a t a l l a c t o r s w i l l w o r k t o g e t h e r v e r y c o l l a b o r a t i v e l y a n d i n c l o s e i n t e r a c t i o n a n d e x c h a n g e . OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 5 C l a r i f y t h a t t h e a d o p t i o n o f c o m m o n s p e c i f i c a t i o n s i s p u r s u e d i n e x c e p t i o n a l c a s e s o n l y A r t i c l e 4 1 , C o m m o n S p e c i f i c a t i o n s , p r o v i d e s f o r t h e E u r o p e a n C o m m i s s i o n , v i a i m p l e m e n t i n g a c t s , t o a d o p t c o m m o n s p e c i f i c a t i o n s i n s t e a d o f h a r m o n i s e d s t a n d a r d s . T h i s s i t u a t i o n s h o u l d , h o w e v e r , b e a v o i d e d , a b o v e a l l b y a c l o s e i n t e r a c t i o n b e t w e e n t h e r e s p e c t i v e t e c h n i c a l c o m m i t t e e s a n d t h e e x p e r t s w o r k i n g t h e r e i n o n t h e o n e h a n d a n d t h e E u r o p e a n C o m m i s s i o n o n t h e o t h e r h a n d . R e g u l a r a n d e a r l y f e e d b a c k t o t e c h n i c a l c o m m i t t e e s i s r e q u i r e d i f t h e r e s h o u l d b e c o n c e r n s t h a t a h a r m o n i s e d s t a n d a r d m e e t s t h e e x p e c t a t i o n s a n d n e e d s a s o u t l i n e d i n t h e r e s p e c t i v e s t a n d a r d i s a t i o n r e q u e s t s . M o r e o v e r , O F E p r o p o s e s a c l a r i f i c a t i o n t o A r t i c l e 4 1 . 1 . I t i t s c u r r e n t v e r s i o n t h e p a r a g r a p h m a y b e m i s u n d e r s t o o d i n t h e f o l l o w i n g w a y s : ( i ) t h a t i f n o h a r m o n i s e d s t a n d a r d s a r e a v a i l a b l e t h e E u r o p e a n C o m m i s s i o n m a y r i g h t a w a y - v i a a d e l e g a t e d a c t - a d o p t c o m m o n s p e c i f i c a t i o n s . A s h a r m o n i s e d s t a n d a r d s a l w a y s r e q u i r e a s t a n d a r d i s a t i o n r e q u e s t t o b e i s s u e d f i r s t i t i s , a s i t w e r e , t h e r u l e t h a t t h e y d o n t e x i s t i f n o r e s p e c t i v e s t a n d a r d i s a t i o n h a d b e e n i s s u e d . T h e r e f o r e i t s e e m s a p p r o p r i a t e t o a d d t h e r e q u i r e m e n t t h a t f o r a n y l a c k o f h a r m o n i s e d s t a n d a r d s t h e f i r s t s t e p i s t h e i s s u i n g o f a s t a n d a r d i s a t i o n r e q u e s t ; ( i i ) t h a t f o r m a t t e r s o f s a f e t y o r f u n d a m e n t a l r i g h t s i t w e r e g e n e r a l l y a n o p t i o n f o r t h e E u r o p e a n C o m m i s s i o n t o a d o p t c o m m o n s p e c i f i c a t i o n s w i t h o u t r e q u e s t i n g t h e d e v e l o p m e n t o f r e s p e c t i v e h a r m o n i s e d s t a n d a r d s . I t s h o u l d b e c l a r i f i e d t h a t o n l y i f a h a r m o n i s e d s t a n d a r d d o e s n o t m e e t t h e r e q u i r e m e n t s a n d n e e d s m a y t h e E u r o p e a n C o m m i s s i o n t a k e t h e s t e p t o a d o p t c o m m o n s p e c i f i c a t i o n s . O F E t h e r e f o r e o f f e r s t h e f o l l o w i n g a m e n d m e n t s a s p r o v i d e d i n t h e t a b l e b e l o w : T e x t i n d r a f t r e g u l a t i o n A m e n d m e n t s p r o p o s e d b y O F E W h e r e h a r m o n i s e d s t a n d a r d s r e f e r r e d t o i n A r t i c l e 4 0 d o n o t e x i s t o r w h e r e t h e C o m m i s s i o n c o n s i d e r s t h a t t h e r e l e v a n t h a r m o n i s e d s t a n d a r d s a r e i n s u f f i c i e n t o r t h a t t h e r e i s a n e e d t o a d d r e s s s p e c i f i c s a f e t y o r f u n d a m e n t a l r i g h t c o n c e r n s , t h e C o m m i s s i o n m a y , b y m e a n s o f i m p l e m e n t i n g a c t s , a d o p t c o m m o n s p e c i f i c a t i o n s i n r e s p e c t o f t h e r e q u i r e m e n t s s e t o u t i n C h a p t e r 2 o f t h i s T i t l e . T h o s e i m p l e m e n t i n g a c t s s h a l l b e a d o p t e d i n a c c o r d a n c e w i t h t h e e x a m i n a t i o n p r o c e d u r e r e f e r r e d t o i n W h e r e h a r m o n i s e d s t a n d a r d s r e f e r r e d t o i n A r t i c l e 4 0 d o n o t e x i s t t h e C o m m i s s i o n s h a l l i s s u e r e s p e c t i v e s t a n d a r d i s a t i o n r e q u e s t s i n a c c o r d a n c e w i t h A r t i c l e 1 0 o f R e g u l a t i o n 1 0 2 5 / 2 0 1 2 . I f o r w h e r e t h e C o m m i s s i o n c o n s i d e r s t h a t t h e r e s u l t i n g r e l e v a n t h a r m o n i s e d s t a n d a r d s a r e i n s u f f i c i e n t a n d f a i l t o o r t h a t t h e r e i s a n e e d t o a d d r e s s t h e s p e c i f i c s a f e t y o r f u n d a m e n t a l r i g h t c o n c e r n s a s o u t l i n e d i n t h e s t a n d a r d i s a t i o n r e q u e s t s , t h e C o m m i s s i o n m a y , b y m e a n s o f OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 6 A r t i c l e 7 4 2 . i m p l e m e n t i n g a c t s , a d o p t c o m m o n s p e c i f i c a t i o n s i n r e s p e c t o f t h e r e q u i r e m e n t s s e t o u t i n C h a p t e r 2 o f t h i s T i t l e . T h o s e i m p l e m e n t i n g a c t s s h a l l b e a d o p t e d i n a c c o r d a n c e w i t h t h e e x a m i n a t i o n p r o c e d u r e r e f e r r e d t o i n A r t i c l e 7 4 2 . W e b e l i e v e t h a t t h e s e a m e n d m e n t s a d d c l a r i t y a n d h e l p t o a v o i d m i s u n d e r s t a n d i n g s a n d m i s r e a d i n g s o f t h e R e g u l a t i o n . O n c e a g a i n w e h o p e t h a t t h e E u r o p e a n C o m m i s s i o n m a y b e a b l e t o s u p p o r t t h e i n t r o d u c t i o n o f s u c h a m e n d m e n t s d u r i n g t h e c o - l e g i s l a t i v e p r o c e s s . S t a n d a r d s s h o u l d b e p r e f e r r e d o v e r C o d e s o f C o n d u c t O F E i s c o n c e r n e d a b o u t T i t l e I X , C o d e s o f C o n d u c t , a n d t h e r e s p e c t i v e A r t i c l e 6 9 . O F E w o u l d l i k e t o c a u t i o n t h e E u r o p e a n C o m m i s s i o n a n d M e m b e r S t a t e s t o e n c o u r a g e a n d f a c i l i t a t e t h e d r a w i n g u p o f c o d e s o f c o n d u c t i n t e n d e d t o f o s t e r t h e v o l u n t a r y a p p l i c a t i o n t o A I s y s t e m s o t h e r t h a n h i g h - r i s k A I . W e b e l i e v e t h a t a l s o f o r A I s y s t e m s o t h e r t h a n h i g h - r i s k A I t h e u s e o f s t a n d a r d s s h o u l d b e p r o m o t e d a n d s t a n d a r d s s h o u l d c l e a r l y b e p r e f e r r e d o v e r c o d e s o f c o n d u c t . T h e m a j o r r e a s o n s f o r t h i s a r e : S t a n d a r d s a r e d e v e l o p e d i n o p e n , t r a n s p a r e n t a n d i n c l u s i v e p r o c e s s e s a n d r e p r e s e n t t h e c o n s e n s u s o f t e c h n i c a l e x p e r t s . F o r c o d e s o f c o n d u c t s u c h c l e a r a n d o p e n d e v e l o p m e n t p r o c e s s e s a r e n o t d e f i n e d . A l a r g e n u m b e r o f r e l e v a n t s t a n d a r d s a r e a l r e a d y a v a i l a b l e o r u n d e r d e v e l o p m e n t g l o b a l l y . T h e y c a n b e u s e d a l r e a d y o r i n t h e n e a r f u t u r e , i . e . w i t h o u t m u c h d e l a y . C o d e s o f c o n d u c t , h o w e v e r , w o u l d h a v e t o b e i n i t i a t e d a n d d e v e l o p m e n t w o u l d t a k e t i m e t h u s s i g n i f i c a n t l y d e l a y i n g t h e i r a v a i l a b i l i t y c o m p a r e d t o s t a n d a r d s . T h e d e v e l o p m e n t o f c o d e s o f c o n d u c t e n c o u r a g e d a n d f a c i l i t a t e d b y t h e E u r o p e a n C o m m i s s i o n o r M e m b e r S t a t e s p r e s e n t s a r i s k o f d u p l i c a t i n g e f f o r t s w i t h o u t p r o v i d i n g a d d i t i o n a l b e n e f i t s t o a c t i v i t i e s t h a t h a v e a l r e a d y b e e n c a r r i e d o u t i n s t a n d a r d i s a t i o n p r o c e s s e s . S t a n d a r d i s a t i o n w i t h i t s o p e n a n d w e l l - e s t a b l i s h e d p r o c e s s e s g i v e s a n o p p o r t u n i t y f o r p a r t i c i p a t i o n t o a l l s t a k e h o l d e r s i n c l u d i n g s o c i e t a l s t a k e h o l d e r s a n d S M E s . T h e d r a f t R e g u l a t i o n r i g h t l y p r o v i d e s f o r f u r t h e r a r e a s t o b e a d d e d a s h i g h - r i s k i n t h e f u t u r e . M o r e o v e r , t h e e v o l u t i o n o f t e c h n o l o g i e s w i l l a l m o s t c e r t a i n l y l e a d t o n e w a n d u p d a t e d r e q u i r e m e n t s i n t h e f u t u r e . I n t h i s c o n t e x t i t w i l l b e OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 7 i m p o r t a n t t h a t s t a n d a r d s m a y e v o l v e i n t o h a r m o n i s e d s t a n d a r d s - i n o t h e r w o r d s t h a t s t a k e h o l d e r s m a y b u i l d o n a b r o a d s p e c t r u m o f s t a n d a r d s w h e n d e v e l o p i n g h a r m o n i s e d s t a n d a r d s . A p a r a l l e l w o r l d o f c o d e s o f c o n d u c t w i l l c r e a t e b a r r i e r s f o r s u c h l i n k a g e s . T h e d e v e l o p m e n t o f t h e r e s p e c t i v e s t a n d a r d s m a y b e i n i t i a t e d v i a t h e E U R o l l i n g P l a n f o r I C T S t a n d a r d i s a t i o n w h i c h h a s p r o v e d t o b e h i g h l y s u c c e s s f u l i n o t h e r p o l i c y a r e a s a l r e a d y . M o r e o v e r , t h e E u r o p e a n C o m m i s s i o n m a y a l s o i s s u e s t a n d a r d i s a t i o n r e q u e s t s f o r o t h e r t h a n h a r m o n i s e d s t a n d a r d s . O F E w o u l d , t h e r e f o r e , l i k e t o p r o p o s e t h e f o l l o w i n g a m e n d m e n t s : T e x t i n d r a f t r e g u l a t i o n A m e n d m e n t s p r o p o s e d b y O F E A r t i c l e 6 9 C o d e s o f c o n d u c t 1 . T h e C o m m i s s i o n a n d t h e M e m b e r S t a t e s s h a l l e n c o u r a g e a n d f a c i l i t a t e t h e d r a w i n g u p o f c o d e s o f c o n d u c t i n t e n d e d t o f o s t e r t h e v o l u n t a r y a p p l i c a t i o n t o A I s y s t e m s o t h e r t h a n h i g h - r i s k A I s y s t e m s o f t h e r e q u i r e m e n t s s e t o u t i n T i t l e I I I , C h a p t e r 2 o n t h e b a s i s o f t e c h n i c a l s p e c i f i c a t i o n s a n d s o l u t i o n s t h a t a r e a p p r o p r i a t e m e a n s o f e n s u r i n g c o m p l i a n c e w i t h s u c h r e q u i r e m e n t s i n l i g h t o f t h e i n t e n d e d p u r p o s e o f t h e s y s t e m s . 2 . T h e C o m m i s s i o n a n d t h e B o a r d s h a l l e n c o u r a g e a n d f a c i l i t a t e t h e d r a w i n g u p o f c o d e s o f c o n d u c t i n t e n d e d t o f o s t e r t h e v o l u n t a r y a p p l i c a t i o n t o A I s y s t e m s o f r e q u i r e m e n t s r e l a t e d f o r e x a m p l e t o e n v i r o n m e n t a l s u s t a i n a b i l i t y , a c c e s s i b i l i t y f o r p e r s o n s w i t h a d i s a b i l i t y , s t a k e h o l d e r s p a r t i c i p a t i o n i n t h e d e s i g n a n d d e v e l o p m e n t o f t h e A I s y s t e m s a n d d i v e r s i t y o f d e v e l o p m e n t t e a m s o n t h e b a s i s o f c l e a r o b j e c t i v e s a n d k e y p e r f o r m a n c e i n d i c a t o r s t o m e a s u r e t h e a c h i e v e m e n t o f t h o s e o b j e c t i v e s . 3 . C o d e s o f c o n d u c t m a y b e d r a w n u p b y i n d i v i d u a l p r o v i d e r s o f A I s y s t e m s o r b y o r g a n i s a t i o n s r e p r e s e n t i n g t h e m o r b y A r t i c l e 6 9 C o d e s o f c o n d u c t S t a n d a r d s a n d t e c h n i c a l s p e c i f i c a t i o n s f o r A I s y s t e m s o t h e r t h a n h i g h - r i s k A I 1 . T h e C o m m i s s i o n a n d t h e M e m b e r S t a t e s s h a l l e n c o u r a g e a n d f a c i l i t a t e t h e d r a w i n g u p a n d u s e o f s t a n d a r d s a n d t e c h n i c a l s p e c i f i c a t i o n s c o d e s o f c o n d u c t i n t e n d e d t o f o s t e r t h e v o l u n t a r y a p p l i c a t i o n t o A I s y s t e m s o t h e r t h a n h i g h - r i s k A I s y s t e m s o f t h e r e q u i r e m e n t s s e t o u t i n T i t l e I I I , C h a p t e r 2 o n t h e b a s i s o f t e c h n i c a l s p e c i f i c a t i o n s a n d s o l u t i o n s t h a t a r e a p p r o p r i a t e m e a n s o f e n s u r i n g c o m p l i a n c e w i t h s u c h r e q u i r e m e n t s i n l i g h t o f t h e i n t e n d e d p u r p o s e o f t h e s y s t e m s . 2 . T h e C o m m i s s i o n a n d t h e B o a r d s h a l l e n c o u r a g e a n d f a c i l i t a t e t h e d r a w i n g u p a n d u s e o f s t a n d a r d s a n d t e c h n i c a l s p e c i f i c a t i o n s c o d e s o f c o n d u c t i n t e n d e d t o f o s t e r t h e v o l u n t a r y a p p l i c a t i o n t o A I s y s t e m s o f r e q u i r e m e n t s r e l a t e d f o r e x a m p l e t o e n v i r o n m e n t a l s u s t a i n a b i l i t y , a c c e s s i b i l i t y f o r p e r s o n s w i t h a d i s a b i l i t y , s t a k e h o l d e r s p a r t i c i p a t i o n i n t h e d e s i g n a n d d e v e l o p m e n t o f t h e A I s y s t e m s a n d d i v e r s i t y o f d e v e l o p m e n t t e a m s o n t h e b a s i s o f c l e a r o b j e c t i v e s a n d k e y p e r f o r m a n c e i n d i c a t o r s t o m e a s u r e t h e OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 8 b o t h , i n c l u d i n g w i t h t h e i n v o l v e m e n t o f u s e r s a n d a n y i n t e r e s t e d s t a k e h o l d e r s a n d t h e i r r e p r e s e n t a t i v e o r g a n i s a t i o n s . C o d e s o f c o n d u c t m a y c o v e r o n e o r m o r e A I s y s t e m s t a k i n g i n t o a c c o u n t t h e s i m i l a r i t y o f t h e i n t e n d e d p u r p o s e o f t h e r e l e v a n t s y s t e m s . 4 . T h e C o m m i s s i o n a n d t h e B o a r d s h a l l t a k e i n t o a c c o u n t t h e s p e c i f i c i n t e r e s t s a n d n e e d s o f t h e s m a l l - s c a l e p r o v i d e r s a n d s t a r t - u p s w h e n e n c o u r a g i n g a n d f a c i l i t a t i n g t h e d r a w i n g u p o f c o d e s o f c o n d u c t . a c h i e v e m e n t o f t h o s e o b j e c t i v e s . 3 . I n o r d e r t o i n i t i a t e t h e d e v e l o p m e n t o f s t a n d a r d s f o r a d d r e s s i n g s p e c i f i c n e e d s t h e C o m m i s s i o n m a y l e v e r a g e t h e E U R o l l i n g P l a n f o r I C T s t a n d a r d i s a t i o n o r m a y i n i t i a t e a s t a n d a r d i s a t i o n r e q u e s t . 3 . 4 . W h e r e s t a n d a r d i s a t i o n i s n o t a n a p p r o p r i a t e t o o l , c o d e s o f c o n d u c t m a y b e d r a w n u p b y i n d i v i d u a l p r o v i d e r s o f A I s y s t e m s o r b y o r g a n i s a t i o n s r e p r e s e n t i n g t h e m o r b y b o t h , i n c l u d i n g w i t h t h e i n v o l v e m e n t o f u s e r s a n d a n y i n t e r e s t e d s t a k e h o l d e r s a n d t h e i r r e p r e s e n t a t i v e o r g a n i s a t i o n s . C o d e s o f c o n d u c t m a y c o v e r o n e o r m o r e A I s y s t e m s t a k i n g i n t o a c c o u n t t h e s i m i l a r i t y o f t h e i n t e n d e d p u r p o s e o f t h e r e l e v a n t s y s t e m s . 4 . 5 . T h e C o m m i s s i o n a n d t h e B o a r d s h a l l t a k e i n t o a c c o u n t t h e s p e c i f i c i n t e r e s t s a n d n e e d s o f t h e s m a l l - s c a l e p r o v i d e r s a n d s t a r t - u p s w h e n e n c o u r a g i n g a n d f a c i l i t a t i n g t h e d r a w i n g u p o f c o d e s o f c o n d u c t . M o r e o v e r , g o v e r n a n c e a n d s t r u c t u r e s f o r d e v e l o p i n g C o d e s o f C o n d u c t s h o u l d b e d e f i n e d . E q u i p m a r k e t s u r v e i l l a n c e a u t h o r i t i e s w i t h t h e a p p r o p r i a t e a c c e s s t o t e c h n o l o g y t h e y n e e d T h e N L F r e l i e s o n m a r k e t s u r v e i l l a n c e t o m o n i t o r t h e m a r k e t a n d e n s u r e p r o p e r i m p l e m e n t a t i o n o f t h e R e g u l a t i o n a n d t h e f u n c t i o n i n g o f t h e s i n g l e m a r k e t . A r t i c l e 6 4 o f t h e d r a f t R e g u l a t i o n m a k e s p r o v i s i o n s f o r m a r k e t s u r v e i l l a n c e a u t h o r i t i e s t o g e t f u l l a c c e s s t o t r a i n i n g , v a l i d a t i o n a n d t e s t i n g d a t a s e t s u s e d b y t h e p r o v i d e r A r t . 6 4 . 1 a s w e l l a s u p o n a r e a s o n e d r e q u e s t g e t a c c e s s t o s o u r c e c o d e ( A r t 6 4 . 2 . O F E w o u l d l i k e t o p r o p o s e s o m e f u r t h e r t h i n k i n g a n d e x c h a n g e o n t h e e x a c t p a r t s o f a n A I s y s t e m t h a t n e e d t o b e s h a r e d w i t h a r e l e v a n t m a r k e t s u r v e i l l a n c e a u t h o r i t y . T h e r e a r e s e v e r a l e l e m e n t s o f A I s y s t e m s t h a t w o u l d b e h e l p f u l t o a m a r k e t s u r v e i l l a n c e a u t h o r i t y s u c h a s h u m a n - r e a d a b l e g o a l s o f a g i v e n s y s t e m , i n f o r m a t i o n OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 9 a b o u t a l g o r i t h m s a n d s e v e r a l o t h e r f e a t u r e s t h a t a l l o w t h e a u t h o r i t y t o v e r i f y c o m p l i a n c e w i t h t h e R e g u l a t i o n . T h e s e d i s c u s s i o n s m a y a l s o c o n s i d e r t h e n u m e r o u s o p e n s o u r c e t o o l s c u r r e n t l y a v a i l a b l e f o r a s s e s s i n g A I s y s t e m s a n d t h e r o l e t h a t m a r k e t s u r v e i l l a n c e a u t h o r i t i e s s h o u l d p l a y i n i n c e n t i v i z i n g f u r t h e r d e v e l o p m e n t o f s u c h t o o l s . F i n a l l y , t h e s e d i s c u s s i o n s s h o u l d a l s o c o n s i d e r t h e p r e c e d e n t i a l a n d g e o p o l i t i c a l i m p l i c a t i o n s o f a n y m a r k e t s u r v e i l l a n c e r e q u i r e m e n t o n A I s y s t e m s w i t h i n t h e p r o p o s a l . F i n a l l y t h e s t a t e m e n t i n A r t 6 4 . 3 t h a t n a t i o n a l p u b l i c a u t h o r i t i e s o r b o d i e s w h i c h s u p e r v i s e o r e n f o r c e t h e r e s p e c t o f o b l i g a t i o n s u n d e r U n i o n l a w p r o t e c t i n g f u n d a m e n t a l r i g h t s i n r e l a t i o n t o t h e u s e o f h i g h - r i s k A I s y s t e m s r e f e r r e d t o i n A n n e x I I I s h a l l h a v e t h e p o w e r t o r e q u e s t a n d a c c e s s a n y d o c u m e n t a t i o n , n e e d s f u r t h e r c l a r i f i c a t i o n . C o n c l u d i n g r e m a r k s O F E w e l c o m e s a n d s u p p o r t s t h e d r a f t R e g u l a t i o n o n A I A I A c t ) . W e s t r o n g l y b e l i e v e t h a t t h e a p p r o a c h t a k e n w i t h a r i s k b a s e d a p p r o a c h f o c u s s i n g o n h i g h - r i s k A I o n l y f o r r e g u l a t i o n , w i t h u s i n g h a r m o n i s e d s t a n d a r d s f o r d e m o n s t r a t i n g c o m p l i a n c e a n d w i t h i n c l u d i n g s e l f - a s s e s s m e n t a n d t h e p r e s u m p t i o n o f c o n f o r m i t y i s t h e r i g h t a p p r o a c h - f o l l o w i n g p r o v e n p a t h s o f t e c h n i c a l r e g u l a t i o n i n E u r o p e . T h e c o m m e n t s w e m a k e i n t h i s C o m m i s s i o n a d d r e s s v e r y s p e c i f i c , b u t v e r y i m p o r t a n t a s p e c t s w h e r e w e s e e a c l e a r n e e d f o r i m p r o v e m e n t s a n d c l a r i f i c a t i o n . O u r p r o p o s a l s a i m a t i n c r e a s i n g c e r t a i n t y a n d a v o i d c o n f u s i o n o r e v e n n e g a t i v e i m p a c t s f o r i n n o v a t i o n . W e t h a n k t h e E u r o p e a n C o m m i s s i o n f o r c o n s i d e r i n g o u r c o m m e n t s a n d w e h o p e t h a t t h e C o m m i s s i o n m a y b e r e a d y t o p r o p o s e a n d s u p p o r t r e s p e c t i v e c o m m e n t s d u r i n g t h e p r o c e s s o f c o - l e g i s l a t i o n . O F E s h a l l b e a v a i l a b l e a n y t i m e t o d i s c u s s a n d e x c h a n g e f u r t h e r o r t o p r o v i d e c l a r i f i c a t i o n s t o o u r p r o p o s a l s i f r e q u i r e d . OpenForum Europe AISBL Avenue des Arts 56 4C Brussels 1000 OFE in the EU transparency register: 27021 14689 1 0",an
Fondation pour le droit continental (France),F2665524,06 August 2021,Other,Medium (50 to 249 employees),France,"R glementation sur l Intelligence Artificielle et Justice Avec l appui scientifique de Monsieur Bruno Deffains Professeur l Universit Paris II Panth on Assas Note destin e la Commission Europ enne Avec la proposition de r glement sur l intelligence artificielle (IA) pr sent e le 21 avril 2021, la Commission europ enne r affirme l importance strat gique de l IA pour l'Europe et la n cessit d encadrer son usage dans les diff rents secteurs d application. Nous tenons saluer cette initiative unique dans le monde , qui place l intelligence artificielle au centre des r flexions juridiques, politiques et soci tales , desquelles elle est d sormais indissociable. En investissant le terrain r glementaire, l Union Europ enne entend se positionner en chef de file, comme elle l a d j fait avec le RGPD et c est une excellente nouvelle . Comme avec le RGPD, l objectif est d instaurer un climat de confiance tout en permettant l innovation . L approche par les risques e st quilibr e (I) pour permettre un juste d ploiement des syst mes d IA en Europe. N anmoins, en raison de ses enjeux sp cifiques et d licats, nous appelons traiter le secteur de la Justice comme un secteur hautement sensible pour nos concitoyens (II) . Nous regrettons que le texte soit trop restrictif et ne comprenne pas suffisamment les enjeux de la justice pr dictive avec les garde -fous n cessaires au bon respect des droits fondamentaux des individus . L approche par les risques : une approche quilibr e L approche de la Commission europ enne se fonde ainsi avant tout sur une identification et un encadrement des risques selon les domaines d applications (publics ou priv s) concern s. La proposition de la Commission europ enne classifie les syst mes d IA en quatre groupes : a) ceux cr ant un risque inacceptable (art., b) ceux haut risque (art.6 et s.) et c) ceux avec un risque faible (art. , devant r pondre des exigences de transparence (comme l es chatbots, o l on devra savoir que l on se trouve face une IA , ou les deepfakes) ou d) minimum (p.. Les risques sont ainsi consid r s comme inacceptables dans le champ de la s curit , des moyens de subsistance et des droits des personnes. Les r isques sont per us comme lev s dans les domaines touchant les infrastructures critiques ( nergie, transports ), l ducation, la formation professionnelle, l emploi, les ressources humaines, les publics essentiels l image du maintien de l ordre, de la ju stice ou des processus de d cision d mocratiques. Ainsi, par exemple, les syst mes d identification biom trique distance fond s sur l IA , sont consid r s haut risque et la Commission rappelle l'interdiction de leur utilisation dans l'espace public et e n temps r el ""aux fins du maintien de l ordre"" en dehors de cas sp cifiques encadr s judiciairement. Dans les secteurs o les risques sont limit s, la Commission recommande une transparence d information sur la pr sence de l IA. Enfin, dans d autres domain es d application comme les jeux vid o ou les filtres antispam, les risques li s la pr sence de l IA sont consid r s comme minimes et ne n cessitent pas d'encadrement sp cifique. Il est important de souligner le tournant strat gique que constitue cet te r glementation. Apr s une longue p riode de r gulation prudente des outils et applications num riques, except sous l angle de la protection des donn es ou de la lutte contre la cybercriminalit , la Commission entend acc l rer le pas. Cette volution t ouchant l IA est l une des composantes d une strat gie clairement nonc e dans les lignes politiques 2019 -2024 de la Commission et laquelle vont contribuer d autres textes parmi lesquels le Digital Market Act, le Digital Service Act, le Data Governance A ct ou encore l Open Data Directive. L Europe compte juste titre s imposer en gardien ne des valeurs dans le nouvel environnement num rique et jouer pleinement de son exp rience de r gulateur pour aligner les op rations de ses concurrents directs (am ricai ns et asiatiques) sur son rythme. Le secteur de la Justice hautement sensible pour les citoyens europ ens : le texte m rite d tre approfondi avec davantage de garanties pour la justice predictive Ces ambitions conduisent la Commission propose r une approche originale en termes de risques en distinguant 4 types d applications, avec des contraintes l intensit d croissant. Ce faisant, elle n chappe toutefois pas une certaine complexit pour la mise en conformit des applications pr sentant l e plus de risque de dommage sur les individus. C est particuli rement vrai dans le domaine de la justice. La classification des syst mes d bouchera n cessairement sur des interpr tations et des d bats, des op rateurs pouvant tre tent s d viter la r gulat ion contraignante pour des applications la limite du haut risque (est -ce qu un potentiel syst me de gestion des audiences dans les tribunaux repr sente un haut risque par exemple ?). Le prononc de sanctions au titre des ventuels manquement devra g alement prendre en compte la concurrence possible entre diff rents ordres de juridictions (p nales et administratives), probl matique d j connue entre les autorit s de protection des donn es et les juridictions p nales notamment. Par ailleurs, si l on peut se r jouir de la mention de certains probl mes sous -estim s (comme les biais d automatisation art. 14, 4, b), on comprend que des questions de principe n ont pas t approfondies , notamment celle de l opportunit du recours d es algorithmes dans certaines mati res comme la police ou la justice. M me si, dans ce domaine haut risque , une proc dure d examen de conformit s appliquera, l annexe III autorise de fait le principe d un appui de syst mes algorithmiques pour la pri se de d cision judiciaire, le profilage des individus ou le contr le aux fronti res. A titre d exemple, rien n est r ellement dit sur l att nuation concr te des biais ou le degr d explicabilit attendu, notamment dans ces domaines. La cons quence de cette position sera de ne satisfaire personne en d finitive : les d fenseurs de droits jugeront comme une r gression cette l gitimation ; les legaltechs et autres op rateurs priv s vont se voir imposer une tr s lourde mise en conformit sans n cessairement r po ndre au fond des critiques pouvant leur tre adress es (comme le sens des pr visions des outils de justice pr dictive ). Nombre d applications risquent donc d tre blanchies par un dispositif de mise en conformit . Les enjeux en la mati re sont loi n d tre n gligeables tant on doit mesurer les cons quences que ces applications peuvent avoir sur le fonctionnement long terme de la justice. La justice pr dictive appara t donc au c ur de nombreux d bats qui renvoient la fois son potentiel de d vel oppement du fait de son appropriation croissante par les praticiens du droit et des inqui tudes suscit es sur un plan ontologique, notamment dans le contexte particulier des syst mes de droit codifi s o la r gle prime en principe sur le fait . Si o n peut s accorder sur le fait que l analyse quantitative des donn es jurisprudentielles permet de d terminer des valeurs qui doivent tre interpr t es et replacer dans le contexte particulier de la fabrique du droit qui ne saurait tre d tach e des car act ristiques inh rentes l organisation de la justice dans une d mocratie moderne la fois du point de vue du travail des juges et des conditions de collecte et de traitement des donn es. Ceci est d autant plus important que dans la plupart des pays (de droit civil mais aussi de common law ), le travail de traitement des donn es est largement confi au secteur priv , ce qui pose n cessairement la question de la contribution effective de la justice pr dictive l am lioration du service public de la ju stice. De mani re g n rale, la proposition marque une tape importante mais elle semble encore h siter entre le trop ou le trop peu de pr cisions, laissant craindre la mise en place d un cadre juridique l gitimant des applications tout fait critiqua bles. Les garde -fous sont n cessair es. Cr er de la confiance dans la justice dans une p riode de transformation num rique massive passe par des recours facilit s pour les individus, par des mesures soci tales prenant mieux en compte la dimension collective des enjeux du num rique et en imposant une charge de mise en conformit , fond e sur des preuves scientifiques solides, qui soit une r elle valeur ajout e qualitative pour les citoyens europ ens. Pour toute information compl mentaire, veuillez co ntacter Anne -Charlotte Gros, Directrice G n rale de la Fondation pour le droit continental l adresse suivante : acgros@fondation - droitcontinental.org",fr
Deutscher Anwaltverein (Germany),F2665503,06 August 2021,Other,Medium (50 to 249 employees),Germany,"Deutscher Anwaltverein Littenstra e 11, 10179 Berlin Tel.: +49 30 726152 -0 Fax: +49 30 726152 -190 E-Mail: dav@anwaltverein.de B ro Br ssel Rue Joseph II 40 1000 Br ssel, Belgien Tel.: +32 2 28028 -12 Fax: +32 2 28028 -13 E-Mail: bruessel@eu.anwaltverein.de Transparenz -Registern ummer: 87980341522 -66 Stellungnahme des Deutschen Anwaltvereins durch den Aussch uss Informationsrecht zum Vorschlag der EU -Kommission f r eine Verordnung zur Festlegung harmonisierter Vorschriften f r k nstlic he Intelligenz (Gesetz ber K nstliche Intelligenz) vom 2021 (COM ( 206 final) Berlin /Br ssel , im Juli 2021 Mitglieder des Ausschusses Informationsrecht - Rechts anwalt Dr. Helmut Redeker (Vorsitzender) - Rechtsanwalt Dr. Simon Assion, Frankfurt am Main - Rechtsanw ltin Dr. Christiane Bierekoven, D sseldorf - Rechtsanw ltin Isabell Conrad, M nchen - Rechtsanwalt Dr. Malte Gr tzmacher, LL.M., Hamburg (Berichterstatter) - Rechtsanwalt Prof. Niko H rting, Berlin - Rechtsanwalt Peter Huppertz, LL.M, D sseldorf - Rechtsanw ltin Birgit Roth -Neuschild, Karlsruhe - Rechtsanwalt Dr. Robert Selk, LL.M. (EU), M nchen Zust ndig in der DAV -Gesch ftsf hrung - Rechtsanw ltin Nicole Narewski , Berlin Ansprechpartnerin in Br ss el - Hannah Adzakpa, LL.M. Seite 2 von 11 Der Deutsche Anwaltverein (DAV) ist der freiwillige Zusammenschluss der deutschen Rechtsanw ltinnen und Rechtsanw lte. Der DAV ve rsammelt mehr als 000 Rechts anw ltinnen und Rechtsanw lte sowie Anwaltsnotarinnen und Anwaltsnotare, die in 252 lokalen Anwaltvereinen im In - und Ausland organisiert sind. Er vertritt die Interess en der deutschen Anwaltschaft auf nationaler, europ ischer und internationaler Ebene. Diese Stellungnahme beschr nkt sich auf einige Punkte aus Sicht des Informationsrechtsausschusses und geht u.a. nicht auf Fragen der Rechtsstaatlichkeit oder Auswirkungen auf die juristischen Berufe ein. Diesbez glich wird auf die ausf hrliche DAV -Stellung nahme Nr. 40/2020 zum Wei buch de r EU-Kommission verwiesen. Grunds tzlicher Ansatz der Regulierung Der grunds tzliche Ansatz der Regulierung in Form einer horizontalen Regulierung ist zu begr en. Soweit Art. 2 Abs. 2 des Vorschlag s der EU-Kommission f r eine Verordnung zur F estlegung harmonisiert er Vorschriften f r k nstliche Intelligenz (im Folgenden abgek rzt KI-VO-E) allerdings un ter Verweis auf entspre chende Verordnungen die Fahrzeug - und Luftfahrtind ustrie von der Regulierung prak tisch vollst ndig ausnimmt, ist dieses mit Blick auf diese besonders komplexen Bereiche zwar f r einen gewissen Zeitraum tolerabel; es sollte jedoch, wie von der Kommission angedacht , auch in diesen Bereichen zeitnah eine entsprechende Regulierung erfolgen. Und dabei ergibt es Sinn, ein System zu schaffen, welches sowohl die im derzeitigen Entwurf erfassten KI -Systeme wie auch die in den besagten Industrien mehr oder minder gleichbehan delt. Denn eine Abgrenzung d rfte zum einen bei KI -Systemen, die in verschiedenen Industrien zum Einsatz kommen, zu zus tzlichem Problem - und Administrationsaufwand f hren. Zum anderen wird es auch immer wieder Systeme geben, die im Grau - bzw. Grenzbereich dieser Ausnahme li egen. Man denke an Verkehrsinfr astruktursysteme, die mit Fahrzeugen kommunizieren. Die Grundpfeiler des KI -VO-E f r hochriskante KI -Systeme (dazu unter ) sind eben falls positiv zu bewerten, n mlich namentlich: Seite 3 von 11 - eine verst rkte Verpfli chtung zum Qualit ts - und Risikomanagement ( Art. 9 und 17 KI -VO-E) einschl. Post Market Monitoring (Art. 61 KI -VO-E), - eine st rkere Regulierung von Trainings - und Testdaten ( Art. 10 und 9 Abs. 5 7 KI-VO-E), - eine Forderung nach den M glichkeiten und der Durchf hrung eines Event Logging ( Art. 12, 16 lit. a) und d) bzw. Art. 29 Abs. 5 KI -VO-E) sowie schlie lich - die Beobachtungspflichten nicht nur des Anbieter s, sondern auch des Nutzers (Art. 29 Abs. 4 KI -VO-E). Die besagten Anforderunge n und Pflichten sollten dazu f hren, den typischen Risiken zumindest der sog. schwachen KI insbesondere solc her KI -Systeme, die zu einem gewissen Grad auch noch selbstlernend agieren ein St ck weit entgegenwirken zu k nnen. So liegt die besondere Schw ierigkeit der rechtlichen Behandlung der Gefahren der KI darin, dass KI -Systeme einerseits menschliches Ver halten und menschliche Entschei dungen substituieren bzw. bernehmen k nnen, insofern also effizienzf rdernd wirken, andererseits ihr Verhalten und ih re Entscheidung oftmals unvorhersehbar sind, so dass es eines erh hten Qualit ts - und Risikomanagements bedarf. Hinzu kommt, dass M ngel von KI -Systemen nicht allein in der Konstruktion und Fabrikation begr ndet sein m ssen, sondern insbesondere das Traini ng der Systeme (etwa neuronaler Netze) von besonderer Bedeutung ist. Insofern wirken die Anforderungen an das Training und die Governance von Trainings - und anderen Daten (vgl. Art. 10, Art. 9 Abs. 5 - 7 KI-VO-E) mutma lich risikoreduzierend. Da Fehlent scheidungen und Fehlverhalten dieser Systeme aber nicht von vornherein ausgeschlossen werden k nnen, ist es konsequent, (i) mit dem Event Logging eine sp tere Nachverfolgbarkeit einzufordern und (ii) mit Hilfe der Anforderungen und Pflichten mit Blick auf Testdaten sowie Beobachtungspflichten eine erh hte Aufmerksamkeit mit Blick auf die Systeme einzufordern. Allerdings ist kritisch zu hinterfragen, ob nicht die in Art. 29 Abs. 4 KI -VO-E gefor derten Monitoring -, also berwachungspflichten des Nu tzers ber ihr Ziel hinausschie en. Das Monitoring/die berwachung von Systemen d rfte regelm ig dem eigentlich innovativen autonomen Verhalten der Systeme entgegenstehen. Hier ist zum einen Seite 4 von 11 ber eine sachliche - aber auch m glicherweise ber eine zeitliche - Beschr nkung nachzu denken. Das gilt insbesondere, wenn KI -Systeme mutma lich nach einer bestimmten Zeit nicht weiter trainiert werden bzw. ggf. nicht mehr selbst lernen. Jedenfalls in diesen F llen, tendenziell je nach Gefahr auch zuvor, sollte sodann eine Beobachtungspflicht ausreichend sein. Gegenstand und Reichweite der Regulatorik Die KI -Systeme sind in Art. 3 Nr. 1 KI -VO-E legal definiert. Die Regelung erscheint einerseits mit Blick auf zuk nftige Entwicklungen insoweit zu eng zu sein, als Art. 3 Abs. 1 KI-VO-E auf von Menschen festgelegte Ziele abstellt. Denn k nftig kann nicht ausgeschlossen werden, dass auch die KI selbst Ziele definiert, zumindest dann, wenn sie sich einer sogenannten starken KI ann hert. Dieser Bereich muss erst recht reguliert werden. W hrend insofern eine Nachbesserung allerdings in Ansehung der Unsicherheit ber den Durchbruch starker KI nicht dringlich ist, besteht unmittelbarer Nachbesserungsbedarf mit Blick auf den Annex I des Entwurfs, welcher die regulierten Systeme sehr weit fasst und hierunter insbesondere auch normale Expertensysteme sowie Such - und Optimierungsmethoden fasst. Zu pr fen ist allgemein, ob als KI mittels des Annex I nur solche Systeme definiert werden, deren Entscheidungen bzw. deren Verhalten (als mit zumutbaren Mitteln) praktisch unvorhersehbar anzusehen sind. Auf diesem Wege w rden man im Zweifel ohne Not zahlreiche bereits bestehende IT - Systeme bzw. Softwarel sungen der umfangreichen, von der Kommission geplanten Regulierung f r KI -Systeme unterwerfen. Dieser Mehraufwand erscheint in Ansehung der Tatsache, dass diese sich bisher nicht als besonders gef hrlich erwiesen haben, problematisch, da administrativ berb rdend. Soweit dann nach der KI -VO-E ein Fall k nstlicher Intelligenz vorliegt, unterscheidet diese zwar zu Recht verschiedene Stufen der KI; die im Grundsatz vorgesehene Dreistufigkeit erscheint jedoch teils etwas willk rlich: - So finden sich in Art. 5 KI-VO-E intolerable und verbotene KI -Systeme , bei denen es ganz offenbar im W esentlichen darum geht, besonders gravierende Grund - bzw. Menschenrechtseingriffe zu unterbinden. Die in Art. 5 Abs. 1 KI -VO- E aufgef hrten KI -Systeme sind in der Tat auch durchaus problematisch, so Seite 5 von 11 dass gegen deren Auflistung im Grundsatz nichts einzuw enden ist. Was allerdings fehlt, ist eine Regelung, welche eine gewisse Guidance f r oder gegen das Verbot entsprechender KI schafft und auf diesem Wege die Grundlage f r eine zukunfts bezogene Erweiterung eines entsprechenden Katalogs bietet. Auch d rfte i m Sinne der Grundrechtsrelevanz noch deutlicher zwischen dem Einsatz von KI durch den Staat und durch Private zu differenzieren sein. - Auch die in Art. 6 ff. KI -VO-E gelisteten Hochrisiko -KI-Systeme werden z un chst legal definiert. berzeugend ist dies e Definition insoweit, als sie sicherheitsrelevante KI bzw. Produkte mit KI -Basis reguliert ( Art. 6 Abs. 1 KI -VO- E). Ob die regulierten Systeme dabei wirklich au f solche beschr nkt werden sollten, bei denen eine Konformit tspr fung durch Dritte erforder lich ist, sollte kritisch hinterfragt werden. Immerhin d rfte die insofern in Annex II aufgef hrte EU-Gesetzgebung hier ein deutlicher Fingerzeig f r ein h heres Gefahrenpotenzial sein. - Vor diesem Hintergrund ist es allerdings auch verst ndlich, dass Abs. 2 des Art. 6 KI-VO-E die M glichkeit zur Klassifizierung an das hochriskante KI -System und damit zu regulierende KI -System durch Annex III erweitert. Zwar ist auch hier hnlich wie bei Art. 5 KI-VO-E ersichtlich, dass es der EU -Kommission vor allem um die Regulierung grund - bzw. menschenrechtsrelevanter KI -Systeme geht. Auch hier gilt aber, dass die Abgrenzung in Ansehung der Liste des Annex III teils willk rlich erscheint und damit auch mit Blick auf die Erweiterungsm glichkeiten des Annex III nach Art. 7 KI-VO-E anf llig f r politische Einflussnahmen durch Lobbyisten ist. Auch hier gilt, dass Art. 7 KI-VO- E in Abs. 2 noch klarere Leitlinien f r eine Erfassung weiterer KI -Systeme in Annex III bieten sollte. - Schlie lich findet sich in Art. 69 KI -VO-E eine Regelung f r sonstige KI-Systeme, welche mit Ausnahme der Regelung in Art. 52 KI -VO-E unreguliert bzw. der Selbstregulierung berlassen bleiben sollen. Da es sich um ein junges Feld der Regulierung handelt, ist nachvollziehbar, dass nich t s mtliche Systeme ohne weiteres reguliert werden sollen. Auch spricht der bereits angesprochene starke Formalismus und der erh hte Dokumen tations - und Administrationsauf wand der Regulierung daf r, dass derartige Systeme zumindest vorerst unreguliert blei ben sollten. Andererseits sollte nicht verkannt werden, dass auch auf diese die Regulierung Auswirkungen hat (vgl. dazu unten unter ). Und schlie lich fragt Seite 6 von 11 sich auch, ob nicht die Gesamtregulierung auch auf diese Gruppen ausgedehnt werden sollte. Sie de nkt ja stark in den Kategorien von Risiken und Nutzen und kommt daher bei dieser Gruppe von Systemen automatis ch zu niedrigeren Anforderungen . Die Ausdehnung der Regulatorik h tte also keine dramatischen Folgen. Erm glicht w rden dann flie ende berg nge. Das Datenschutzrecht etwa un terscheidet f r seine Anwendbarkeit ja auch nicht zwischen datenschutzrechtlich unterschiedlich riskanten Verarbeitungen, reguliert also nicht nur hochriskante Verarbeitungen, sondern siehe allenfalls zus tzliche gesetzlichen Anforderungen vor. Schlie lich gilt im brigen auch hier wieder, dass KI -Systeme naturgem teils bei gleicher Technologie bzw. gleichen Systemen je nach Anwendungsgebiet sodann reguliert oder eben unreguliert w ren. Abgrenzungsschwierigkeiten liegen da bei auf der Hand. Umfang und Aufbau des Verordnungsentwurfs / Regelungstechnik Die Gesamtverordnung erscheint auf den ersten Blick sehr lang und in ihrer Struktur durchaus komplex. Dieses d rfte zu gewissen Anwendungsschwierigkeiten und u.U. auch zu Rechtsunsicherheiten f hren: - So ist etwa f r den Leser nicht ohne weiteres ersichtlich, welche Anforderungen des Kapitel 2 den Anbieter in welcher Form treffen, bzw. warum dieses eigentlich separat von den Anbieterpflichten in Kapitel 3 geregelt ist, der sodann zum einen pauschal ( Art. 16 lit. a KI -VO-E) und zum anderen wiederholt kon kret (so et wa in Art. 17 Abs. 1 lit. e und f KI -VO-E) au f das Kapitel 2 zur ckverweist. - Problematisch erscheinen auch die vielen redu ndanten Regelungen, die zu Norm widerspr chen f hren k nnten (z. B. Art. 16 lit. g und Art. 21 KI -VO-E). - Auch die R ckverweisungen auf andere Verordnungen (etwa Art. 42 Abs. 2 und Art. 47 Abs. 6 KI -VO-E) erschweren die Lesbarkeit und damit die Anwendung der KI-VO-E. Abschlie end i st zu monieren, dass die Regelungen von u erst unterschiedlicher Regelungstiefe sind. Teils werden echte Details, teils nur gro be Linien vorgegeben. Hier sollten die allgemeinen Prinzipien deutlicher herausgearbeitet und mit anderen Prinzipien des europ i schen Produktsicherheits -, aber auch des Produkthaftungsrechts abgeglichen werden. Damit w rde auch die Rechtssicherheit erh ht. Seite 7 von 11 Einzelregelungen und Aspekte Ohne den Anspruch auf Vollst ndigkeit sei im Detail auf Folgendes hingewiesen: - Inhaltlich z u hinterfragen ist, warum Nutzer im Sinne der geplanten Verordnung nur professionelle Nutzer sind ( Art. 3 Abs. 4 KI -VO-E). Auch wenn das wahrscheinlich praktisch nur in wenigen F llen von Bedeutung ist, fragt sich, was f r nicht professionelle Anbieter u nd Anwender (etwa bei Idealvereinen und NGOS) hei t. Die DSGVO etwa kennt eine Ausnahme nur f r nat rliche Personen zur Aus bung ausschlie lich pers nlicher oder famili rer T tigkeiten (Art. 2 Abs. 2 lit. c) KI -VO-E). Der Unterschied berzeugt nicht. - Weiter kritisch zu hinterfragen ist, dass die biometrischen Identifikationssysteme weitgehend nur verboten sind, wenn sie in Realtime funktionieren ( Art. 5 Nr. 1 lit. d) KI -VO-E), sonst aber nur als Hochriskante KI -Systeme zu behandeln sind. Es ist nicht z u erkennen, dass die Gefahren solcher Systeme so unterschiedlich sind, dass sie diese unterschiedliche Behandlung rechtfertigen. - Auff llig ist, dass in Art. 9 KI-VO-E f r Sicherheitsma nahmen lediglich der anerkannte Stand der Technik gefordert wird. Dieses ist gerade f r Hochrisiko - KI-Systeme berraschend, zumal etwa das Produkthaftungsrecht und auch die deutsche Rechtsprechung sogar die Einhaltung des Stands der Wissenschaft und Technik fordern (vgl. 1 Abs. 2 Nr. 5 ProdHaftG; Hofmann , CR 2020, 282, 284 f.). Hier sollte in Ansehung der Hoch -Risiko -Systeme einerseits und Bu gelder sowie zur Innovationsf rderung anderseits zumindest der Kompromiss gesucht werden, auf den neuesten Stand der Technik abzustellen. - Nicht realistisch erscheint die Anforde rung in Art. 10 Abs. 3 S. 1 KI -VO-E, nach der Trainings -, Validierungs - und Testdatens t ze relevant, repr sentativ, fehlerfrei und vollst ndig sein m ssen. Gerade mit Blick auf die Vollst ndigkeit und Fehlerfreiheit scheint dieses unm glich. Erg nzt wer den sollte ein ""bestm glich"" oder ""im zumutbaren Rahmen"". Auch ist zu bedenken, dass mitunter je nach Zweckbestimmung auch schlechte Daten gut sein k nnen. Au erdem lassen sich die Relevanz, Repr sentanz, Vollst ndigkeit und Fehlerfreiheit der Daten nur vo r dem Hintergrund des bestimmungsgem en Verwendungszwecks definieren. Dieser Bezug in Art. 10 Abs. 3 S. 1 KI -VO-E durch die Erg nzung "" m ssen mit Blick auf die Zweckbestimmung des Hochrisiko -KI-Systems relevant "" klargestellt werden. Schlie lich fe hlt zu Art. Seite 8 von 11 10 Abs. 3 S. 1 KI -VO-E eine R ckausnahme, die es erlaub t, von diesen Qualit tsanforderungen an Trainings -, Validierungs - und Testdatens tze abzur cken, soweit der Schutz anderer Rechtg ter (insb. der Datenschutz) dieses zwingend erforder t. - Art. 14 Nr. 5 KI -VO-E sieht die Best tigung eine r durch lernende Systeme getroffenen Identifikation von Personen durch zwei Menschen vor, was zumindest dann nicht berzeugt, wenn auch ohne KI nur ein Mensch entsch eidet. Oder ist hier intendiert , KI-Vorschl ge, die sonst aus Bequemlichkeit bernommen werden k nnten, einem Vieraugen -Prinzip zu unterwerfen? - Art. 28 Abs. 1 KI -VO-E fordert vom Nutzer die Anbieterpflichten einzuhalten, wenn er die Zweckbestimmung eines bereits im Verkehr befindlichen o der in Betrieb genommenen Hochrisiko -KI-Systems ver ndert oder wenn er eine wesentliche nderung an dem Hochrisiko -KI-System vornimmt. Es ist zu bezweifeln, dass er hierzu in der Lage sein wird, ohne sich hier ber mit dem Original -Anbieter zu verst ndige n. Bei der Veredelung von IT -Diensten k nnte dieses zu einer Abh ngigkeit von der Wissenshoheit de s Original -Anbieters auf abgeleiteten M rkten f hren, der entweder durch ""Zugangsrechte"" zu diesem Wissen gegen angemessen e Verg tung entgegnet werden sollte oder aber zumindest durch eine Relativierung dieser Pflichten (z.B. ""soweit"" statt ""wenn""). - Widerspr chlich ist es, wenn in Art. 28 Abs. 2 KI -VO-E der Anbieter teils aus der Verantwortlichkeit entlassen wird, wenn die KI -Systeme stark ver ndert bzw. entgegen ihrem Verwendungszweck genutzt werden. Dieses widerspricht dem grunds tzlichen Ansatz sowohl des Produkthaftungsrechts als auch des KI -VO-E (vgl. etwa Art. 9 Abs. 2 lit. b), 4 lit. c), 13 Abs. 3 lit. b) (iii) und 14 Abs. 2 KI -VO-E), nachdem auch i mmer der zu erwartende Missbrauch eines Systems vom Anbieter mitber cksichtigt und im optimalen Fall (Konstruktion vor Instruktion) mit verhindert werden sollte. - Die Regelungen zu harmonisierten Normen nac h Art. 40 KI -VO-E tragen das Risiko in sich, in einem sehr innovativen Gesch ftsfeld nicht ausreichend schnell agieren zu k nnen (sprich: die Vermutung k nnte sich nach kurzer Zeit als berholt erweisen), die Regelung nach Art. 41 KI -VO-E beinhaltet das Risiko , Durchf hrungsa kte in besonders sensiblen und grundrechtsreleva nten Bereichen auf die Kommissi on (also die Verwaltung) zu verlagern. Seite 9 von 11 - Art. 63 Abs. 2 KI -VO-E sieht die Information nur von ""einschl gigen nationa ler Wettbewerbsbeh rden"" vor. Unklar ist, ob das hei t, dass nur Beh rden aus einzeln en Mitgliedsstaaten unterrichtet werd en m ssen, oder ob in jedem Mitgliedsstaat die zust ndige Wettbewerbsbeh rde informiert werden m ssen Eine Klarstellung w re sinnvoll. Daten - und Geheimnisschutz Die aus Sicht des ffentlichen Sicherheits - und des Zivilrechts zu begr ende, umfas sende Datenaufzeichnung (insb. von Eventlogs) und Dokumentation, wie sie von der KI -VO-E gefordert werden, kollidieren mit dem Daten - und Geheimnisschutz. Die KI -VO-E versucht, den widerstreitenden Schutz vor Gefahren mit d em Datenschutz an einigen Stellen in Einklang zu bringen ( Art. 10 Abs. 5, Art. 29 Abs . 6 KI-VO-E). Es ist zu bezweifeln, dass diese Regelungen ausreichen, um KI -Systeme, die oftmals auf Big Data aufsetzen, ausreichend zu regulieren. Die Thematik un d das Verh ltnis zur DSGVO sind weiter zu kl ren. So stellt sich u.a. die Frage, ob Eventlogs fortlaufend mitgeschrieben und aufgezeichnet werden d rfen bzw. m ssen. Sinnvoll k nnte es u.U. sein, die Archivierung zeitlich zu begrenzen (""Ring speicherung"") und nur im St rfall oder bei Rechtsgutverletzungen / Unf llen die Daten l ngerfristig zu speichern. berdies sollte gerade mit Blick auf KI -Systeme im medizinischen Bereich mit Blick auf sensitive Daten i.S.v. Art. 9 Abs. 1 DSGVO eine zus tzliche Erlaubnisnorm geschaffen werden, die ber die dort in Abs. 2 geregelten Tatbest nde hinausgeht. Die dortigen Erlaubnisse (einschl. der Einwilligung) greifen regelm ig zu kurz; ob die Erg nzung in der DSGVO oder in der KI -VO-E erfolgt , kann dahins tehen. Hintergrund ist, dass Art. 6 Abs. 1 lit. c DSGVO f r Daten i.S.v. Art. 9 Abs. 1 DSGVO nicht greift. Auch die Kollision mit dem Geheimnisschutz sollte nicht nur mit Blick auf Beh rden ( Art. 70 KI -VO-E) geregelt werden. Zwar werden prim r mit diese n Informationen zur Dokumentation und ber St rungen ausgetauscht. Es besteht aber gleichwohl die M glichkeit, dass Dritte diese Informationen einsehen k nnten. Hier fragt sich, ob Art. 70 KI -VO-E klar genug vermittelt, ob auch Eventlogs und Trainingsdaten (etwa im Seite 10 von 11 Rahmen zivilrechtlicher Auseinandersetzungen) zur Verf gung gestellt werden d rfen oder ob es sich um nach Abs. 1 lit. a schutzw rdige Daten handelt. Regulatorik und KMUs Kritisch zu hinterfragen ist, ob die KI -Reallabore (San dboxes), wie sie in Art. 53 f. KI - VO-E geregelt sind, im Rahmen des verfassungsrechtlich Zul s sigen (Gleichbe rechtigung) ausgeweitet werden sollten, um KMUs die Entwicklung innovativer KI-Systeme und auch deren Erprobung in der Praxis zu erm glichen. D ie umfassende Regulatorik, insbesondere die zahlreichen Dokumentations - und Meldepflichten k nnten ein Hemmnis f r KMUs, insb. Startups, darstellen, se lbst wenn die Pflicht zum Quali t tsmanagement durch Art. 17 Abs. 2 KI -VO-E wenn auch kaum prognostiz ierbar relativiert wird und auch andere Erleichterungen vorgesehen sind (vgl. Art. 3 Nr. 3, Art. 55, 59 Abs. 7, 69 Abs. 4, 71 KI -VO-E). Unklar ist bei Art. 17 Abs. 2 KI-VO-E brigens, ob es richtig ist, auf den Anbieter bzw. dessen Gr e abzuste llen oder ob nicht eher der Konzern des Anbieters entscheidend sein sollte. Zu erw gen ist, auch f r den Umfang der Regulatorik noch st rker auf die Gefahren der KI -Systeme (auch in quantitativer Hinsicht) abzustellen. Hier ist zu empfehlen, den Dialog mit entsprechenden Wirtschaftsverb nden zu suchen. Sonstige Konsequenzen Die KI -VO wird, wenn sie in Kraft tritt direkte Auswirkungen auf das nationale Recht haben. In Deutschland wird sie als Schutzgesetz i.S.v . 823 Abs. 2 BGB u.a. eine deliktische Haftung begr nden k nnen. Auch wird sie im Rahmen des 823 Abs. 1 BGB Verkehrs(sicherungs)pflichten begr nden. Insofern fragt sich, ob nicht einige der Rege lungen der KI -VO-E den Akteuren zu weit reichende Pflichten und damit Haftungsrisiken auferlegten. Das gilt insb. f r die Pflicht der Nutzer zur Befolgung der Instruktionen nach Art. 29 Abs. 1 KI -VO-E und die Informations - und berwachungspflichten der Nutze r nach Art 29 Abs. 4 KI -VO-E. Besonders kritisch k nnte diese auch mit Blick auf strafrechtliche Fahrl ssigkeitsnormen (insb. die fahrl ssige K rperverletzung und T tung) sein, f r die die KI -VO-E m glicherweise im Sinne der Konkordanz der Rechtsordnung Sorgfaltsma st be statuieren w r de. Seite 11 von 11 Unbenommen dessen ist es richtig, davon auszugehen , dass die Regelungen die zivilrechtliche Haftung zumindest der Anbieter mit pr gen sollten; andernfalls m ssten sie sich auf zwei Haftungsma st be einstellen: einerseits auf einen Ma stab des ffentl ichen Sicherheitsrechts und anderseits auf einen zivilrechtlichen Haftungsma stab. Dies d rfte unzumutbar sein.",de
Verband kommunaler Unternehmen e.V. (Germany),F2665488,06 August 2021,Company/business,Medium (50 to 249 employees),Germany,"Verband kommunaler Unternehmen e.V. Invalidenstra e 91 10115 Berlin Fon +49 30 58580 -0 Fax +49 30 58580 -100 info@vku.de Der VKU ist mit einer Ver ffentlichung der Stellungnahme ei nverstanden. Sofern Kontaktdaten von Ansprechpartnern enthalten sein sollten, bitten wir, diese vor einer Ver ffentlichung zu schw rzen. Der Verband kommunaler Unternehmen (VKU) vertritt rund 500 Stadtwerke und kommunalwirtschaftliche Un- ternehmen in den Bereichen Energie, Wasser/Abwasser, Abfallwirtschaft sowie Telekommunikation. Mit mehr als 000 Besch ftigten wurden 2018 Umsatzerl se von rund 119 Milliarden Euro erwirtschaftet und mehr als 12 Milliarden Euro investiert. Im Endkundensegment haben die VKU -Mitgliedsunternehmen gro e Marktanteile in zentralen Ver - und Entsorgungsbereichen: Strom 62 Prozent, Erdgas 67 Prozent, Trinkwasser 90 Prozent, W rme 74 Prozent, Abwasser 44 Prozent. Sie entsorgen jeden Tag 500 Tonnen Abfall und tragen durch getrennte Sammlung entscheidend dazu bei, dass Deutschland mit 67 Prozent die h chste Recyclingquote in der Europ i- schen Union hat. Immer mehr kommunale Unternehmen engagieren sich im Breitbandausbau. 190 Unternehmen investieren pro Jahr ber 450 Mio. EUR. Sie steigern j hrlich ihre Investitionen um rund 30 Prozent. Beim Breit- bandausbau setzen 93 Prozent der Unternehmen auf Glasfaser bis mindeste ns ins Geb ude. STELLUNGNAHME zum Verordnungs entwurf der Europ ischen Kommis- sion f r den Artificial Intelligence Act vom April 2021 Berlin , August 2021 2 / 5 Der VKU bedankt sich f r die M glichkeit, zu dem Verordnungsvorschlag der Kommission ber harmonisierte Regeln f r k nstliche Intelligenz Stellung zu nehmen. Wir begr en, dass die Kommission in ihrem Vorschlag einen risikobasierten Ansatz ver- folgt . Damit bleibt die Mehrzahl der KI-Anwendungen unber hrt , da von ihnen kein Risiko ausgeht. Wichtig ist nun, dass unter den Anwendungsbereich des Verordnungsvorschlags nur ent- sprechend risikoreiche Systeme fallen . Dies bedeutet erstens , dass nur Systeme den stren- gen Anforderungen entsprechen m ssen, die unmittelbar im Hochrisikobereich zum Ein- satz kommen . Zweitens d rfen unter die Definition der k nstlichen Intelligenz keine her- k mmlichen Algorithmen fallen . Bedeutung des Vorhabens f r kommunale Unternehmen Kommunale Unternehmen verwenden bereits heute in vielen Bereich en k nstliche Intel- ligenz. Neben der Momentaufnahme ist die mittel - bis lang fristige Perspektive von gro er Relevanz , da KI zuk nftig noch breiter und in allen Gesch ftsbereichen zum Einsatz kom- men wird. Dar ber hinaus wird die Menge an Daten aus intelligenter Sensorik stark an- wachse n und so auch die Nutzung von KI in vielen Gesch ftsbereichen erm glichen und voranbringen . Schon heute wird die Verw endung k nstlicher Intelligenz in verschiedens- ten Betriebs - und Gesch ftsbereichen , beispielsweise dem Vertrieb, bei Kundenschnitt- stellen, der Instandhaltung von Maschinen und Ger ten oder auch in der Netz - und Ver- kehrs steuerung erwogen und teilweise bereits von den Unternehmen selbst oder in Ko- operation mit Partnern entwickelt. Dar ber hinaus werden auch Open Source L sungen genutzt oder KI -L sungen eingekauft , die wiederrum teilweise an die spezifischen Unter- nehmenssituationen angepasst werden . Letztlich ist f r die Unternehmen auch die eigene Entwicklung oder die gemeinsame Entwicklung mit Partnern von KI -Systemen denkbar, die dann auch auf dem Markt angeboten werden k nnten. Positionen des VKU in K rze Um die Innovationskraft der Kommunalwirts chaft auch in Zukunft zu erhalten und die fl - chendeckende Nutzung von KI -Systemen zu gew hrlei sten, schl gt der VKU f olgende An- passungen an de m Vorschlag der Kommission vor: Definition von KI -Systemen Nach ak tuellem Stand sind die Definitionen von Technik en und Konzepten der k nstlichen Intelligenz aus Anhang I zu weit gefasst. Erkl rtes Ziel der Kommission ist es , besonders offen, insbesondere auch technologieoffen und neutral regulieren zu wollen , um den rasanten Entwicklungen Rechnung zu tragen (S. . Gem dem Wortlaut des Verord- 3 / 5 nungsvorschlags w rden allerdings zahlreiche Anwendungen, die keine autonom agieren- den oder selbstlernenden KI-Systeme darstellen, unter die umfangreichen Bestimmungen der Verordnung fallen. Daher spricht sich der VKU f r ein e pr zisere und engere Defini- tion von k nstlicher Intelligenz aus. Dies bezieht sich insbesondere auf Anhang I des Ver- ordnungsvorschlags. Unter b) und c) werden Logik - und wissensgest tzte Konzepte, einschlie lich Wissensre- pr sentation, induktiver (logischer) Programmierung, Wissensgrundlagen, Inferenz - und Deduktionsmaschinen, (symbolischer) Schlussfolgerungs - und Expertensysteme sowie Statistische Ans tze, Bayessche Sch tz -, Such - und Optimierungsmethoden genannt. Diese Definition en beziehen verschiedenste Algorithmen mit ein, die nicht als KI gelten sollten , da sie nicht selbstlernend sind oder sich selbstst ndig weiterentwickeln. Unter die Definitio n fallen auch herk mmliche Algorithmen, wie sie schon heute vielf ltig im Einsatz sind. Diese breite Definition unter b) und c) w rde jegliche Software miteinschlie en , die wenn -dann -Beziehungen nutzt. Damit w re nahezu jede Software bis hin zu einfachsten Anwendungen einbezogen und w rde durch die KI -Verordnung erfasst. Der VKU fordert daher , dass die Definition von KI -Systemen nachgesch rft wird und insbesondere die unter b) und c) formulierte n Techniken und Konzepte pr zisiert werden, damit her- k mmliche Software und simplere Algorithmen nicht in den Anwendungsbereich fallen. Definition von Hochrisiko -KI-Systemen Die Betroffenheit von KI -Systemen, die von kommunalen Unternehmen genutzt werden, ergibt sich aus Anhang III Verwaltung und Betrieb kritischer Infrastrukturen: a) KI-Systeme, die bestimmungsgem als Sicherheitskomponenten in der Verwaltung und im Betrieb des Stra enverkehrs sowie in der Wasser -, Gas -, W rme - und Stromversorgung verwendet werden sollen; . Aus VKU -Sicht ist eine klare Definition und Eingrenzung von Sicherheitskomponenten notwendig, um sicherzustellen, dass nur KI -Systeme von den Ma gaben der Verordnung betroffen sind, die aufgrund ihres Anwendungskontexts als Sicherheitskomponente tat- s chl ich ein hohes Risiko bergen. Zudem w rde eine solche Pr zisierung des Begriffs der Rechtssicherheit von Unternehmen, die KI -Systeme potenziell als Sicherheitskomponen- ten nutzen, zugutekommen. KI f r den Eigengebrauch Gem Art. 28 des Verordnungs vorsch lags gelten Nutzer von Hochrisiko -KI-Systemen als Anbieter im Sinne der Verordnung , wenn eine wesentliche nderung an einem Hochri- siko-KI-System vorgenommen wird. Mit der Einstufung als Anbieter geht die Verantwor- tung f r eine umfangreiche Konformit tspr f ung einher. Damit w rden auch kommunale Unternehmen, die KI -Systeme f r den Eigengebrauch entwickeln oder eingekaufte Sys- teme an die eigenen Betriebsprozesse anpassen , unter diese strengen Anforderungen fal- len. 4 / 5 Der Aufwand der Konformit tspr fung ist bei der kommerziellen Entwicklung von Hoch- risiko -KI-Systemen angemessen, da diese von vielen Betreibern genutzt werden und so ein kumulatives Risiko von Ihnen ausgeht. Entwickelt oder modifiziert ein Unternehmen hingegen eine KI f r den Eigengebrauch, steht da s Risiko in einem g nzlich anderen Ver- h ltnis zu dem Aufwand der Konformit tspr fung. F r kommunale Unternehmen w rde eine solche Pr fung schlimmstenfalls ein weiteres Hemmnis in der fl chendeckenden Nut- zung von KI -Systemen darstellen, da der Aufwand der K onformit tspr fung abschreckend wirken k nnte. Gleichzeitig w rde dies einen Anreiz schaffen, KI -Systeme nicht selbst zu entwickeln oder zu modifizieren, sondern als fertige L sung einzukaufen. Langfristig w r- den so die Innovationskraft kommunaler Unterneh men gehemmt und die Abh ngigkeit von Drittanbietern erh ht . Vielmehr sollte die eigene Entwicklung von KI -Systemen, sowie die Anpassung eingekaufter Systeme an die eigen en Bed rfnisse gef rdert werden, da sich h ierdurch betriebsspezifisches Know -how bildet . Daher spricht sich der VKU daf r aus, die Entwicklung und Modifizierung von Hochrisiko -KI-Systeme n f r den Eigenge- brauch von den versch rften Anforderungen f r Anbieter auszunehmen. Gegebenen- falls k nnte hier eine vereinfachte Konformit tspr fung einen g eeigneten Mittelweg bilden. 5 / 5 Bei R ckfragen oder Anmerkungen stehen Ihnen zur Verf gung: Simon Kessel Referent f r Digitales und Mobilit t VKU -Europab ro Telefon: +32 2 740 16 -55 E-Mail: Kessel@vku.de",de
Bundesverband Digitale Wirtschaft (BVDW) e.V. (Germany),F2665487,06 August 2021,Business association,Small (10 to 49 employees),Germany,"1 Stellungnahme des Bundesverbands Digitale Wirtschaft (BVDW) e.V. zum Verord- nungsvorschlag der EU -Kommission f r einen Rechtsrahmen f r K nstliche Intelligenz Vorbemerkungen Der Bundesverband Digitale Wirtschaft (BVDW) e.V . ist die Interessenvertretung f r Unternehmen, die digitale Gesch ftsmodelle betreiben oder deren Wertsch pfung auf dem Einsatz digitaler Technologien beruht. Als Impulsgeber, Wegweiser und Be- schleuniger digitaler Gesch ftsmodelle ver tritt der BVDW die Interessen der digitalen Wirtschaft gegen ber Politik und Gesellschaft und setzt sich f r die Schaf- fung von Markttransparenz und innovationsfreundlichen Rahmenbedingungen ein. Sein Netzwerk von Experten liefert mit Zahlen, Daten und Fakt en Orientierung zu einem zentralen Zukunftsfeld. Hintergrund Infolge der europ ischen Strategie zu K nstlicher Intell igenz ( KI) aus dem Jahr 2018 legte die EU -Kommission 2020 ihr KI-Wei buch vor. Parallel entwickelten hochran- gige Interessentr ger im Rahmen der hochrangigen Expertengruppe f r K nstliche Intelligenz ( HEG -KI) Leitlinien f r vertrauensvolle KI. Unter Ber cksicht igung der Ent- wicklungen der letzten Jahre sowie der ffent lichen Konsultationen , stellte die EU - Kommission am April 2021 einen Regulierungsvorschlag ber ein europ isches Konzept f r KI vor, welche r als Rechtsrahmen f r K nstliche Intelligenz auf EU - Ebene zu verstehen ist. Durch die Wahl des Instruments einer Verordnung soll dies e Gesetzgebung nach ihrem Inkrafttreten direkt in den europ ischen Mitgliedstaaten ohne Notwendigkeit einer Umsetzung in nationales Recht gelten. Entsprechend ist die zielf hrende Ausgestaltung dieser Vorschl ge von h chster Relevanz. Der vorgelegte Verordnungsvorschlag regelt unter anderem : Verbote bestimmter Praktiken im Bereich der KI; besondere Anforderungen an Hochrisiko -KI-Systeme und Verpflichtungen f r Betreiber solcher Systeme; August 2021 Ansprechpartner: Katharina Rieke Bereichsleiterin Politik & Gesellschaft T:+49 30 206 218 617 rieke@bvdw.org Dr. Anna Dietrich Referentin Mobilit t, K I & Smart Cities T:+49 30 206 218 61 5 dietrich@bvdw.org STELLUNGNAHME 2 harmonisierte Transparenzvorschriften f r KI -Systeme ; Vorschriften f r die Marktbeobachtung und Markt berwachung. Die Frist der ffentliche EU-Konsultation zu diesem Vorschlag endet am August Der BVDW will sich mit der vorliegenden Stellungnahme dara n beteiligen. Grundlegende Bewertung des Vorschlags Der BVDW begr t die Auseinandersetzung der EU -Kommission mit dem Thema der KI und unterst tzt grundlegend das Hauptziel der Kommission, das darin liegt , die Entwicklung und Einf hrung sicher er und legaler KI in Europa zu f rdern, die auch die Grundrechte im gesamten Binnenmarkt respektiert . Die Europ ische Union nimmt mit dieser Auseinandersetzung eine Vorreiterrolle ein und hat die Gelegen- heit einen wichtigen Standard im Bereich KI zu schaffen. Auch aus Sicht des BVDW ist v ertrauensvolle und innovationsfreudige KI ein we- sentliche r Standortfaktor f r Europa und seine Wirtschaft . Die Einhaltung europ ischer Werte und Grunds tze ist dabei von h chster Relevanz und der Mensch sowie die Auswirkungen auf ihn sollte n bei allen Bestrebungen im Fokus stehen . Die Entwicklung und Einf hrung neuer Technologien kann aber auch nur dann gelingen, wenn gleichzeitig gen gend Freir ume f r Innovationen und unter- nehmer ische Initiative bestehen. Hier muss eine angemessene Balance zwischen den unterschiedlichen Interessen gefunden werden. Der Digitalverband ist daher der Ansicht, dass vorrangig Anreize anstelle von Verboten wichtig sind , dass nur so viel wie notwendig reg uliert w erden sollte und es eine klare Abgrenzung zu anderen Re- gelungsbereichen (z. B. Datenschutz, IT -Sicherheit) geben muss. Der BVDW bef rwortet zwar grunds tzlich einen europaweiten Ansatz im Umgang mit KI, stellt jedoch auch klar in Frage, ob eine solche einheitliche Verordnung , wie sie nun vorgelegt wurde , das geeignete Mittel ist , um KI in Europa sinnvoll und ge- winnbringend zu gestalten. Eine umfassende Grundregulierung erscheint aus Sicht des BVD W vor dem Hintergrund weiterhin laufender wissenschaftlicher und wirt- schaftlicher Entwicklungen verfr ht. Zudem stellt sich die Frage, ob eine solche Verordnung wirklich umsetzbar ist und Rechtssicherheit berhaupt erreicht werden kann. Das Ziel e ine erste umfassende Grundregulierung f r KI zu schaffen, erscheint somit sehr ambitioniert . 3 Um den Chancen und Risiken von KI bereits jetzt Rechnung zu tragen, w re es a us Sicht des Digitalverbands ein sinnvollerer Weg, einen sektorale n Ansatz zu w hlen, und zwar ber die Erweiterung der bereits bestehenden fachspezifischen Regulie- rung en. Die Details der Verordnung legen aus unserer Sicht offen, dass d er horizontale Ansatz bei der Vielfalt der Funktionsweise n und Einsatzgebiete von KI massive Schwierigkeit en und Rechtsunsicherheiten mit sich bringt. Denn KI findet in den unterschiedlichsten Bereichen eine Anwendung , bringt in den Anwendungen unterschiedliche Herausforderungen mit sich und birgt dementsprechend auch un- terschiedliche Risiken und Chancen. Auch mit Blick auf datenschutzrechtliche Fragestellungen h tte dies eine nicht zu untersch tzende Bedeutung. Wenn bei- spielsweise KI im Gesundheitsbereich eingesetzt wird, k nnten ber einen sektoralen Ansatz zahl reiche ungekl rte Rechtsfragen einer L sung zugef hrt wer- den. Daher forde rt der BVDW die Kommission auf, den sektoralen Ansatz zu w hlen und dort verh ltnism ige Anpassungen vorzunehmen. Aus Sicht des BVDW muss nochmals verst rkt auf den Ste llenwert der Daten - und Datenschutz regulierung f r KI hi ngewiesen werden . Zum einen besteht ber einen sektoralen Ansatz nicht die Gefahr der berregulierung. Die sektoralen Regelungen sollten den allgemeinen Re- gelungen der Datenschutzgrundverordnung (DSG -VO) vorgehen, indem sie diese f r die konkreten Anwendungsfelder, z. B. dem Gesundheitsbereich, pr zisieren. Es w rde dadurch sogar sichergestellt werden, dass die verschiedenen Bereiche ange- messen und ""passgenau"" reguliert werden, da die Besonderheiten ber cksichtigt werden k nnen. Zum anderen entstehen d igitale Innovationen nicht (nur) in geschlossenen Syste- men. Der Mehrwert skalierbarer L sungen liegt in ihrer cross -funktionalen und branchen bergreifenden Nutzbarmachung von Daten und Informationen. Die KI -Re- gulierung muss daher auch Teil eines koh renten Rechtsrahmens f r Daten sein, der sicherstellt, dass KI wenn auch unter gewissen Anforderungen zum Schutze hochwertiger G ter nicht unverh ltnism ig beschr nkt wird, z. B. auch durch pa- rallele Gesetzesvorhaben. Die aktuellen Ver handlungen zur ePrivacy Verordnung lassen bef rchten, dass ber restriktive Datenschutzvorgaben auch f r nicht per- sonenbezogene Daten ein Gro teil des Innovationspotenzials von KI im Keim erstickt werden k nnte. Neben dieser grundlegenden Infragestel lung des gew hlten Mittels, m chte der BVDW auf einzelne Regelungsinhalte des Vorschlags eingehen. Der Digitalverband unterst tz prinzipiell den von der Kommission gew hlte n Ansatz, dass risikobasiert mit KI umgegangen werden muss und dass der Verordnung svorschlag der EU -Kom- mission daher in erster Linie Hoch risiko -KI-Systeme reguliert sowie Transparenzvorschriften f r den Einsatz von KI festlegt. Wir sehen dennoch einige 4 Problemfelder im Vorschlag, die zu Recht sunsicherheit en f hren , Innovation hem- men und m chte diese gerne in den n chsten Abschnitten beleuchten. Besonders problematisch ist aus Sicht des BVDW : o die zu weit gefasste Definition von KI; o Rechtsunsicherheiten allgemein und insbesondere in Bezug auf Hochrisiko - KI; o die Vielzahl an Widerspr chen im Vorschlag insbesondere bei den Transpa- renzpflichten ; o Die teils unverh ltnism igen Anforderungen und die B rokratie , die im Vor- schlag mit einem hohen Bu geld einherge hen; Eine innovationsfreundliche und vertrauensvolle KI made in Europe braucht aus Sicht des BVDW : eindeutige Begriffsdefinitione n, klare Anwendungsgebiete und Rechtssi- cherheit ; Auswirkungsregulierung statt Technikregulierung; Weniger b rokratischen Aufwand; Eile bei den technischen Spezifikationen ; Forderungen und Erl uterungen: Rechtsunsicherheit vermeiden durch eindeutige Begriffsdefinitionen und An- wendungsgebiete : Aus Sicht des BVDW ist es besonders kritisch zu sehen, dass der Verordnungsent- wurf unscharfe Definitionen verwendet, die Rechtsunsicherheit statt -sicherheit schaffen. In Anhang I gem Artikel 3 Absatz 1 ist der Begriff KI so weit definiert, dass so gut wie jede Software -Anwendung darunterfallen d rfte. Denn u nter dem Begriff KI -Sys- tem versteht die Kommission eine Software, die im Hinblick auf eine Reihe von Zielen, die vom Menschen festgelegt werden, Ergebnisse wie Inhalte, Vorhersagen, Empfehl ungen oder Entscheidungen hervorbringen kann, die das Umfeld beeinflus- sen, mit dem sie interagieren und die mit einem oder mehreren der folgenden Techniken und Ans tze entwickelt wird: 5 - mit machine learning ( berwacht/un berwacht/verst rkt) in allen Varia n- ten; - mit logik - und wissensbasierten Ans tzen in allen Varianten; - mit statistischen Ans tzen in allen Varianten . Diese Definition muss dringend berarbeitet und differenziert er werden. Die Regu- lierung sollte KI -Systeme im engeren Sinne treffen, um effektiv zu sein. Mit der jetzigen Formulierung w re jegliche Software betroffen, die beispielsweise Statistik nutzt. Die KI -typische Gefahr geht jedoch nicht von jeglicher Software aus, sondern vorrangig von selbstlernenden Systemen. Aufgrund der hohen te chnischen Komple- xit t und Diversit t von KI -Anwendungen braucht es hier trennscharfe Formulierungen, um Unternehmen Rechtssicherheit zu bieten und kein Hemmschuh f r Innovation zu sein . Zudem w re es aus Sicht des BVDW notwendig mit Positiv- merkmalen zur De finition von KI zu arbeiten. Eine weit gefasste Definition mit negativen Abgrenzungen sollte im Sinne der Rechtssicherheit vermieden werden. Zus tzlich bietet der Vorschlag auch viel Interpretationsspielraum in Bezug auf Hoch risiko -KI. Auch wenn Anhang III des Vorschlags eine Liste der Anwendungen aufstell t, die unter diese Begrifflichkeit fallen sollen, sind diese Ausf hrungen nicht sehr detailliert und die Kommission kann diese Liste weiter anpassen. Der BVDW unterst tzt zwar prinzipiell den in Artikel 7 ( definierten Ansatz, der eine enge De- finition von KI-Systemen mit hohem Risiko verwendet . Es werden in diesem Rahmen m gliche Sch den f r die Gesundheit, Sicherheit und die Grundrechte von Personen ber cksichtigt, sowie die Schwere, die Wahr scheinlichkeit ihres Auftretens und die Anzahl der potenziell betroffenen Personen. Allerdings bleibt die Frage offen , wie Artikel 7( auf die in Anhang III aufgelisteten Kategorien von Hoch risiko -KI ange- wendet und wie diese Kategorien regelm ig neu bew ertet werden sollen. Der BVDW ist daher der Meinung, dass die Formulierungen des Anhang s III weiter zu kl ren und einzugrenzen sind, da es eine Vielfalt an Anwendungen geben kann, die unter einige der Definitionen fallen k nnen. Die in Anhang III genannten KI -Anwen- dungen im Bereich der Besch ftigung decken beispielsweise eine breite Palette vo n Systemen ab, darunter m glicherweise auch Werbekampagnen im Bereich der Be- sch ftigung. Ohne weitere Kl rung w rde die Einstufung der Besch ftigung als risikoreiche KI -Kategorie erhebliche Folgen f r deutsche Werbetreibende und Ver- lage haben, die im Bereich der Personal beschaffung t tig sind. Es bedarf somit einer sauberen R egulierung, die auch immer m gliche, in der Kon- sequenz, unverh ltnism ige Aufw nde f r klein und mittelst ndische 6 Unternehmen (KMU) mitdenkt. Dar ber hinaus muss gekl rt werden, wie das Ver- fahren zur Aktualisierung der Liste des Anhang s III konkret aussehen soll . Auch in Bezug auf die genaue Ausgestaltung der Anforderungen und Bestimmung en an KI sind weitere Fragen offen . So hei t es beispielsweise in Artikel 15 (: Hoch- risiko -KI-Systeme werden so konzipiert und entwickelt, dass sie im Hinblick auf ihre Zweckbestimmung ein angemessenes Ma an Genauigkeit, Robustheit und Cybersi- cherheit erreichen (...) . Was unter einem angemessenem Ma zu verstehen ist, bleibt v llig unklar. Auch hier m chten wir nochmals auf die klare Abgrenzung zur DSG -VO hinwei sen. Diese gibt mit Blick auf den Schutz personenbezogener Daten bereits etliche Vorgaben. Wenn die vorliegende Regulierung eine Art ""Produktvor- gabe"" abbilden soll, dann m ssen Datenschutzthemen von vornherein sauber ausgeklammert werden. Dies sollte auch f r andere berschneidungen gelten, z. B. zum Cybersicherheitsrecht. Unternehmen bekommen durch diese n Vorschlag somit keinerlei Rechtssicherheit, sind aber aufgefordert umfangreiche Anforderungen zu erf llen und stehen vor der Gefahr hoher Bu gelder. Neben der m glichen Einord nung als Hoch risiko -KI werden auch einige Anwendun- gen im Vorschlag ber Artikel 5 g nzlich verboten. Der BVDW versteht die Idee der Europ ischen Kommission, einige KI -Anwendungen zu verbieten, wie z. B. den Ein- satz von biometri schen Fernidentifikationssystemen in ffentlich zug nglichen R umen mit einigen Ausnahme n. Aber auch in diesem Zusammenhang ist es es- senziell , genau und detailliert zu definieren, welche KI -Systeme verboten und welche akzeptiert werden, um Unsicherheiten zu reduzieren. Hier bedarf es weiterer Nach- besserungen. Abschlie end m chte der BVDW auch noch auf die Regelungen des Artikel s 52 ein- gehen , und zwar in Bezug auf KI im digitale n Marketing, das richtigerweise grundlegend mit einem geringen Risiko eingestuft wird . In Artikel 52 zum T hema Transparenzpflichten f r bestimmte KI -Systeme hei t es: ( Die Anbieter stellen sicher, dass KI -Systeme, die f r d ie Interaktion mit nat rlichen Personen bestimmt sind, so konzipiert und entwickelt werden, dass nat rlichen Per- sonen mitgeteilt wird, dass sie es mit einem KI -System zu tun haben ( .) ( Die Verwender eines Emotionserkennungssystems oder eines Systems zu r bio- metrischen Kategorisierun g informieren die davon betroffenen nat rlichen Personen ber den Betrieb des System s ( .) 7 Dies h tte aus Sicht des BVDW auch Auswirkungen auf das Digitale Marketing, wenn es beispielsweise auf eine KI-Optimierung durch semantische Klassifizierung der werbetreibenden Seiten oder Apps setzt . In dem Fall m ssten die Ma nahmen auf den entsprechenden Werbetr g ern vorher ank ndigen werden . Dies scheint zum ei- nen au erhalb der Intension dieses Artikel s zu liegen und zum anderen w re dies auch nicht praktikabel und sollte daher ausgeschlossen werden. Innovationskraft durch Auswirkungsregulierung statt Technikregulierung si- chern : Wie bereits in der Einleitung aufgef hrt betrachtet d er Verordnungsentwurf KI ganz- heitlich als Technologie, unabh ngig von ihrem konkreten Anwendungsbereich. Die m glichen Risiken dieser Technologie gehen aber letztendlich nicht von ihr selbst aus, sondern von ihrem Einsatz und den Einsatzbedingungen. Der BVDW sieht in dem horizontalen, globalen Ansatz der Kommission die Gefahr, dass die Ents tehung von Innovationen auf Basis datenbasierter L sungen massiv erschwert werden . Bei- spielsweise sieht der Vorschlag generell und uneingeschr nkt vor, KI-Anwendungen im Bereich der kritischen Infrastruktur kategorisch als Hoch risiko -KI-Anwendungen einzustufen. Es gibt jedoch Anwendungsm glichkeiten, die bei genauerer Betrach- tung nicht denselben Stellenwert haben und gleichzeitig in einem digitalen kosystem gro en Nutzen f r Unternehmen und Menschen bergen . Hier k nnte man an Smart Mete ring zur Verbrauchsdatenmessung und Optimierung der indivi- duellen bzw. Kollektiven Energiebilanz denken Eine technologieoffene gesetzliche L sung nach dem Innovationsprinzip ist daher notwendig, um unterschiedlichste Anwendungsm glichkeiten zu erm glichen . Investitionen durch Reduktion des b rokratischen Aufwands sichern und An- reize schaffen : Um das gew nschte Ziel der Sicherheit und Transparenz zu erreichen , sieht der Ent- wurf aus Sicht des BVDW einen unverh ltnism ig gro en Dokumentations - und Pr faufwand f r neue KI-Systeme vor. Eine digitale Wertsch pfung wird dadurch verhindert statt erm glicht, geschweige denn erleichtert und unterst tzt. Artikel 10 sollte daher beispielsweise besser gestaltet werden, um den Unternehmen das Tes- ten ihrer KI -Systeme zu erm glichen und nicht zu viele Vorabverpflichtungen und - beschr nkungen in Bezug auf ""fehlerfreie"" Daten aufzuerlegen. Der Schwerpunkt sollte immer auf dem endg ltigen KI -System li egen und nicht darauf, die Grunds tze 8 der Regulierung bereits in den Test - oder Trainingsphasen aufzuerlegen. Diese Schl sselphasen f r innovative KI -Systeme m ssen gesichert sein und Unterneh- men m ssen in die Lage versetzt werden in einer ""sicheren Umgebu ngen"" zu arbeiten, in denen Fehler gemacht werden k nnen . Dar ber hinaus ist es f r Unternehmen wichtig, flexible Werkzeuge an die Hand zu bekommen, die dabei helfen, die notwendigen Dokumentationen zu KI -Systemen einfach, effektiv und schnell bereitzuste llen. So sollte beispielsweise vermieden werden, dass eine Software, die von einem Unternehmen als Basissystem produ- ziert und in einer zweiten Phase an die unterschiedlichen Bed rfnisse verschiedener Kunden angepasst wird, ohne dass die grundlegende Archit ektur und der Zweck ge- ndert werden, erneut denselben Verpflichtungen unterliegt . Es w re sinnvoll ber M glichkeiten nachzudenken, wie der Verwaltungsaufwand und die B rokratie auf ein Minimum reduzie rt werden kann und sich auf die Bereitstellung der Informatio- nen zu konzentrieren, die wirklich f r den jeweiligen Sektor erforderlich sind, insbesondere in Bezug auf Artikel 11 (Technische Dokumentation) und Artikel 13 (Aufbewahrung von Aufzeichnungen). Wenn mit Anreizen und Positivmerkmalen gearbeitet werden w rde, dann k nnte n auch in Bezug auf die Dokumentationspflichten konkrete Schwerpunkte gebildet werden und so die Aufw nde reduziert und Rechtssicherheit geschaffen werden . Auch wenn also je nach Anwendungsfall das Risiko gewisse Dokumentationspflich- ten und Pr fungen angemessen darstellt , so sollte hier aber ebenfalls differenziert werden nach dem Einsatzgebiet. Ansonsten besteht gro e Gefahr, dass Investitio- nen in Entwicklung und Einsatz von KI -Technologien wirtschaftlich nicht me hr tragbar sind . Dies gilt sowohl f r KMU, als auch umso mehr f r Startups , die hier eher Unterst tzung und Erleichterungen ben tigen, um schnell und kreativ L sun- gen f r einen wettbewerbsf higen digitalen Binnenmarkt zu schaffen . KMU , die durch KI gro e Optimierungspotenziale heben k nnten, werden auch geschw cht, da dies im Verh ltnis zum b rokratischen Aufwand unrentabel werden k nnte. Auf- grund der vielf ltigen Einsatzm glichkeiten von KI- und Software -Bausteinen sollte eine versch rfte Dokumentationspflicht hinsichtlich Datenqualit t, Robustheit, etc. nicht a priori f r die Entwicklung des Algorithmus gelten. Stattdessen w re eine wir- kungsbasierte Dokumentation empfehlenswert, die a posteriori auf Basis des Einsatzszenarios und die m gli chen Auswirkungen festh lt. 9 Eile bei den technischen Spezifikationen, die gepr ft werden sollen : Generell muss gesagt werden, dass es f r Unternehmen nur sinnvoll ist in neue Technologien zu investieren, wenn diese sp ter auf den Markt gebracht werden k n- nen. Vor diesem Hintergrund sind die im Entwurf umrissenen Sandboxes nicht geeignet, um Innovationen zu f rdern . Ein Investment auf Basis einer tempor ren Sandbox ist in der Regel nicht wirtschaftlich, da KI-Produkte am Markt unter realen Bedingungen getestet werden m ssen. Auch die Dokumentations - und Zertifizie- rungspflichten haben das Potenzial, Innovationen im Keim ersticken zu lassen. Diese induzieren bereits in einer fr hen Phase als schon vor der Feststellung der technischen Umsetzbarkeit einen hohen b rokratischen und finanziellen Auf- wand, um Produkte am Markt zu erproben. Hier braucht es klare Regelungen, die die Verh ltnism igkeit von Aufwand und po- tenziellem Schaden in Relation setzen , ggf. auch e ine neue Beh rde ohne B rokratisierungswahn.",de
DeepMind (United Kingdom),F2665473,05 August 2021,Company/business,Large (250 or more),United Kingdom,D e e p M i n d r e s p o n s e t o t h e A r t i ,it
ZPP (Poland),F2665472,05 August 2021,Business association,Small (10 to 49 employees),Poland,"ZPP od dawna podkre la , e przygotowanie adekwatnej regulacji w zakresie sztucznej inteligencji b dzie wyj tkowo wymagaj cym zadaniem. Z jednej strony bowiem oczywistym celem regulatora jest zabezpieczenie obywateli i podmiot w gospodarczych przed nieetycznym stosowaniem technologii AI, z drugiej jednak wprowadzenie zbyt daleko id cych restrykcji skutkowa oby zahamowaniem innowacji, a przez to r wnie pogorszeniem pozycji konkurencyjnej europejskich podmiot w. Jakkolwiek w przedstawionym projekcie dostrzegamy przestrze do doprecyzowa i zmian, uwa amy e podej cie Komisji jest w powy szym kontek cie co do zasady proporcjonalne i w odpowiedni zabezpiecza oba ze wspomnianych d br. W przedstawionym projekcie dostrzegamy cztery obszary, kt re powinny by przedmiotem dalszych prac b d rewizji. W pierwszej kolejno ci zwracamy uwag na brak adekwatnego rozr nienia odpowiedzialno ci mi dzy u ytkownikami AI, realnie wykorzystuj cymi okre lone rozwi zania w prowadzonej dzia alno ci, a podmiotami dostarczaj cymi te rozwi zania na rynek. Wydaje si , e najbardziej logiczne by oby, gdyby odpowiedzialno za zgodno rozwi zania i monitorowanie go po wprowadzeniu na rynek ponosi y podmioty wdra aj ce (wspomniani u ytkownicy) tylko oni mog bowiem weryfikowa ostateczne zastosowanie konkretnego rozwi zania opartego na AI. Problematyczny w tym kontek cie wydaje si brak definicji podmiotu wdra aj cego wydaje si , e nale a oby uzupe ni regulacj w tym zakresie. Dalej, zwracamy uwag na fakt, i niekt re sformu owania wykorzystane w przedstawionym projekcie wyznaczaj standardy de facto niemo liwe do spe nienia. Dla przyk adu, art. 10 ust. 3 stanowi, e zbiory danych szkoleniowych, walidacyjnych i testowych musz by adekwatne, reprezentatywne, wolne od b d w i kompletne . Trudno jest zagwarantowa brak b d w , a wi c doskona o dlatego zobowi zanie powinno dotyczy raczej nale ytych stara w zakresie zapewnienia, e zbiory danych s wolne od b d w i kompletne. Co wi cej, art. 14 ( stanowi, e osoby kt rym powierzono nadz r ludzki musz umo liwia zrozumienie w pe ni mo liwo ci i ogranicze systemu sztucznej inteligencji wysokiego ryzyka . Zrozumienie w pe ni tak skomplikowanej i szybko ewoluuj cej materii b dzie prawdopodobnie wyznacza o nieracjonalnie wysoki standard, st d te nale a oby zrewidowa regulacj w taki spos b, by odnosi a si do odpowiedniego lub wystarczaj cego zrozumienia. Cz przewidzianych w regulacji wymog w wydaje si ponadto nieproporcjonalna, cho by art. 64 ( zobowi zuj cy do zapewnienia (na uzasadniony wniosek) organom nadzoru rynku dost pu do kodu r d owego systemu sztucznej inteligencji. Wobec faktu, e istniej alternatywne metody weryfikacji dzia ania systemu AI, a sam kod r d owy jest chroniony jako tajemnica handlowa, obowi zek ten wydaje si by nadmierny. Ostatecznie, zwracamy uwag na konieczno doprecyzowania cz ci element w regulacji, m.in. poprzez skonkretyzowanie oczekiwa dot. nale ytej staranno ci w kontek cie art. 10 po wi conego danym i zarz dzaniu nimi, czy cho by sposobu pogodzenia wynikaj cego z art. 12 obowi zk w dotycz cych rejestrowania, z wynikaj cymi z RODO zasadami w zakresie minimalizacji pobieranych danych.",pl
Fédération nationale des travaux publics (FNTP) (France),F2665445,05 August 2021,Business association,Medium (50 to 249 employees),France,"L approche par les risques de la Commission europ enne semble tre la meilleure approche dans la mesure o elle favorise la confiance dans l intelligence artificielle sans entraver son d veloppement. En revanche, il est essentiel de garder une marge d innovation. Une attention particuli re doit donc tre port e aux d finitions, notamment celles des syst mes IA et des syst mes haut risque, car les obligations et exigences aff rentes sont tr s lourdes et difficiles mettre en place. Des d finitions claires et suffisamment pr cises sont d'autant plus importantes qu'elles seront amen es servir de r f rences dans d'autres textes. Elles ne doivent donc pas conduire cr er de l'ins curit juridique. L article 7 pr voit la possibilit pour la Commission europ enne d adopter des actes d l gu s pour faire voluer l Annexe III tablissant une liste de syst mes IA consid r s haut risque. S il est effectivement n cessaire de tenir compte des volutions dans la d finition des IA haut risque, le fait que la Commission puisse le faire par actes d l gu s est source d ins curit juridique. Or, cela pourrait d courager les entreprises d velopper des solutions d'IA innovantes en raison de l' volution impr visible du champ d'application de la r glementation au cours des prochaines ann es. De plus, les crit res num r s l'article 7, qui habilite la Commission mettre jour la liste de l'annexe III, sont parfois vagues et m riteraient d tre pr cis s afin de soutenir la s curit juridique et la pr visibilit du march . Il conviendrait par exemple d'introduire des dispositions explicites pour la participation des entreprises tout processus futur de mise jour de la liste. Par ailleurs, il semble que la proposition de r glement ait t labor e en m connaissance du fait que de nombreux produits r glement s int grant de l'IA en tant que fonction de s curit , sont aujourd'hui utilis s en particulier des machines soumises la Directive 2006/42/CE. Or, la m thodologie retenue par la directive Machines est d'effectuer une analyse de risques afin de prendre les mesures de protection adapt es. La proposition de r glement, quant elle, consid re d'office certains syst mes IA comme tant haut risque, sans consid ration pour l'analyse de risques effectu e par l'entreprise aux termes de la directive Machines, ce qui est contradictoire. En outre, dans la mesure o les donn es sont tr s importantes pour le d veloppement de l IA, il est n cessaire d articuler la proposition de r glement sur l IA avec les textes europ ens relatifs aux donn es pr existants ou en cours de discussion (RGPD, Data Governance Act, Data Act) afin d assurer la compl mentarit de ces textes et de veiller l absence de contradictions ou la superposition d obligations similaires (acc s et partage des donn es, obligations en termes de fiabilit des donn es ou de profilage, sanctions ). Au niveau national, il existe aujourd hui de nombreuses instances et autorit s fran aises agissant dans le domaine du num rique et, avant de d signer une nouvelle autorit en charge de l IA, il serait souhaitable, d une part, de mieux d finir les missions de cette nouvelle autorit l aune des enjeux de comp titivit internationale, d innovation et de traitement des donn es (personnelles ou industrielles) et, d autre part, de clarifier le r le de chacune de ces autorit s d j en place et ventuellement de repenser le p rim tre de ces instances. Il est, de surcro t, essentiel que les d cisions et doctrines des autorit s de contr le nationales soient harmonis es afin d viter les risques de fragmentations dans l application du r glement.",fr
Verband der TÜV e. V. (Germany),F2665436,05 August 2021,Business association,Small (10 to 49 employees),Germany,,unknown
Związek Cyfrowa Polska (Poland),F2665383,04 August 2021,Company/business,Micro (1 to 9 employees),Poland,"Warszawa, 4 sierpnia 2021 r. W zwi zku z prowadzonymi konsultacjami w sprawie w sprawie Rozporz dzenia Parlamentu Europejskiego i Rady Ustanawiaj cego zharmonizowane przepisy dotycz ce sztucznej inteligencji (Aktu w sprawie sztucznej inteligencji) i zmieniaj cego niekt re akty ustawodawcze Unii z dnia 2021 r. , przedstawiam poni ej stanowisko Zwi zku Cyfrowa Polska, reprezentuj cego polski sektor cyfrowy i nowych technologii. Maj c na wzgl dzie to , e projektowane w ramach Rozporz dzenia przepisy b d mia y fundamentalne znaczenie dla rozwoju innowacyjnych, nowoczesnych przedsi biorstw oraz powstawania nowatorskich produkt w i us ug XXI w., a w efekcie wzrostu cyfrowej gospodarki i potencja u Polski i Europy w oparciu o mo liwo ci s ztucznej inteligencji (AI), wyra amy aprobat dla inicjatywy Komisji . Uwa amy, e konieczne s jasne ramy prawne, w kt rych przedsi biorstwa b d ch tniej opracowywa takie rozwi zania, a obywatele obdarz zaufaniem i zaakceptuj produkty oraz us ugi opart e na sztucznej inteligencji. Popieramy cele, kt re Komisja Europejska stawia przed proponowanymi regulacjami dotycz cymi sztucznej inteligencji . To w szczeg lno ci zapewnienie pewno ci prawa na potrzeby u atwienia inwestycji i innowacji w dziedzinie sztuc znej inteligencji oraz u atwienie rozwoju jednolitego rynku zastosowa sztucznej inteligencji. Cele te s zbie ne z naszym pogl dem n a temat konieczno ci budowania przejrzystych ram prawnych, kt re sprzyjaj rozwojowi innowacyjnych us ug i produkt w oparty ch o nowoczesn technologi . Przede wszystkim pochwalamy przyj cie proporcjonalnego podej cia regulacyjnego do nak adania obowi zk w opartego na ryzyku, kt re to ogranicza si do minimalnych wymog w niezb dnych do zaradzenia temu ryzyku i problemom zwi zan ym ze sztuczn inteligencj bez nadmiernego ograniczania lub utrudniania rozwoju technologicznego, lub nieproporcjonalnego zwi kszenia koszt w wprowadzania do obrotu rozwi za AI. Jeste my g boko przekonani, e Komisja Europejska osi gn a w a ciw r wnow ag pomi dzy ochron obywateli a zachowaniem przestrzeni dla innowacji. Maj c jednak na wzgl dzie, e proponowane przepisy b d mia y fundamentalne znaczenie dla budowy warunk w sprzyjaj cych wzrost owi opartych o sztuczn inteligencj , konkurencyjnych, inn owacyjnych polskich i europejskich produkt w oraz us ug cyfrowych , a tak e podkre laj c kluczowe znaczenie jasno ci i przejrzysto ci projektowanych ram prawnych, poni ej przedstawiamy nasze uwagi i komentarze do projektu Rozporz dzenia. Naszym zdaniem niek t re z zapis w Aktu w sprawie sztucznej inteligencji wymagaj r ewizji lub wyja nienia . Po pierwsze, w naszej opinii konieczne jest jasne wyja nienie r wnowagi w zakresie odpowiedzialno ci dostawc w, podmiot w wdra aj cych i u ytkownik w AI, w szczeg lno ci w przypadku Interfejs w Programowania Aplikacji (API) og lnego przeznaczenia i modeli typu open source . W obecnym brzmieniu rozporz dzenie nie wprowadza wystarczaj cego rozr nienia mi dzy obowi zkami u ytkownik w AI w roli podmiotu wdra aj cego a o bowi zkami dostawc w wobec swoich klient w. Brak obja nienia tej kwestii rodzi ryzyko negatywnego wp ywu na publikacj modeli open source i interfejs w API, a w efekcie utrudnienie innowacji na polu AI i przyj cia nowatorskich rozwi za przez przemys . Zalecamy tym samym, aby rozporz dzenie zawiera o jasn definicj podmiotu wdra aj cego , kt ra naszym zdaniem powinna odnosi si do podmiotu udost pniaj cego system AI do stosowania w okre lonym kontek cie operacyjnym. Pozwoli to regulowa stosownie sytuacje, w kt rych podmiot wdra aj cy nie jest to samy z dostawc systemu sztucznej inteligencji , np. w przypadku wykorzystywania system w AI og lnego przeznaczeni a. Ponadto, uwa amy, e g wn odpowiedzialno za zachowanie zgodno ci i jej ocen oraz monitorowanie po wprowadzeniu na rynek powinni ponosi dystrybutorzy system w AI. W istocie wy cznie oni mog zweryfikowa zastosowania ko cowe, kt rym poddawane s i ch systemy, oraz wszelkie dodatkowe dane, kt re zosta y wprowadzone do szkolenia w zakresie ich system w. Jeste my przeciwni obarczeniu odpowiedzialno ci podmiot w zwi zanych z systemem na wcze niejszych etapach a cucha dostaw, gdy nie maj ju oni wp yw u na jego dystrybucj i funkcjonowanie. Innymi s owy, obowi zek zachowania zgodno ci, jej oceny i monitorowania systemu obecnego na rynku powinien spoczywa na podmiotach wdra aj cych go bez wzgl du na mark i dok adny spos b pozyskania systemu sztucznej i nteligencji. Organizacja korzystaj ca z systemu ma bowiem jako jedyna pe n wiedz na temat sposobu jego wykorzystania niezale nie od tego, czy system AI og lnego przeznaczenia jest wdra any w warunkach wysokiego ryzyka, czy te zosta on zmodyfikowany. Po drugie, uznajemy za konieczne udoskonalenie j zyka zapis w, kt ry wyznacza niemo liwy do spe nienia w warunkach rynkowych standard. Cho w pe ni popieramy postulat, aby na o one na podmioty wymagania by y zgodne z najlepszymi praktykami bran owymi, to musz one pozostawa mo liwe do realizacji w praktyce rynkowej. O ile wymagania dotycz ce system w AI wysokiego ryzyka s prawid owe, nie powinny one utrudnia lub wr cz uniemo liwia wdra ania system w sztucznej inteligencji ustanawiaj c standardy, kt re s de facto niemo liwe do spe nienia przez jakiegokolwiek dostawc . Dotyczy to w szczeg lno ci artyku u 10 ust. 3, kt ry stanowi, e zbiory danych szkoleniowych, walidacyjnych i testowych musz by adekwatne, reprezentatywne, wolne od b d w i kompletn e . Wym g taki jest niemo liwy do spe nienia, poniewa nie mo na zagwarantowa doskona o ci zbior w danych, a niekt re metody sprzyjaj ce zachowaniu prywatno ci celowo wprowadzaj do nich b d (w postaci szumu). Niemo liwe jest r wnie , aby zbiory danych by y kompletne, poniewa z natury stanowi one jedynie pr bk rzeczywisto ci, a zatem nigdy nie b d zawiera ka dego mo liwego punktu danych. W zwi zku z powy szym zalecamy nast puj ce brzmienie przepisu: Nale y podj odpowiednie wysi ki, aby zapewni , e zbiory danych s wystarczaj co istotne, reprezentatywne, wolne od b d w i kompletne . W tym zakresie istotny jest r wnie artyku 14 ust. 4 lit. a, stanowi cy, e osoby, kt rym powierzono nadz r ludzki, musz umo liwia , odpowiednio do okoliczno ci zrozumienie w pe ni mo liwo ci i ogranicze systemu sztucznej inteligencji wysokiego ryzyka . W naszej opinii standard ten jest nieracjonalnie wysoki i niemo liwy do spe nienia w przypadku z o onych sieci neuronowych. Proponujemy zatem, aby od wyznaczonych os b wymagano , np. odpowiedniego zrozumienia mo liwo ci i ogranicze . Po trzecie, jeste my przekonani, e konieczne jest wyja nienie w przepisach praktycznych aspekt w nale ytej staranno ci . Bardziej szczeg owe wytyczne dotycz ce oczekiwa co do sposobu przestrzegania przepis w musi mie miejsce w przypadku: Artyku u 10 - Dane i zarz dzan ie danymi. W przypadku system w sztucznej inteligencji budowanych z wykorzystaniem zbior w danych dostarczanych przez osoby trzecie, w tym tych udost pnianych na zasadzie open source, jasne musi by , w jakim stopniu mo na polega na o wiadczeniach z o onyc h przez tw rc w wykorzystywanych zbior w danych dotycz cych m.in. zgody i prywatno ci. Ponadto, wyja nienia wymaga, jakie s oczekiwania co do nale ytej staranno ci w przypadku, gdy nie s dost pne informacje nt. pochodzeniu zbioru danych. Artyku u 12 - Wymagania dotycz ce rejestrowania: W przypadku us ug, w kt rych system sztucznej inteligencji jest zaprojektowany, aby korzysta z uczenia si na urz dzeniach (a nie w chmurze), mog zachodzi obawy zwi zane z czno ci lub prywatno ci . Nale y w proje ktowanych przepisach doprecyzowa , jak w takich okoliczno ciach spe ni wym g rejestrowania, skoro nie wyst puje w nich scentralizowany punkt odniesienia. Innymi s owy, zgodno z obowi zkiem rejestrowania wydaje si sprzeczna z zasad minimalizacji danych zawart w RODO. Uzasadnione jest zatem pytanie o to, jak w praktyce osi gn r wnowag pomi dzy tymi oczekiwaniami. Po czwarte uwa amy za konieczne przeformu owanie wymog w, kt re s w naszej opinii nieproporcjonalne i powinny zosta stosownie zmienione. Dotyczy to w szczeg lno ci artyku u 64 ust. 2, wedle kt rego ...na uzasadniony wniosek, organom nadzoru rynku zapewnia si r wnie dost p do kodu r d owego systemu sztucznej inteligencji . Nale y zwr ci uwag , e kod r d owy jest chroniony przez dyre ktyw UE o tajemnicy handlowej, a jednocze nie zawsze b d istnia y alternatywne metody weryfikacji dzia ania systemu AI (np. audyt wej cia/wyj cia), co czyni dost p do kodu r d owego zb dnym i nieuzasadnionym. Proponujemy tym samym nast puj ce brzmienie ust. na uzasadniony wniosek dostawcy lub wdra aj cy AI powinni wspiera organy nadzoru rynku i wyposa y je w urz dzenia niezb dne do przeprowadzenia rzetelnych test w (np. audyt w wej cia/wyj cia), je eli jest to konieczne do potwierdzenia zgodno ci . Niezale nie od przedstawionych powy ej komentarzy na temat konieczno ci dopracowania i doprecyzowania projektu, w szczeg lno ci w odniesieniu do r wnowagi odpowiedzialno ci pomi dzy podmiotami zaanga owanymi w rozw j i wykorzystywanie sztucznej inteligen cji oraz niekt rych wymog w prawnych, stoimy na stanowisku, e projekt rozporz dzenia jest pomocny w zapewnieniu jasnych ram prawnych dla zastosowa AI obarczonych wysokim ryzykiem. Z entuzjazmem przyjmujemy system regulacyjny zbudowany wok analizy ryzyk a, kt ry nie tworzy niepotrzebnych ogranicze handlu oraz wyrasta ze zrozumienia przez Komisj Europejsk znaczenia sztucznej inteligencji dla kluczowej przewagi konkurencyjnej przedsi biorstw i europejskiej gospodarki.",pl
Kammer für Arbeiter und Angestellte für Wien (Austria),F2665345,04 August 2021,Consumer organisation,Large (250 or more),Austria,"Positionspapier der Bundesarbeitskammer zum EU -Verordnung sentwurf K nstliche Intelligenz Worum geht es inhaltlich und im Prozess Der 2018 entstandene koordinierte Plan zur Entwicklung, Einsatz und Regulierung k nstlicher Intelli- genz (KI) sieht vor, dass die Mitgliedstaaten der Europ ische Union Strategien entwickeln, um eine F hrungsrolle rund um vertrauensw rdige k nstliche Intelligenz im globalen Wettbewerb bernehmen zu k nnen. 2020 entstand dazu das Wei buch, welches einen risikobasierten Ansatz zur Regulierung von KI vorsieht. 2021 liegt nun ein Verordnungsentwurf der Europ ischen Kommission vor. Was ist gut an dem derzeitigen Entwurf? Zu begr en ist, dass ein breit angelegter Prozess, dieses zukunftsweisende Thema aufgreift und ver- sucht, einen Rahmen zu F rderung, Entwicklung und Einsatz, sowie zur Regulierung zu schaffen. Es wurde dabei ein risikobasierter Ansatz gew hlt, der unabh ngig von der Technologie die Auswirkungen betrachtet und versucht das dabei entstehende oder entstandene Risiko zu bewerten woraus sich wie- derum der Grad des Regulierungserfordernisses ableiten soll. Die Risikokategorien umfassen unakzep- tables, hohes, limi tiertes und geringes Risiko. Ein Annex (2 und listet Beispiele von Anwendungen je Risikokategorie auf. Sp testens hierin ergeben sich jedoch eine Reihe von Fragestellungen, denn die Risikoeinstufung ist entscheidend f r die G ltigkeit von Regulierungsbe stimmungen. Welche Kritik ist angebracht, was fehlt? Der Entwurf hat einen sehr technikzentrierten Fokus mit Blick auf die Erfordernisse des Binnenmarkts. Der urspr nglich propagierte menschenzentrierte Ansatz findet sich kaum wieder. Wichtige Schutz- mechanismen f r ArbeitnehmerInnen und KonsumentInnen fehlen, M glichkeiten zur Mitbestimmung ebenso. Viele im Grunde richtige Ansatzpunkte werden durch Ausnahmen und Einschr nkungen stark verw ssert. Inwiefern bedeutet der Annex eine abschlie ende Taxonomie , wie kann diese laufend aktualisiert wer- den und was ist, wenn sich die Risikoauswirkung einer Technologie ver ndert? Wie kann die Taxonomie laufend und der technischen Entwicklung entsprechend aktualisiert werden? Wie wird k nstliche Intelli- genz berhaupt definiert, sprich, was gilt es berhaupt in die Taxonomie aufzunehmen? Auch das insti- tutionelle Setting der mit der Regulierung beauftragten Beh rde(n) ist offen und entscheidend f r den Umgang mit den Entwicklungen k nstlicher Intelligenz und ihren Risik en. Was braucht es daher : KI-Anwendungen, die ArbeitnehmerInnenrechte, Arbeitsbedingungen und die Gesundheit am Arbeitsplatz ber hren sollten prinzipiell als hochriskant eingestuft werden und einer entspre- chenden Regulierung unterliegen. Bestimmte f r ArbeitnehmerInnen besonders riskante Anwendungen sollten nicht erlaubt sein Das Prinzip der menschlichen Kontrolle soll ArbeitnehmerInnen und ManagerInnen gleicherma- en umfassen. Transparenzbestimmungen sollen auch den Bildungsaspekt abdecken, sodass KI -Anwendun- gen verstanden und ihre Funktionsweisen erlernt werden k nnen. St rkung von ArbeitnehmerInnenbeteiligung in der Ausgestaltung, Entwicklung, Anwendung und Kontrolle von KI im Sinne eines menschenzentrierten Bottom -Up-Ansatzes F rderung betriebli cher und berbetrieblicher Aushandlungsprozesse durch eine St rkung der Mitbestimmungsrechte Konformit tsbewertung von KI -Systemen f r ArbeitnehmerInnen -Management von autorisier- ten Stellen n tig sowie ein Mechanismus, der Ex -Ante Compliance und Ex -Post En forcement kombiniert. Die Normung zeigt ein demokratisches Defizit die Beteiligung der Gewerkschaften ist n tig. Begleitende Aus - und Weiterbildungen f r die betrieblichen InteressenvertreterInnen und alle ArbeitnehmerInnen. Neue Anwendungen bergen unbek annte Risiken, das Vorsichtsprinzip ist anzuwenden. Arbeits- unf llen und arbeitsbedingten Erkrankungen muss vorgebeugt werden und ArbeitnehmerInnen mit speziellen Bed rfnissen m ssen mitbedacht werden. Die Arbeitsinspektion als Aufsichtsbe- h rde braucht dahe r ausreichend personelle und technische Mittel, um die neuen Aufgaben abzudecken. Grund - und Pers nlichkeitsrechte, Datenschutz, ArbeitnehmerInnenschutz und KonsumentIn- nenrechte m ssen Priorit t haben und d rfen nicht durch Ausnahmen und Einschr nkungen ausgeh hlt werden. I. KI und Arbeitswelt Allgemein: Vollst ndiges Fehlen des im Wei buch angek ndigten menschen- zentrierten Konzepts . Mit ihrem Vorschlag f r einen Rechtsrahmen zur K nstlichen Intelligenz strebt die Kommission selbst folgende Ziele an: Es m uss gew hrleistet sein, dass die auf dem Unionsmarkt in Verkehr ge- brachten und verwendeten KI -Systeme sicher sind und die bestehenden Grundrechte und die Werte der Union wahren. Zur F rderung von Investitionen in KI und Innovationen muss Rechtssicherheit gew hrleistet sein. Governance und die wirksame Rechtsdurchsetzung zur Wahrung der Grundrechte sowie Sicherheitsanforderungen an KI -Systeme m ssen gest rkt und die Entwicklung eines Binnen- markts f r rechtskonforme, sichere und vertrauensw rdige KI -Anwendung en muss erleichtert wer- den. Noch in ihrer Mitteilung vom 2018 bekannte sich die Kommission dazu, dass KI zu Ver nderun- gen in unserer Arbeitswelt f hrt und die EU diesen Wandel steuern und begleiten muss; dass sie einen menschenzentrierten, integrativen Ansatz f r K nstliche Intelligenz verfolgt und angesichts des Ausma es der mit KI verbundenen Herausforderungen ein breites Spektrum von TeilnehmerInnen (ua Gewerkschaften) zu mobilisieren sind, um an allen Aspekten von KI zu arbeiten. Die BAK weist besorgt darauf hin, dass genau das nicht passiert ist und der Aspekt K nstliche Intelligenz und Arbeitswelt mit seinen vielf ltigen Herausforderungen in der vorgeschlagenen Verordnung nicht ber cksichtigt wurde! Es fehlen spezielle Regelungen im Sin ne von Schutzbestimmungen f r die betroffenen ArbeitnehmerInnen bei der Anwendung von KI am Arbeitsplatz! Auch vor dem Hintergrund, dass die Europ ische Kommission in ihrem Wei buch ein menschen- zentriertes KI -Konzept f r den Arbeitsplatz unter Einbeziehu ng der Sozialpartner angek ndigt hat, ist es umso bedenklicher und entt uschender, dass in der Verordnung im Wesentlichen ein rein technikzentrierter Ansatz gew hlt wurde . ArbeitnehmerInnen und deren (betriebliche) Interessenver- tretungen kommen dort als ei gene Kategorien schlichtweg nicht vor. Im Wei buch wurden wesentliche Gefahren, wie die Gefahr der berwachung von ArbeitnehmerInnen, oder die Gefahr diskriminierender KI, dargestellt. Dies wurde von der BAK in einem Positionspapier zum Wei buch auch positiv gew rdigt. Umso wichtiger ist es , beim Inverkehrbringen von KI am Arbeitsplatz einen Ansatz zu w hlen, bei dem die Anwendungen (unter umfassender Einbeziehung von ArbeitnehmerInnen und ihrer In- teressenvertretungen) gleichgewichtig das Ziel haben, Arbeit besser und humaner zu gestalten. Es darf nicht alles zugelassen werden, was auch technisch m glich ist. Daher s ollte der Einsatz von KI in der Arbeitswelt grunds tzlich als Hochrisikoanwendung gelten und bestimmte Anwendungen sollten gar nicht erlaubt sein. Im Falle des Inverkehrbringens solcher Hochrisikoanwendungen am Arbeitsplatz braucht es mehr als technische Rahmenbedingungen und Dokumentationspflichten . Den Arbeitneh- merInnen und ihren Interessenvertretungen m ssen immer auch entsprechende Mitspra- che- und Vetorechte zukommen . Die noch im Wei buch an mehreren Stellen angef hrten Sozialpartner sollen etwa nach dem Willen der Kommission im Europ ischen Ausschuss f r K nstliche Intelligenz nicht vertreten sein. F r einen menschenzentrierten KI -Ansatz, der auch die Auswirkungen der KI -Anwendungen auf die Arbeitswelt und ArbeitnehmerInnen im Blickpunkt hat, w re es unabdingbar, dass auch die Interessenvertretungen von ArbeitnehmerInnen und nicht nur die nationalen Beh r- den in den beratenden Gremien der Kommission vertreten sind. L sungsans tze beim Einsatz von K nstlicher Intelligenz am Arbeitsplatz KI-Systeme im Bereich Arbeitswelt und Besch ftigung wirken besonders einschneidend auf die Arbeitsbedingungen und k nnen negative Auswirkungen auf ArbeitnehmerInnen haben. Diese Themen der Arbeitswelt und der Mitbestimmung im Sinne eines umfangreichen europ ischen und nationalen Ansatzes unter Einbeziehung der wichtigsten Stakeholder wer- den in der Verordnung nicht einmal im Ansatz erw hnt. Die wichtige Rolle der betrieblichen und berbetrieblichen ArbeitnehmerInneninteressenvertretung bei der Einf hrung /Ver- wendung von KI am Arbeitsplatz, um das dort herrschende Machtungleichgewicht zwi- schen ArbeitgeberInnen und ArbeitnehmerInnen auszugleichen, gilt es explizit zu veran- kern! Im Wei buch kam die Kategorie der Arbeit und der ArbeitnehmerInnen noch in Ans tz en vor, auch sprach die Europ ische Kommission von einem menschenzentrierten KI -Ansatz am Arbeitsplatz und wies auf die Gefahr der berwachung von ArbeitnehmerInnen durch KI sowie durch diskriminierende KI und auch auf die Kompetenzanforderungen f r Arbe itnehmerInnen hin. Nun fallen aufgez hlte KI-Anwendungen etwa bei Einstellungsverfahren oder bei Ent- scheidungen ber Bef rderungen oder K ndigungen , f r Aufgabenzuweisung sowie f r die berwachung und Bewertung von Leistungen und des Verhaltens von Persone n in Be- sch ftigungsverh ltnissen verwendet werden sollen, zwar unter Hochrisiko -KI-Systeme, nur sollen diese Anwendungen unter Einhaltung spezifischer Anforderungen und einer ex-ante- Konformit tsbewertung auf der Grundlage interner Kontrollen zul ssig sein . Damit wird aber zu wenig getan, um die Risiken zu begrenzen oder zu verbieten, die sich durch die vielf ltigen Einsatzm glichkeiten von KI -Anwendungen im Besch ftigungsverh ltnis und aufgrund des dort herrschenden Machtungleichgewichts zwischen Arbeitgeb erIn- nen und ArbeitnehmerInnen ergeben. Augenscheinlich orientiert sich diese Verordnung pri- m r an Technologieanbietern, wobei doch der Schutz der EU -B rgerInnen und der Arbeitneh- merInnen vorrangig sein m sste. Zum Schutz von ArbeitnehmerInnen d rfen besti mmte KI -Anwendungen in der Arbeitswelt gar nicht erst zugelassen werden. Anwendungen, die auf die Arbeitsrealit ten und Ar- beitsbedingungen Auswirkungen haben, sind als hochriskant zu klassifizieren . Insbe- sondere darf die vorzunehmende Konformit tsbewertu ng nicht ohne Einbeziehung der Betroffe- nen, dh der ArbeitnehmerInnen und ihrer Interessenvertretungen, erfolgen. Bei der Einf hrung derartiger KI -Systeme am Arbeitsplatz sollte jede Bewertung von Risiken in Abstimmung mit den Interessenvertretungen der Arb eitnehmerInnen erfolgen. Werden die Risiken als zu hoch eingestuft, m ssen diese von den AnbieterInnen eliminiert werden, andernfalls d rfen die Systeme am Arbeitsplatz nicht eingesetzt werden. Bestimmte Anwendungen im Arbeitsverh ltnis (automatisierte Ent scheidungen im Einzelfall und Profiling) sollten aufgrund der besonders einschneidenden Auswirkungen auf die Arbeitsbedin- gungen berhaupt untersagt werden. Nach Art 8 der EU -Grundrechtscharta hat jedermann An- spruch auf Geheimhaltung seiner Daten, soweit ei n schutzw rdiges Interesse daran besteht. Beschr nkungen des Anspruchs sind nur zur Wahrung berwiegender berechtigter Interessen eines anderen zul ssig. Aber selbst dann darf nur in der gelindesten Form ins Grundrecht ein- gegriffen werden. In der Praxis de s Arbeitsalltags erh lt das Grundrecht aber oft nicht den Stel- lenwert, der ihm geb hrt. Die Entwicklung in der Personalverwaltung bzw in der Betriebsorganisation geht in Richtung einer Daten konomie, die nach immer mehr Daten f r immer mehr Zwecke verlang t. Die daten- schutzrechtliche Lage f r die ArbeitnehmerInnen hat sich auch durch die DSGVO nicht ma - geblich verbessert. Verst rkt wird dies zudem durch die EU -weite F rderung datengetriebener Wirtschaft. Angesprochen sind dabei Daten mit und ohne Personenbe zug und solche, bei de- nen der Personenbezug entfernt wurde, die also anonymisiert wurden. Bez glich letzteren r u- men ExpertInnen allerdings ein, dass Algorithmen durch maschinelles Lernen so gut wie jede Anonymisierung r ckf hren k nnen und ArbeitnehmerInn en re -identifizierbar werden. Profiling, Scoring und Verhaltensprognosen sowie automatisierte Entscheidungsfindungen mit Hilfe von Algorithmen, maschinellem Lernen und KI k nnen ArbeitnehmerInneninteressen jedenfalls massiv gef hrden. ArbeitnehmerInnenverh alten, pers nliche Eigenschaften uvm d rfen nur aus besonderen, berechtigten Gr nden und unter strikten Kautelen analysiert, klassifiziert oder prognostiziert werden. Unserer Auffassung nach sind automatisierte Entscheidungen im Ein- zelfall und Profiling im Arbeitsverh ltnis nicht erforderlich und d rfen daher nicht zul ssig sein. Dies hat auch f r menschliche Entscheidungen blo vorbereitende, halbautomatisierte Be- wertungen zu gelten. ArbeitnehmerInnen f rchten um die Wertsch tzung f r ihre menschliche Arbeit: Werden Arbeit- nehmerInnen noch als individuelle Personen wahrgenommen oder wird menschliche Arbeit zu- k nftig immer mehr wie automatisierte und (leicht) automatisierbare Prozesse definiert und be- wertet? Mit der bersetzung aller Arbeitsbereiche in eine Datenwelt entsteht die Gefahr im Arbeitsprozess zu einem technikzentrierten und damit inhumanen Menschenbild zu gelangen. Die Arbeitsleistung der ArbeitnehmerInnen wird zunehmend in Zahlen ausgedr ckt, gemessen, verglichen, analysiert und es werden daraus automatisiert Entscheidungen und Vorhersagen getroffen. Der Mensch am Arbeitsplatz wird zu einem blo en messbaren Produktions - und Kos- tenfaktor herabgew rdigt; der immaterielle Wert der Arbeit und die W rde der Arbeitenden blei- ben dabei auf der Stre cke. Die Wahrung der Menschenw rde, die Pers nlichkeitsrechte, sind auch bei der Erbringung der Arbeitsleistung sicherzustellen, die Europ ische Union muss dazu ein klares Bekenntnis abgeben! Herausforderungen beim Einsatz von KI am Arbeitsplatz Die Ve rordnung entspricht in der Arbeitswelt keineswegs dem angek ndigten menschen- zentrierten Ansatz . Deshalb sollen hier noch einmal die grundlegenden Herausforderungen dargelegt werden, an denen sich die Regeln f r Anwendungen in der Arbeitswelt orientieren sollten . Diese legen auch Gr nde dar, warum es f r die Arbeitswelt einen wirklich menschenzentrierten An- satz braucht, der auf die bessere und humane Gestaltung der Arbeit und nicht nur auf die Ge- staltung der Technik abzielt : KI wird die Arbeitsbedingungen einschneidend ver ndern, erste Anzeichen sind bereits erkenn- bar (zB Einsatz von Bewerbungs - oder Karrieretools, automatisierte Pr mienberechnungen, usw). Die wirtschaftlichen Chancen, die sich durch den Einsatz von KI ergeben , sind zu nutzen, aber aufgrund der Tatsache, dass damit auch die technischen M glichkeiten der berwa- chung am Arbeitsplatz und der Verwendung von ArbeitnehmerInnendaten zunehmen m s- sen die Rechte der Besch ftigten durch konkrete Regelungen gesch tzt w erden! IT/KI -Systeme (Laptop, Smartphone, vernetzte Maschinen und Arbeitsmittel, Programme zur Personalverwaltung und Betriebsorganisation) werden immer vielf ltiger und komplexer. Die Menge der dabei generierten und verwendbaren Besch ftigtendaten nim mt exponen- tiell zu und auch die technischen Verkn pfungs - und Analyse -M glichkeiten dieser Da- ten werden immer ausgereifter und aussagekr ftiger bis hin zum Erstellen von Bewertun- gen und Verhaltensvorhersagen von ArbeitnehmerInnen (Profiling) und automati sierter Ent- scheidungsfindungen im Bereich der Personalverwaltung , der Personal - und Karriereplanung, des Einsatzes von Personalinformationssystemen etc. Entscheidend f r den Schutz von ArbeitnehmerInnen sind vor allem Mitbestimmungs- rechte der betrieblichen und berbetrieblichen Interessenvertretungen bei der Einf h- rung von KI am Arbeitsplatz : Das k nnen Informations -, Mitgestaltungs - und Zustimmungs - bzw. Vetorechte der einzelnen Besch ftigten, aber vor allem auch angesichts der Verhand- lungsunterlegenheit der einzelnen Besch ftigten gegen ber dem Arbeitgeber von betriebli- chen und berbetrieblichen Interessenvertretungen sein. Hervorgehoben sei auch, dass eine allf llige Zustimmung der ArbeitnehmerInnen zur Ver- wendung ihrer personenbezogenen Daten in der Regel nicht freiwillig erfolgen kann, weil sich im Arbeitsverh ltnis keine gleichberechtigten VertragspartnerInnen gegen berste- hen. So zeigt die Praxis, dass ArbeitnehmerInnen im aufrechten Arbeitsverh ltnis ihre Rechte so gut wie nie einfordern, also die M glichkeit eine Beschwerde bei der Datenschutzbeh rde bzw eine Klage bei Gericht einzubringen , nicht in Anspruch nehmen. Um dem entgegenzuwir- ken, braucht es starke Mitbestimmungsrechte der Interessenvertretungen bei der Einf h- rung von KI am Arbeitsplatz und ein explizites Verbandsklagerecht der berbetrieblichen Inte- ressenvertretung zur St rkung der Rechtsdurchsetzung. Zudem erfolgt die Beauskunftung von Datenverarbeitungen oft nur mangelhaft und meist in einer nicht leicht verst ndlichen Sprache, womit Transparenz, Information und Nachvollziehbarkeit bei den ArbeitnehmerInnen und ihrer Interessenvertretungen in der Praxis in den seltensten F l- len ausreichend gegeben ist (so erfolgt die Befragung der betroffenen ArbeitnehmerInnen und ihrer Interessenvert retungen bei der Datenschutz -Folgenabsch tzung nach der DSGVO oft nur ungen gend oder unterbleibt sogar ganz) . Um die positiven Potenziale von KI auch f r ArbeitnehmerInnen zu heben und sie dennoch vor den Gefahren zu sch tzen, bedarf es eines Bottom -Up-Ansatzes , bei dem nicht nur die technischen Grundlagen und Anwendungen der Mitbestimmung unterzogen werden, sondern bei dem von Beginn an die Auswirkungen von KI auf die arbeitenden Menschen und die Arbeitsbedingungen untersucht werden und ber den endg ltigen Einsatz erst auf Basis dieser Erfahrungen entschieden wird . Zumindest ein klares Bekenntnis der Euro- p ischen Kommission zu einem solchen Ansatz w re w nschenswert, damit in der operativen und oft schnelllebigen Umsetzung auch die entspreche nde Position der ArbeitnehmerInnenver- tretung und damit der ArbeitnehmerInnenrechte gew hrleistet werden kann. II. KI und KonsumentInnen Die Absicherung eines hohen Verbraucherschutzniveaus ist auch bei Algorithmen und KI wichtig. Kon- sumentInnen m ssen vor einer Aush hlung ihrer Grund - und Freiheitsrechte, Intransparenz, Diskriminierung, k rperlichen sowie psychischen Risken und sonstigen Schadensrisiken, die von derartiger Analysesoftware ausgehen, bestm glich gesch tzt werden. Um KonsumentInnen angemessen zu sch tzen, sind folgende Punkte erforder- lich Regeln nicht nur f r Hochrisiko -KI. Freiwillige Selbstverpflichtungen sind zu wenig . Auch bei blo riskanten Anwendungen sind Transparenz, Diskriminierungsfreiheit, Beschwerder echte durch Vorschriften abzusichern Verankerung von Rechten f r betroffene B rgerInnen und VerbraucherInnen : ua das Recht auf Information, Auskunft, Selbstbestimmung (M glichkeit, KI -Analysen und Entschei- dungen basierend auf pers nlichen Daten auch abzul ehnen), Beschwerderechte. Verbot von gesellschaftlich unerw nschten KI -Systemen statt l ckenhafte Verbote einiger Spielarten von Social Scoring, biometrischer Fern berwachung und Verhaltensmanipulation . Konkrete Benennung von Risiken, die Hersteller und Nu tzer ausschlie en bzw minimie- ren m ssen: f r hochriskante KI finden sich zwar Hinweise auf Gefahren f r die Sicherheit, Gesundheit und Grundrechte. Doch ist weder ein Diskriminierungsverbot verankert noch genau normiert, in welchem risikofreien bzw -behaft eten Zustand KI auf den Markt gelangen darf. Schlie en von Schlupfl chern im korrespondierenden Art 22 DSGVO bez glich algorith- mischer, automatischer Einzelentscheidungen. KI-Zertifizierung ausnahmslos durch unabh ngige Beh rden (bzw ihnen zurechenbarer Dienstleister) statt blo er Selbstzertifizierung durch die Hersteller. KI-Entscheidungen, -Dienste und Produkte m ssen bei sonstigem Verbot tats ch- lich erkl r - und berpr fbar bleiben , vor allem in Hinblick auf unzul ssige Diskriminierung, Benachtei ligung, Verhaltensmanipulation oder Betr gereien. Schutznormen f r biometrische KI -Analysen bei Verbrauchergesch ften. keine Ausnahmen von der DSGVO f r den Dateneinsatz in KI - Reallaboren institutionelle Einbindung der Betroffenen bei interessensabw genden Entscheidungen ber die (Un -)Zul ssigkeit von konkreten KI -Anwendungen. berarbeitung der unzeitgem en Regeln f r Produkthaftung und Produktsicherheit um sie KI -fit zu machen kollektive Rechtsschutzm glichkeiten f r Betroffene ua durch Verbandsklagbefugnisse. Allgemeine konsumentenpolitische Defizite des Entwurfes: Verbraucheranliegen werden berhaupt nicht mitgedacht : KonsumentInnen werden durch Algorith- men oft kategorisiert und bewertet. Die EU -Kommission bagatellisiert die Risiken, wenn sie daf r nur eine freiwillige Selbstverpflichtung empfiehlt. Intransparenz, Grundrechtsverletzungen, Benachteiligung, Verhaltensmanipulation und berwachung entstehen auch bei der Nutzung s marter Dienste und G ter. KI kann auch aus anonymisierten Datens tzen Personen identifizieren, klassifizieren, oder als Informa- tionsfilter Meinungen beeinflussen. Die BAK h lt deshalb gesetzliche Anforderungen nicht nur f r Hoch- risiko -KI, sondern f r alle KI-Anwendungen f r angemessen. Diese sollten entsprechend ihrer Gefah- renneigung abgestuft sein. KI muss vertrauensw rdig sein! : Auch die EU Kommission sieht bei KI viele Bedrohungsszenarien. Die vorgesehenen Rechtsinstrumente sind aber schwach. F r Entwi ckler und Verwender sollen laut Kommission keine unverh ltnism ig hohen B rden entstehen. Man setzt prim r auf die Regulierung von hochriskanter KI. Es ist jedoch irrelevant, ob ein Schaden von einer hochriskanten oder blo risiko- behafteten KI herr hrt. Vorabkontrolle, Transparenz und Beschwerderechte sind des- halb in jedem Fall notwendig. Skepsis gegen ber ethischer Technik angebracht: Der Philosoph Richard David Precht spricht vom Irrsinn, Maschinen Ethik einzuprogrammieren : K nstliche Intellige nz etwa darauf zu program- mieren, wie sie sich in ethischen Grenzf llen verhalten soll sei ein Angriff auf die Menschenw rde . Unmissverst ndliche Verbote seien n tig: Besonders in ethisch sensiblen Bereichen bestehe die Ge- fahr, dass wir Maschinen sehr weitreichende Handlungsvollmachten bertragen, die sie auf keinen Fall bekommen d rfen . Ben tigt werden klare Ge - bzw Verbote: die im Entwurf beinhalteten Verbote greifen nur in wenigen spezifischen F llen. Klare Grenzen und rote Linien werden nicht gese tzt: keine Definition maximal zu- l ssiger Restrisiken; kein Verbot von Diskriminierungsrisiken; Selbstzertifizierung der Hersteller ohne klare Vorgaben. Man berl sst vieles nur Herstellern und allenfalls noch nachpr fenden Beh rden. Was fehlt sind Verbote ohne vielf ltige Ausnahmen, Risikobenennung (auch bei Diskriminierungsgefahren), Selbstbestimmungsrechte dar ber, ob KI die eigene Person betreffende Entscheidungen berhaupt treffen darf, Informationspflichten, beh rdliche Vorabpr fung der Folgen f r Mens chenw rde und Frei- heitsrechte, Produktsicherheit und haftung, au ergerichtliche Beschwerdestellen und Verbandsklags- befugnisse im Interesse aller Betroffenen. Der blo er Verweis auf die in Art 22 DSGVO enthaltenen Rechte reicht dabei keinesfalls aus (siehe AK- Stellungnahme zur Evaluation der Datenschutz -Grundverordnung ). Blackbox auch f r die Verantwortlichen: KI hnelt einer Blackbox. Auch KI -ExpertInnen k nnen bei selbstlernender Software oft nicht genau erkl ren, warum eine KI zu bestimmten Ergebnissen gelangt. K nnen Hersteller und Nutzer KI -Ergeb- nisse aber nicht verantworten, weil sie sie selbst nicht begreif en und beherrschen k nnen, ist aus Sicht der BAK eine Anwendung zu verbieten. Transparenz? Nicht f r B rgerInnen und VerbraucherInnen : Transparenzverpflichtungen f r User gelten nur f r professionelle Anwender von KI Systemen. Ge- gen ber betroffenen Endn utzerInnen und KonsumentInnen sind kaum welche festgeschrieben. Wer nicht wei , wo und wie KI -Systemen eingesetzt werden, kann aber auch nicht absch tzen, ob und wie er/sie davon betroffen ist, und sich im Bedarfsfall nicht wehren. Die DSGVO schafft hier a uch keine Abhilfe, weil sie nur bei personenbezogenen Daten bzw bei vollautomatisierten Einzelentscheidungen Informations - und Auskunftspflichten vorsieht. Fehlender Rechtsschutz : Komplexe Algorithmen und maschinelle Selbstlernf higkeit werden die zu- st ndi gen Aufsichtsbeh rden und Gerichte weit ber ihre Grenzen fordern, was zu Lasten des Recht- schutzes geht. Au ergerichtliche Anlaufstellen, insbesondere bei grenz berschreitenden Problemen : Zulassungen und Konformit tsentscheidungen eines Mitgliedsstaates s ind in der gesamten EU wirk- sam, was zu Problemen f hren kann, wenn etwa die Niederlassungsstaaten von Herstellern, Nutzern und VerbraucherInnen auseinanderfallen. Es braucht deshalb niedrigschwellige Rechtsschutzmecha- nismen f r Betroffene, um grenz berschr eitende Informationen einfordern oder Beschwerden t tigen zu k nnen. Mehr Pr vention : KonsumentInnen und ArbeitnehmerInnen erwarten sich einen vorbeugenden Schutz durch beh rdliche Vorabkontrollen und Genehmigungen. Selbstzertifizierung durch Hersteller v on KI und nachtr gliche Schadenersatzanspr che reichen nicht aus. Ohne bestausgestattete Vollzugsbeh rden kein Durchblick : Eine wirksame Marktaufsicht erfordert ausreichende Ressourcen. Beh rden k nnen die komplexen Pr faufgaben ansonsten weder finanziell noch fachlich bew ltigen. Das gilt nat rlich auch im Bereich des Arbeitnehm erInnenschutzes (Arbeitsinspektorate) . Kollektive Rechtsdurchsetzung erm glichen (Beschwerden bei Beh rden, Verbandsklagen): individuelle zivilrechtliche Klagen alleine schaffen kein Kr ftegleichgewicht. Verbandsklagsbefugnisse f r Organisationen, die B rger - und Verbraucherinteressen f r Betroffene vertreten, sind deshalb auch im Bereich von KI -Anwendungen notwendig. Unabh ng ige Zertifizierung: eine externe Zertifizierung von KI Systemen mit hohem Risiko wird aufgrund der VO wohl nur selten tats chlich erfolgen. Einerseits, weil Stand -alone -Systeme mit hohem Risiko meist nur einer herstel- lerseitigen Pr fung zu unterziehen s ind und andererseits, weil Systeme nach Annex II nur dann als KI mit hohem Risiko zu qualifizieren sind, wenn sie einer externen Zertifizierung unterliegen, was wiederum durch andere Produktstandardregeln festgelegt wird. Eine ex -ante Pr fung wird dabei nu r selten ver- langt. Bei hochriskanter KI m ssten aus BAK -Sicht aber ausnahmslos unabh ngige, externe Pr fer, herangezogen werden. Zu den Konsumentenanliegen im Detail: Anwendungsbereich (Art 2 Abs 1 c) Begr t wird, dass auch Hersteller und Nutzer von KI -Systemen aus Drittstaaten vom Anwendungsbe- reich erfasst sind, sofern die KI -Ergebnisse in der EU genutzt werden. Zudem sollte aber auch in den Anwendungsbereich fallen, wenn EU -B rgerInnen von KI aus Dri ttstaaten betroffen sind. Definitionen (Art Die augenf lligen Definitionsdefizite verweisen auf eine Regelungsl cke im gesamten Entwurf: Auf von KI betroffene KonsumentInnen und ihren Schutzbedarf wird berhaupt nicht eingegangen. ZB sind User defini tionsgem nur die professionellen Anwender von KI. (Private) Endnutzer von KI-Produkten und Diensten sind nicht erfasst. Sie sind in den Adressatenkreis unbedingt aufzunehmen, damit auch Schutznormen zu ihren Gunsten verankert werden k nnen. Dar ber hina us k nnen Personen auch von KI betroffen sein, ohne direkt KI Anwendungen zu nutzen (zB als Subjekte der berwachung). Bei automatisierten Einzelentscheidungen kann zwar auf die DSGVO verwiesen werden, aber der Begriff Betroffene geht hier noch dar ber h inaus und sollte sich etwa auch auf eine KI -basierte Bildung von statistischen Gruppen erstrecken, da auch diese Folgen f r die Einzelperson haben k nnen. Ebenso erscheint die Definition von Sicherheitskomponenten eines Produktes oder Systems et- was willk rlich . Es wird nicht erkl rt, warum nur bestimmte Funktionen von KI hervorgestrichen werden, andere, ebenso riskante, aber nicht (zB Spracherkennung, Biometrie bei Handys). Der Entwurf l sst auch eine prinzipielle kritische Distanzierung zu Technologien vermissen, die Men- schenw rde ber hren bzw verletzen k nnen, wie etwa Emotionserkennungssysteme oder die bi- ometrische Fernidentifikation von Personen . Eine klare Abgrenzung zwischen KI, die grunds tzlich zum Einsatz kommen darf und solcher, der der Betrieb (von wenigen Ausnahmen abgesehen) zu ver- sagen ist, w re w nschenswert Ziffer 44 fasst unter dem Begriff ernster Vorfall den Tod einer Person, ernste Gesundheitsfolgen oder Sch den am Eigentum, an der Umwelt oder kritischen Infrastrukturen zusamm en. Bei der Umschrei- bung von hochriskanter KI (Artikel 6 ff) fehlen einige dieser Tatbestandelemente. Erw hnt werden nur Gefahren f r Gesundheit und Sicherheit, daf r aber werden auch negative Folgen f r die Grundrechte erw hnt. Die Risikoszenarien sollten durchg ngig koh rent sein Verbotene Praktiken (Art Bei der Pr sentation des Entwurfes nahm die EU -Kommission eine strikte Haltung in Bezug auf unan- nehmbare Risiken ein. KI-Systeme die eine Bedrohung f r die Sicherheit, Lebensgrundlagen und Rechte d arstellen sollen ver- boten sein. Doch im Entwurf wird dieses Prinzip oft durchl chert. So sollen etwa subliminare, verhal- tensmanipulierende Techniken verboten sein, allerdings nur, wenn sie den Betroffenen nicht bewusst sind und physischen bzw psychischen S chaden anrichten (von wirtschaftlichem Schaden ist nicht ein- mal die Rede). Ein Verbot von unbewusster Manipulation menschlichen Verhaltens sollte allerdings nicht vom Eintritt eines Schadens abh ngig sein. Solche Praktiken widersprechen per se schon der Menschenw rde und Pers nlichkeitsrechten. Auch bei Techniken, die die Verletzlichkeit bestimmter Personengruppen ausn tzen, darf nicht die Eintrittswahrscheinlichkeit von Sch den eine Voraussetzung f r ein Verbot sein, wie es der Entwurf vorsieht. Ebenso sind die Einschr nkungen beim social scoring kritisch zu hinterfragen. Auch wenn die be- h rdliche Bewertung von sozialem Verhalten verboten wird, so bleiben trotzdem viele Spielarten von (grundrechtswidrigem) social scorings erlaubt. Ein Verbot von beh rd lichen social scoring soll n mlich nur f r Daten gelten, die urspr nglich f r andere Zwecke gesammelt wurden oder wenn die Benachtei- ligungen von Menschen, die dadurch entstehen, unverh ltnism ig zum sozialen (Fehl -) Verhalten sind. Werden hingegen Daten von vornherein zum Zweck des Scorings erhoben, so bleibt die Bewertung von sozialem Verhalten erlaubt. Das ber hrt aber rasch die Menschenw rde. Hier sollte es kaum Spielraum f r zul ssige Anwendungen geben. Ben tigt wird ein generelles Verbot der sozialen berwachung und Profilbildung der Bev lkerung. Unklar ist auch, was f r social scoring gilt, das vom extrem l ckenhaften Verbot nicht erfasst und dennoch grundrechtswidrig ist. K nnen Praktiken, die nach Art 5 nicht untersagt sind, mit Blick auf die EMRK oder Art 22 DSGVO verboten werden (etwa soziales Scoring durch die Privatwirtschaft oder Bewertungen von anderen Eigenschaften als der Vertrauensw rdigkeit einer Per- son)? Der Entwurf b te jedenfalls die Chance, auch Unzul nglichkeiten im Artikel 22 DSGVO zu besei- tigen (Erweiterung des Schutzes auf statistische Gruppen, bei denen kein Personenbezug vorliegt und auf F lle mit abschlie ender menschlicher kontrollierender Aufsicht). Auch die Ausnahmen vom Verbot (Einwilligung, Rechtsakt, Vertragsnotwendigkeit ) sind zu weitreichend und deshalb berarbeitungsbe- d rftig. Ziffer d verbietet die biometrische Fernidentifikation von Personen in Echtzeit im ffentlichen Raum f r Zwecke der Rechtsdurchsetzung. Auch hier gibt es umfangreiche Ausnahmen (Suche nach Verbrechensopfern, Lebensbedrohung von Personen, Terrorismus, Personensuche wegen schwerer Verbrechen). Begr t wird, dass der Einsatz solcher bio metrischen Systeme in der Regel einer vorhe- rigen Genehmigung durch die Justiz oder einer unabh ngigen Verwaltungsbeh rde bedarf. Angemes- sen w re allerdings auch hier ein weitgehend ausnahmsloses Verbot des Einsatzes KI -basierter biometrischer Erkennung von Personen ohne deren Zustimmung. Unvertretbar erscheint die Einschr nkung auf Echtzeiterfassungen, denn auch die biometrische Aus- wertung von Videomaterial kann tief in Grundrechte eingreifen. Arbeitspapiere der EU -Kommission ent- hielten noch ein mehrj hr iges Verbot der KI -Analyse von biometrischen Merkmale f r private wie ffent- liche Akteure. F r den Grundrechtsschutz in der EU ist es das falsche Signal, wenn der Entwurf kein (zumindest tempor res) Einsatzverbot ausspricht. Neben Datenschutzbedenken beste ht auch die Ge- fahr von falschen Ergebnissen aufgrund der Fehlerraten. Menschen geraten dabei irrt mlich ins Visier, obwohl sie nichts verbrochen haben. Wichtige Regulierungsanliegen w ren dabei: Biometrie darf kein Gesch ft werden : Der Handel mit biometr ischen Daten sollte verboten und mit hohen Strafen sanktioniert sein. Wahlfreiheit ist oberstes Gebot : Jede/r sollte selbst entscheiden k nnen, ob seine/ihre bio- metrischen Daten verarbeitet werden d rfen oder nicht. Pflichtcheck vor dem Griff nach biometr ischen Daten : Vor jedem Einsatz biometrischer Da- ten sollten Datenschutzbeh rden angesichts des hohen Risiko - und Schadenspotenzials pr - fen, ob die Verarbeitung biometrischer Daten notwendig und sinnvoll ist. Onlinebanking und andere Anwendungen ohne bleibe nde biometrische Daten : Es darf zu keiner dauerhaften Speicherung von biometrischen Daten kommen, um das Risiko von Identi- t tsdiebstahl zu minimieren. Gesichtsfotos als sensible Daten : Onlinefotos werden bereits in unz hligen F llen f r die Identifikation von Personen durch Gesichtserkennung genutzt. Rechtlich ist offen, inwieweit diese Daten als biometrisch gelten. Hier besteht dringend Bedarf, Portr ts vor versteckter biometrischer Auswertung zu sch tzen. Klassifizierung von KI -Systemen als hoch -riskan t (Art Hochriskant sind KI -Systeme nur dann, wenn sie als Sicherheitskomponente oder -produkt nach den in Anhang II angef hrten Harmonisierungsrechtsvorschriften gelten. Zus tzlich muss die Sicherheitskom- ponente bzw das Sicherheitsprodukt einer Konformit tsbewertung durch Dritte wiederum nach den in Anhang II angef hrten Harmonisierungsrechtsvorschriften unterzogen werden. KI w re nur dann hochriskant, wenn sie mit einer externen Zertifizierung nach den New Approach RL ber die technische Produ ktkonformit t verbunden ist. F r die Qualifizierung eines KI -Sicherheitspro- duktes als hochriskant kann aber nicht ernsthaft ausschlaggebend sein, ob es einer New Approach RL unterliegt und nach dieser extern zu zertifizieren ist (was im brigen selten der Fall ist). Dieser Ansatz ist verfehlt und muss durch sachgerechte Kriterien ersetzt werden. Als hochriskant gelten zudem die im Annex III aufgez hlten Anwendungen. Diese Liste sollte nur de- skriptiv sein, denn wichtige Bereiche finden gar keine Erw hnung (z B KI, die sensible Gesundheitsdaten benutzt, Betrugs - und Missbrauchserkennung aufgrund des Kundenverhaltens, werblich -manipulative Beeinflussung des Nutzerverhaltens, Produktempfehlungen, Nachrichtenselektion uvm). Die EU -Kommission kann zwar den Annex I II erg nzen, allerdings nur die bereits angelegten Kategorien um weitere Beispiele erweitern. Neue Kategorien sind ausgeschlossen. Damit k nnen wichtige, ver- braucherrelevante Bereiche nicht erfasst werden. Zudem muss von weiteren Beispielen ein hohes Ri- siko in Form von Sch den an Gesundheit oder Sicherheit oder eine negative Beeintr chtigung von Grundrechten ausgehen. Wirtschaftliche Sch den sind nicht erw hnt. Anmerkungen zum Annex: Die Erfassung von KI-Systemen, die f r die biometrische Echtzeit -Fern identifizierung verwendet werden sollen ist zu eng. Biometrische KI -Systeme sind auch dort im Vormarsch, bei denen keine Fern -Identifikation stattfindet (Onlinebanking, Ger teentsperrung etc). Aufgrund der hohen Missbrauchsgefahr und den Fehlerraten sol lten auch diese Anwendungen mitregu- liert werden. Bei der Zug nglichkeit und Inanspruchnahme grundlegender privater und ffentlicher Dienste und Leistungen bedarf es erl uternder Beispiele, was darunterf llt. Die Kleinanbieter -Ausnahme f r den Eigengebrauch in Bezug auf KI -Systeme, die f r die Kreditw rdigkeitspr fung und Kreditpunktebewertung verwendet werden sollen sollte kri- tisch hinterfragt werden. Risiken bestehen unabh ngig von der Unternehmensgr e. KI-Systeme, die von Strafverfolgun gsbeh rden f r individuelle Risikobewertungen na- t rlicher Personen verwendet werden sollen, um das Risiko abzusch tzen, dass eine nat rliche Person Straftaten begeht oder erneut begeht sollten zu den absolut verbotenen Praktiken z hlen. Verletzung der Me nschenw rde, hohe Fehlerraten, diskriminierende Bias uvm sind nur einige der Gr nde, warum f r derartige Anwendungen grunds tzlich kein Platz sein sollte. Auch KI -Systeme, die von Strafverfolgungsbeh rden als L gendetektoren und hnliche In- strumente ode r zur Ermittlung des emotionalen Zustands einer nat rlichen Person verwendet werden sollen sollten der Liste verbotener Praktiken hinzugef gt werden. Nicht nur als hoch- riskant, sondern in einer Demokratie als unannehmbar sollten au erdem KI -Systeme gelten , die von Strafverfolgungsbeh rden zur Vorhersage des Auftretens einer tats chlichen oder potenziellen Straftat auf der Grundlage des Profils nat rlicher Personen oder zur Bewer- tung von Pers nlichkeitsmerkmalen und Eigenschaften oder vergangenen kriminell en Verhal- tens nat rlicher Personen oder von Gruppen verwendet werden sollen. Au erdem sind KI - Systeme, die zur Kriminalanalyse nat rlicher Personen eingesetzt werden sollen und es den Strafverfolgungsbeh rden erm glichen, gro e komplexe verkn pfte und un verkn pfte Da- tens tze aus verschiedenen Datenquellen oder in verschiedenen Datenformaten zu durch- suchen, um unbekannte Muster zu erkennen oder verdeckte Beziehungen in den Daten aufzudecken mit den Grundregeln des Datenschutzes unvereinbar und deshalb verboten. Transparenz und Bereitstellung von Informationen f r Nutzer (Art Es ist unakzeptabel, dass nur dem professionellen Anwender Informationen zum KI -Betrieb zug nglich sein m ssen. Auch Betroffene haben einen Anspruch auf Transparenz. Die in Abs 3 genannten Infor- mationen (Kontaktdaten , Merkmale des KI -Systems, Risiken f r Gesundheit und Sicherheit etc.) m s- sen daher auch den von der Anwendung Betroffenen zug nglich sein. menschliche Aufsicht (Art Die Anforderung, einer menschlichen Aufsicht, wird begr t. Unklar ist, welche Qualit tsanforderungen dabei einzuhalten sind. Unklar ist auch, in welchem Verh ltnis diese Anforderung zu Artikel 22 DSGVO steht, der automatisierte Einzelentscheidungen grunds tzlich auch ohne menschliche Aufsicht gestat- tet, im Gegenzug aber gewisse Rechte einr umt (zB Anfechtung). Qualit tsmanagement (Art Provider sind zu einer Strategie ua f r die rechtliche Konformit t verpflichtet. Es sollte klargestellt wer- den, dass dies auch die Einhaltung datenschutzrechtlich er Bestimmungen umfasst. Abzulehnen ist je- doch, dass sich diese Verpflichtungen sich nach der Gr e des Unternehmens richten. Risiken m ssen unabh ngig von der Unternehmensgr e mit gr ter Sorgfalt minimiert werden. Aussetzung der Konformit tsbewertung ( Art Markt berwachungsbeh rden sollen Verfahren zur Konformit tsbewertung in bestimmten F llen aus- setzen k nnen. Die daf r ausschlaggebenden au ergew hnlichen Gr nde sind viel zu unbestimmt. Transparenzpflichten f r bestimmte AI -Systeme (Art Informationspflichten beim Einsatz von Chatbots sind grunds tzlich sehr zu begr en. Die Bestimmung ist jedoch um generelle vorherige Informations - und nachtr gliche Auskunftsrechte f r alle von KI be- troffenen Personen zu erweitern. Emotionserkennungssysteme g reifen erheblich in die Grundrechte ein eine blo e Kenntlichmachung ist keine hinreichende Schutzma nahme. Ihr Einsatz sollte grunds tz- lich zu den verbotenen Praktiken des Artikel 5 z hlen. Weiterverarbeitung personenbezogener Daten in KI - Sandboxes/Re allaboren (Art In sogenannten KI -Reallaboren sollen personenbezogene Daten, die eigentlich f r andere Zwecke er- hoben wurden, zum Testen von KI benutzt werden d rfen, wenn ein erhebliches ffentliches Interesse besteht und mit anonymen Daten nicht das Auslangen gefunden werden kann. Dies h hlt jedoch die DSGVO aus, die einer Weiterverarbeitung von Daten zu anderen Zwecken enge Grenzen setzt. Be- troffene w ren von einem solchen Vorhaben zu informieren und ihre Zustimmung einzuholen. Eine Missachtung des S elbstbestimmungsrechtes ber eigene Daten w re in hohem Ma e grundrechtswid- rig und l uft auch Gefahr, einer EUGH -Kontrolle nicht stand zu halten. Zudem ist zu berwachen, ob w hrend des Testens hohe Grundrechtsrisiken bestehen. Auch diesem Risiko kann man Personen nicht zu Testzwecken ungefragt aussetzen. Es braucht eine explizite Zu- stimmung, als Proband zur Verf gung zu stehen. Die Datenschutzbeh rde hat ein solches Vorhaben au erdem vorab zu pr fen und geeignete Auflagen zu erteilen oder zu untersagen. Weitere Verbraucheranliegen: Hersteller und Nutzer hochriskanter Anwendungen ben tigen eine Haftpflichtversicherung: Hersteller und Nutzer sollten gegen ber Betroffenen f r materielle und immaterielle Sch den solidarisch haften m ssen. Ebenso sollte eine diesbez gliche Versicherungspflicht bestehen. leichte Rechtsdurchsetzung: Es sind f r Betroffene nationale Anlaufstellen einzurichten (f r Beschwerden, Nachpr fungen von KI Ergebnissen, sowie bei grenz berschreitenden Problematiken). Ebenso ist eine Verbandsklagsbefugnis und Beschwerdem glichkeiten von Vertretungen zur Wahrung k ollektiver Interessen von Betroffenen- gruppen vorzusehen. Schutz vor Intransparenz, Diskriminierung und Manipulation in niedrigeren Risikoklassen : Auch in niedrigeren Risikoklassen braucht es verbindliche Ge - und Verbote, die Transparenz, Diskrimi- nierungs freiheit und die Beachtung der Grundrechte sicherstellen. Eine Aufsichtsbeh rde sollte Einblick in die technischen Prozesse erhalten und durch ein Zulassungsverfahren garantieren, dass keine dis- kriminierenden, die Informationsfreiheit und Meinungsvielfalt beeintr chtigende bzw datenschutzwidrige Entscheidungskriterien verwendet und darauf basierende Entscheidungen getroffen werden. Schlie en von Schlupfl chern in der DSGVO f r den Einsatz intransparenter Algorithmen : Derzeit sind nach DSGVO nur vollautoma tisierte Einzelentscheidungen, die Rechtsfolgen haben oder KonsumentInnen erheblich beeintr chtigen, grunds tzlich verboten. Dieser Schutz sollte auf halbauto- matisierte Entscheidungen ausgedehnt werden, bei denen zwar Menschen entscheiden, aber Maschi- nen diese Entscheidung vorbereiten , denn Bewertungen werden von Mitarbeitern nachtr glich selten abge ndert. Au erdem sollten Betroffene ber jeden Algorithmus, der mit Daten von KonsumentInnen arbeitet, informiert werden - unabh ngig von den Rechtsfolgen o der einer starken Beeintr chtigung der KonsumentInnen, wie es die DSGVO derzeit verlangt. Die Erlaubnistatbest nde des Artikel 22 gehen ebenfalls viel zu weit. Algorithmische Entscheidungen sind unter bestimmten Bedingungen zul ssig (zB bei Abschluss bzw Erf llung von Vertr gen sofern KonsumentInnen die M glichkeit haben die Entscheidung anzufechten). Der Einsatz bei Verbraucher- vertr gen sollte aber nur in besonders begr ndeten F llen (wie einem hohen Zahlungsausfallsrisiko bei Krediten) m glich sein. Ruf nach mehr Trainingsdaten f r KI erfordert wirksameren Datenschutz : Selbstlernende Systeme werden mit Trainingsdaten gef ttert um in riesigen Datenbest nden nach un- erkannten Mustern und Zusammenh ngen zu suchen. Werden personenbezogenen Daten genutzt, l sst das mit der Pflicht zur Datensparsamkeit, engen Zweckbindung und privacy by design and default schwer in Einklang bringen. Ein Nachweis, wie dies im Einzelfall gelingt, ist von den Herstellern und Nutzern von KI unbedingt zu verlangen. KI l sst sich mit zentralen Datenschutzprinzipien schwer vereinbaren. Dieser immanente Kon- flikt ist offen anzusprechen : Der Entwicklung zu einer Daten konomie stehen der Grundsatz der Datensparsamkeit und die Gebote von privacy by design bzw default entgegen. Viele Expe rtInnen gehen zB davon aus, dass konkrete Personen auch aus anonymisierten Datens tzen durch Einsatz von KI individuell bestimmbar sind. Es ist deshalb zu definieren, wann man noch von Daten ohne Personenbezug reden kann. (siehe dazu auch -der-datenschutz -grundverordnung -dsgvo ) Die DSGVO enth lt allgemeine Grunds tze, die die vielen Rechtskonflikte zwischen Geheimhaltungs - und V erwertungsinteressen nicht unmittelbar l sen k nnen. Unzul ssige Verarbeitungspraktiken aus- zuforschen und rechtlich richtig zu w rdigen, berfordert nicht nur KonsumentInnen, sondern aufwands- bedingt zunehmend auch die Aufsichtsbeh rden. Dies schadet der Re chtssicherheit und mindert das Vertrauen in die Vorteile von KI. Die Ausstattung der Beh rden entspricht nicht dem Bedarf, um rasch, sorgf ltig, technikkundig und investigativ den vielf ltigen Aufsichtsaufgaben nachzukommen. Die Ver- lagerung von einer ex -ante Pr fpflicht in sensiblen F llen zu einer nachtr glichen Aufarbeitung von Rechtsverletzungen samt Schadenersatzanspr chen er ffnet schwerwiegende Schutzl cken, wenn Rechtsdurchsetzung nicht rasch und reibungslos funktioniert. Verbot von Anwendungen, bei denen die Accountability an Grenzen st t: Mit der Selbstlernf higkeit der Systeme k nnen Softwareentwickler oft selbst nicht mehr nachvollziehen, welchen logischen Weg Algorithmen einschlagen. Entscheidet KI aber selbst dar ber, welche Daten sie f r we lchen Zweck nutzt, widerspricht dies fundamental dem Rechtsgrundsatz der Accountability (Zu- rechnung, Verantwortung, Haftung), und kollidiert auch mit der Pflicht, im Erhebungszeitpunkt bereits den genauen Verwendungszweck der Daten anzugeben Alle Entsche idungen, Produkte und Dienste die auf Algorithmen basieren, m ssen erkl r - und berpr f- bar bleiben. KonsumentInnen d rfen angesichts einer Vielzahl an Beteiligten (Entwickler, Hersteller, Anwender, Dienstleister) nicht zum Spielball unklarer Verantwortlich keiten werden. Sie sollen im Sinne einer Solidarhaftung Unterlassungs - und Schadenersatzanspr che gegen jeden Beteiligten in der Wert- sch pfungskette richten k nnen (mit anbieterseitigen Regressm glichkeiten). Einbindung der Betroffenen : Daten - und Privatsph renschutz sollten wirtschaftlichen Interessen grunds tzlich vorgehen. Wie verh lt es sich aber, wenn Eingriffe in diese Rechte mit lebenswichtigen Interessen einzelner Personen, von Gruppen oder der Gesamtgesellschaft begr ndet werden? Interessenskollisionen sind vorprogram- miert, sobald KI -Anwendungen im Gesundheitssektor Verbesserung bei der Erkennung, Behandlung und Heilung von Krankheiten oder im sicherheitspolizeilichen Einsatz eine bessere Kriminalit tspr ven- tion bzw -aufkl rung ve rsprechen. Der Preis f r diesen (potentiellen) Fortschritt ist hoch: Interessen von gro en Bev lkerungsteilen k nnen damit gef hrdet werden. Vor diesem Hintergrund braucht es f r die Mehrzahl an KI -Anwendungen, die Grundrechte ber hren, eine ex ante -Genehm igung durch ein unab- h ngiges Gremium. In dieses sind neben Datenschutzbeh rden und Technikexperten auch VertreterIn- nen der jeweils betroffenen Gruppen (ArbeitnehmerInnen, KonsumentInnen, PatientInnen, etc) mitein- zubeziehen. Denn auch bei der Kl rung von Re chtsfragen wird sorgf ltig zwischen verschiedenen Inte- ressen, Verh ltnism igkeiten, Werten etc. abzuw gen sein. Diese Entscheidungen k nnen abh ngig von der jeweiligen Betroffenheit und dem jeweiligen weltanschaulichen Hintergrund sehr verschieden ausfall en. Die gesellschaftliche Akzeptanz von Entscheidungen f r oder gegen einzelne KI -Anwendun- gen und flankierende Auflagen f llt h her aus, wenn bei der Zusammensetzung des Entscheidungsgre- miums auf eine breite Beteiligung aller betroffenen Gruppen geachtet w ird. Produkthaftungsregeln aktualisieren : Die Produkthaftungs -RL aus dem Jahr 1985 kennt f r digitale Trends wie KI keine Antworten. Eine berarbeitete RL muss auf alle materiellen und nicht materiellen Sachen, digitale Dienstleistungen und digitalen In halte anwendbar sein und sollte deshalb auch Cybersicherheitsrisiken, mangelnde Software- updates und unzureichende DSGVO -Konformit t zu den Defekten eines Produktes z hlen. Ebenso Sch den, die durch die F higkeit selbst zu lernen und autonome Entscheidung en zu treffen oder durch einen Missbrauch der verwendeten Daten entstehen. Ausgezeichnete Detailvorschl ge f r die berar- beitung der Produkthaftungs -RL enth lt das BEUC -Positionspapier Product Liability 0 berholte Produktsicherheits -RL um KI -Risiken erweitern : Die RL aus dem Jahr 2001 enth lt zentrale Schutznormen, die Hersteller verpflichtet nur sichere Pro- dukte in Verkehr zu bringen und VerbraucherInnen durch Informationspflichten und Warnhinweisen vor Risiken bewahrt. Es ist klarzustellen, dass auch die Produktsicherheits -RL auf alle Produkte, Dienste und Software, die Algorithmen/KI enthalten, anwendbar ist. Alle mit KI verbundenen Risiken m ssen auch hier abgedeckt sein. III. Fazit Mit dem Wei buch hat die Kommission einen Plan zur Diskussion gestellt, wie zuk nftig mit K nstlicher Intelligenz zu verfahren ist. Darin wurde lobenswerterweise stets ein menschenzentrierter Ansatz und die Einbindung aller Stakeholder propagiert. Es ist prinzipiell zu begr en, dass K nstlicher Intelligenz ein europ ischer Rechtsrahmen gegeben werden soll. Doch der vorliegende Verordnungsentwurf ent- t uscht auf vielen Ebenen und beschr nkt sich auf eine se hr technikzentrierte Sicht auf den Binnen- markt, w hrend viele notwendige Rahmenbedingungen f r ArbeitnehmerInnen und KonsumentInnen keine Erw hnung finden. Der Menschenzentrierte Ansatz bleibt hier zugunsten eines liberalen Marktes f r KI oft auf der Str ecke. Europa sollte hier eine F hrungsrolle bernehmen und alle Interessen zum gemeinsamen Nutzen zu ber cksichtigen. Dazu bedarf es allerdings der Erg nzung und Pr zisierung des geplanten Rechtsrah- mens um hohe Sicherheitsstandards f r alle zu erm glichen und insbesondere auch einen hohen Grundrechtsschutz aufrecht zu erhalten . Die wichtigsten Eckpunkte w ren dabei: Regeln nicht ausschlie lich f r Hochrisiko Anwendungen: Auch weniger risikobehaftete KI bedarf eines Regelwerks Mitbestimmung : Die Einbindung Betroffener ist essentiell. Nicht nur im Bereich der Grundrechte ist eine st rkere Einbindung von Betroffenen sinnvoll. Insbesondere beim Einsatz von KI im Arbeitsumfeld ist ein hohes Ma an betrieblicher und berbetrieblicher Mitbestimmung durch ArbeitnehmerInnen und ihrer Vertretungen notwendig. Sowohl im laufenden Betrieb als auch bei der Einf hrung solcher Anwendungen sollten MitarbeiterInnen bzw ihre Interessensvertretungen im Sinne eines Bot- tom-Up-Ansatzes stets umfangreich eingebunden sein. Das f hrt auch dazu, dass die Einf h- rung von KI -Systemen in Produktions - und Organisationsabl ufen wesentlich zielgerichteter und besser gestaltet werden kann, ArbeitnehmerInnen und ihre Vertretungen fr hzeitig einge- bunden werden und die Projekte von Anfang an begleiten und mitgestalten k nnen. Deshalb sollte auch hier mehr Augenmerk daraufgelegt werden, dies aktiv zu f rdern. KI im Arbeitszusammenhang sollte prinzipiell als Hochrisiko -Anwendung gelten Rechte und Pflichten klar verankern Beschwerdem glichkeiten bei unabh ngigen Stellen, Informationspflichten nicht nur f r professionelle Anwender, Selbstbestimmungsm glichkeiten der Betroffenen sind essenziell zur Abwendung und Aus- gleich von Sch den, Schutz vor Eingriffen in Grund - und Pers nlichkeitsrechte sowie f r ein hohes Da- tenschutzniveau. Klare Haftungs - und Versicherungsregelungen m ssen verankert werden. Nein zu einer umfassenden Selbstzertifizierung Kontrolle, Konformit tsbewertungen und Zertifizierungen sollten nicht den Herstellern selbst berlassen werden, sondern vorrangig durch unabh ngige Stellen erfolgen. berpr fbarkeit von KI -Entscheidungen herstellen KI hnelt oft einer Blackbox. Nicht einmal die Hersteller selbst k nnen immer das (zuk nftige) Verhalten von selb stlernenden Systemen vorhersagen. Eine h chstm gliche berpr fbarkeit muss aber stets ge- geben sein. Der Mensch sollte immer die Kontrolle behalten. Ausnahmen hintanhalten Viele (begr enswerte) Ziele und Grunds tze werden in der VO durch zahlreiche Ausna hmen und Ein- schr nkungen stark durchl chert. In der Praxis bleibt oft vom Bekenntnis zu einem umfassenden Schutz von Grundrechten, Datenschutz, ArbeitnehmerInnen -Schutz, dem Schutz der Privatsph re und hnli- chem nicht mehr viel brig. Grunds tzlich verbote ne Praktiken wirken stark aufgeweicht, notwendige Teilbereiche werden nicht abgedeckt . effektiver Rechtsschutz Rechtsschutzm glichkeiten f r einzelne aber auch durch kollektive Interessensvertretungen (zB im Wege von Verbandsklagen) m ssen umfassend zu g nglich sein. Auch auf eine ausreichende Ressour- cenausstattung der Vollzugs - bzw Kontrollbeh rden (inklusive Arbeitsinspektorate) ist dabei zu achten. Aus- und Weiterbildung KI am Arbeitsplatz bedarf einer Verpflichtung zu vorbeugenden Ma nahmen wie Aus - und Weiterbil- dung. Das sch tzt ArbeitnehmerInnen und versetzt sie in die Lage, die Rolle von Daten und KI, sowie ihren Einfluss auf Arbeitsorganisation zu verstehen. Neue Technologien enthalten Unsicherheiten und unbekannte Risiken, darum m ssen Pr venti on und das Vorsorgeprinzip Teil des regulatorischen Rah- menwerks sein . Ungew nschte Anwendungen verbieten KI erm glich durch den permanenten Strom an Daten bisher ungeahnte M glichkeiten. (Beil ufig) an- fallende Daten k nnen mittels Algorithmen benutzt werden um Betroffene zu berwachen, zu kontrol- lieren, zu bewerten und sie zu identifizieren (auch nachtr glich aus anonymisierten Daten). Sowohl im Arbeitszusammenhang, als auch bei KonsumentInnen bedarf es deshalb strenger Regelungen und Mit- bestimmungsm glichkeiten. Bestimmte Anwendungen sollten dabei g nzlich verboten sein. ArbeitnehmerInnenschutz und Inklusio n Der Sicherheit und Gesundheit am Arbeitsplatz sollte ein wichtiger Stellenwert einger umt werden. Schutz vor k rperlichen und psychischen Risiken ist f r ArbeitnehmerInnen wichtig. Gerade im Hinblick auf Arbeitsunf lle und arbeitsbedingten Erkrankungen bedarf es ausreichender Kontrollm glichkeiten und der unabh ngigen Zertifizierung von Systemen. Wie bei der CE -Kennzeichnung zu sehen ist, f hrt eine Selbstkontrolle zu l ckenhafter Sicherheit, deren M ngel zu Arbeitsunf llen und Berufskrankheiten f hren k nnen. Deren Folgen werden externalisiert und die Kosten den Sozialversicherungen sowie zum Gro teil den betroffenen ArbeitnehmerInnen selber aufgeb rdet. Unternehmen haben zudem ein Interesse daran, ein Minimum Viable Product auf den Markt zu bringen, u m Entwicklungskosten gering zu halten. Demgegen ber braucht ArbeitnehmerInnenschutz aber h chstm glich sichere Maschinen oder Technologien. In diesem Spannungsfeld ist die EU gefragt, die ArbeitnehmerInnen zu sch tzen. Ebenso fehlt auch eine st rkere Ber c ksichtigung von Menschen mit Behinderungen (zB H r - und Seh- defizite) in der Betrachtung. Entwicklungs - und Anpassungsm glichkeiten der VO schaffen Die Taxonomie der Anwendungen im Anhang wird sehr starr definiert. Erweiterungen d rfen nur inner- halb exist ierender Kategorien erfolgen, neue Felder d rfen hingegen nicht aufgenommen werden. An- gesichts der Dynamik des technischen Fortschritts sich stetig ver ndernder Anwendungsfelder f r KI, sollte hier mehr Raum f r Adaptierungen gelassen werden um auch auf zu k nftige Probleme und Her- ausforderungen reagieren zu k nnen. F r Informationen stellen wir Ihnen jederzeit zur Verf gung: AK EUROPA St ndige Vertretung sterreichs bei der EU Avenue de Cortenbergh 30 1040 Br ssel, Belgien T +32 ( 2 230 62 54",de
Thorn (United States),F2665284,03 August 2021,Non-governmental organisation (NGO),Medium (50 to 249 employees),United States,"R e s p o n s e t o t h e E u r o p e a n C o m m i s s i o n C o n s u l t a t i o n o n A r t i c i a l I n t e l l i g e n c e - e t h i c a l a n d l e g a l r e q u i r e m e n t s T h o r n w e l c o m e s t h e o p p o r t u n i t y t o p r o v i d e f e e d b a c k o n t h e C o m m i s s i o n ' s p r o p o s a l f o r a r t i c i a l i n t e l l i g e n c e r e g u l a t i o n . T h o r n i s a U S - b a s e d n o n p r o t o r g a n i z a t i o n t h a t b u i l d s t e c h n o l o g y t o d e f e n d c h i l d r e n f r o m s e x u a l a b u s e a n d o n l i n e e x p l o i t a t i o n . A t T h o r n , w e b e l i e v e i n t h e p o w e r a n d p o t e n t i a l o f g o v e r n m e n t , N G O s , a n d t e c h c o m p a n i e s w o r k i n g t o g e t h e r t o e l i m i n a t e c h i l d s e x u a l a b u s e m a t e r i a l o n l i n e . T h a t g o a l c a n n o t b e a c h i e v e d b y j u s t o n e o f t h e s e e n t i t i e s a l o n e , a n d w e a r e g r a t e f u l f o r t h e E u r o p e a n U n i o n s l e a d e r s h i p . W e b e l i e v e t h a t t a i l o r e d a n d p r e c i s e a r t i c i a l i n t e l l i g e n c e l e g i s l a t i o n i s n e c e s s a r y t o e n s u r e t h a t c h i l d u s e r s ' p r i v a c y a n d s a f e t y i s p r o t e c t e d . L e g i s l a t i o n o n a r t i c i a l i n t e l l i g e n c e s h o u l d a l l o w f o r i n n o v a t i o n a n d g r o w t h i n t e c h n o l o g y t h a t p r o t e c t s c h i l d r e n o n l i n e . I f r e g u l a t i o n d o e s n o t a l l o w f o r t h i s k i n d o f i n n o v a t i o n , t h e n w e w i l l c o n t i n u e t o b e b e h i n d t h e c u r v e o f i n d i v i d u a l s e x p l o i t i n g c h i l d r e n o n l i n e . A t T h o r n w e a r e a l w a y s w o r k i n g t o i n n o v a t e a n d r e n e o u r t e c h n o l o g y t o p r o t e c t c h i l d r e n . W e , a n d o u r p a r t n e r s i n t h e c h i l d p r o t e c t i o n e c o s y s t e m , n e e d t h e e x i b i l i t y t o c o n t i n u e t o c r e a t e c u t t i n g e d g e t e c h n o l o g i e s t o e l i m i n a t e c h i l d s e x u a l a b u s e m a t e r i a l f r o m t h e i n t e r n e t . I f r e g u l a t i o n b e c o m e s i n d i s c r i m i n a t e , o r d o e s n t p r o v i d e n e c e s s a r y e x i b i l i t y f o r t h i s s p e c i c u s e c a s e , i t c a n c r e a t e u n i n t e n d e d c o n s e q u e n c e s t h a t c o u l d d e t e r t h e d e v e l o p m e n t o f n e w t e c h n o l o g i e s t o p r o t e c t c h i l d r e n o n l i n e . I n t h e s p a c e o f c h i l d p r o t e c t i o n , t h e r e a r e w e l l e s t a b l i s h e d t e c h n o l o g i e s t h a t h a v e b e e n t e s t e d a n d r e n e d f o r o v e r a d e c a d e b u t m a n y o f t h e m o s t c u t t i n g e d g e t e c h n o l o g i e s s t i l l n e e d t h e s p a c e f o r f u r t h e r i n n o v a t i o n . T h e s e t e c h n o l o g i e s h a v e p r o v e n r e s u l t s o f n d i n g a n d s a v i n g c h i l d r e n f r o m o n l i n e s e x u a l e x p l o i t a t i o n . T a i l o r e d t e c h n o l o g i c a l s o l u t i o n s i n t h i s s p a c e a r e t h e f u t u r e o f p r o t e c t i n g c h i l d r e n f r o m o n l i n e e x p l o i t a t i o n a n d t h e r e n e e d s t o b e a l e g i s l a t i v e f r a m e w o r k t h a t a l l o w s f o r t h i s c r u c i a l w o r k t o c o n t i n u e . W e u n d e r s t a n d t h e c o n c e r n s t h a t s o m e A I a p p l i c a t i o n s c o u l d l e a d t o t h e i n v a s i o n o f i n d i v i d u a l u s e r s ' p r i v a c y b u t c h i l d a d v o c a c y o r g a n i z a t i o n s h a v e a l w a y s w o r k e d t o w a r d s s u r g i c a l a n d b a l a n c e d s o l u t i o n s i n o r d e r t o p r o t e c t c h i l d r e n o n l i n e . A I a n d m a c h i n e l e a r n i n g a r e i m p o r t a n t t o o l s w h e n i t c o m e s t o o n l i n e c h i l d p r o t e c t i o n - f r o m t e x t a n a l y s i s t h a t c a n p r e v e n t t h e g r o o m i n g o f a c h i l d f o r a b u s e , t o f a c i a l r e c o g n i t i o n t e c h n o l o g y t h a t c a n i d e n t i f y m i s s i n g a n d / o r e x p l o i t e d c h i l d r e n ' s p h o t o s . W h e n a c h i l d i s m i s s i n g o r e x p l o i t e d l a w e n f o r c e m e n t n e e d s t h e t o o l s t h a t c a n h e l p t h e m n d t h e s e c h i l d r e n i n t h e q u i c k e s t a n d m o s t e ",an
"Federal Ministry for Social Affairs, Health, Care and Consumer Protection (Austria)",F2665262,03 August 2021,Public authority,Large (250 or more),Austria,"Eine rechtliche Regulierung von KI-Systemen ist dringend notwendig. Das AIA wird daher grunds tzlich begr t, bedarf aber einer ausf hrlichen Diskussion insb aus Sicht der betroffenen Konsument*innen. Der risikobasierte Ansatz ist sinnvoll, ber cksichtigt aber leider keine wirtschaftliche Risiken. Dies greift zu kurz, wenn man an zunehmendes personalisiertes Marketing/Profiling denkt, einschlie lich personalisierter Preise. Konsument*innen erhalten immer fter nur Ausschnitte der Angebotswelt. Vieles wird ihnen vorenthalten oder zB bei smarten Ger ten f r sie entschieden, ohne dass sie h ufig den Grund daf r kennen. Bonit tsscoring ist gem Annex III auch nur dann hochriskant, wenn es nicht durch Klein(st)unternehmer erfolgt. Das Risiko steht aber in keinem Verh ltnis zur Gr e eines Unternehmens. Auch Emotionserkennung gilt offenbar nicht als hochriskant, sondern unterliegt ausschlie lich der Informationspflicht gem Art Die Definition der KI-Systeme ist zwar breit. Der Kern der Regelungen gilt aber nur f r hochriskante KI. IoT-Anwendungen erfordern mit Ausnahme von Infrastrukturleistungen bedauerlicherweise keinerlei Verpflichtungen f r den Anbieter. Die Liste der verbotenen KI-Systeme greift ebenfalls zu kurz. So verbietet Art 5 Abs 1 lit a KI-Systeme mit unterschwelliger Beeinflussung nur dann, wenn damit ein Schaden einhergeht, w hrend die AVMD Richtlinie etwa Schleichwerbung generell verbietet. Das Abstellen auf einen Schaden sollte daher gestrichen werden. Dasselbe gilt f r Art 5 Abs 1 lit b. Auch das Verbot von social scoring, das grunds tzlich begr t wird, ist zu eng gefasst (kein Verbot der Prim rnutzung von Daten f r social scoring, wenn verh ltnism ig , kein Verbot KI-basierter sozialer Auslese durch Unternehmen). berwachungsma nahmen au erhalb von Echtzeit-Fernidentifizierungssystemen werden ebenfalls nicht erfasst. Diese Liste bedarf einer grundlegenden berarbeitung. Ein weiterer grunds tzlicher und schwerwiegender Kritikpunkt liegt darin, dass Betroffene keinerlei Informations- oder sonstige Betroffenenrechte au erhalb der DSGVO haben und Diskriminierung daher kaum einsch tzen k nnen (zB bei Bonit tspr fung). Noch schwerer wiegt, dass der VO Vorschlag keinerlei Rechtsbehelfe oder haftungsrechtliche Anspr che f r Betroffene vorsieht. Die Kontrolle erfolgt damit ausschlie lich beh rdlich. Der zivilrechtliche Vollzug wird in keiner Weise adressiert. Unklar ist auch, wer Recht auf Einspruch gegen Entscheidungen notifizierter Stellen hat ( Beteiligte , die ein berechtigtes Interesse an einer solchen Entscheidung haben , ohne Erl uterung des berechtigten Interesses). Wenn die Produkthaftungsrichtlinie nicht in ausreichendem Ausma ge ndert wird, m sste das AIA jedenfalls durch Haftungsregelungen erg nzt werden. Hinsichtlich der Rechtsdurchsetzung sieht der VO Vorschlag auch keine nderung der Verbraucherbeh rdenkooperationsVO (CPC) oder der VerbandsklagenRL hinsichtlich einer Ausweitung des Anhangs vor, sodass auch hier kein erweitertes zivilrechtliches Schutzniveau f r Verbraucher*innen geschaffen wird. Schlie lich bedarf es einer umfassenden Diskussion der vorgeschlagenen Konformit tsbewertungsregelungen. KI-Systeme, die in den Annex II fallen, sind gem Art 6 Abs 1 nur dann als KI mit hohem Risiko zu qualifizieren, wenn sie einer externen Zertifizierung unterliegen. Ob dies der Fall ist, muss nach der jeweiligen New Approach Richtlinie gepr ft werden. Die New Approach Richtlinien sehen aber nur in wenigen F llen eine Drittzertifizierung vor. Das Risiko durch Verwendung eines KI-Systems konnte aber zum Zeitpunkt der RL noch nicht mitbedacht werden (s. zB die Puppe Cayla). Auch bei Annex III-Anwendungen wird eine interne Konformit tsbewertung h ufig nicht ausreichen, wie dies Art 43 festlegt. Jedenfalls f r Biometrie und Bonit tsbewertungssysteme darf eine interne Bewertung nicht ausreichen. Biometrische KI-Systeme sollten einer Zustimmung der Betroffenen bed rfen.",de
ASF - ASSOCIATION FRANCAISE DES SOCIETES FINANCIERES (France),F2665226,02 August 2021,Business association,Small (10 to 49 employees),France,"COMMISSION EUROPEENNE - PROPOSITION DE R GLEMENT DU PARLEMENT EUROP EN ET DU CONSEIL TABLISSANT DES R GLES HARMONIS ES CONCERNANT L INTELLIGENCE ARTIFICIELLE ET MODIFIANT CERTAINS ACTES L GISLATIFS DE L UNION L Association fran aise des Soci t s Financi res (ASF) repr sente les m tiers de financement sp cialis en mati re de cr dit ainsi que les services financiers et d investissement. Les tablissements membres de l ASF financent plus de 20 % des cr dits au s ecteur priv Observations liminaires L Association fran aise des Soci t s Financi res (ASF) accueille avec int r t la consultation publique lanc e en avril dernier sur le projet de r glement tablissant des r gles harmonis es concernant l intelligence artificielle . Ce projet de r glement est selon nous un point positif dans la mesure o il prend en compte l utilisation des syst mes d IA dans la relation entre les entreprises et leurs clients. N anmoins, l ASF rappelle que l utilisation des donn es personnelles n cessaires au fonctionnement des IA est d j encadr e quant aux conditions de collecte et finalit s de traitement et de conservation des donn es , ainsi qu l exercice des droits des per sonnes (droit l information, droit d opposition, droit d acc s, droit de rectification, ) et ce, afin de prot ger la vie priv e et les libert s des personnes concern es. Enfin, des dispositions juridiques interdisent diff rentes formes de discrimination , de sorte que nous disposons d j d un arsenal apportant une s curit juridique dans l utilisation des IA. D finition de l IA (article La d finition propos e nous parait trop large car elle int grerait toutes cat gories de score sans distinction , y compris ceux destin s l analyse pr alable un octroi de cr dit . En effet, les tablissements du secteur bancaire et financier, afin d optimiser les contraintes r glementaires et prudentielles qui p sent sur eux, sont de plus en plus amen s une exploit ation de la donn e avanc e , syst me qualifi d IA. L exploitation de donn es peut avoir plusieurs types de finalit : - Pour l efficacit op rationnelle : gestion des m ls au service apr s -vente, de bots pour les relations clients ou souscription digitalis e, le d veloppement de la fid lit ; 1 Il s agit des tablissements de cr dit et les soci t s de financement ayant pour activit le cr dit -bail, le cr dit la consommation ou encore l affacturage ou les service s de caution, tablissements tous r gul s et supervis s. 2 - Pour la gestion du temps n cessaire la d cision d octroi avec une automatisation des contr les dans la phase d tude et d acquisition ; - Pour la lutte contre la fraude, avec une recherche de mod les de fraude complexes ; - Pour la gestion des risques par les scores d octroi, mais aussi les scores au recouvrement . Un quilibre doit tre recherch entre d une part, l adoption d exigences minimales pour encadrer les risques et les prob l mes li s l IA avec un cadre suffisamment souple et d autre part, la promotion du d veloppement technologique , sans augment ation disproportionn e des co ts de mise sur le march pour les tablissements quelle que soit leur taille. Syst mes d IA interd ites (article Le texte pr voit l interdiction de l utilisation de syst mes d IA susceptibles d exploiter les ventuelles vuln rabilit s dues l ge ou au handicap physique ou mental d un groupe de personnes donn pour alt rer substantiellement le comp ortement d un membre de ce groupe d une mani re qui cause ou est susceptible de causer un pr judice physique ou psychologique cette personne ou un tiers . Cette d finition particuli rement large pourrait viser indirectement les scores de cr dit qui utilise nt le crit re de l ge parmi d autres crit res et au m me titre que ces autres crit res . Ces pratiques d IA interdites devraient tre plus pr cis ment d finies. Classification de syst mes d IA comme syst mes haut risque (annexe III) Parmi les IA risque lev (annexe III), on rel ve les IA dans les domaines suivants : l identification biom trique et la cat gorisation des personnes physiques (les I A utilis es en temps r el et distance permettant une identification des personnes physiques sont dans le p rim tre), l emploi, la gestion des salari s et l acc s au travail ind pendant, l acc s aux services priv s essentiels et aux services publics. Les IA utilis es pour valuer la solvabilit des personnes physiques ou tablir leur score de cr dit sont dans cette cat gorie , ce qui nous para t contestable. Les scores de cr dit Les tablissements sp cialis s en France1 les utilisent depuis de nombreuses ann es en vue de r pondre notamment un triple enjeu : - respecter les r gles de solvabilit auxquelles les tablissements sp cialis s sont assujettis ; - valuer la solvabilit de l emprunteur ; - laborer leur mod le inter ne. Dans ce cadre , ils recourent aux IA pour l laboration, l actualisation et l utilisation de mod les de score pour l attribution de cr dit , ce qui permet de : - mesurer le risque statistique de d faut de remboursement qui correspond aux demandes de cr dit (ou de moyen de paiement adoss un contrat de cr dit) pr sent es par des clients personnes physiques ; - apporter une aide la s lection des demandes dont le niveau de risque, ainsi valu , permet la conclusion d un contrat de cr dit ; - constituer des mod les de score ; 3 - v rifier la pertinence des mod les de score mis en uvre et leur actualisation ; - valuer le risque de d faut de remboursement qui est attach chaque demande de cr dit en vue d apporter une aide l instruction de la demande. L encadrement des usages de l IA dans le secteur bancaire et financier L IA est un moyen et non une fin. Seuls les usages de l IA doivent tre encadr s . Ce n est pas parce que la donn e collect e et utilis e est sensible que le risque est n cessairement lev d s lors que son usage est strictement encadr . La qualification de haut risque se d finit en fonction de l usage qui est fait de l IA par l uti lisateur. Les usages sont souvent d j encadr s par des r glementations sp cifiques . Pour les services bancaires et financiers, la r glementation prudentielle d finit d j le processus de contr le et d valuation des syst mes d octroi. Cette r glementati on limite les risques li s l IA dans le domaine. - Les algorithmes d octroi sont strictement r gis par un principe de non -discrimination (avec en France, des sanctions p nales) qui interdit de les fonder uniquement sur un crit re de discrimination prohib ( ge, nationalit , handicap ), ou d e les contourner en donnant plus d importance l un de ces crit res par rapport aux autres. Un seul crit re ne peut lui seul emporter la d cision d octroi du cr dit. - Ces algorithmes exempts de discrimination, sont exe mpts de risques pour le client en fonction de l usage qui en est fait. Cet usage est l valuation de la solvabilit du candidat l emprunt qui lui permet d viter le risque d endettement excessif au regard du cr dit envisag . L objectif de l utilisation du score est donc bien de limiter le risque financier pour le client comme pour le pr teur. - Le Comit de B le impose aux tablissements bancaires et financiers des contraintes prudentielles. Pour estimer leurs besoins en fonds propres associ s aux cr ances , ces tablissements peuvent avoir recours aux IA. - Par ailleurs, les usages et les proc dures de monitoring sont d j largement encadr s par un corpus r glementaire (exigence de repr sentativit , d exhaustivit des donn es, de monitoring de s ventuels contournement , d finies notamment par les orientations de l EBA sur l octroi et le suivi des pr ts Guidelines on loan origination and monitoring - EBA/GL/2020/06 du 29 mai ) - La qualification de ce type d IA en IA haut risque nous semble inadapt e et disproportionn e au regard des r glementations d j existantes et des o bligations respecter. Ce type d IA est par ailleurs utilis par les tablissements bancaires et financiers depuis un grand nombre d ann es. Ces algorithmes ne devraient donc pas entrer dans la cat gorie des mod les risque lev s. Renvoi des r gles sectorielles Dans certains cas, l valuation de la conformit est r alis e dans le cadre de la proc dure de la directive 2013/36 sur le processus de contr le et d valuation prudentiels. Pour viter une double r glementation qui risquerait de g n rer des difficult s d articulation, l ASF pr conise d exclure du champ de la proposition de r glement les IA utilis es par le secteur bancaire et financier, les sp cificit s de ces IA tant d j prises en compte . Le texte devrait prendre davantage en compte la r glementation applicable en mati re bancaire et financi re. 4 Exigences applicables aux syst mes d IA haut risque / Obligations des fournisseurs et des utilisateurs (articles 8 et obligation de transparence (article S agissant de la transparence et de la fou rniture d informations, l article 13 pr voit que la conception et le d veloppement des syst mes d IA haut risque sont tels que le fonctionnement de ces syst mes est suffisamment transparent pour permettre aux utilisateurs d interpr ter les r sultats du s yst me et de l utiliser de mani re appropri e . Un type et un niveau ad quats de transparence permettent de veiller au respect des obligations pertinentes incombant l utilisateur et au fournisseur. Ces exigences nous semblent redondantes avec la r glemen tation bancaire et financi re. En effet, les orientations de l EBA sur l octroi et le suivi des pr ts ( Guidelines on loan origination and monitoring - EBA/GL/2020/06 du 29 mai 20 , pr voi ent d j un cadre de gouvernance et d exigence en ce qui concerne l utilisation de scores de cr dit pour valuer la solvabilit des emprunteurs . Par ailleurs, c ette exigence de transparence dans le fonctionnement de l IA fait doublon avec le RGPD . Le RGPD et les textes fran ais impose nt en cas d utilisation de scores de cr dit, notamment pour valuer la solvabilit des consommateurs candidats au cr dit, de permettre c es derniers de : - de demander et d obtenir une intervention humaine de la part du pr teur pour r examiner la d cision ; - de demander et d obtenir du pr teur une explication claire de l valuation de la solvabilit r alis e, notamment de la logique et des risques associ s au t raitement automatis des donn es caract re personnel, ainsi que sa signification et ses effets sur la d cision ; - d'exprimer leur point de vue et de contester l valuation de la solvabilit et la d cision. En outre , les tablissements financiers sont assujettis des r gles de lutte contre la fraude, le blanchiment de capitaux et le financement du terrorisme . Les IA permettent de g n rer des alertes qui font l objet d une analyse, assurant ainsi une fluidit et une s curisation du processus de traitemen t manuel. Le b n fice de ces syst mes a t d montr en termes d efficacit et de rapidit . L ASF souhaite que les obligations de transparence en mati re d IA n aient pas pour effet de lever le secret des affaires et d entraver le respect des obligations de lutte contre la fraude et le blanchiment et le financement du terrorisme pour les tablissements. C est un point crucial car l IA est galement utilis e dans ces domaines2. Enfin, l articulation des obligations et des responsabilit s entre fournisseurs et utilisateurs des syst mes d IA pourrait tre am lior e. Dans certains cas, le fournisseur et l utilisateur sont une m me personne, il convient donc dans ce cas de ne pas dupliquer les obligations applicables. Robustesse et cybers curit (article La s curit informatique constitue un enjeu majeur pour le secteur bancaire et financier. Ce domaine est d j tr s r glement au niveau europ en (Directive 2013/36/UE, DSP2, NIS ). 2 - france.fr/sites/default/files/medias/documents/20200612_gouvernance_evaluation_ia.pdf 5 L ASF pr conise l application de ces textes plus adapt s au secteur bancaire et financier afin d viter le doublonnage de r glementations . Autorit en charge du contr le (article Des autorit s nationales comp tentes seraient tablies ou d sign es par chaque tat membre aux fins d assurer l application et la mise en uvre du r glement. Les autorit s nationales comp tentes seraient organis es de mani re garantir l objectivit et l impartialit de leurs activit s et de leurs t ches. Chaque tat membre d signerait une autorit de contr le nationale parmi les autorit s nationales comp tentes. L autorit de contr le nationale agirait notamment en qualit d autorit de surveillance du march . Dans le domaine bancaire et financier aux niveaux europ en et national, plusieurs autorit s sont d ores et d j amen es intervenir. L ASF s interroge sur l articulation entre ces autorit s en mati re de contr le et d incident (autorit comp tente en mati re de protection des donn e s, autorit comp tente pour se conformer la D irective concernant les services de paiement 2, autorit comp tente en mati re de s curit dans le cadre de la directive NIS notamment ). Sanctions (articles 71 et suivants) L ASF estime que les sanctio ns pr vues sont trop lev es et pourraient avoir pour effet de freiner l innovation. Un quilibre devrait tre trouv d autant qu il existe un probl me de cumul de sanctions pour certains acteurs. Application des r gles Aucune pr cision n est apport e quant l application dans le temps de ce texte aux IA d j mises en uvre au sein des Etats membres (par exemple pour l exigence d une certification). ASF le 2 juillet 2021",fr
Hub France IA (France),F2665170,30 July 2021,Business association,Micro (1 to 9 employees),France,"Hub France IA Groupe de Travail Banques et Auditabilit p 1/ 12 QUESTIONS SUR LA PROPOSITION DE LA COMMISSION EUROPEENNE POUR LA REGLEMENTATION DE L IA - JUILLET 2021 GROUPE DE TRAVAIL - BANQUES ET AUDITABILITE - HUB FRANCE IA TABLE DES MATIERES Introduction Pr cision des termes & p rim tre d application D finition de l IA Syst me IA haut risque Probl mes concrets pour l impl mentation de la mise en conformit Mises jour fr quentes Algorithmes pr -entra n s par tiers Biais Tra abilit Transparence Exceptions (int r t l gitime) Exemples de cas d usage identifi s haut risque (existants ou possibles) Score de cr dit Usages par les autorit s r pressives Biom trie Hub France IA Groupe de Travail Banques et Auditabilit p 2/ 12 INTRODUCTION Le Groupe de travail Banque et Auditabilit du Hub France IA, qui regroupe des experts IA de trois grandes banques fran aises, BNP Paribas, la Banque Postale et Soci t G n rale, souhaite apporter une r ponse la Commission Europ enne dans le cadre de la consultation ouverte sur le projet de r gulation des syst mes IA (AI Act). Les membres du groupe de travail soul vent un ensemble d interrogations et apportent des cas d exemples de syst mes IA qualifi s haut risque relatifs aux applications d ploy es dans le secteur bancaire, en analysant les probl mes identifi s. En tant qu experts du secteur bancaire, nous amenons notre connaissance de la mise en pratique de r glementations et actions d audit auxquelles les banques sont soumises sur une grande partie de leurs activit s et des syst mes qui sont d ploy s par les diff rentes structures. Les banques sont d j organis es pour mettre en uvre une r glementation comme celle propos e par la CE. En effet, une partie des mesures pr sent es dans le cadre de la proposition est couverte par les processus d audit d j en place. Nous sommes ainsi convaincus de l importance de r glementer les syst mes d IA au m me titre que sont aujourd hui r glement s les syst mes bancaires, dans une perspective d uniformisation des proc dures et d extension des r gulations existantes tous les syst mes qualifi s haut risque . En tant que citoyens galement, nous comprenons l importance de r glementer de tels syst mes, et aussi d identifier de fa on pr cise les syst mes d IA dont le d ploiement serait totalement interdit en Europe. N anmoins, la lecture approfondie de la proposition, elle nous appara t, pour les syst mes haut risque , particuli rement complexe mettre en place, voire impossible dans certains cas d usages innovants de l IA, en raison de divers aspects critiques : La d finition propos e de l Intelligence Artificielle est extr mement large ; L emploi de certains termes est parfois sujet interpr tation d une part pour la d finition d un syst me haut risque, mais surtout dans les attentes au niveau de la mise en uvre des exigences de conformit ; Le p rim tre d application est parfois mal identifi et nous avons longuement d battu sur les sp cificit s des cas d usage d crits comme haut-risque ; Un nombre important d exigences de conformit nous appara t comme irr alisables en pratique. Nous pensons qu une approche proposant des principes plut t que des exigences sp cifiques serait m me de s int grer dans les organisations actuelles. Les questions que nous identifions font ainsi appara tre un v ritable risque d ins curit juridique absolument pr judiciable pour l investissement et l innovation. Enfin, compte tenu de la faible maturit de certaines technologies d IA, mais galement de certaines entreprises ou certains m tiers vis- -vis de l IA, cette r glementation apparait particuli rement contraignante et laisse craindre un vrai ralentissement de l innovation pour les entreprises europ ennes. Globalement, nous sommes en accord avec le besoin de mettre en place progressivement une r glementation de l IA, mais dont le contenu s adapte au niveau de risque encouru par les citoyens europ ens l usage de la technologie et la port e en termes d utilisateurs de cette technologie. Nous nous interrogeons sur la n cessit d tablir le risque ex ante. En effet si certains cas d usage peuvent tre proscrits sur des consid rations thiques, c est bien le contexte de l utilisation d une technologie qui en d finit le risque r el. Faire porter de lourdes contraintes a priori peut mener simplement un d placement de l innovation en dehors de l union europ enne. Hub France IA Groupe de Travail Banques et Auditabilit p 3/ 12 En synth se il est n cessaire de r glementer, la vision par le risque est pertinente, la r glementation doit s appliquer tous les fournisseurs d IA y compris les petits fournisseurs , une r glementation ex ante ne semble pas applicable de mani re g n rale en particulier sur un p rim tre aussi large que celui pr sent dans la proposition, la r glementation englobe de fa on trop vaste tout type de syst me d IA et de technologie, ce qui rend complexe et trop co teuse sa mise en pratique. La r glementation de l IA ne doit pas tre un frein l innovation ou limiter la comp titivit des entreprises. PRECISION DES TERMES & PERIMETRE D APPLICATION DEFINITION DE L IA Dans le secteur bancaire, de nombreuses solutions en production sont port es par des solutions classiques de r gles ou de statistiques et pourraient donc dor navant, au vu de la d finition tr s extensive de l IA (annexe , tre soumises la r glementation. Si au sein des banques, nous avons une d marche de recensement des solutions et algorithmes IA, nous n avons pas identifi la n cessit de couvrir aussi largement le domaine de l IA du point de vue des attentes des r gulateurs nationaux qui, eux, s int ressent plus particuli rement aux IA de type apprentissage automatique dont la mise en uvre peut en effet entra ner des modifications des processus d audit actuellement en place. En revanche, largir le domaine de l IA des domaines plus anciens (b et c de l annexe) reviendrait faire porter de nouvelles contraintes des applications d j largement utilis es. La consultation lanc e en f vrier 2020 avait d ailleurs fait appara tre une demande dans le m me sens (expos des motifs : Les parties int ress es ont pour la plupart demand que l IA soit d finie de mani re stricte, claire et pr cise Recommandation 1 : restreindre la d finition de l IA en annexe 1 au a) SYSTEME IA A HAUT RISQUE On doit noter que syst me IA n est jamais pr cis ment d fini. Dans la section 1 (Expos des motifs), les objectifs de la proposition de r glementation indiquent vouloir : veiller ce que les syst mes d IA mis sur le march de l Union et utilis s soient s rs et respectent la l gislation en vigueur en mati re de droits fondamentaux et les valeurs de l Union Les syst mes IA risque sont ensuite d finis en extension dans le Titre III article 6 et l annexe III : les syst mes d IA vis s l annexe III sont consid r s comme haut risque Un syst me IA serait donc un syst me contenant un composant IA (IA d fini en Annexe I), mis sur le march et utilis sur le march europ en. Hub France IA Groupe de Travail Banques et Auditabilit p 4/ 12 Cependant, dans l introduction (, un usage secondaire est indiqu : si un syst me IA n 1 non mis sur le march (par exemple d velopp dans un pays non europ en ou galement pour un usage interne) est ensuite utilis pour produire des r sultats par un syst me (IA ou non d ailleurs) n 2 qui, lui, est mis sur le march , alors le risque du syst me IA n 1 doit tre valu : Compte tenu de leur nature num rique, certains syst mes d IA devraient relever du pr sent r glement m me lorsqu ils ne sont ni mis sur le march , ni mis en service, ni utilis s dans l Union Cet usage secondaire s applique-t-il exclusivement aux syst mes IA n 1 d velopp s en dehors de la Communaut , ou galement aux solutions IA d velopp es en interne dans les entreprises ? Dans ce second cas, la v rification de la conformit ex ante pourrait s av rer tr s difficile et co teuse. Une d finition pr cise de syst me IA devrait donc tre donn e en limitant explicitement l usage secondaire ( aux syst mes d velopp s hors CE et excluant les usages internes aux soci t s, la cl tant bien toujours la finalit de l usage ( destination d finie l article et le p rim tre d utilisation (en termes d usages et d utilisateurs finaux). On doit demander que la finalit du syst me IA soit sp cifi e de fa on beaucoup plus pr cise, par exemple sous la forme d une liste d usages pr vus. destination , l utilisation laquelle un syst me d IA est destin par le fournisseur, y compris le contexte et les conditions sp cifiques d utilisation, telles que pr cis es dans les informations communiqu es par le fournisseur dans la notice d utilisation, les indications publicitaires ou de vente, ainsi que dans la documentation technique; Recommandation 2 : pr ciser la d finition de syst me IA Un syst me IA haut risque est un syst me IA utilis pour l un des usages cit s en annexe III, donc n cessairement un syst me mis sur le march europ en. Il serait int ressant de d finir des crit res de risque (sant , s curit des personnes, droits fondamentaux, etc.) sur lesquels les usages pr vus pourraient tre valu s, ce qui pr figurerait le syst me de gestion des risques d crit l article Un m me syst me IA, selon l usage particulier vis (et faisant partie de sa finalit d clar e), pourrait tre d fini haut risque avec plus de finesse selon les crit res de risque impact s. La proposition de mise en conformit existante tant largement prescriptive, avec un p rim tre tr s large, implique un impact tr s fort sur la comp titivit . L impact conomique valu au Analyse d impact de l expos des motifs d passe tr s largement le simple co t d obtention du label CE, puisqu il faut lui adjoindre la mise en place des l ments pr vus au titre III : Les co ts de mise en conformit correspondants sont estim s entre 6 000 EUR et 7 000 EUR pour la fourniture d un syst me d IA haut risque moyen d une valeur d environ 170 000 EUR d ici 2025 On peut estimer les co ts de mise en place 60 100 k pour 6 k de co t d obtention de label. Il est donc important de limiter ce risque majeur pour la comp titivit europ enne. Nous proposons d ajuster cette approche par les risques, de sorte de d finir deux niveaux, d finis selon l analyse des crit res de risque associ s aux cas d usage de la finalit d clar e du syst me IA : Une liste tr s limit e et tablie selon un processus d fini au pr alable de cas d usage n cessitant l application de la r gulation telle que d finie la lettre, Une autre liste pour laquelle la r glementation rige des principes de bonne pratique suivre tout en laissant aux acteurs conomiques la flexibilit de les mettre en uvre en accord avec leurs processus internes. Hub France IA Groupe de Travail Banques et Auditabilit p 5/ 12 Il serait n cessaire d laborer une analyse d impact sur les co ts (et la perte de b n fice des secteurs haut risque ) plus compl te que celle indiqu e au Recommandation 3 : dans les domaines haut risque, pr ciser deux sous-cat gories de syst me IA haut risque permettant de diff rencier deux niveaux de mise en uvre de la conformit . Pr ciser les impacts conomiques complets des secteurs haut risque concern s. Par ailleurs, la d finition en extension du p rim tre de tels syst mes pourrait faire appara tre un risque juridique si l usage vis n apparait pas dans la liste au moment de la mise sur le march , mais que celle-ci est ensuite modifi e. L Article 7 (Modifications de l annexe III) semble indiquer que la liste des domaines de l annexe III (points 1 ne peut pas tre modifi e : La Commission est habilit e adopter des actes d l gu s conform ment l article 73 afin de mettre jour la liste figurant l annexe III en y ajoutant des syst mes d IA haut risque lorsque les deux conditions suivantes sont remplies: (a) les syst mes d IA sont destin s tre utilis s dans l un des domaines num r s l annexe III, points 1 8; (b) les syst mes d IA pr sentent un risque de pr judice pour la sant et la s curit , ou un risque d incidence n gative sur les droits fondamentaux, qui, eu gard sa gravit et sa probabilit d occurrence, est quivalent ou sup rieur au risque de pr judice ou d incidence n gative que pr sentent les syst mes d IA haut risque d j vis s l annexe III Un usage ne figurant pas dans la liste des domaines num r s l annexe III ne peut donc pas y tre int gr ensuite. Cependant s il y figure et que la liste de l Annexe III est donc modifi e, comment les acteurs seront-ils notifi s ? la mise en conformit sera-t-elle tre r troactive ? dans quels d lais ? De m me, si nous restons dans la perspective d un tablissement des risques ex ante fond sur des cas d usage, quels sont les processus qui seront mis en place afin de r valuer au fil du temps le niveau de risque des cas d usage ? Le recours aux actes d l gu s est tr s impr cis et leur p rim tre devrait tre tr s clairement encadr . Recommandation 4 : pr ciser les r gles de modification de l Annexe III pour les syst mes IA haut risque par le biais d actes d l gu s. PROBLEMES CONCRETS POUR L IMPLEMENTATION DE LA MISE EN CONFORMITE Nous avons identifi de nombreux cas o l impl mentation pratique de la mise en conformit semble extr mement co teuse, voire impossible. Notre crainte repose principalement sur la mise en place d une r glementation qui sera vue comme un frein l innovation permise par l IA, compte tenu de ces contraintes de mise en conformit . Par ailleurs, nous ne voyons pas comment il serait possible d appliquer la mise en conformit sur certains syst mes d j en production mais pour lesquels les exigences requises ne peuvent tre r troactivement mises en uvre. Pour chaque contrainte de mise en conformit devrait tre conduite une analyse d impact sur l innovation. Nous listons ici quelques cas qui nous apparaissent critiques. MISES A JOUR FREQUENTES Une fois qu une solution comprenant un composant d apprentissage a t mise sur le march , elle doit tre monitor e pour contr ler ses performances. Habituellement, les donn es d rivent peu peu et leur distribution Hub France IA Groupe de Travail Banques et Auditabilit p 6/ 12 s cartant de la distribution des donn es d apprentissage, les performances vont finir par se d grader. On pr voit donc toujours des proc dures de r apprentissage des mod les, la plupart du temps non automatiques, mais en g n ral sur lev e d alertes (il existe cependant des syst mes auto-apprenants, qui vont d clencher automatiquement ces r apprentissages). Quand ce r apprentissage est effectu , une modification est apport e au syst me IA d origine, mais alors faut-il le revalider ? Il est indiqu au 3 : En cas de modification substantielle des syst mes d IA, ceux-ci devront faire l objet de r valuations ex ante de la conformit La question de la d finition pr cise de modification substantielle est alors cruciale, puisque si le r apprentissage peut tre consid r comme apportant une modification substantielle, le r apprentissage au fil de l eau devient impossible, ce qui de fait va limiter consid rablement l int gration d approche IA innovantes dans les syst mes. Cependant la d finition du terme dans le document n est pas assez claire : ( modification substantielle , une modification apport e au syst me d IA la suite de sa mise sur le march ou de sa mise en service, qui a une incidence sur la conformit de ce syst me avec les exigences nonc es au titre III, chapitre 2, du pr sent r glement ou entra ne une modification de la destination pour laquelle le syst me d IA a t valu ( Conform ment la notion commun ment tablie de modification substantielle pour les produits r glement s par la l gislation d harmonisation de l Union, il convient que les syst mes d IA fassent l objet d une nouvelle valuation de la conformit chaque fois qu ils subissent une modification susceptible d avoir une incidence sur leur conformit avec le pr sent r glement ou que la destination du syst me change Nous recommandons d ajuster la d finition d une modification substantielle en l orientant par l usage du syst me, ses performances ou la modification de son niveau de risque. Cela faciliterait la mise en uvre de la r glementation pour le r apprentissage qui ne vient pas n cessairement modifier la finalit du syst me, mais au contraire, am liorer les r sultats obtenus. Recommandation 5 : pr ciser la d finition de modification substantielle La proc dure indiqu e dans le document pour int grer le r apprentissage dans la mise en conformit est la suivante : D crire les modifications anticip es dans la documentation technique : Article 13 Les syst mes d IA haut risque sont accompagn s d une notice d utilisation comprenant (b) les caract ristiques, les capacit s et les limites de performance du syst me d IA haut risque, (c) les modifications du syst me d IA haut risque et de ses performances qui ont t pr d termin es par le fournisseur au moment de l valuation initiale de la conformit , le cas ch ant Si les modifications apport es ont t d crites, alors elles ne constituent pas une modification substantielle : Article 43, Pour les syst mes d IA haut risque qui continuent leur apprentissage apr s avoir t mis sur le march ou mis en service, les modifications apport es au syst me d IA haut risque et ses performances qui ont t d termin es au pr alable par le fournisseur au moment de l valuation initiale de la conformit et font partie des informations contenues dans la documentation technique vis e l annexe IV, point 2 f), ne constituent pas une modification substantielle Mais si les modifications vont au-del de ce qui a t d crit : Hub France IA Groupe de Travail Banques et Auditabilit p 7/ 12 En cas de modification substantielle des syst mes d IA, ceux-ci devront faire l objet de r valuations ex ante de la conformit (notamment lorsque les modifications vont au-del de ce qui est pr d termin par le fournisseur dans sa documentation technique et v rifi lors de l valuation ex ante de la conformit ) Pour que les r apprentissages r guliers soient possibles, la documentation technique initiale doit donc adopter une description large des modifications possibles : comment ces limites seront-elles appr ci es par l organisme certificateur ? Si la modification est consid r e comme substantielle, quels seront les d lais pour la mise en conformit ? Si le r apprentissage n cessite une mise en conformit syst matique il est craindre une perte de performance des syst mes d IA int grant du r apprentissage qui ne seront alors plus mis jour aussi r guli rement. Ces pertes de performance se traduiront par des co ts en augmentation, qui, in fine, seront support s par les utilisateurs finaux. Une autre approche classique en IA, pour les syst mes d apprentissage, consiste d velopper le syst me dont on value les performances techniques, puis, quand celles-ci sont satisfaisantes, l valuation sur le terrain pour valider que ces performances techniques se traduisent bien en performances m tier. Apr s it rations, on d cide alors de mettre sur le march . Comment peut-on valuer sur le march la solution pour arriver la solution finale ? Est-ce que ce type d approche entre dans le champ de la r glementation si elle est utilis e pour la mise en uvre d un syst me haut risque ? ou bien ces valuations sont-elles consid r es comme des tests au sens de l article 9 : Les tests des syst mes d IA haut risque sont effectu s, selon les besoins, tout moment pendant le processus de d veloppement et, en tout tat de cause, avant la mise sur le march ou la mise en service. Les tests sont effectu s sur la base de m triques et de seuils probabilistes pr alablement d finis, qui sont adapt s la destination du syst me d IA haut risque. De m me, comment certifier des approches de type A/B testing ? Comment les certifier ex-ante alors que la solution finale n est pas encore totalement d finie ? Est-ce que ce type d approche entre dans le champ de la r glementation si elle est utilis e pour la mise en uvre d un syst me haut risque ? Recommandation 6 : pr ciser le processus suivre en cas de r apprentissage ALGORITHMES PRE-ENTRAINES PAR TIERS De plus en plus, les composants IA sont d velopp s en utilisant des solutions de d veloppement comme une plateforme de d veloppement de solutions IA (e.g. Watson d IBM, Palantir, DataRobot, Dataiku ), des biblioth ques d algorithmes open source (e.g. PyTorch, scikitlearn ) ou des mod les pr -entra n s disponibles en open source (e.g. yolov3, FaceNet, BERT et d riv s ). Si une entreprise d veloppe un syst me IA haut risque en utilisant de telles solutions de d veloppement, on doit consid rer (Article qu il est le fournisseur du syst me IA haut risque et que, comme il a apport une modification substantielle la solution de d veloppement (c) ci-dessous) le fournisseur n est plus assujetti aux contraintes de conformit : Tout distributeur, importateur, utilisateur ou autre tiers est consid r comme un fournisseur aux fins du pr sent r glement et est soumis aux obligations incombant au fournisseur au titre de l'article 16 dans toutes les circonstances suivantes: (a) il met sur le march ou met en service un syst me d IA haut risque sous son propre nom ou sa propre marque; (b) il modifie la destination d'un syst me d IA haut risque d j mis sur le march ou mis en service; (c) il apporte une modification substantielle au syst me d IA haut risque. Lorsque les circonstances vis es au paragraphe 1, point b) ou c), se produisent, le fournisseur qui a initialement mis sur le march ou mis en service le syst me d IA haut risque n est plus consid r comme un fournisseur aux fins du pr sent r glement. Hub France IA Groupe de Travail Banques et Auditabilit p 8/ 12 Cependant, les conditions de l Article 16 (Obligations incombant aux fournisseurs de syst mes d IA haut risque) peuvent devenir impossibles remplir : par exemple, pour l utilisation de syst mes pr -entra n s sur des jeux de donn es qui ne sont pas disponibles. Doit-on consid rer qu un r entrainement partiel est une modification substantielle ? Dans ce cas, les fournisseurs de ces solutions de d veloppement devraient-ils eux-m mes tre valu s ex ante ? V rifier la conformit de ces solutions de d veloppement ne peut tre la charge des producteurs secondaires , mais les grandes entreprises du num rique, sources des solutions de d veloppement, accepteront-elles de faire certifier leurs solutions ? Il conviendrait donc de pr ciser ces cas. Comment traiter alors les syst mes d IA qui s appuient sur des solutions IA g n riques dont l usage final ni le niveau de risque ne peuvent tre tablis a priori a ? Comment se met en place le processus de certification ? Quel poids suppl mentaire va porter sur les fournisseurs de ces solutions g n riques pour permettre aux int grateurs de les exploiter dans le respect des exigences de certification ? Par ailleurs, comment l exigence de conformit portant sur la mise disposition du code source et des donn es (Article peut-elle tre mise en uvre lorsqu un composant IA tiers est int gr dans le syst me IA final ? En effet, il parait impossible d exiger l acc s au code source d un fournisseur tiers portant en particulier une solution propri taire. Recommandation 7 : pr ciser les conditions de certification de syst me IA haut risque comprenant un composant IA exploitant une solution de d veloppement provenant d un tiers BIAIS Les syst mes IA utilisant des techniques d apprentissage doivent utiliser des jeux de donn es satisfaisant des crit res de qualit , notamment en mati re de biais (Articles 10, 14 et : Les jeux de donn es d entra nement, de validation et de test sont assujettis des pratiques appropri es en mati re de gouvernance et de gestion des donn es. Ces pratiques concernent en particulier : (f) un examen permettant de rep rer d ventuels biais (g) la d tection d ventuelles lacunes ou d ficiences dans les donn es, et la mani re dont ces lacunes ou d ficiences peuvent tre combl es. Les jeux de donn es d entra nement, de validation et de test sont pertinents, repr sentatifs, exempts d erreurs et complets. Les mesures pr vues donnent aux personnes charg es d effectuer un contr le humain, en fonction des circonstances, la possibilit (b) d avoir conscience d une ventuelle tendance se fier automatiquement ou excessivement aux r sultats produits par un syst me d IA haut risque ( biais d automatisation ) Les syst mes d IA haut risque qui continuent leur apprentissage apr s leur mise sur le march ou leur mise en service sont d velopp s de telle sorte que les ventuels biais dus l utilisation de r sultats comme donn es d entr e pour les op rations futures ( boucles de r troaction ) fassent l objet d un traitement ad quat au moyen de mesures d att nuation appropri es. Cependant, on sait que tous les jeux de donn es comprennent des erreurs et sont biais s. Si on a pu d tecter des lacunes (g) on les a videmment combl es ! Quant aux biais, ils sont difficiles identifier et potentiellement difficiles supprimer. On peut donc tout au plus mettre en uvre des pratiques appropri es et pr voir des traitements ad quats . Par ailleurs, il conviendrait de restreindre l tude des biais aux variables sensibles (telles que d finies dans le RGPD). Hub France IA Groupe de Travail Banques et Auditabilit p 9/ 12 Recommandation 8 : pr ciser la notion de biais et la nature des exigences de prise en compte des biais TRA ABILITE Pour les syst mes IA haut risque, il faut mettre en place ex ante un processus de mise en conformit qui aboutira la d livrance d un label CE ( 3 Expos des motifs) : Pour les syst mes d IA haut risque, les exigences en mati re de donn es de haute qualit , de documentation, de tra abilit , de transparence, de contr le humain, d exactitude et de robustesse Ces exigences comprennent des contraintes d enregistrement des v nements (article tout au long du cycle de vie du syst me IA haut risque : La conception et le d veloppement des syst mes d IA haut risque pr voient des fonctionnalit s permettant l enregistrement automatique des v nements ( journaux ) pendant le fonctionnement de ces syst mes. Ces fonctionnalit s d enregistrement sont conformes des normes ou des sp cifications communes reconnues. Les fonctionnalit s d enregistrement garantissent un degr de tra abilit du fonctionnement du syst me d IA tout au long de son cycle de vie qui soit adapt la destination du syst me. En particulier, ces fonctionnalit s permettent de surveiller le fonctionnement du syst me d IA haut risque dans l ventualit de situations ayant pour effet que l IA pr sente un risque au sens de l article 65, paragraphe 1, ou entra nant une modification substantielle, et facilitent la surveillance apr s commercialisation vis e l article Les fonctionnalit s d enregistrement automatique doivent tre limit es : en effet, tout enregistrer aboutit rapidement de tr s grandes quantit s de donn es. La tra abilit devient rapidement extr mement complexe mettre en uvre car elle va n cessiter une capacit de stockage importante sur toute la dur e de vie du syst me d IA. Il convient donc de limiter le p rim tre d enregistrement : selon quelles normes ou des sp cifications communes reconnues ? Jusqu o va la tra abilit : quelle est la profondeur de l historique conserver ? doit-on conserver les journaux de tous les tests et toute la base d apprentissage initiale ? Comment la CE imagine-t-elle les cas o il est n cessaire de stocker la vie des donn es et des mod les de 20 millions de clients ? Cela ne semble pas faisable et probablement trop co teux. Par exemple, sur le credit scoring, il y a un cadre de validation qui est d j en place et lourd, mais moins lourd cependant que celui propos par la CE. Par ailleurs, l exigence de conserver les donn es sur de grandes profondeurs d historique peut tre en d saccord avec RGPD. L exigence de conservation exhaustive des v nements aboutissant une volum trie trop importante est donc irr aliste. Recommandation 9 : pr ciser les exigences d enregistrement en termes de profondeur d historique, p rim tre des donn es, etc. ainsi que les normes ou des sp cifications communes reconnues Le processus de mise en conformit comporte galement des exigences d acc s aux donn es (Annexe VII et article : La documentation technique est examin e par l organisme notifi . cette fin, l organisme notifi se voit accorder un acc s complet aux jeux de donn es d entra nement et de test utilis s par le fournisseur, y compris par l interm diaire d interfaces de programmation ou d autres moyens et outils appropri s permettant un acc s distance. Hub France IA Groupe de Travail Banques et Auditabilit p 10/ 12 Ces exigences sont aligner avec les contraintes RGPD, et, de fa on r aliste, tre limit es exclusivement aux donn es du syst me en production. Par ailleurs, l acc s distance aux donn es pose un risque de s curit qui ne semble pas acceptable. En particulier, les syst mes sensibles (s curit financi re : fraude, blanchiment ) doivent tre prot g s en acc s. Recommandation 10 : restreindre les exigences d acc s aux donn es du syst me sur le march , et viter absolument les acc s distance. TRANSPARENCE Les exigences de transparence (Article , et notamment les informations contenues dans la notice d information ( devraient tre restreintes pour viter les menaces li es aux attaques cyber ou concernant les syst mes sensibles (s curit financi re : fraude, blanchiment ). Recommandation 11 : restreindre les exigences de transparence pour prot ger la cybers curit des syst mes IA, et plus particuli rement les syst mes sensibles (fraude, blanchiment). EXCEPTIONS (INTERET LEGITIME) La proc dure de r gulation propos e se consid re comme compl mentaire aux r gulations d j en place ( 2 de l expos des motifs) : Le caract re horizontal de la proposition requiert une coh rence parfaite avec la l gislation de l Union existante applicable aux secteurs dans lesquels des syst mes d IA haut risque sont d j utilis s ou sont susceptibles de l tre dans un avenir proche. Cependant, il peut se poser des questions de hi rarchie des normes. Ainsi, dans le cas de certaines applications ou certains services propos s par les banques (lutte contre le blanchiment d argent, lutte contre la fraude, devoir de diligence), des r glementations sont d j en place, sont-elles alors consid r es comme prioritaires par rapport la r glementation IA de la CE ? En particulier dans le document il est indiqu une coh rence parfaite sans que pour autant une priorit sp cifique soit exprim e. D s lors, est-ce qu il peut y avoir des exceptions l gitimes li es aux contraintes l gales en vigueur. Par exemple, sur certains cas d usage il n est pas l galement possible de stocker les donn es et les mod les, la d marche de transparence est complexe voire impensable, la mise jour des mod les est faite de fa on tellement r guli re qu il n apparait pas possible de repasser dans le processus de r gulation chaque it ration etc Recommandation 12 : pr ciser la hi rarchie des normes EXEMPLES DE CAS D USAGE IDENTIFIES A HAUT RISQUE (EXISTANTS OU POSSIBLES)SCORE DE CREDIT Ce domaine concerne videmment tr s fortement les banques (attendus, : les syst mes d IA utilis s pour valuer la note de cr dit ou la solvabilit des personnes physiques devraient tre class s en tant que syst mes d IA haut risque Plusieurs questions de p rim tre se posent : Hub France IA Groupe de Travail Banques et Auditabilit p 11/ 12 Est-ce que cela englobe tout type de cr dit ou uniquement les cr dits essentiels ? Le p rim tre d application devrait tre d fini plus pr cis ment. Ensuite, est-ce que cela inclut galement le monitoring du cr dit ou est-ce qu on reste uniquement au niveau de l octroi d s lors que le monitoring ne supprime pas de service essentiel ? Qu en est-il des mod les d valuation de la solvabilit d une personne qui peuvent ensuite tre utilis s pour tablir un score d octroi ou pour suivre le niveau de risque associ un pr t existant ? Question sur l emploi du terme personne physique . Il est fait mention ici de la personne physique, pas du citoyen. Dans le cas des soci t s unipersonnelles (personne morale) repr sent es par une seule personne physique, les auto-entrepreneurs, doit-on consid rer que la demande de cr dit de la personne morale est classifi e comme haut risque ? L IA tant dans le document d finie de mani re tr s large/vaste, est-ce que des solutions bas es sur des syst mes de r gles m tiers ou m me parfois des calculs fait sur des fichiers Excel et qui font de l valuation de solvabilit vont rentrer sous le coup de la r gulation ? USAGES PAR LES AUTORITES REPRESSIVES Les dispositifs bas s sur l Intelligence Artificielle mis en uvre par les banques ce titre peuvent concerner : a) la lutte contre le blanchiment d argent et le terrorisme, b) lutte contre la fraude interne et externe, c) devoir de diligence pour la connaissance client. Ces syst mes pourraient tre consid r s comme des composantes de la s curit (au sens de Art.6 ) des op rations financi res et semblent relever de l Annexe g et seraient donc consid r s comme haut risque ou pourraient le devenir la faveur d une modification telle que pr vue l article Est-ce bien le cas ? Dans l affirmative, les d lais induits par les obligations pr vues au chapitre 3 ou la transparence requise au Titre IV n iront-elles pas l encontre des obligations r glementaires vis es ? La clause g peut-elle tre pr cis e ? Recommandation 13 : exclure explicitement les syst me IA d di s la s curisation des op rations financi res, la lutte anti-fraude, anti blanchiment ou anti-terroriste de la liste des syst mes haut risque. BIOMETRIE Les cas d usage connus date de l usage de la biom trie sont potentiellement les suivants : Authentification client par reconnaissance faciale ou par reconnaissance d empreinte digitale dans nos applications mobiles pour acc der l application et pour effectuer les op rations sensibles (enregistrement nouveau RIB, souscription produit) Authentification client dans les centres d appels par reconnaissance d empreinte vocale Authentification par biom trie dans les ATM ( Authentification par empreinte digitale pour s curiser des paiements directement sur les cartes de paiement ( Authentification par empreinte digitale ou reconnaissance d IRIS des collaborateurs (ou de prestataires) accr dit s p n trer dans des locaux sensibles (type datacenter) Usage de la reconnaissance faciale pour comparer le visage du client la photo de sa pi ce d'identit lors du processus d'onboarding distance (exemple fintech Hub France IA Groupe de Travail Banques et Auditabilit p 12/ 12 Ces usages sont aujourd hui majoritairement fond s sur des solutions externes l entreprise. Ainsi dans ces cas d usage, les banques ne font qu int grer une solution existante au sein d un programme de d veloppement d outil IT. Notre compr hension est que dans ces cas-l il n appartient pas la Banque de certifier le syst me IA, mais c est le fournisseur de la solution qui doit obtenir la certification (voir Recommandation . CONTACT Hub France IA 8-10 rue Charles V, 75004 Paris. E-mail : contact@hub-franceia.fr",fr
APDSI - Associação para a Promoção e Desenvolvimento da Sociedade da Informação (Portugal),F2665167,30 July 2021,Non-governmental organisation (NGO),Micro (1 to 9 employees),Portugal,"RECOMENDA O Consulta p blica da Comiss o Europeia em mat ria de Intelig ncia Artificial 29 de julho de 20 21 reas prin cipais que requerem revis o ou esclarecimento Esclarecer o balan o de responsabilidades entre prestadores de IA, distribuidores e utilizadores, especialmente para API s de prop sito geral e modelos de open source: como foi explanado, o AIA n o distingu e suficientemente as responsabilidades dos utilizadores de IA quando no desempenho do papel de distribuidor e as responsabilidades dos p restadores para com os seus consumidores. A n o ser que tal seja claro na medida razo vel, arrisca -se a ter um efeito di ssuasor na publica o de modelos em open source e em API s, que t o importante para a inova o de IA e na sua ado o pela ind stria. D eixamos algumas recomenda es: A diretiva de IA n o fornece uma defini o de ""distribuidor"". Por quest es de clareza, seria til que o fizesse. Uma defini o sensata seria a de distribuidor para nos referirmos entidade que faz com que o sistema de IA e steja dispon vel para uso num contexto operacional espec fico. Por vezes (ex: se o sistema est Recomenda o da APDSI para a consulta p blica da Comiss o Europeia em mat ria de Intelig ncia Artificial APDSI Associa o para a Promo o e Desenvolvimento da Sociedade da Informa o 2 constru do de forma pe rsonalizada para o distribuidor pelo programador) o distribuidor pode ser o mesmo que o prestador. Mas, noutros casos, tal n o acontecer se sistemas IA de prop sito geral forem utilizados. Os distribuidores devem suportar a responsabilidade prim ria de observ ncia, conformidade, avalia o e monitoriza o post -market, pois s eles podem verificar as aplica es finais para as quais os seus si stemas est o a ser usados e outra informa o adici onal que tenha sido introduzida da forma o do seu sistema. Ao contr rio, seria igual a responsabilizar os fabricantes de tijolo por assegurar a integridade estrutural de uma torre, ao inv s de os arquiteto s, engenheiros e construtores que desenharam e con stru ram a mesma. o Para ser claro, o nus deve ser colocado aos distribuidores em todas as circunst ncias, independentemente da marca ou da maneira precisa em que o sistema de IA foi obtido. Caso se esteja a utilizar IA de prop sito geral, tirado da prate leira, numa opera o de alto risco ou caso o sistema tenha sido modificado, s a organiza o que utiliza o sistema de IA que ter conhecimento sobre como estar a ser utilizado o sistema. Rever a linguagem usada em standards invi veis: importante ma nter requisitos realistas, em concord ncia com as boas pr ticas e pr ticas vi veis da ind stria. Enquanto concordamos com a dire o dos requisitos para sistemas de IA de risco elevado, consideramos que alguma l inguagem utilizada merece aten o acrescida de forma a evitar a cria o de standards que s o de facto imposs veis para qualquer fornecedor alcan ar. Em particular: O artigo 10 ( indica que Os conjuntos de dados de treino, valida o e teste devem ser per tinentes, representativos, isentos de erros e completos. No entanto, imposs vel garantir este n vel de perfei o e consequentemente imposs vel de alcan ar este requisito, pois algumas t cnicas de privacidade introduzem deliberadamente erros (em forma de ru do) nos conjuntos de dados. Adicionalmen te, imposs vel a complei o total de conjuntos de dados, uma vez que a natureza destes conjuntos materializa -se numa amostra da realidade e porventura n o inclui todos os dados dispon veis. Sugerimos uma frase mais Recomenda o da APDSI para a consulta p blica da Comiss o Europeia em mat ria de Intelig ncia Artificial APDSI Associa o para a Promo o e Desenvolvimento da Sociedade da Informa o 3 realista como Devem ser garantidos esf or os adequados de forma a garantir um conjunto de dados relevante, representativo, livre de erros e completo . O artigo 14 ( afirma que indiv duos respons veis por supervis o humana devem compreender complet amente as capacidades e limita es do sistema de IA de risco elevado . Consideramos este requisito injustificadamente elevado visto ser imposs vel atender a este n vel de compreens o quando se fala de redes neurais complexas. Sugerimos um requisito mais re alista que requer indiv duos a ter um entendimento apropriado das capacidades e limita es . Esclarecer praticalidades de due diligence : existem v r ias reas onde necess ri a uma maior orienta o quanto s expectativas de conformidade . Por exemplo: O artigo 10 - Dados e governa o de dados: Por vezes, sistemas de IA s o constru dos utilizando conjuntos de dados providenciados por terceiros, incluin do os de open -source . Ao avaliar a conformidade com o artigo 10, quanta confian a pode ser colocada nas r epresenta es feitas pelos criadores dos conjuntos de dados, relativamente ao consentimento, privacidade, etc .? Quais as expectativas de due diligence caso n o haja nenhuma informa o sobre a proveni ncia do conjunto de dados? O artigo 12 - Manuten o de r egistos: Para certos servi os, pode haver preocupa es sobre conectividade ou privacidade que resultam num sistema de IA a ser constru do para utiliza r on-device learning (em vez de na Cloud ). Como deve a manuten o de registos ser cumprida nestas circunst ncias, quando n o h uma refer ncia centralizada? De um modo geral, o cumprimento das obriga es de registo parecem violar o princ pio da minimiza o dos dados presente no RGPD - na pr tica, como deve ser isto equilibrado? Reenquadrar requisitos despropo rcionais . Em alguns casos, os requisitos s o geralmente, ou at extremamente, desproporcionais, devendo ser alterados. Especificamente: O Artigo 6 4 ( refere que ...mediante pedido fundamentado, deve ser concedido s autoridades de fiscaliza o do mercad o o acesso ao c digo -fonte do sistema de Recomenda o da APDSI para a consulta p blica da Comiss o Europeia em mat ria de Intelig ncia Artificial APDSI Associa o para a Promo o e Desenvolvimento da Sociedade da Informa o 4 IA . Por m o c digo -fonte encontra -se protegido pela diretiva europeia de segredos comerciais, havendo sempre a possibilidade de m todos alternativos para verificar a performance de um sistema de IA (ex. auditorias internas/externas) tornando o acesso ao c digo -fonte sup rfluo. Consideramos como melhor op o a alte ra o parcial do n 2 do artigo 64 para o seguinte: ap s solicita o justificada, os operadores ou implantadores de IA devem apoiar e equipar autoridades d e fiscaliza o de mercado com os meios necess rios de forma a facilitar uma testagem robusta (ex. aud itoria internas/externas) nos casos que exijam conformidade com os requisitos . Recomenda o da APDSI para a consulta p blica da Comiss o Europeia em mat ria de Intelig ncia Artificial APDSI Associa o para a Promo o e Desenvolvimento da Sociedade da Informa o 5 SOBRE A APDSI Criada em 2001, a Associa o para a P romo o e Desenvolvimento da Sociedade da Informa o (APDSI) tem por obje tivo a promo o e desenvolvimento da transforma o e inclus o digital em Portugal, reunindo com este interesse com um profissi onais, acad micos, em presas, organismos p blicos e cidad o s em geral. Na linha destes prop sitos a APDSI tem vindo a desenvolver d iversas atividades em torno de causas tecnol gicas e societais, que se traduzem num conjunto de e ventos , recomenda es e estu dos realizados por gr upos de trabalho multidisciplinares e m diversas reas de interven o, como a Seguran a, os Servi os P blicos D igitais, a Sa de, a Cidadania e Inova o Social, o Territ rio Inteligente, a Governa o das TIC, a Intelig ncia Di gital, a Po l tica Digital e Gove rnan a, os Futuros da Sociedade da In forma o e as Compet ncias digitais. Em todos estes trabalhos a APDSI pr ocura identificar as tend ncias de evolu o e tamb m as intera es entre as tecnologias e outras dimens es sociais e econ mic as, contribuindo com uma vis o mais aberta para a discuss o e tendo como meta a eficaz perce o e implementa o destes conceitos na Sociedade Portuguesa. A APDSI tem o Estatuto de Utilidade P blica e foi em 2008 reconhecida como ONGD. Associa o de Utilidade P blica ONG Organiza o N o Governamental Rua Alexandre Cabral, 2C Loja A 1600 -803 Lisboa Portugal URL: dsi.pt Tel.: (+ 217 510 762 Fax: (+ 217 570 516 E-mail: secretariado@apdsi.pt Patr ocinadores Glob ais da APDS I",pt
ASNEF (Spain),F2663391,30 July 2021,Business association,Small (10 to 49 employees),Spain,"Vel zquez, 64 -66, 2 planta - 28001 MADRID - asnef@asnef.com CIF: G28516003 P gina 1 Madrid, 30 de julio de 2021 La Asociaci n Nacional de Establecimientos Financieros de Cr dito (ASNEF) , representada por su Secretario General , D. Ignacio Pla Vidal, y debidamente inscrita en el Registro de Transparencia de la Uni n Europea con el n 11218815591 -29, presenta las siguientes observaciones dentro del plazo de consulta p blica abierta en relaci n con: Propuesta De Reglamento Del Parlamento Europeo Y Del Consejo Para El Establecimiento De Reglas Armonizadas Sobre Inteligencia Artificial (Ley De Inteligencia Artificial) [COM(206 ] En primer lugar, con relaci n al considerando 37, la propuesta de Reg lamento menciona lo siguiente: Habida cuenta del alcance sumamente limitado de su impacto y de las escasas alternativas disponibles en el mercado, conviene dejar exentos a los sistemas de IA destinados a evaluar la solvencia y la calificaci n crediticia c uando los pongan en servicio proveedores a peque a escala para su propio uso. Consideramos de suma importancia que se especifique el significado de ""proveedores a peque a escala y para su propio uso en el contexto de esta excepci n a la consideraci n como riesgo alto y a la aplicaci n de los consiguientes requisitos y obligaciones. En segundo lugar, rogamos que se especifique c mo deber n cumplir aquellos sistemas ya en producci n que, seg n esta regulaci n, son de alto riesgo. Por ltimo, solicitamos que se incluya un amplio periodo transitorio para su aplicabilidad , al objeto de que las entidades que ya est n utilizando I nteligencia artificial para la evaluaci n de la solvencia y credit score puedan adaptarse a los nuevos requisitos. Vel zquez, 64 -66, 2 planta - 28001 MADRID - asnef@asnef.com CIF: G28516003 P gina 2 Courtesy translation Madrid, July 30, 2021 ASNEF, t he Finance Houses Association of Spain, represented by the Secretary General, Mr. Ignacio Pla Vidal, and duly registered in the Transparency Registry with n 11218815591 -29, submits the following observations within the period of open public consultation in relation to: Proposal for a EU Regulation laying down harmonised rules on artificial intelligence [COM(206] Concerning recital 37, the proposed Regulation mentions the following: ""Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small -scale providers for their own use . We consider it of utmost importance that the m eaning of ""small -scale suppliers"" and ""for their own use"" be specified in the context of this exception to consideration as high risk and the application of the consequent requirements and obligations. Secondly, we ask for further clarification on how t hose high -risk systems that are already in use by the institutions will need to adapt to the new regulation. Finally, we request a wide transitional period to be included, so that entities that are already using Artificial Intelligence for the creditworthiness assessment and credit score can adapt to the new requirements.",es
Vereinigung der Arbeitgeberverbände der Deutschen Papierindustrie e. V. (Germany),F2663356,29 July 2021,Business association,Small (10 to 49 employees),Germany,"VAP Seite 1 von 3 R ckmeldung zum Verordnungsvorschlag ber ein europ isches Konzept f r k nstliche Intelligenz Wir begr en den risikobasierten Ansatz der Kommission, der im Verordnungsvorschlag ber k nstliche Intelligenz skizziert wird, und teilen das Bestreben, KI sicher, rechtm ig und im Einklang mit den EU-Grundrechten zu gestalten. Grunds tzliche Anforderungen Die Pr fung des Verordnungsvorschlags durch Parlament und Rat muss darauf abzielen: ein angemessenes Verh ltnis zwischen Risikopr vention und neuen Belastungen zu schaffen, welches weder Innovation erstickt, noch die Einf hrung von KI verlangsamt oder gar aufh lt, die angemessene Durchf hrbarkeit f r Herstellende und Nutzende sicherzustellen, eine ausreichende Flexibilit t zur Anpassung an neue Erkenntnisse sowie an unter- schiedliche Organisationsstrukturen innerhalb der KI-Wertsch pfungsketten sicher- zustellen, die Koh renz mit den bestehenden Rechtsvorschriften zu gew hrleisten und einen flexiblen Marktzugangsrahmen zu f rdern. Daf r sollten folgende Punkte beachtet werden: Anwendungsbereich klug anpassen Anpassungen des Anwendungsbereichs sind entscheidend, um sicherzustellen, dass die neuen Regeln effektiv, verh ltnism ig und rechtlich eindeutig auf hochriskante KI-Systeme anwendbar sind und zu den gew nschten politischen Ergebnissen f hren. Die aktuelle Definition von KI (Art. 3(), die Kriterien zur Bestimmung verbotener Praktiken (Art. und die Klassifizierung von KI-Systemen als Hochrisiko-Systeme (Art. m ssen daf r besser gekl rt und eingegrenzt werden, um sich auf die Bereiche zu konzentrieren, in denen die h chsten und weitreichendsten Risiken erwartbar sind. So wie sie derzeit formuliert ist, w rde zum Beispiel die Definition die meisten modernen Softwares umfassen , die rein statistische und wissensbasierte Ans tze f r die herk mmliche Datenanalyse verwenden, die nur geringe Auswirkungen auf die Einzelnen haben. Stattdessen sollte die Hochrisiko-Definition die Komponente der menschlichen Aufsicht ber cksichtigen und damit KI-Systeme, die lediglich Empfehlungen geben, nicht zu den Hochrisiko-Systemen z hlen und sich auf intelligente KI-Systeme konzentrieren, die tats chliche Entscheidungen treffen k nnen. Seite 2 von 3 Einstufung von KI-Systemen mit hohem Risiko unbedingt nachbessern Wir stimmen zu, dass einige eigenst ndige KI-Einsatzf lle in den in Anhang III auf- gelisteten Bereichen spezifischen Anforderungen unterworfen werden m ssen, aber die Definition dieser Bereiche ist zu breit. Die Annahme, dass bei KI-Systemen ein hohes Risiko besteht, wenn sie im Bereich Schul- oder Berufsbildung, Besch ftigung, Personalmanagement und Selbstst ndigkeit (Anhang III, Nr. 3 und 4, Art. 6, Abs. eingesetzt wird, w rde zu Rechtsunsicherheit und unverh ltnism igem b rokratischen Aufwand f r Unternehmen f hren, die versuchen festzustellen, ob sie davon betroffen sind. Ob KI als hohes Risiko betrachtet werden sollte, h ngt vom spezifischen Kontext und von Situationen, in denen das KI-System die endg ltigen Entscheidungen trifft, ab ein pauschaler Ansatz ist nicht angemessen . Die Einstufung w rde die Verbreitung innovativer KI-Anwendungen behindern, insbeson- dere von KI-L sungen, die eine st rkere Nutzung im Besch ftigungs- und Bildungs- kontext unterst tzen. KI-Systeme haben das Potenzial , die Produktivit t von Unternehmen und gleichzeitig das Wohlbefinden der Arbeitskr fte zu steigern, etwa durch eine effektive Aufgabenteilung zwischen Mensch und Maschine, durch die Bereitstellung von Tools zur Kompetenz- entwicklung und durch den Zugang zu besseren Arbeitsbedingungen, insbesondere im Bereich Gesundheit und Sicherheit. Dar ber hinaus gibt die autonome Vereinbarung der europ ischen Sozialpartner zur Digitalisierung bereits einige Richtungen und Grunds tze vor, wie und unter welchen Umst nden KI in die Arbeitswelt eingef hrt wird. Eine zu weit gefasste Definition w rde vor allem KI-Anwendungen im Personal- und Bildungswesen ausbremsen, die ihre Effektivit t und Sicherheit bei der Verbesserung des Bewerbenden- und Mitarbeitenden-Erlebnisses sowie bei der Steigerung der Effizienz unter Beweis gestellt haben. Aus diesen Gr nden empfehlen wir, die in Anhang III aufgef hrten Bereiche auf spezifischere Anwendungsf lle mit hohem Risiko einzugrenzen. Aktualisierung der Liste von KI-Systemen mit hohem Risiko schafft Unberechenbarkeit Die Europ ische Kommission wird erm chtigt, die Liste der eigenst ndigen KI-Systeme mit hohem Risiko durch delegierte Rechtsakte (Art. zu aktualisieren. Diese dynamische Anpassung des Geltungsbereichs kann zu gro er Unberechenbar- keit f r den Markt f hren. KI-Anbieter w rden aufgrund der unvorhersehbaren Entwicklung des Anwendungs- bereichs der Verordnung in den n chsten Jahren davon abgehalten, innovative KI- L sungen zu entwickeln. Seite 3 von 3 Die Kriterien (Art. 7, Abs. , die die Kommission erm chtigen, die Liste in Anhang III zu aktualisieren, indem sie KI-Systeme mit hohem Risiko unter bestimmten Bedingungen hinzuf gt, sind zu vage. Um die Rechtssicherheit und die Vorhersehbarkeit des Marktes zu unterst tzen, begr en wir weitere Klarheit ber die genauen Kriterien, die es der Kommission erm glichen w rden, die Liste der Hochrisiko-KI-Systeme zu aktualisieren. Die Einf hrung expliziter Bestimmungen f r die Beteiligung der Anbieter und der betrieblichen Nutzer an jedem zuk nftigen Prozess zur Aktualisierung der Liste etwa durch die Ausweitung des Mandats der hochrangigen Expertengruppe f r KI w re sinnvoll. Verpflichtungen f r Anbieter und Anwender nachbessern Im Verordnungsvorschlag bleibt die Verantwortungsverteilung zwischen Anbietern und Anwendern unklar. Es scheint nicht ber cksichtigt zu werden, dass generelle KI-Anwendungen durch den Nutzer f r einen bestimmten Zweck konfiguriert werden k nnen. In diesem Fall hat der Anbieter keine Kontrolle ber die Anwendung. Derzeit gelten die Pflichten Dritter inklusive Nutzer (Art. nur f r Systeme, die bereits von Anfang an als Hochrisiko-Systeme klassifiziert werden. Hier sollte der Geltungsbereich auch auf Nutzer ausgeweitet werden, die den Ver- wendungszweck eines sich bereits auf dem Markt befindlichen oder in Betrieb genommenen KI-Systems so ver ndern, dass ein Hochrisiko-System geschaffen wird. Vereinigung der Arbeitgeberverb nde der Deutschen Papierindustrie e. V. Papierzentrum Scheffelstra e 29 | 76593 Gernsbach Telefon +49 7224 6401-119 Telefax +49 7224 6401-463 vap@papierzentrum.org Stand: Juli 2021",de
BDA - Bundesvereinigung der Deutschen Arbeitgeberverbände (Germany),F2663263,28 July 2021,Business association,Medium (50 to 249 employees),Germany,"R ckmeldung zum Verordnungsvorschlag ber ein europ isches Konzept f r k nstliche Intelligenz Wir begr en den risikobasierten Ansatz der Kommission, der im Verordnungsvorschlag ber k nstliche Intelligenz skizziert wird, und teilen das Bestreben, KI sicher, rechtm ig und im Einklang mit den EU -Grundrechten zu gestalten . Grunds tzliche Anforderungen Die Pr fung des Verordnungsvorschlags du rch Parlament und Rat muss darauf abzielen : ein angemessenes Verh ltnis zwischen Risikopr vention und neuen Belastungen zu schaffen, welche s weder Innovation erstickt , noch die Einf hrung von KI verlangsamt oder gar aufh lt , die angemessene Durchf hrbarkeit f r Herstellende und Nutzende sicherzustellen, eine ausreichende Flexibilit t zur Anpassung an neue Erkenntnisse sowie an unterschiedliche Organisationsstrukturen innerhalb der KI -Wertsch pfungsketten sicherzustellen , die Koh renz mit den bestehende n Rech tsvorschriften zu gew hrleiste n und einen flexible n Marktzugangsrahmen zu f rdern . Daf r soll ten folgende Punkte beachtet werden: Anwendungsbereich klug anpassen - Anpassungen des Anwendungsbereichs sind entscheiden d, um sicherzustellen, dass die neuen Regeln effektiv, verh ltnism ig und rechtlich eindeutig auf hochriskante KI-Systeme anwendbar sind und zu den gew nschten politischen Ergebnissen f hren. - Die aktuelle Definition von K I (Art. 3() , die Kriterien zur Bestimmung verbotener Praktiken (Art. und die Klassifizierung von KI -Systemen als Hochr isiko -Systeme (Art. m ssen daf r besser gekl rt und eingegrenzt werden, um sich auf die Bereiche zu konzentrieren, in denen die h chste n und weitreichendste n Risiken erwartbar sind . - So wie sie derzeit formuliert ist, w rde zum Beispiel die Definition die meisten modernen Softwares umfassen , die rein statistische und wissensbasierte Ans tze f r die herk mmliche Datenanalyse verwenden , die nur geringe Auswirkungen auf die Einzelnen haben . - Stattdessen sollte die Hochrisiko -Definition die Komponente der menschliche n Aufsicht ber cksichtigen und damit KI -Systeme, die lediglich Empfehlungen geben, nicht zu den Hochrisiko -Systemen z hlen und sich auf intelligente KI -Systeme konzentrieren, die tats chliche Entscheidungen treffen k nnen . Einstufung von KI -Systemen mit hohem Risiko unbedingt nachbessern - Wir stimmen zu, dass einige eigenst ndige KI -Einsatzf lle in den in Anhang III aufgelisteten Ber eichen spezifischen Anforderungen unterworfen werden m ssen, aber die Definition dieser Bereiche ist zu breit. - Die Annahme, dass bei KI -Systemen ein hohes Risiko besteht, wenn sie im Bereich Schul - oder Berufsbildung, Besch ftigung, Personalmanagement und Selbstst ndigkeit (Anhang III, Nr. 3 und 4 , Art. 6, Abs. 2 ) eingesetzt wird, w rde zu Rechtsunsicherheit und unverh ltnism ige m b rokratischen Aufwand f r Unternehmen f hren , die versuchen festzustellen, ob sie davon betroffen sind. - Ob KI als hohes Risiko betrachtet werden sollte, h ngt vom spezifischen Kontext und von Situationen, in denen das KI -System die endg ltigen Entscheidungen trifft, ab ein pauschaler Ansatz ist nicht angemessen . - Die Einstufung w rde die Verbreitung innovativer KI -Anwendungen behindern, insbesondere von KI-L sungen, die eine st rkere Nutzung im Besch ftigungs - und Bildungs kontext unterst tzen . - KI-Systeme haben das Potenzial , die Produktivit t von Unternehmen und gleichzeitig das Wohlb efinden der Arbeitskr fte zu steigern, etwa durch eine effektive Aufgabenteilung zwischen Mensch und Maschine, durch die Bereitstellung von Tools zur Kompetenzentwicklung und durch den Zugang zu besseren Arbeitsbedingungen, insbesondere im Bereich Gesundhe it und Sicherheit. - Dar ber hinaus gibt die autonome Vereinbarung der europ ischen Sozialpartner zur Digitalisierung bereits einige Richtungen und Grunds tze vor, wie und unter welchen Umst nden KI in die Arbeitswelt eingef hrt wird. - Eine zu weit gefasste Definition w rde vor allem KI -Anwendungen im Personal - und Bildungs wesen ausbremsen, die ihre Effektivit t und Sicherheit bei der Verbesserung des Bewerbe nden - und Mitarbeite nden -Erlebnisses sowie bei der Steigerung der Effizienz unter Beweis gestellt haben. - Aus diesen Gr nden empfehlen wir , die in Anhang III aufgef hrten Bereiche auf spezifischere Anwendungsf lle mit hohem Risiko einzugrenzen. Aktualisierung der Liste von KI -Systemen mit hohem Risiko schafft Unberechenbarkeit - Die Europ ische Kommissi on wird erm chtigt, die Liste der eigenst ndigen KI -Systeme mit hohem Risiko durch delegierte Rechtsakte (Art. zu aktualisieren. - Diese dynamische Anpassung des Geltungsbereichs kann zu gro er Unberechenbarkeit f r den Markt f hren. - KI-Anbieter w rden aufgrund der unvorhersehbaren Entwicklung des Anwendungsbereichs der Verordnung in den n chsten Jahren davon ab gehalten, innovative KI -L sungen zu entwickeln. - Die Kriterien (Art. 7 , Abs. 2 ), die die Kommission erm chtig en, die Liste in Anhang III zu aktualisieren, indem sie KI -Systeme mit hohem Risiko unter bestimmten Bedingungen hinzuf gt, sind zu vage . - Um die Rechtssicherheit und die Vorhersehbarkeit des Marktes zu unterst tzen, begr en wir weitere Klarheit ber die genauen Kriterien , die es der Kommission erm glichen w rden, die Liste der Hochrisiko -KI-Systeme zu aktualisiere n. - Die Einf hrung expliziter Bestimmungen f r die Beteiligung der Anbieter und der betrieblichen Nutzer an jedem zuk nftigen Prozess zur Aktualisie rung der Liste etwa durch die Auswei tung des Mandats der hochrangigen Expertengruppe f r KI w re sinnvoll . Verpflichtungen f r Anbieter und Anwender nachbessern - Im Verordnungsvorschlag bleibt die Verantwortungsv erteilung zwischen Anbietern und Anwendern unklar . - Es scheint nicht ber cksichtigt zu werden, dass generelle KI-Anwendungen durch den Nutzer f r einen bestimmten Zweck konfiguriert werden k nnen. In diesem Fall hat der Anbieter keine Kontrolle ber die Anwendung . - Derzeit gelten die Pfli chten Dritter inklusive Nutzer (Art. nur f r Systeme, die bereits von Anfang an als Hochrisiko -System e klassifiziert werden. - Hier sollte der Geltungsbereich auch auf Nutzer ausgeweitet werden, die den Verwendungszweck eines sich bereits auf dem Markt befindlichen oder in Betrieb genommenen KI -Systems so ver ndern, dass ein Hochrisiko -System geschaffen wird .",de
AFNUM - Alliance Française des Industries du Numérique (France),F2663256,28 July 2021,Business association,Micro (1 to 9 employees),France,"R ponse consultation Proposition de R glement Artificial Intelligence Act L AFNUM salue tout d abord l approche privil gi e par la Commission Europ enne afin de r glementer l Intelligence Artificielle . Cette technologie r volutionnaire, l origine du bouleversement de nombreuses pratiques , constitue une opportunit formidable pour am liorer la vie de nos con citoyens, mais repr sente galement un potentie l de d veloppement conomique, de croissance et d emploi s sans commune mesure . D s lors, les nombreux choix faits par la Commission , qui montr ent le souci de promouvoir le d veloppement conomique de l IA et le potentiel de croissance repr sent par cette technologie , r pondent aux attentes des adh rents de l AFNUM . La volont , d une part, de ne pas fragmenter le march europ en en favorisant un texte d application directe dans tous les Etats membres, et d autre part, l approche par le risque visant ne p as soumettre toutes les applications IA aux m mes obligations , nous apparaissent tr s positifs . La proposition de R glement indique , dans ses grandes lignes , une r elle prise en compte des r alit s de l IA, par la diff renciation entre ce qui rel ve de la recherche et ce qui peut tre mis disposition sur le march . L id e d un cadre s appliquant l chelle europ enne , est non seulement profitable pour l ens emble des acteurs conomiques mais permet galement l tablissement de normes harmonis es et de standards essentiels au d veloppement p renne d un secteur . Toutefois, afin que les objectif s de la Commission , savoir assurer un quilibre entre protection e t innovation tout en cr ant des standards exportables dans le cadre de la concurrence internationale, soient atteints, certains aspects de la proposition de R glement doivent d tre am lior s . Un cadre g n ral qui peut gagner en pr cision La d finition d AI system semble trop tendue En premier lieu, la proposition de R glement d finit l ensemble des techniques d IA derri re la notion de AI system Si cette d finition tr s large permet d inclure les produits contenant de l IA , l ment essentiel pour l es adh rents de l AFNUM, l tendue de cette d finition interroge sur l inclusion de certains logiciels et techniques logicielles . En effet, de nombreuses applications IA initialement exclues du p rim tre de la proposition de R gleme nt pourraient se retrouver sous le joug de ce texte , du fait de certaines impr cisions de r daction . L AFNUM recommande de clarifier la d finition d AI system , notamment au regard de la diversit importante de techniques et r alit s sous -jacent es cette d finition et aux techniques list es au sein de l annexe I. Ainsi, alors que les deux premi res familles de techniques num r es l'annexe I(a) machine learning et I(b) knowledge based sont intrins quement identifi es l'IA, le paragraphe (c) statistical approaches, Bayesian estimation, search and optimization methods liste des techniques 1 Softw are that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of human -defined objectives, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they i nteract with; qui ne sont pas li es sans quivoque l'IA ou fonctionnent en tandem avec d'autres techniques d'IA. L'appellation approches statistiques manque en effet de pr cision tandis que l'estimation bay sienne est principalement utilis e avec le machine learning . Enfin, les m thodes de recherche et d optimisation sont utilis es depuis des d cennies dans notre vie quotidienne pour effectuer div ers types de recherche, de formation et d'optimisation . Par exemple, l estimation statistique des syst mes sans fil a t utilis e dans les syst mes cellulaires 2G. Ainsi, t ous les algorithmes de recherche, tous les probl mes d'optimisation, tous les calculs statistiques ne sont pas des applications d'IA. Pour cette raison, nous sugg rons de supprimer le point ( c) de l'annexe I, en se concentrant uniquement sur les approches et techniques d'IA num r es aux points (a) et (b) de l'annexe I. Certaines hypoth ses d applications haut -risque doivent tre clarifi es L AFNUM tient rappeler ici son attachement une approche par le risque et la diff renciation n cessaire entre les applications d IA. Nous souhaitons galement r it rer notre soutien la d finition de certains pr judices graves pour les personnes comme des applications haut -risque (par exemple, des menaces pour la sant , la vie ou les droits fo ndamentaux) et l interdiction de l'utilisation de technologies , telles que la reconnaissance faciale pour la surveillance de masse ou le profilage racial , qui constituent de potentielles violations des droits de l'homme et des libert s fondamentales. Nous sommes en phase avec la Commission pour interdire l'utilisation de syst mes d'IA par les autorit s charg es de l'application de la loi pour l'identification biom trique - sauf dans certai ns cas tr s limit s , avec l application de certaines garanties , comme cela est pr vu dans le projet de r glement. Cependant, certain es applications d IA qualifi es haut -risque selon les processus d crits l article 7 et l annexe III interrogent l AFNUM . En effet, ceux -ci pourraient inclure des utilisations qui ne sont pas haut risque, par exemple dans le domaine des ressources humaines. En outre, certain s cas d applications haut -risque doivent tre clarifi s . La notion de safety component ainsi que celle de road traffic 2 sont pr ciser, leur incertitude pouvant pr senter un probl me de s curit juridique. S il s agit d applications IA int gr es directement dans un v hicule, il y aurait un enjeu de coh rence avec la r glementation homologation (2018/858 ). En effet, certaines applications IA int gr es dans une automobile , par exemple un assistant vocal, ne sont pas couvertes par l homologation parce qu elles n ont pas d impact sur la s curit . D s lors, l a d nomination employ e dans la proposition de R glement manque de pr cision et risque d inclure ces applications dans l ensemble d applications haut -risque , alors que la l gislation sectorielle a consid r que cela n tait pas n cessaire . Cela aurait pour cons quence de soumettre toutes ces applications une processus de certification. Ainsi , il conviendrait de pr ciser quel type d application est vis par la d nomination employ e dans la proposition de r glement et pr ciser s il s agit des applications d j int gr es dans le v hicule, qui sont soumises une homologation sous l gislation sectorielle et devraient donc exclues du champ d application du p r sent r glement ou bien s il s agit d applications non int gr es directement au v hicule, mais qui, ayant un impact sur l infrastructure routi re, serait soumises au pr sent r glement en vertu de l annexe III. L Annexe III gagnerait ainsi en clart en ex cluant les applications int gr es dans les v hicules et pour que les applications concernant la gestion de l infrastructure routi res soient limit es celles qui ne 2 AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity sont pas int gr es dans les v hicules et qui sont d velopp es avec un usage pr vu ( inten ded use ) clairement li la s curit et qui actionnent des composants d infrastructure routi re. Plus largement, la Commission devrait envisager de r duire la liste des syst mes d'IA de l'annexe III afin qu'elle n'englobe que les syst mes d'IA qui pr sentent des ""risques lev s"" syst miques pour les personnes physiques qui interagissent avec eux. Il est n cessaire d assurer une c oh rence entre les textes Par ailleurs, il nous appara t important de rappeler que, bien que cette proposition de R glement s inscrive dans un contexte r glementaire global, les liens avec les autres textes mentionn s dans l explanatory memorandum (Digital Services Act, RGPD, Data Governance Act etc.) manquent de lisibilit . En effet, le texte voque peu l acc s a ux donn es, pourtant essentiel au fonctionnement de l IA, en renvoyant trop implicitement aux pr c dentes ou prochaines volutions r glementaires. Il appara t ici primordial de rendre l ensemble de ces l ments coh rents et clairement lisibles afin d assurer la s curit juridique de l ensemble des acteurs. De m me fa on, la pr sente proposition de R glement n aborde pas la question des responsabilit s, trait es dans un autre texte annonc d ici la fin de l ann e 2021 ( Liability Act ). Sur ce point, l AFNUM recommande de conserver la logique de clart et de s curit juridique qui a pr sid jusqu alors la d finition des responsab ilit s du fait des produits d fectueux (Directive 85/374/CE3), qui est parfaitement adapt e aux d fis pos s par l mergence de nouvelles technologies . De ce point de vue, la d finition d un usage intentionn ( intended purpose en anglais) et d un producteur responsable de la mise sur le march va dans la bonne direction puisqu elle permettrait de clarifier les r les et responsabilit s . N anmoins, la complexit des chaines de valeurs de l utilisation de logiciels et d applications d Intelligence Artificielle devrait tre prise en compte. La d finition large de syst me d'IA et, par la suite, de fournisseur ( provider en anglais) , ne permet pas de d terminer efficacement q uels syst mes d'IA et quelle s entit s (fournisseurs) entreraient dans le champ d'application du r glement. Pour cette raison, nous sugg rons que le r glement clarifie la diff renciation des r les dans la cha ne de valeur de l'IA, de sorte que les entit s d veloppant des bo tes outils ou des biblioth ques logicielles d IA usage g n ral ne soient pas consid r es comme des providers . Par exemple, la proposition de r glement pourrait pr ciser que ces tiers concern s ne sont pas consid r s comme des fournisseurs de syst mes d'I A au sens du r glement , car ces entit s ne seront pas en mesure de d terminer l avance l utilisation pr vue de leurs outils IA et ne pourraient donc pas pr voir une utilisation haut -risque ou emp cher une mauvaise utilisation raisonnablement pr visib le . Sur ce point -l , nous sugg rons aussi que le r glement pr voit la possibilit pour les fournisseurs de syst mes d IA et leurs utilisateurs de r partir contractuellement leurs responsabilit s. Les utilisateurs sont en effet souvent mieux plac pour a ssurer le respect de certains exigences dans la pratique (par exemple, la transparence, la surveillance humaine, la cybers curit , etc.). 3 Directive 85/374/CEE du Conseil du 25 juillet 1985 relative au rapprochement des dispositions l gislatives, r glementaires et administratives des tats membres en mati re de responsabilit du fait des produits d fectueux Les obligations pour les applications haut -risque doivent tre affin es. L AFNUM soutient plusieurs des obligations pr vues par la proposition de R glement, notamment pour les applications haut -risque. Certaines d entre elles sont d j mises en uvre par plusieurs de nos adh rents afin de s curiser leurs produits, tel que le risk-management pr vu l article N anmoins , si plusieurs de ces obligations, telles que l es obligations de transparence (article ou de supervision par l individu (article , semblent tre de r els outils pour aider d velopper la confiance dans l IA et contribuer son d veloppement, certaines de ces mesures doivent tre clarifi es pour assurer la s curit juridique des fournisseurs d applications IA. En effet, les obligations de record -keeping (article , par exemple , interrogent les responsabilit s de chaque acteur (fournisseur et utilisateur de l application IA), ainsi que la faisabilit de l enregistrement de telles donn es. De m me mani re, si certaines obligations, telle que le risk- management , sont d j appliqu es pour des produits actuellement sur le march , leur transcription aux nouveaux produits mis sur le march pose la question de la mise en uvre les processus actuels peuvent -ils tre tendus tels quels aux nouveaux produits ? Le record keeping et le risk management devraient suivre les proc dures d finies dans les l gislations sectorielles r f renc es l Annexe II pour les applications haut -risque que cette Annexe couvre. Parall lement, les applications stand alone list es l Annexe III qui, elles, ne sont pas soumises de telles obligations, n cessiteront la d finition de proc dures claires, pour une mise en uvre dans les meilleures conditions. Enfin, la notion de free of error 8 figurant l article 109 au sujet de la g estion des donn es , appara t impossible garantir pour les fournisseurs d applications IA sans une d finition plus pr cise de sa mesure . Ind pendamment de l impossibilit d assurer juridiquement une absence totale d erreur, cette mesure ne prend pas en compte l hypoth se d applications IA aliment es par les donn es des clients sur lesquelles le fournisseur n a pas d e moyens de contr ler le taux d erreur . Une possibilit serait alors de s inspirer d autres processus de certification pendant lesquels un pourcen tage limite d erreur ne pas d passer est fix sur un chantillon donn pour que le test soi t valid . L AFNUM recommande donc une clarification des obligations pr vues aux articles 10 et 12 . 4 A risk management system shall be established, implemented, documented and maintained in relation to high -risk AI systems 5 High -risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to interpret the system s output and use it appropriately. An appropriate type and degree of transparency shall be ensured, with a view to achieving compliance with the relevant obliga tions of the user and of the provider 6 High -risk AI systems shall be designed and developed in such a way, including with appropriate human -machine interface tools, that they can be effectively overseen by natural persons during the period in which th e AI system is in use. 7 High -risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events ( logs ) while the high -risk AI systems is operating. Those logging capabilities shall conform to recognised stan dards or common specifications. 8 Training, validation and testing data sets shall be relevant, representative, free of errors and complete. 9 High -risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to Les m canismes de certification sont au service de la s curit juridique des produits uniquement Nous saluons le processus propos pour que les entreprises utilisent des normes harmonis es et proc dent une valuation de la conformit de certains de leurs produits , y compris par une auto - valuation lorsque c ela est pr vu par les l gislation s sectorielles . Ces m canismes , rassembl s au sein du New Legislation Framework pour le march europ en , se sont av r s efficaces pour stimuler l'innovation , d velopper et mettre sur le march europ en des technologies s res et fiables . Le syst me des organismes d' valuation de la conformit est bien tabli et efficace. Ces m canismes sont d ailleurs d j mis en uvre et bien maitris s par les adh rents de l AFNUM. Cependant, le process us de certification, tel que d crit dans la proposition de R glement, semble tre un processus lourd et co teux pour les nouveaux produits et nouveaux acteurs sur le march , ce qui pourrait constituer un frein l innovation. De plus , au regard de la d fin ition donn e pour les applications d IA ( AI system ), de tels m canismes de certification s appliqueraient aussi bien aux produits qu aux logiciels. Dans la seconde hypoth se, l AFNUM s interroge sur le fait que ces standards soient applicables en l ta t aux logiciels , notamment lorsqu ils concernent les algorithmes ou les jeux de donn es . Aussi, il appara t essentiel d accorder un d lai suffisant afin de mettre en uvre ce processus et de s interroger sur la coh rence des normes avec la r alit du march et de la technologie vis e . Par ailleurs, il n y a pas de processus d valuation de la conformit (auto - valuation ou certification) sans standard international . Ces derniers devraient tre pris en compte pour d finir les r gles. Enfin, la notion d e composant de s curit ( safety component en anglais) gagnerait tre clarifi e et mise en coh rence avec le cadre europ en de la s curit des produits. La d finition pourrait tre sujette interpr tation et devenir une source d'incertitude pour la d finition des syst mes d'IA haut risque. Pour r duire cette ambigu t , nous pensons qu'il est important que l' valuation d'un composant de s curit renvoie la l gislation harmonis e de l'Union , pour s'aligner sur toutes les exigences essentielles pert inentes . En d'autres termes, lors de l' valuation d'un syst me d'IA aux fins de l'article 6, paragraphe 1, un composant de s curit doit tre d fini tel qu il l est dans la l gislation d'harmonisation de l'Union pertinente num r e l'annexe II. Un cadre pour la transparence et pour l innovation favorable aux entreprises L AFNUM soutient les principes de transparence et d explicabilit en mati re d IA pr vus par le texte (article . Il est primordial, pour d velopper la confiance dans cette tech nologie, que les consommateurs soient inform s qu ils interagissent avec une IA , m me pour des applications risque faible . L AFNUM s interroge toutefois sur la formulation unless this is obvious from the circumstances and the context of use (article 52, alin a , qui semble exon rer les utilisateurs d IA de l obligation 10 Providers shall ensure that AI systems intended to interact with natural persons are designed and developed in such a way that natural persons are informed that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. d informer les consommateurs de leur interaction avec une application d IA . Cette formulation nous para t tre source d ins curit juridique du fait de son manque de clart . Enfin, l AFNUM salue vivement l approche privil gi e par la Commission s agissant des applications ne pr sentant pas de risque, savoir les incitations adopter des codes de bonne conduite ainsi que les mesures en faveur de l innovation (Article . Les bacs sable r glementaires sont des outils propices au d veloppement d une technologie encore jeune . Sur l innovation, l AFNUM note que les petit es entreprises sont, juste titre , privil gi s. Il conviendrait toutefois que le cadre r glementaire permette plus ais ment les collaborations entre les acteurs de diff rentes tailles afin d am liorer l acc s l innovation et le d veloppement des applications d intelligence artificielle . A propos de l AFNUM L AFNUM (Alliance Fran aise des Industries du Num rique) repr sente, en France, les industriels du secteur IT, des r seaux, de l lectronique grand public, de l impression, de la photographie et des objets connect s. Le poids conomique des 56 entreprises adh rentes de l AF NUM est de 000 emplois directs et de 000 emplois indirects et induits en France pour 26 milliards d euros de chiffre d affaires. L AFNUM est membre de la FIEEC, du MEDEF et de Digitaleurope. (Airbus DS, Alcad, Alcatel Lucent Enterprise, Amazon, Apple , Art -Fi, Brother, Cae, Canon, Cisco, Continental, Crosscall, Dell, Doc up, Epson, Erard, Ericsson, FP Francotyp -Postalia, Fracarro, Fujifilm, HP, IBM, Intel, Kodak alaris, Leica, Lenovo, Lexmark, LG, Lumiere Imaging, Microsoft, Nikon, Nokia, Oppo, Optex N ormand, Panasonic, Quadient (ex -Neopost), Qwant, Ricoh imaging, Samsung, Sequans Communications, Sigma, Sony, Storit.io, Tamron, TCL, Technicolor, Televes, Tetenal, Toshiba, Trax, Triax, Verbatim, Vitec Imaging Distribution, WDC, WISI) 11 AI regulatory sandboxes established by one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan.",fr
Numeum (France),F2663064,26 July 2021,Trade union,Small (10 to 49 employees),France,"Contribution de Numeum au Artificial Intelligence Act (AI Act) Context e Dans la continuit du livre blanc sur l intelligence artificielle (IA), la Commission europ enne a pr sent , le mercredi 21 avril, une proposition de r glement pour l tablissement de r gles harmonis es en mati re d IA, aussi intitul e Artificial Intelligence Act. Avec cette initiative, la Commission propose de nouvelles r gles visant faire de l'Europe la place mondiale de l IA de confiance . La proposition pr vo it notamment : Des exigences relatives aux utilisations de l'IA haut risque ; L interdiction de certaines utilisations de l IA ; L autor gulation sur les IA dites faible risque ; La cr ation d un Conseil de l IA anim par les 27 Etats membres. Numeum soutient la Commission europ enne dans son ambition de stimuler le d veloppement et l'adoption de l'IA et des nouvelles technologies, tout en veillant ce que les risques potentiels soient trait s de mani re ad quate. Ainsi, la volont de la Commission de cr er un syst me europ en m me de garantir la confiance des citoyens et stimuler l adoption des usages IA, tout en assurant celle des entreprises dans le d ploiement de leurs produits et applications IA et la capacit d innovation en Europe , nous appara t une strat gie ambitieuse et adapt e aux enjeux de d veloppement du potentiel de l IA en Europe. L UE a les moyens de devenir un a cteur mondial de l IA. Cela suppose une am lioration de l'acc s aux donn es et la collaboration entre les entreprises, ce qui contribuera la transformation num rique de l'Europe. L UE et les Etats membres doivent pleinement s engager dans cette transitio n, par des investissements massifs dans les technologies et les infrastructures qui permettront l'Europe de d velopper ses atouts en mati re d IA, notamment pour la formation des chercheurs et ing nieurs et l accompagnement de l volution des m tiers con cern s. Numeum appelle continuer fa onner une approche europ enne de l IA ouverte et inclusive qui favorise l innovation tout en assurant la sauvegarde des droits fondamentaux. En somme, doter l IA d une triple dimension qui soit culturelle, thique et juridique. Compte tenu de la diversit des applications et des technologies de l'IA, nous saluons le fait que la Commission adopte une approche cibl e et fond e sur les risques. Une telle approche devrait tre bas e sur des d finitions claires et prendre en compte le risque pos par le d ploiement d'un syst me d'IA, le domaine d'application, le type de d ploiement et la nature des risques. Dans cette optique, Numeum et ses adh r ents souhaitent r it rer ici l attention port e l adoption d une approche pragmatique et quilibr e dans la d finition du nouveau cadre r glementaire par la Commission europ enne. Afin de garantir la praticabilit de certaines dispositions du r glement, l valuation des risques pos s par un syst me d IA doit n cessairement tre limit e aux risques connus et pr visibles associ s chaque syst me d IA haut risque. Enfin, notre organisation souhait e poursuivre son implication vis - -vis des travaux et des r flexions conduits par la Commission europ enne , le Parlement et le Conseil dans le cadre de cette initiative. 2 Champ d application et d finitions : Il semble n cessaire que le champ d application de la proposition de r glement , les d finitions et la distinction entre les acteurs soient pr cis s. Evaluation des risques : Afin de garantir la praticabilit de certaines dispositions d e la proposition de r glement, nous consid rons que l valuation des risques pos s par un syst me d IA d oit n cessairement tre limit e aux risques connus et pr visibles associ s chaque syst me d IA haut risque. Gouvernance : Un cadre d'application aussi complexe avec de nombreuses autorit s diff rente s entra nera un chevauchement des comp tences. Pour des raisons de s curit juridique et afin d'assurer une surveillance r glementaire fluide, il est essentiel qu une autorit soit identifi e comme un point de contact unique vis - -vis de l'o rganisation concern e. Responsabilit : Une r partition plus claire des responsabilit s entre le fournisseur et l utilisateur correspondrait davantage la r alit du d ploiement de l IA et sa mise sur le march . Cette r partition pourrait s inspirer du RGPD, en reconnaissant que l valuation de conformit doit tre entreprise par l entit d finissant l usage de l IA dans un des domaines identifi s . PME : Les plus petites entreprises auront besoin de conseils, de soutiens financiers, ainsi que de processus simples et rationalis s pour tre en mesure de r pondre aux exigences. De mani re g n rale, des co ts de mise en conformit lev s pourraient tre attendus et pourraient rester lev s m me apr s la mise sur le march d'un syst me d'IA. Coh rence r glementaire : Il conviendra d assurer une coh rence entre les diff rents textes l gislatifs en cours et venir, notamment sur l acc s et le partage des donn es (Data Act, Data Governance Act, etc.) et sur l IA (R glement sur la responsabilit civile, R glement sur la responsabilit du fait des produits, etc.). La question des donn es est centrale et la connexion entre le AI Act et le Data Act sera cl . Innovation : Il convient de veiller ce que les nouvelles r glementations mergentes ne tendent pas complexifier l innovation par l IA dans l U nion europ enne , et permette au contraire de promouvoir l utilisation de technologies de pointe . L approche par les risques La Commission europ enne propose de d velop per et graduer la r gulation europ enne en mati re d IA selon une approche bas e sur le niveau de risque , avec une classification quatre niveaux : les pratiques d IA interdites (Article , les s yst mes d IA haut risque (Titre , les s yst mes d IA avec des obligations de transparence sp cifiques (Titre et toutes les a utres syst mes IA (sans risques) . Numeum se f licite que la Commission adopte une approche fond e sur le risque et reste attentif ce que les nouvelles exigences soien t suffisamment simples et claires, et que la mise en uvre de l initiative soit suffisamment ambitieuse pour accompagner l'Europe devenir un p le mondial de l'IA. Dans nos prises de positions pr c dentes sur le livre blanc sur l IA1, nous plaidions pour l adoption d une approche proportionn e visant r guler les cas d'utilisation haut risque et non la technologie d'IA. Dans ce cadre, il semble essentiel que le champ d application , les d finitions et la distinction entre les acteurs soient pr cis s . Certaines d finitions ( intelligence artificielle , wifi , 1 Nos r ponse s la consultation sur le livre blanc sur l IA (ici et ici) 3 technique subliminale , pratiques manipulatrices , mauvaise utilisation raisonnablement pr visible , syst me d identification biom trique distance au-del de la cons cience d'une personne , alt rer mat riellement le comportement d'une personne , susceptible de causer un pr judice psychologique etc.) restent tr s larges ou trop vagues . La d finition des syst mes IA haut risque ainsi que la liste des techniques couvertes (Annexe s I et III) restent aussi pr ciser . A titre d exemple, les cas d'IA pour le domaine de l'emploi mentionn s l'annexe III couvrent un large ventail de syst mes, comme la r partition des t ches, dont certains ne sont pas dangereux (par exemple, le routage des appels t l phoniques) et d'autres pourraient l' tre (r partition des quipes et ges tion du temps). Sans qualificatif, cette section engloberait trop de syst mes ne pr sentant pas de risque lev . Par cons quent, et afin d' viter une surr glementation , cette annexe devrait tre limit e aux cas pouvant causer un pr judice. Avec une d finit ion et une liste aussi tendue s, le risque est de faire entrer de nombreuses applications dans le champ d application du Titre III et ainsi de faire peser d importantes obligations aux acteurs concern s, mais galement de susciter un large contentieux de qualification de syst mes d IA (l IA est -elle haut risque ou non, et son fournisseur tait -il redevable des obligations associ es ou non) . La d finition des syst mes d IA haut r isque aura pour effet de faire peser d importantes obligations de tr s nombreux acteurs , avec comme cons quence un ralentissement de l innovation. Une balance b n fice/risque des volutions technologiques devrait tre mise en place en vue de promouvoir l innovation. En l tat des mesures propos es par le texte, il existe un risque de limitation de l innovation. Nous regrettons que le texte ne connaisse pas plus de dispositions de partage de bonnes pratiques qui pourraient permettre de mieux promouvoir le d veloppement de solutions innovantes et de confiance. Pour mettre jour la liste des syst mes d IA haut risque (Annexe III), la Commission pr voit l adoption d actes d l gu s . Bien qu il soit n cessaire pour l a proposition de r glement de tenir compte des volutions technologiques , ces actes d l gu s pourraient tre source d ins curit juridique. La fa on dont les r gles et conditions s appliquent l'IA usage g n ral pourrait galement tre clarifi e ; le fournisseur ne peut en effet pas savoir l'avance si l'utilisation sera haut risque et ne peut pas dicter l'utilisation exacte du syst me par l'utilisateur . Concernant les utilisations de l IA faible risque, n ous soutenons les obligations minimales de transparence . Compte tenu du faible risque associ , i l convient de limiter au maximum les obligations pour de telles IA . Certaines obligations relatives aux syst mes IA haut risque doivent tre revues ou pr ci s es pour tre plus praticables : Il est difficile pour un d veloppeur d un syst me d IA d imaginer l ensemble des mauvaises utilisations raisonnablement pr visibles, qui sont souvent con ues par des personnes aux intentions frauduleuses. L valuation des risques pos s par un syst me d IA doit n cessairem ent tre limit e aux risques connus et pr visibles associ s chaque syst me d IA haut risque (article . La proposition de r glement impose une obligation d utiliser des ensembles de donn es sans erreur (article , ce qui est en pratique irr alisa ble. L'apprentissage supervis repose sur de grandes quantit s de donn es tiquet es par l' Homme. M me s'il tait possible de d finir des cat gories compl tement non ambigu s, tout processus pilot par l' Homme contiendrait des erreurs. De plus, dans la plupart des cas, il est impossible d'avoir des cat gories compl tement 4 non ambigu s, ce qui signifie que m me les tiqueteurs humains les plus experts ne seront pas d'accord et feront des erreurs. Une norme sans erreur rendrait l'apprentissage supervis impossible et exclurait certaines des avanc es les plus prometteuses de la recherche en IA. On peut notamment citer l exemple de la sant . Plus g n ralement, les obligations de l article 10 sont peu claires. A titre d exemple , l obligation que les datasets d entrainement poss dent les propri t s statistiques appropri es est difficilement compr hensible . Une approche plus r aliste et pragma tique consisterait ce que la proposition de r glement demande aux fournisseurs de faire des efforts raisonnables pour atteindre les objectifs de l'article En outre, l article 10( indique que dans la mesure o cela est strictement n cessaire pour assurer la surveillance, la d tection et l a correction des biais en relation avec les syst mes d'IA haut risque, les fournisseurs de ces syst mes peuvent traiter les cat gories particuli res de donn es caract re personnel vis es . Sur ce point, il conviendrait d inclure explicite ment dans le texte une base l gale pour le traitement des cat gories sp ciales de donn es personnelles pour la surveillance des biais des syst mes d'IA, afin de clarifier que ce traitement est autoris par le RGPD . L obligation de tenue d une documentation technique avant toute mise en service est impraticable pour des startups et des jeunes soci t s, qui ont par d finition besoin de tester leur produit pour it rer dessus avant ouverture plus large au march (article . De la m me mani re, l article 14 impose le recrutement tr s t t dans le d veloppement d une soci t de personnel hautement qualifi , peu compatible avec le statut de startup . Les menaces de cybers curit tant en perp tuelle volution, il est inconcevable de garantir qu un syst me infor matique, quel qu il soit, est inviolable. Il convient d assouplir les formulations de l article 15, notamment en s inspirant de l article 32 du RGPD. La proposition de r glement pr voit que les autorit s de surveillance des march s puissent acc der aux ensembles de donn es de formation, de validation et de test utilis s par le fournisseur . Lorsque cela est n cessaire et sur demande motiv e pour valuer la conformit du syst me d'IA haut risque avec les exigences de la proposition de r glement , les au torit s de surveillance peuvent se voir accorder l'acc s au code source du syst me d'IA. A ce stade, cela soul ve un certain nombre de questions . tant donn qu un mod le commercial sp cifique peut tre r glement par diverses autorit s de march lorsqu une entreprise op re sur plusieurs march s simultan ment, il sera essentiel de clarifier quelle autorit de surveillance sera autoris e superviser l'IA d velopp e pour un type d activit s donn . De plus, les sanctions devraient tre impos es sur la base d'un catalogue clair, bas sur des infractions sp cifiques num r es. Nous nous inte rrogeons sur la justification technique d acc der aux codes sources du fournisseur dans le cadre d e la proposition de r glement. Si l acc s aux codes sources constitue un risque pour le fournisseur lui -m me , il peut aussi constituer un r el frein l innovation en mati re d Intelligence Artificielle. Il semble difficile de mettre disposition un code source m me une autorit publique ou un organism e notifi . Cette mesure ne semble pas respecter les dispositions en mati re de cybers curit ainsi que le principe de proportionnalit au regard de l utilit de cette d marche. Il n est pas certain que les autorit s de surveillance auront m me les capacit s techniques pour valuer les codes sources. 5 Il est galement n cessaire de clarifier la mani re dont devront se coordonner les autorit s de protection des donn es personnelles et les autorit s de surveillance des march s comp tentes, lorsque de tels cas de co -comp tence surviendront. Aussi, il convient de se demander quel traitement sera donn aux syst mes d IA uniquement aliment s par les donn es des clients, et non par celles du fournisseur. Responsabilit s des fournisseurs et des utilisateurs La proposition de la Commission europ enne comprend une s rie d obligations incombant aux fournisseurs de syst mes d IA avant leur mise sur le march . Apr s avoir d termin que le syst me d IA peut tre consid r haut risque, le fournisseur doit entreprendre une proc dure d valuation de conformit et s assurer que son syst me d IA remplit toutes les obligations en termes de transparence, de gouvernance des donn es, etc. L utilisateur de l IA est quant lui soumis des obligations li es la bonne utilisation du produit ou du service. Cette r partition des responsabilit s entre les fournisseurs et les utilisateurs d IA manque de clart , ce qui pourrait poser des difficult s . Les diteurs de logiciels int grant des fonctionnalit s d IA leurs produits ne sont pas en mesure d anticiper la fa on dont ces syst mes d IA seront mis en uvre par leurs clients. Ils ne peuvent donc pas anticiper le degr de risque et entreprendre une valuation de conformit pour des utilisations hypoth tiques de leurs produits, et sur lesquelles ils ont peu , voire pas de contr le. Dans cette logique, cela ne permettra pas de soumettre les datasets aux r gles de gouvernance nonc es dans la proposition (Article . La question de l organisation informatique de l entreprise utilisatrice et de la multiplicit des briques logiciels se pose galement . De nombreux syst mes d IA se basent sur des datasets diff rents , qui peuvent co -exister pour un e m me utilisation. Si le fournisseur fournit l outil , il ne peut pr dire la fa on dont les donn es seront trait es. Le cas le plus vident est celui du machine learning qui est capable de reproduire un comportement gr ce des algorithmes, eux- m mes aliment s par un grand nombre de donn es. Lorsqu il est confront de nombreuses situations, l'algorithme apprend quelle est la d cision adopter et cr un mod le. Concernant la distinction des technologies d IA, le cas par cas reste cl . La question de la responsabilit se pose d autant plus que certaines utilisations d IA sont la main des utilisateurs. Il n est pas rare que l entreprise utilisatrice d veloppe avec le fournisseur son syst me d IA et qu il ajoute par la suite de nouvelles briques technologiques. Dans ce cas pr cis, le fournisseur n est pas toujours impliqu dans le formatage ex ante. De plus, dans certains secteurs ( par exemple le secteur bancaire), il est compliqu d avoir acc s aux donn es et donc de comprend re comment les datasets sont construits . Une r partition plus claire des responsabilit s entre le fournisseur et l utilisateur correspondrait davantage la r alit du d ploiement de l IA et sa mise sur le march . Il s agit avant tout de d terminer quelle est l entit la plus comp tente pour d terminer le niveau de risque de l IA. Cette r partition pourrait s inspire r du RGPD, en reconnaissant que l valuation de conformit doit tre entreprise par l entit d finissant l usage de l IA dans un des domaines identifi s l Annexe III. A ce titre, l entit d terminant l usage du syst me d IA pourrait s apparenter au conce pt de contr leur dans le RGPD. En appliquant la dichotomie contr leur/processeur l utilisation de l IA, le contr leur aurait le statut de l utilisateur d IA ( par exemple, une banque appliquant un syst me d IA pour les octrois de pr ts), et le processeur serait le d veloppeur/fournisseur du syst me d IA. Il ne s agit pas pour les fournisseurs de se d charger 6 de leurs responsabilit s , dans la mesure o ils restent pertinents pour expliquer comment le syst me d IA a t labor (Article , ses c apacit s et ses limites, ainsi que les conditions optimales de son utilisation. L article 28, qui pr voit de faire basculer la responsabilit du fournisseur vers l utilisateur dans certaines circonstances (notamment quand l utilisateur reprend sous son n om le syst me d IA pour le placer sur le march ), ne semble pas adapt . Nous recommandons d ajouter une cat gorie suppl mentaire l article 28 pour couvrir les cas o un utilisateur d IA ou un tiers utilise ou modifie un syst me d IA usage g n ral d une mani re qui le rendrait haut risque. Dans ces circonstances, l utilisateur ou les tiers seraient consid r s comme le fournisseur d IA selon les termes d e la proposition de r glement. Les syst mes d IA usage g n ral pourraient tre d finis comme des syst mes d IA d velopp s sans usage pr d termin dans un secteur sp cifique. Les articles 9, 19 et 43 pr voit pour les op rateurs l obligation de mener des analyses de risque et de conformit l ensemble des l gislations app licables. Au vu des similitudes que le AI Act peut avoir avec le RGPD, on peut consid rer qu une analyse d impact relative la protection des donn es (AIPD) est n cessaire dans les cas notamment o un projet comprend une innovation technologique et en la mati re quel que soit le nombre de conditions remplies, une telle analyse est pr conis e lors de l utilisation d une IA. On peut se demander si l AIPD pr vu l article 35 du RGPD sera compl t e ou si une autre analyse sera pr vue. On peut se demander quel le sera l articulation de l analyse de risques et de conformit fix e par le texte et l AIPD pr vue l article 35 du RGPD . La question du r le largi du DPO pourrait galement se poser. Enfin, il convient de se demander qui sera en charge au sein de l organisation de proc der l valuation de la conformit et de rendre des avis sur les projets faisant appel l IA . Impact sur les PME et l innovation La Commission europ enne encourage les tats membres mettre disposition des entrepri ses des bacs sable r glementaires pour tester les syst mes d IA avant leur mise sur le march . Elle souhaite galement r duire le poids r glementaire induit par ce nouveau projet de r glement sur les PME et les start-ups. Nous saluons les mesures de soutien l innovation propos es par la Commission. La pratique des bacs sables r glementaires doit tre encourag e. Cela permet aux entreprises, notamment les startups et les PME, de tester les nouvelles technologies qu elles d veloppent avant de les lancer sur le march . Cette d marche de r glementation permet notamment aux entreprises innovantes de b n ficier d un all gement des obligations relatives la protection des donn es personnelles, afin de tester leurs produits ou services. Dans ce cadre, l es entreprises peuvent se faire accompagner pour tre conformes aux r gles de protection des donn es tout en innovant, et sans risqu er de sanctions. Un tel dispositif est donc positif tant pour les entreprises que pour les citoyens, car l innovation n irait pas l encontre de leur protection. Pour les applications d IA qui ne sont pas d j soumises une valuation de conformit , il conviendrait que cette valuation ex ante prenne la forme d'une auto - valuation et soit combin e une valuation ex post, lorsque des probl mes sont identifi s. Il est en effet indispensable que les l gislations venir sur l IA (AI Act, l gislation sur la responsabilit de l IA, etc.) soient proportionn es et ne soient pas trop complexes mettre en 7 uvre par les PME, afin de ne pas les p nalise r et de s timuler l innovation, en donnant aux entreprises la s curit juridiq ue n cessaire. Ce nouveau cadre r glementaire devra galement viter de faire peser sur les entreprises des contraintes disproportionn es. Les plus petites entreprises auront besoin de conseils, de soutiens financiers, ainsi que de processus simples et ra tionalis s pour tre en mesure de r pondre aux exigences. De mani re g n rale, d es co ts de mise en conformit lev s pourraient tre attendus et pourraient rester lev s m me apr s la mise sur le march d'un syst me d'IA . L'impact pourrait tre similaire celui du RGPD pour les PME et startups , ce qui nous am ne nous interroger sur le niveau de sanction qui semble lourd . Compl t avec les sanctions pr vues par le RGPD, certaines entreprises pourraient conna tre des diff icult s importantes. Sanctifier des secteurs pourrait repr senter un co t d entr e trop lev pour les plus petites entreprises . A titre d exemple, dans le domaine des infrastructures de transport, le fait d impose r une startup de s aligner avec les di spositions du AI Act avec toutes les obligations post - markets s y rattachant, l entreprise pourrait avoir moins d int r t d velopper son produit en Europe. On prend ici l exemple des transports de fa on global, or, les sources de donn es sont diff rentes entre celles du v hicule autonome, des objets connect s sur la voierie ou m me de reconnaissance de la couleur d une carrosserie de v hicule. Au-del des dispositions r glementaires, il serait int ressant que la proposition de la Commission aille encore plus loin dans la promotion de l innovation en Europe, en proposant par exemple une s rie de programmes pilotes pour la promotion de l IA dans des secteurs -cl s (sant , secteur public, lutte contre le changement climatique, etc .) et en fournissant des guides de bonnes pratiques pour les start -ups et les PMEs, ainsi que des conseils pour acc der aux financements europ ens disponibles. Acc s au march unique et marquage CE Marquage CE La proposition de r glement pr voit que les syst mes d'IA haut risque porte nt le marquage CE pour indiquer leur conformit au r glement afin qu'ils puissent circuler librement dans le march int rieur (article 49 ). Les fournisseurs de syst mes d'IA haut ri sque devront veiller ce que leurs syst mes soient soumis la proc dure d' valuation de la conformit (article avant leur mise sur le march ou leur mise en service. Lorsque l eur conformit aux exigences a t d montr e la suite de cette valuation de la conformit , les fournisseurs tablissent une d claration UE de conformit conform ment l'article 48 et apposent le marquage CE de conformit conform ment l'article En ce qui concerne la port e extraterritoriale du r glement, il sera galeme nt attendu que la Commission aborde les aspects de responsabilit li s aux technologies d'IA d velopp es en dehors de l'Union europ enne dans le cadre de la proposition de r glement sur l'IA, en vue de compl ter le projet de r glement d di aux aspects de responsabilit juridique du d veloppement de l IA. 8 Monitoring post market La proposition d finit des exigences communes obligatoires applicables la conception et au d veloppement de certains syst mes d'IA avant leur mise sur le march . La Commission propose galement de d finir la situation apr s la mise sur le march des syst mes d'IA en harmonisant la mani re dont les contr les ex post sont effectu s. Ainsi, tous les fournisseurs devront disposer d'un syst me de surveillance apr s la commercialisation de leur syst me . La Commission souhaite ainsi garantir que les risques ventuels li s aux syst mes d'IA qui continuent apprendre apr s leur mise sur le march ou leur mise en service puissent tre trait s plus efficacement et plus rapidement. Dans ce contexte, les fournisseurs seront galement t enus de mettre en place un syst me permettant de signaler aux autorit s comp tentes tout incident grave ou toute violation du droit national et de l UE prot geant les droits fondamentaux r sultant de l'utilisation de leurs syst mes d'IA. L'application ex p ost devra garantir qu'une fois le syst me d'IA mis sur le march , les autorit s publiques disposent des pouvoirs et des ressources n cessaires pour intervenir au cas o les syst mes d'IA g n rent des risques inattendus, qui justifient une action rapide. El les contr leront galement le respect par les op rateurs des obligations qui leur incombent. La proposition ne pr voit pas la cr ation automatique d'organismes ou d'autorit s suppl mentaires au niveau des tats membres. Les tats membres peuvent donc d sig ner (et s'appuyer sur l'expertise) des autorit s sectorielles existantes, qui seraient galement charg es de contr ler et de faire appliquer les dispositions d e la proposition de r glement. Il conviendra d assurer une coh rence entre les diff rents textes l gislatifs en cours et venir , notamment sur l acc s et le partage des donn es (Data Act, Data Governance Act, etc .) et sur l IA (R glement sur la responsabilit civile, R glement sur la responsabilit du fait des produits, etc.). Aujourd hui, les domaines d application et usages potentiels d une IA sont de plus en plus divers (compr hension du langage naturel, reconnaissance visuelle, robotique, syst me autonome, machine learning). Dans le cas du machine learning , la qualit des donn es , le training pattern de ces donn es et donc les data sets propos s la machine , sont essentiels . Comme indiqu pr c demment, l es entreprises qui fournissent les solutions d IA n ont pas forc ment la possibilit d y acc der une f ois cr es . A titre d exemple, l entreprise A fournit une solution d IA une entreprise B pour valuer l impact d un produit sur un consommateur (on peut citer l exemple d un produit cosm tique) . Si l entreprise A doit v rifier le syst me ex post , cela signifie aussi que l entreprise B donn e acc s de ses datasets l entreprise A . Les consid rations relatives l acc s la propri t intellectuelle peuvent se poser , ce qui pourra poser des diffic ult s dans le monitoring post -market. Si le monitoring post -market est possible dans le B2C, il est plus complexe dans le B2B. On peut galement consid rer que cela pourrait engendrer des effets de bord pour le d ploiement de ces technologies. Ceci est d autant plus complexe qu ouvrir l acc s ses datasets pour une entreprise se heurte aussi la question de la plus-value conomique pour cette entreprise et de la pro pri t intellectuelle . 9 Gouvernance Conseil europ en de l IA Pour garantir l application d e la proposition de r glement, la Commission propose la cr ation d'un conseil europ en de l'IA (European Artificial Intelligence Board), compos de 27 autorit s nationales et de l EDPS (autorit de protection des donn es des insti tutions europ ennes). Pr sid par la Commission europ enne, le Board r digera des lignes directrices destination des Etats membres. Comme pour le RGPD, chaque Etat d signera son autorit charg e de la bonne application du r glement. Une autorit de super vision devra aussi tr e d sign e pour r aliser les notifications et la surveillance du march . Les membres du conseil pourraient avoir une influence sur les utilisations qui seront class es comme haut risque l'avenir. Nous nous interrogeons sur l a utorit (article qui sera charg e d valuer la conformit en la mati re. Il serait opportun de mieux d finir les missions de cette autorit l aune des enjeux de comp titivit internationale et de prendre en consid ration les probl matiques relevant d e l innovation, de la recherche et du traitement de donn es industrielles ou non -personnelles, mais aussi des crit res de confidentialit . Afin d viter les risques de fragmentations dans l application du r glement , il est essentiel que les d cisions des autorit s de contr le nationales soient harmonis es. Hormis la cr ation de ce conseil europ en de l IA, l a notion de gouvernance reste encore assez floue. Un cadre d'application aussi complexe avec de nombreuses autorit s diff rente entra ne ra un chevauchement des comp tences entre les autorit s. Pour des raisons de s curit juridique et a fin d'assurer une surveillance r glementaire fluide, nous pensons qu'il est essentiel qu une autorit soit identifi e comme un point de contact unique vis - -vis de l'organisation concern e . Les autorit s de protection des donn es devraient conserver une comp tence g n rale sur les applications d'IA impliquant le traitement de donn es personnelles. L'article 57 pr voit la possibilit pour le Conseil d inviter des experts externes et des observateurs assister ses r unions et d avoir des changes avec des tiers int ress s pour informer de ses activit s dans une mesure appropri e. Nous souhaiterions que la participation de l'industrie soit plus syst ma tique dans le cadre de la structure permanente du Conseil. Obligations de monitoring et de reporting Afin de surveiller les effets de la proposition , la Commission pr voit la mise en place un syst me d'enregistrement des applications autonomes d'IA haut risque dans une base de donn es publique l' chelle de l'UE. Cet enregistrement permettra galement aux autorit s comp tentes, aux utilisateurs et aux autres personnes int ress es de v rifier si le syst me d'IA haut risque est conforme aux exigences n onc es dans la proposition et d'exercer une surveillance renforc e sur les syst mes d'IA pr sentant des risques lev s pour les droits fondamentaux. Pour alimenter cette base de donn es, les fournisseurs d'IA seront tenus de fournir des informations signif icatives sur leurs syst mes et l' valuation de la conformit effectu e sur ces syst mes. Les fournisseurs de syst mes d'IA haut risque mis sur le march de l'Union signalent tout incident grave ou tout dysfonctionnement de ces syst mes qui constitue une violation des obligations pr vues par le droit de l'Union visant prot ger les droits fondamentaux aux autorit s de surveillance du march des tats membres o cet incident ou cette violation s'est produit. Cette notification est effectu e imm diatement a pr s que le fournisseur a tabli un lien de causalit entre le syst me d'IA et l'incident ou le dysfonctionnement ou la probabilit raisonnable d'un tel lien, et, en tout tat de cause, au plus tard 15 jours apr s que le fournisseur a eu connaissance de l' incident grave ou du dysfonctionnement. 10 Il conviendrait d inclure la proposition de r glement une section sur les obligations de d claration aux autorit s de surveillance du march pour tout incident grave ou tout dysfonctionnement qui constitue une violation des obligations pr vues par le droit de l UE . En l' tat, cette disposition semble excessivement large. Si la notion d'incident grave est suffisamment limit e dans son champ d'application, celle de dysfonctionnement (malfunctioning ) ne l'est pas. Il existe un risque potentiel de chevauchement des obligations de d claration en vertu de s diff rentes l gis lations europ ennes. Il est possible qu'un incident grave impliquant un syst me d'IA puisse donner lieu , par exemple, des obligations de d claration du AI Act et de la directive NIS ou du RGPD . Utilisations de l IA dans des domaines sectoriel s Sant Dans le secteur de la sant , l utilisation de l IA constitue un grand espoir pour am liorer la prestation des soins et la m decine sous conditions de placer l thique et les droits humains au c ur de sa conception, de son d ploiement et de son utilisation. Compte tenu des enjeux concernant la vie et la sant associ s l usage des solutions d aide la d cision utilisant de l IA, notamment d aide au diagnostic, leur pertinence et leur fiabilit doivent tre garanties. La confiance est un l ment primordial tablir pour rassurer les citoyens . Des m canismes d IA locaux, voire embarqu s, sont privil gier notamment quand ils concernent le traitement de donn es personnelles sensibles comme les donn es de sant . Il conviendra toutefois d valuer le risque de d salignement et de duplication avec les r glements existants comme le r glement europ en sur les dispositifs m dicaux. La m thode d valuation des risques d un dispositif m dical est diff rente de celle utilis e dans l IA qui a vocation voluer au cours du temps et donc remettre en question la certification tablie un instant t. De plus , les preuves cliniques de la r glementation des dispositifs m dicaux sont plus difficiles apporter quand une IA calcule des recommandations de traitement par exemple. Dans d autres cas, des applications de sant pourraient entrer dans le champ d applica tion d u AI Act m me si elles ne font pas partie du dispositif m dical . Ceci entrainerait une ins curit juridique pour les prestataires et les organismes comp tents et aurait un impact n gatif sur la classification des risques et les valuations de la conf ormit dans le cadre du dispositif m dical . Par ailleurs, en France, l acc s des datasets par les industriels aux fins de d veloppement de syst mes d IA est encore compliqu . A cet gard, et concernant les datasets pseudonymis s, les caract ristiques de s projets retenus par le Health Data Hub gagneront tre pr cis es et publi es des fins de lisibilit et de s curit juridique. Enfin , il convient galement de veiller ce que les nouvelles r glementations mergentes ne tendent pas complexifier l inn ovation par l IA dans l UE, pla ant celle -ci dans une position d inf riorit technologique au niveau mondial. Compte tenu de l impact potentiel d une telle mise niveau r glementaire et comme indiqu pr c demment , nous soutenons la mise en place de bacs sable r glementaires pour s assurer que les avanc es technologiques se d roulent dans le respect de la r glementation Europ enne et internationale, et des autres l gislations nationales pertinentes. Le d veloppement et l'entr e sur le march de syst m es d'IA vont tre probablement retard s par l'entr e en vigueur du r glement propos . 11 Justice Nous comprenons que le but du texte est de cat goriser comme tant haut risque un syst me de type juge-robot qui prendrait des d cisions judiciaires la place d un humain (applications dites de justice pr dictive ). Cependant, la formulation actuelle des syst mes d IA haut risque dans l administration de la justice est tr s large et susceptible d englober tous syst mes d IA utilis s par les autorit s judiciaires, y compris par exemple des bases de donn es juridiques - qui servent recherc her et interpr ter la loi - ou des plateformes de veille juridique automatis e. Ainsi, i l semble n cessaire de recentrer la d finition des syst mes d IA haut risque dans le secteur de la justice sur les seuls syst mes d IA destin s directement qu alifier juridiquement des faits et proposer des solutions juridiques des situations donn es . Il conviendrait galement de pr ciser la fin du consid rant 40 que les bases de donn es juridiques et les plateformes d intelligence juridique sont exclues de la qualification. A propos de Numeum Numeum est le premier syndicat professionnel des entreprises du num rique en France (issu de la fusion de Syntec Num rique et TECH IN France) . Il regroupe les entreprises de services du num rique (ESN), les diteurs de logiciels, les plateformes et les soci t s de conseil en technologies en France. Numeum repr sente plus de 2 300 entreprises qui r alisent 85% du chiffre d affaires total du secteur en France (soit plus de 60 Md de chiffre d affaires, 530 000 employ s).",fr
EnBW Energie Baden-Württemberg AG (Germany),F2662935,23 July 2021,Company/business,Large (250 or more),Germany,"Juli 2021 1 EnBW R ckmeldung zu EU-KOM Gesetzesv orschlag zu K nstlicher Intelligenz Kontext Aus Sicht der EnBW Energie Baden -W rttemberg AG wurde mit dem Gesetzes vorschlag der EU -Kommis- sion zu K nstlicher Intelligenz (KI), eine Regulierung entworfen, welche Chancen er ffnet. Nach erster Be- trachtung, hiermit unsere erste kurze R ckmeldung aus energiewirtschaftlicher Perspektive sowie dem Betrieb von kritischer Infrastruktur . Hauptempfehlungen W hrend der in weiten Teilen innovationsoffene Charakter des VO -Vorschlags sehr zu begr en ist, k nn- ten nachfolgende Punkte Klarheit und Ziele der VO weiter unterst tzen . Definition von safety component s (Annex III; 2 .a): Eine Abgrenzung von Sicherheitskomponenten k nnte weitergehend Klarheit erzeugen. Bsp. ob Netzplanung, Personal - und Schichtplanung im weitesten Sinne als Sicherheitskomponente z hlt. Dass KI in der Anlagensteuerung im Kraftwerk oder der Netz- leitstelle unter die Kategorie high risk f llt, ist nachvollziehbar eine Abgrenzung oder Abstufung k nnte hier weiter pr zisieren. [ siehe Abbildung mit Anwendungsf llen auf Seite 4] Beispielhafte t echnische Dokumentation zur Pr zision der Anforderungen (Annex IV): Da die Erwartung hinsichtlich des Detailgrades relevant, aber nicht klar ist, w re an dieser Stelle die Zurverf gungstellung eines konkreten Beispiels sinnvoll. Anlaufstelle f r Fragen zu KI-Anwendungen : F r R ckfragen zu konkrete n KI-Systemen in Entwicklung oder im Ideenstatus w re es hilfreich (nationale) Anlaufstelle (n) zu haben, mit der man Frage n diskutie- ren kann . Besonders die Einordnung ob eine KI -Anwendung high -risk oder nicht ist, w re ist hier wich- tig. KI-Systeme zur in ternen Anwendung : Aus Sicht des Anlagenbetriebs (bspw. in der Energiewirtschaft) werden KI -Systeme absehbar, im Wesentlichen, intern verwendet und nicht als Produkt auf einen Markt und in Umlauf gebracht . Gro teils/Weniger (Produkt -)Endkunden, sondern Mitarbeiter sind Nutzer der Systeme (Bsp. KI-basierte I nstandhaltungsp lanung von Gasnetzen) . Eine Abgrenzung von Anwendungs- bereichen von KI k nnte hier sinnvoll sein. Juli 2021 2 Detail lierte Einsch tzung Aus Sicht EnBW positiv und zu begr en: Die M glichkeit zu Inhouse conformity assessments werten wir als innovationsf rd ernd. Aufwand und Hemmnisse werden hierdurch wesentlich reduziert , da keine Abstimmung mit Dritten notwendig ist . Durch interne Pr fung en findet im Unternehmen ebenfalls Wissen s- und Kompetenz aufbau bzgl. der Konformit t statt. Seite ( Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility , with the only exception of AI systems in- tended to be used for the remote biometric identification of persons, for which the involvement of a notified body in the conformity assessment should be foreseen, to the extent they are not prohib- ited. Aus Sicht EnBW besteht Kl rungsbedarf: Bestimmung von Hochrisik o-Anwendungen ; Seite ( und Annex III, 2a As regards the management and operation of critical infrastructure, it is appropriate to classify as high -risk the AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity, since their failure or malfunctioning may put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities . F r uns w re eine Hoch -Risiko Anwendung durch KI, bspw. eine autonome (Strom -)Netzsteuerung. Keine Hoch -Risikoanwendungen w ren bspw. KI-basierte Erkennung von Sch den an Masten und Freileitungen oder Handelsalgor ithmen ( z.B. im physische n kurzfristige n Stromhandel). Seite The definit ion should be based on the key functional characteristics of the software, in particular the ability [ ] to generate [ ] which influence the environment with which the system in- teracts In diesem Kontext m sste influence bzw. beeinflussen konkretisiert werden . Wenn ein System Controller eine (auf statistischen Methoden basierte) Trafolast f r seine Schaltvorg nge verwendet, w re dies dann bereits KI/AI? Seite ( AI systems identified as high -risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union Hier w re eine genauere Definition hilfreic h. Wie direkt muss der Impact sein? Welche Mittelbarkeit/Unmit- telbarkeit muss vorliegen? Beispiel: In der KI-basierte s Instandhaltungsplanung, trifft die KI eine falsche Entscheidung . Ein deshalb nicht ausgetauschtes Bauteil sorgt f r l ngere Zeit f r einen Stromausfall. Die Juli 2021 3 Wahrscheinlichk eit ist sehr gering, da ss eine Verkettung von Ereignissen vorliegt. Es ergibt sich die Frage, ob solche Konsequenzen ber cksichtigt werden sollte n. Teilweise recht offene bzw. weite Formulierungen in der KI -VO wie a certain degree , appropriate w r- den wir als unternehmerische Freiheit und Verantwortung bei der Adressierung der Anforderungen auffas- sen. Seite ( To address the opacity that may make certain AI systems incomprehensible to or too complex for natural persons, a certain degree of transparency should be required for high -risk AI systems. Seite 29 (: Training, validation and testing data sets sho uld be sufficiently relevant , representa- tive and free of errors and complete in view of the intended purpose of the system. Hinsichtlich der Technical Documentation w re eine beispielhafte Do kumentation sehr hilfreich. Annex IV, Technical Documentation: The provider verifies that the established quality management system is in compliance with the requirements of Article 17 Da die Erwartung hinsichtlich des Detailgrades relevant , aber nicht klar ist, w re an dieser Ste lle die Zur- verf gungstellung eines konkreten Beispiels hilfreich . Intern genutzte KI -Systeme vs. externe in Verkehr gebrachte Produkte . Besonders aus der Perspektive der Energiewirtschaft und kritischer Infrastruktur werden KI -Systeme und L sungen oft im Wesentlichen, intern verwendet und nicht als Produkt auf einen Markt und in Umlauf gebracht. Ein Beispiel ist die KI -ba- sierte Instandhaltungsplanung von Gasnetzen . In diesem und vielen weiteren F llen sind Mitarbeit erinnen und Mitarbeiter die Nutzer innen und Nutzer des KI -Systems . Uns ist noch nicht klar, inwieweit die Regulie- rung hier eine Unterscheidung von Endkundenp rodukten vorsieht. Wie genau funktioniert in den F llen der rein internen Nutzung eine Market Surveillance? Die Definition von KI in Annex 1 ist sehr breit angelegt. Die Definition (incl. Expert Systems und Statistical Approaches) w rde in dieser Form bereits existieren de mathematische L sungen und deterministische An- s tze (z.B. stochastische Prozesse), unter die Definition von KI fallen lassen . Diese erfordern aber nicht die gleichen Qualit tssicherungsma nahmen wie lernende Algorithmen. Anregungen aus Sicht EnBW : Anlaufstelle bei Unklarheiten : Generell bleibt es dem Entwickler/Betreiber selbst berlassen zu interpre- tieren, ob ein AI-System high -risk ist. Es w re hilfreich eine Anlaufstelle zu haben, mit der man diese Frage diskutieren kann. Alternativ m sste man jeglichen Interpretationsspielraum entfernen, was nicht sinnvoll m glich ist. H he der Sanktionen (Article : Bei gef hrdendem Verhalten , ganz besonders im Falle des Einsatzes von KI der unacceptable risk -Klasse, kann ein hohes Strafma gerechtfertigt sein. Hohe Strafma e von bis zu 6% des weltweiten Unternehmensumsatzes (bis zu 30 Mio ) hingegen, k nnen wohlm glich grundlegend Juli 2021 4 abschreck end wirken. Hohe Sanktionen k nnen problematisch sein, wenn Fehler z.B. auf Grund von Unklar- heiten der Regulierung geschehen und schwer geahndet werden. Bei bewussten T uschungen und gef hr- dendem Verhalten k nnen die Sanktionen jedoch angemessen und wichti g sein. Juli 2021 5",de
Patrick Glauner (Germany),F2662602,19 July 2021,EU citizen,,Germany,Schriftliche Stellungnahme von Prof. Dr. Patrick Glauner f r das am 2021 stattfindende gemeinsame Fachgespr ch der Aussch sse f r die Angelegenheiten der Europ ischen Union des Deutschen Bundestages und der franz sischen Assembl e nationale zur Politik der EU im Bereich der K nstlichen Intelligenz (KI) und insbesondere dem Verordnungsvorschlag der Europ ischen Kommission zu KI (COM( 206 final).,de
Deutsche Sozialversicherung Arbeitsgemeinschaft e.V. (Germany),F2662473,15 July 2021,Other,Micro (1 to 9 employees),Germany,"Fon +32 2 282 05 -50 info@dsv -europa.de -europa.de Transparenzregister Nr. 917393784 -31 Deutsche Sozialversicherung Europ avertretung Rue d Arlon 50 B-1000 Bruxelles Die ffentliche Konsultation der EU - Kommission zum Vorschlag eines Ge- setzes ber K nstliche Intelligenz , COM (206 final Stellungnahme der Deutschen Sozialversicherung vom 2021 Die Deutsche Rentenversicherung Bund (DRV Bund), die Deutsche Gesetzliche Unfallversicherung (DGUV), der GKV -Spitzenverband und die Verb nde der ge- setzlichen Kranken - und Pflegekassen auf Bundesebene und die Sozialversiche- rung f r Landwirtschaft, Forsten u nd Gartenbau (SVLFG) haben sich mit Blick auf ihre gemeinsamen europapolitischen Interessen zur Deutschen Sozialversiche- rung Arbeitsgemeinschaft Europa e. V. zusammengeschlossen. Der Verein vertritt die Interessen seiner Mitglieder gegen ber den Organen der Europ ischen Union (EU) sowie anderen europ ischen Institutionen und ber t die relevanten Akteure im Rahmen aktueller Gesetzgebungsvorhaben und Initiativen. Die Kranken - und Pflegeversicherung, die Rentenversicherung und die Unfallver- sicherung bieten als Teil eines gesetzlichen Versicherungssystems wirksamen Schutz vor den Folgen gro er Lebensrisiken. Stellungnahme Die Deutsche Sozialversicherung begr t den Entwurf eines Gesetzes ber K nstliche Intelligenz (KI). Er hat weitreichende Auswirkungen auf die Entwicklung und den Einsatz von KI, nicht zuletzt auch im Bereich der ffentlichen Verwaltung. Die Deutsche Sozialversicherung sieht m gliche mitgliedschafts -, beitrags - und leistungsrechtliche Bez ge und ist sich ihrer Verantwortung im Umgang mit KI be- wusst. Sie begr t daher eine Kl rung unter anderem der ethischen und haftungs- rechtlichen Fragen. Dabei wird im Rahmen der weiteren Verhandlungen des Ver-ordnungsentwurfs und dar ber hinaus zu kl ren sein, bis zu welcher Detail - und Entscheidungstiefe ein europ isches Handeln erforderlich ist. Stellungnahme 2/2 Es ist festzustellen, dass der Entwurf eine sehr weite Definition des Begriffs der KI zugrunde legt. Davon d rften auch etliche in der Vergangenheit entwickelte und angewandte Algorithmen erfasst sein. Zwar w re es f r eine zielf hrende Defini- tion zu eng, allein auf das Vorliegen autonomer Verhaltensweisen abzustellen. Dies ist die h chste Stufe der Automatisierung, die von den heutigen technischen Systemen noch nicht erreicht wird. Auf der anderen Seite k nnten die in Anhang I Techniken und Konzepte der K nstlichen Intelligenz gem Artikel 3 Absatz 1 unter den Punkten b) und c) genannten Konzepte zu weit gehen. Von einer KI sollte daher nur dann die Rede sein, wenn mit der Hilfe von Algorithmen, die mit einer oder mehreren der in Anhang I aufgef hrten Techniken entwickelt wurden, genuin bisher dem Menschen vorbehaltene Vorhersagen, Empfehlungen oder Entscheidungen erfolgen. Vor diesem Hintergrund ist es nicht auszuschlie en, dass einzelne von den Sozi- alvers icherungstr gern eingesetzte Programme/Anwendungen schon heute die Merkmale von KI erf llen. Dennoch wird im Bereich der eigenen Anwendungen der Sozialversicherungstr ger derzeit kein Einsatz von KI mit hohem Risiko ge- sehen. Dies k nnte sich in Zukunft allerdings ndern, falls z. B. maschinelle Lernverfah- ren f r die Unterst tzung personen - und fallbasierter Entscheidungen zum Einsatz kommen sollten. In diesem Fall ist die Schaffung von Transparenz, Nachvollzieh- barkeit, Nichtdiskriminierung und menschlic her Letztverantwortung beim Einsatz maschineller Unterst tzungsverfahren w nschenswert. Vor diesem Hintergrund sind berwachungs - und Kontrollmechanismen sinnvoll. F r den Einsatz von KI -Anwendungen, die kein hohes Risiko darstellen, k nnen die Sozialversicherungstr ger deren Vertrauensw rdigkeit dadurch st rken, dass sie eigene freiwillige Verhaltenscodizes aufstellen oder sich den Verhaltenscodi-zes repr sentativer Verb nde anschlie en. Im brigen wird auf die Stellungnahme der Deutschen Sozial versicherung zur f- fentlichen Konsultation der EU -Kommission zum Wei buch Zur K nstlichen Intel- ligenz - ein europ isches Konzept f r Exzellenz und Vertrauen verwiesen . 1 1 -europa.de/lib/2020 -06-11-DSV- Position -Weissbuch- Endfassung.pdf",de
Radiocommunications Agency/ Agentschap Telecom NL (Netherlands),F2662381,14 July 2021,Public authority,Large (250 or more),Netherlands,"Pagina 1 van 4 European Commission Piet Mondriaanlaan 54 3812 GV Amersfoort Postbus 1671 3800 BR Amersfoort T ( 460 08 00 F ( 460 08 50 Van M. Vrieze T Datum 14 juli 2021 Bijlagen - Agentschap Telecom Reactie Openbare raadpleging AI Act Agentschap Telecom Feedback Algemeen Agentschap Telecom is de autoriteit in het digitale domein en is de uitvoerder en toezichthouder op digitale infrastructuur in Nederland en heeft met interesse kennisgenomen van het voorstel Artificial Intelligence Act (hierna: AI Act) van de Commissie. In 2020 heeft AT in de publieke consultatie op het White paper on artificial intelligence A European approach to excellence and trust van de Commissie gereageerd, het is goed om te constateren dat aandacht is besteed aan onze punten . De inhoud van de AI Act sluit goed aan bij een groot deel van onze werkvelden , zoals continu teit, cybersecurity en weerbaarheid van veilige apparaten, beschikbare telecom & infrastructuur . AT waardeert het initiatief van de EC voor de AI Act en vindt het voorliggend voorstel een goede basis voor verdere ontwikkeling van normen voor AI- systemen . Heldere normen zijn nodig om als autoriteit te kunnen toezien op veilig en betrouwbaar gebruik van algoritmen . Het adresseert de juiste risico s en maakt de juiste risico indeling (deels verbieden, deels controle en deels transparantie eisen). Ook de keuze om bij ( High Risk) AI-systemen vereisten te introduceren voor markttoegang is een verstandige keuze . We hebben de AI Act beoordeeld en vragen aandacht voor aspect en die van invloed zijn op een transparante en eenduidige markttoegang, effectief toezicht en het borgen van een Europees level playing field bij de inzet en het gebruik van AI- systemen in de samenleving . Deze zijn: - Scope: digitale wereld en fysieke wereld ; - Relatie andere EU-wetgeving ; - Definities ; - Standaardisatie en conformiteit ; - Bevoegdheid (nationaal en internationaal) ; - Co rdinatie tussen toezichthouders ; Pagina 2 van 4 - Rechtsbescherming burger s. Het doel is hiermee bij te dragen aan het maatschappelijk vertrouwen in het gebruik van AI. We lichten deze aspecten in onderstaande paragrafen toe. Scope De AI Act maakt geen duidelijke koppeling tussen het fysieke domein en het digitale domein. AI is gedefinieerd als een softwaresysteem maar in het begrip High Risk AI-systemen worden de safety components van een product ten behoeve van fysieke veiligheid van personen en bezittingen aangeduid . Terwijl bij AI-systemen in het digitale domein juist de veiligheid door de werking of het gebruik door (AI) software wordt bepaald . De koppeling tussen de domeinen kan gemaakt worden door een verwijzing op te nemen in de AI Act naar aanpalende regelgeving als de NISDi en eIDASii, het ontbreken daarvan bemoeilijkt de analyse van overlap of gaten in de regelgeving. Daarnaast zijn veel AI-systemen afhankelijk van het functioneren van een digitale infrastructuur , dus een verwijzing naar de kaders die de betrouwbaarheid van die infrastructuur behartigen ligt voor de hand (NIS, Telecomcode). Relatie andere EU-wetgeving Met de opzet van de ve rordening sluit de Commissie aan bij al bestaande Europese regelgeving, in het bijzonder die regelgeving waarin de digitale veiligheid van producten, diensten en processen wordt gereguleerd. Tegelijkertijd roept de wijze waarop dit gebeurt vragen op over d e onderlinge verhouding tussen met name de REDiii, CSAiv, NISD en de AI-verordening . Zou de Commissie kunnen aangeven hoe de verschillende Europese wet - en regelgeving op het gebied van digitale veiligheid in elkaar grijpt en met elkaar samenhangt? Voorbeelden van samenhang: RED: Radio Apparatuur is volgens artikel 6 lid 1 geen High Risk terwijl te veel uitgestraald vermogen wel een gevaar voor de gezondheid kan vormen. Het radioapparaat (zoals een mobiele telefoon) kan aangestuurd worden door AI (bij 5G en 6G bijvoorbeeld) maar omdat het geen safety component betreft, lijkt het buiten de scope van de AI-verordening te vallen . Het is onvoldoende helder of de AI-software die het apparaat aanstuurt onder het AI framework valt , onder de RED , of geen van beide ; NISD: Er is bij de High Risk definitie gekozen voor een meer beperkte scope van critical infrastructure dan de bij NISD, namelijk; supply electricity and water , heating and operation of road security . De ononderbroken levering van deze diensten en de integriteit ervan vormen het risico voor de maatschappij , niet de safety components die de installaties of werknemers beogen te beschermen. Onduidelijk is of de AI- systemen in de operation en management van deze essenti le diensten onder de NISD of het AI framework vallen. CSA: In artikel 41 lid 2 van de verordening wordt verondersteld dat High risk AI-systemen die een CSA conformiteitsverklaring hebben en voldoen aan een van de CSA certificeringsschema s, ook voldoen aan de cybersecurity vereisten zoals beschreven in artikel 15 van de verordening. De CSA kent echter drie assurance niveaus waarop cybersecurity certificering kan plaatsvinden, te weten basic, substantial en high. De Pagina 3 van 4 keuze voor het niveau van certificering vindt onder de CSA plaats door de producent. Wij vinden het wenselijk dat in de AI Act goed wordt vastgelegd hoe de CSA assurance levels passen bij High Risk definitie. Definities De uitleg van definities heeft verstrekkende gevolgen voor de toepasselijkheid van wetgeving en bevoegdheid van de toezichthouders. Toezichthouders zijn bij heldere definities meer voorspelbaar en aanbieders en gebruikers ontlenen er zekerheid aan. Het is belangrijk meer aandacht te besteden aan het aanscherp en van de definities of het nader duiden daarvan. We noemen drie voorbeelden : eIDAS: Het gebruik van de term remote biometric identification system in het AI framework lijkt een andere betekenis te hebben ten opzichte van andere toepassingen (o.a. identi ficatiesystemen voor eID en AML Anti money laundering toepassingen) waar gesproken wordt van remote identification in de eIDAS verordening ; Productregelgeving : Het begrip provide r sluit niet aan bij productregelgeving . Net zomin als small -scale provider of user . Deze verwijzen eerder naar diensten dan producten. Producenten van ( High Risk) AI-systemen : Voor de vraag wie de producent is van een AI-systeem moet duidelijk zijn of een CE-markering gekoppeld wordt aan het doel van het product . Wie is bijvoorbeeld de producent van het AI-systeem in een slimme speaker? Standaardisatie en conformiteit Standaardisatie draagt bij aan harmonisatie van de markttoegang door onder andere producten en diensten veilig, compatibel en uitwisselbaar te maken, waarmee het maatschappelijk belang wordt gediend. Tevens heeft standaardisatie en normering een belangrijke rol bij het uitoefenen van de handhaving - en toezichtstaak op nationaal niveau. De systematische en getrapte indeling van geharmoniseerde standaarden -en bij het ontbreken van deze standaarden - het kunnen stellen van aanvullende vereisten is in de concept Verordening Artifici le Intelligentie helder verwoord . Voor een consistente en systematische opzet van mogelijk aanvullende vereisten op het terrein van AI -en in bredere zin digitale veiligheid -is het goed dat de Commissie vroegtijdig de Europese Standaardisatie Organisaties (ESOs) en ENISA actief heeft betrokken. De ESO s hebben de kennis en expertise om een belangrijke rol t e kunnen vervullen bij de verdere ontwikkeling van standaarden en voor ENISA geldt dit bij de identificatie van relevante ontwikkelingen bij AI binnen de CSA certificering als ook bij de inrichting van het systeem van conformiteitsbeoordeling. Wij advisere n daarom de rol van de ESOs bij de ontwikkeling van standaarden te borgen in de verordening . Bevoegdheid ( nationaal en internationaal) Het is onduidelijk welke competent authority wanneer kan/mag/moet acteren. Een AI-systeem dat op de markt is gebracht kan door meerdere gebruikers in meerdere lidstaten gebruik t worden . Hoe voorziet de EC een co rdinatie van toezichtsactiviteiten en een effici nte aanpak van de handhaving als meer dan n sectorale toezichthouder bevoegd is, en Pagina 4 van 4 mogelijk ook meerdere lidstaten bevoegd zijn ten aanzien van n provider ? Is jurisdictie verbonden aan de vestigingsplaats van de provider, producent of gebruiker? Welke lidstaat is bevoegd om tot handhaving over te gaan, is nog onvoldoend e scherp. Meer duiding of aanscherping is gewenst. Co rdinatie tussen toezichthouders Gedeelde verantwoordelijkheden betekent dat in de verschillende fasen van het toezicht de bevoegde autoriteit zaakkennis moet overdragen of dat een organisatie te make n krijgt met meerdere toezichthouders. Hoe wordt informatiedeling en co rdinatie van toezichtsactiviteiten voorzien? En wat is de juridische basis? Daarnaast vraagt effectief markttoezicht in Europa om naast nationaal toezicht een Europees netwerk op te richten waar aan gezamenlijke toezichtsactiviteiten, onderzoeken en handhaving wordt gewerkt. Rechtsbescherming burgers Er is onvoldoende voorzien in de mogelijkheid voor burgers om individuele problemen met AI te rapporteren , waardoor de bescherming tekortschiet . Op basis van de AI Act kijkt een toezichthouder naar het AI-systeem en de werking in het geheel, niet naar de gevolgen voor een individueel geval. Om de burger s voldoende rechts bescherming te bieden moeten zij kunnen aangeven dat zij zijn benadeeld door de toepass ing van AI . Het maatschappelijk vertrouwen in AI-toepassingen is afhankelijk van rechtsbescherming, effectief toezicht, transparante markttoegang en standaardisatie. i NISD. Directive (EU) 2016/1148 of the European Parliament and of the Council of 6 July 2016 concerning measures for a high common level of security of network and information systems across the Union . ii eIDAS. VERORDENING (EU) Nr. 910/2014 VAN HET EUROPEES PARLEMENT EN DE RAAD van 23 juli 2014 betreffende elektronische identificatie en vertrouwensdiensten voor elektronische transacties in de interne markt . iii RED. Directive 2014/53/EU of the European Parliament and of the Council of 16 April 2014 on the harmonisation of the laws of the Member States relating to the making available on the market of radio equipment . iv CSA. VERORDENING (EU) 2019/881 VAN HET EUROPEES PARLEMENT EN DE RAAD van 17 april 2019 zake E NISA (het Agentschap van de Europese Unie voor cyberbeveiliging), en inzake de certificering van de cyberbeveiliging van informatie - en communicatietechnologie .",nl
CENTRO ESPAÑOL DE DERECHOS REPROGRÁFICOS EGDPI (CEDRO) (Spain),F2662182,13 July 2021,Other,Small (10 to 49 employees),Spain,"1 CONSIDERACIONES DE CEDRO A LA PROPUESTA DE REGLAMENTO SOBRE INTELIGENCIA ARTIFICIAL (ARTIFICIAL INTELLIGENCE ACT) Estas son las contribuciones del CENTRO ESPA OL DE DERECHOS REPROGR FICOS EGDPI (CEDRO) a la propuesta de Reglamento COM(206 sobre Inteligencia Artificial ( Artificial Intelligence Act). CEDRO es una entidad de gesti n de derechos de Propiedad Intelectual establecida en Espa a, autorizada por el Ministerio de Cultura y Deporte, de conformidad con la legislaci n espa ola , para el desempe o de sus fines . CEDRO lleva de sarrolland o su actividad desde 1988 y es la nica entidad de gesti n autorizada en Espa a para representar a escritores, traductores, periodistas y editores de libros, revistas, peri dicos y partituras. Puede obtenerse m s informaci n sobre la Entidad en Las consideraciones que se realizan en este d ocumento se basan en las posibles implicaciones que pueda tener la Inteligencia artificial (IA) en los derechos de propiedad intelectual del colectivo al que CEDRO representa . En primer lugar, esta parte desea manifestar que, en nuestra consideraci n, el texto propuesto deber a abordar y dar respuesta a los interrogantes que esta tecnolog a est suscitando en el mbito de la propiedad intelectual. A este respecto, queremos se alar que en la Resoluci n del Parlamento Europeo sobre los derechos de propiedad intelectual para el desarrollo de las tecnolog as relativas a la inteligencia artificial (2020/2015(INI)) de 20 de octubre de 2020 ya se se alan aspectos que deben ser regulad os de forma armonizada en todo el territorio de la Uni n y que, sin embargo, en el Reglamento propuesto no llegan a abordarse . En primer lugar, en la Resoluci n del Parla mento (2020/2015(INI)) se se ala que los sistemas de IA pueden impedir que los creadores humanos, cuyo trabajo original se utilice para alimentar dichas tecnolog as, reciban una remuneraci n justa (Considerando 2 D). Por otro lado, indica esta Resoluci n que la aplicaci n de los derechos de propiedad intelectual (DPI) a los materiales, los contenidos o los datos generados por la IA es cuestionable y, por ello, es importante diferenciar entre las creaciones humanas obtenidas con ayuda de IA y las creaciones ge neradas por la IA de forma aut noma (Considerando J); Consideramos que estos dos importantes aspectos tendr an que haber sido abordados en la propuesta de Reglamento. A continuaci n, se alaremos por qu entendemos que debe adoptarse con prontitud una solu ci n a los mismos, de forma homog nea en todo el territorio de la UE. PRIMERO: SOBRE EL USO DE CONTENIDO PROTEGIDO POR DERECHOS DE PORPIEDAD INTELECTUAL POR PARTE DE LOS SISTEMAS DE IA Los sistemas de IA requieren del an lisis y procesamiento de grandes cantidades de datos, contenido, obras y prestaciones protegidas por derechos de propiedad intelectual. Ello afecta generalmente a los derechos de reproducci n, transformaci n y comunicaci n p blica que ostentan los creadores sobre sus obras y prestaciones. A este respecto, es importante poder garantizar que el uso de obras y prestaciones protegidas por DPI se realice de forma l cita, esto es, que solo se lleve a cabo esta utilizaci n cont ando con autorizaci n de los titulares de derechos o al amparo de un l mite o excepci n legalmente previsto, como los l mites para miner a de textos y datos recogidos en los art culos 3 y 4 de la Directiva de derechos de autor en el mercado nico digital1. Para poder garantizar que el uso de contenido protegido por DPI se realiza de forma l cita se exige el establecimiento de aquellas medidas de transparencia que resulten necesarias para detectar usos il citos. Por tanto, adem s de las citadas en la propuesta de Reglamento, tambi n se deben imponer obligaciones de transparencia a aquellos sistemas que se nutren, que son entrenados, con material protegido por DPI. Adem s de la obligaci n de indicar que el contenido consistente en im genes, audio o video que 1 Directiva (UE) 2019/790 del Parlamento Europeo y del Consejo, de 17 de abril de 2019, sobre los derechos de autor y derechos afines en el mercado nico digital . 3 parezca real ha sido elaborado por medios autom ticos , en nuestra opini n, tambi n se debe exigir la divulgaci n de qu contenido co ncreto ha sido empleado para la elaboraci n de ese nuevo contenido. Ello es indispensable para garantizar que los creadores y otros titulares de derechos sean remunerados por la utilizaci n de sus obras o prestaciones. Por otro lado, se exige la regulaci n de un sistema de responsabilidad para aquellos casos en los que sistemas aut nomos generen contenido que vulnere DPI. Si el resultado generado por un sistema aut nomo transforma o reproduce contenido ajeno ante qui n deben reclamar los titulares de der echos afectados?. La falta de respuesta legal a esta cuesti n no puede dejar desamparados a los creadores. En este sentido , en la Resoluci n del Parlamento Europeo, de 20 de octubre de 2020, con recomendaciones destinadas a la Comisi n sobre un r gimen de responsabilidad civil en materia de inteligencia artificial (2020/2014(INL)) se considera que es necesario realizar adaptaciones espec ficas y coordinadas de los reg menes de responsabilidad civil para evitar situaciones en las que personas que sufran un da o o un menoscabo a su patrimonio por el empleo de sistemas de IA acaben sin indemnizaci n. SEGUNDO: CONTENIDO CREADO POR SISTEMAS DE INTELIGENCIA ARTIFICIAL Buena parte de la doctrina se ha volcado en el planteamiento del reto que supone la protecci n de los resultados o contenido obtenido mediante sistemas de IA. Mientras que el empleo de sistemas de IA por parte de un creador como una mera herramienta en la creaci n no debe suponer ning n reto ni variaci n a la legislaci n existente , s que plantea dudas la protecci n de los resultados de aquellos sistemas que puedan llegar a crear de forma aut noma. En primer lugar, queremos destacar que la posible protecci n de los contenidos creados por sistemas aut nomos no debe suponer un menos cabo a los intereses o derechos de los creadores humanos. Las creaciones obtenidas por m quinas no deben llegar a competir ni a sustituir a las creaciones humanas. Es altamente probable que las creaciones obtenidas de forma aut noma por sistemas artificial es lleguen a ser monopolio de unas pocas empresas tecnol gicas, por lo que se ha de evitar que estas 4 obtenciones puedan suponer un menoscabo al reconocimiento y a los derechos de los creadores humanos. Queremos se alar que en el punto 14 de la Resoluci n del Parlamento Europeo sobre los derechos de propiedad intelectual para el desarrollo de las tecnolog as relativas a la inteligencia artificial (2020/2015(INI)) se indica que la autonomizaci n del proceso de generaci n de contenidos art sticos puede pla ntear cuestiones relacionadas con la titularidad de los DPI sobre esos contenidos; considera, en este sentido, que no ser a adecuado tratar de dotar a las tecnolog as de IA de personalidad jur dica y pone de relieve el impacto negativo de esta posibilidad en los incentivos para los creadores humanos . No podemos estar m s de acuerdo con esta afirmaci n . No se debe dotar de personalidad jur dica a los sistemas de IA y, por ello, no pueden ser consideradas obras protegibles por derechos de autor las creaciones de sistemas aut nomos de IA. S lo las creaciones fruto del intelecto humano deben ser consideradas obras originales protegibles por derechos de autor, tal y como se desprende de los tratados internacionales (art. 2, pfo. 5 del Convenio de Berna en el que se establece que la protecci n de las obras literarias o art sticas han de constituir una creaci n intelectual ) y derecho de la Uni n (considerando noveno de la Directiva 2001/29/CE y art culo 6 y considerando 16 de la Directiva 2006/116/CE). Ello, adem s, ha sido recalcado por la jurisprudencia del TJUE , entre otras, en la sentencia del asunto C -5/08 (Infopaq ), que claramente esta blece que el derecho de autor s lo aplica a las obras que constituyen creaciones intelectuales atribuibles a este (apdo. . Como decimos, a tribuir derechos de autor al contenido creado de forma aut noma por sistemas artificiales podr a llegar a tener un impacto negativo en los creadores. No obstante, s consideramos que deben gozar de alg n tipo de protecci n para no desincentivar la innovaci n en este terreno . Una opci n podr a ser la atribuci n de derechos vecinos o conexos a favor de la persona f sica o jur dica que edite o divulgue de forma l cita este contenido. 5 Por otro lado, al igual que se alamos en el punto anterior, resulta impresci ndible la introducci n de una obligaci n de informar a los usuarios de cu ndo se encuentran ante contenido creado de forma aut noma por m quinas. TERCERA: NECESARIA PROTECCI N DE LOS DPI FRENTE A FAKE NEWS , DEEP FAKE Y OTRAS FORMAS DE DESINFORMACI N En muchas ocasiones se emplean obras y prestaciones protegidas para la creaci n de las conocidas Fake News , Deep Fakes u otros, con el objeto de confundir o enga ar a los consumidores. Esto tiene un impacto muy negativo en el p blico destin atario y tambi n en los titulares de derechos, que ven c mo sus obras son reproducidas, transformadas y/o descontextualizadas sin su autorizaci n y control . Ello puede poner en riesgo tambi n el prestigio y credibilidad del creador, editor o productor del contenido original que es fraudulentamente manipulado . Por ello, insistimos en la necesidad de que el contenido creado por m quinas sea identificado como tal. Adem s, se requiere una trazabilidad y transparencia en la utilizaci n de obras y prestaciones protegidas por DPI, para que sus titulares de derechos pu edan detectar usos il citos y oponerse a ello. Y, por ltimo, resulta indispensable establecer un r gimen de responsabilidad ante tales conductas. De lo contrario, como ya hemos se alado, estas quedar n impunes y los titulares de derechos y consumidores no podr n obtener un resarcimiento por los da os que les ocasionen estas pr cticas. Por todo lo se alado, consideramos que la propuesta de Reglamento sobre inteligencia artificial ( Artificial Intelligence Act ) tendr a que dar respuesta a las cuestiones que esta tecnolog a plantea en relaci n con los derechos de propiedad intelectual. Madrid, 13 de julio de 2021",es
LO Sweden (Sweden),F2661969,09 July 2021,Trade union,Medium (50 to 249 employees),Sweden,"Remiss av Europeiska kommissionens f rslag till f rordning om harmoniserade regler f r artificiell intelligens LO har i detta skede gjort en f rsta bed mning av f rslaget till AI - f rordning och har valt att l mna n gra vergripande kommentarer p f rslaget. LO ser positivt p ett europeiskt initiativ som syftar till att reglera AI. Det r dock viktigt att en f rordning som inneb r en fullharmonisering inte verkar som ett tak utan som ett golv f r andra regleringar s v l nationellt som internationellt som dire kt eller indirekt syftar till att reglera effekter eller processer r rande AI -system. Det r innefattar ocks de nationella partssystemen och dess regleringar. LO v lkomnar f rordningens syften och hoppas dessutom att f rslaget kan bidra till att ka ty dligheten och likv rdigheten p den inre marknaden inom detta omr de vilket gynnar innovation och r ttvis konkurrens inom unionen. F rslaget till f rordning lyfter ocks vikten av uppf ljning efter en implementering av f rordningen. LO anser att det r av st rsta vikt att Kommissionen och medlemsl nderna gemensamt f ljer utvecklingen och effekterna av f rordningen. Det system som f resl s f r marknads vervakning - och regelefterlevnad genom offentliga organ p s v l nationell som EU -niv ter sig komplext. Det framg r heller inte tydligt av f rslaget vilken relation de olika organen p nationell respektive europeisk niv kommer ha. Om utformningen av marknads vervakning - och regelefterlevnad blir som f rlaget r det viktigt att dessa rollf rdelningar blir t ydliga och att det framf r allt p nationellt plan s kras tillr cklig kompetens och resurser f r verksamheten. Annars riskerar f rordningen bli tandl s. ENHET Enheten f r Avtalsfr gor DATUM 2021 -07-07 DIARIENUMMER 20210182 HANDL GGARE Linda Larsson ERT DATUM Ert datum ER REFERENS Er referens Europeiska kommissionen 2 ( LO f rst r Kommissionens str van efter att h lla registren ver de AI - system som omfattas av f rordni ngen samt de som klassificeras som h g risk relevanta och uppdaterade. LO vill dock lyfta de fr getecken som r f rbundet med en s dan process. Av f rslaget g r att uttolka att kommissionen kommer att ge sig befogenheter att komplettera listan vilket r en indirekt makttransferering och en mindre ppen och demokratisk process n g ngse processer. LO vill heller inte se denna l sning som en m jlig arena f r p verkan fr n intressen som har ett egenintresse av listans utformning. AI-system p arbetsplatsen LO har n gra grundprinciper som handlar om digitala system p arbetsplatsen. A tt utveckla och implementera digitala l sningar s som AI - teknik r komplexa processer som handlar om l ngt mer n enbart de digitala l sningarna i sig. Det st ller krav p en djup are analys av syftet och en tydlig definition av vad som avses att uppn . Vi beh ver ocks klarg ra vilka digitala l sningar som l mpar sig b st beroende p vilken verksamhet det handlar om och vilka moment och beslut som b st g rs genom m nniskor. Vilka v al som g rs och hur AI -systemen fungerar p verkar n mligen arbetsinneh ll, arbetss tt, hur arbetet organiseras och arbetsmilj . Men det kan ven p verka professionen och hur vi ser p dess uppgift. Tekniken f r inte ske p bekostnad av arbetstagaren och det r av st rsta vikt att arbetstagares r ttigheter inte p verkas negativt vid inf randet av digitala system. LO vill se utvecklande och inte utarmande teknik inf ras p arbetsplatser. Kontinuerlig uppf ljning av systemen och dess avsedda effekter av st rsta vikt, inte minst f r att skapa tillit. Det r ocks viktigt att f lja upp vilka eventuella effekter som uppst tt som inte var avsedda. I arbetet med att utveckla, implementera och f lja upp AI -system samt regelefterlevnad st r de verksamhetsn ra expe rterna arbetstagarna i centrum. LO anser att arbetstagarna och deras fackliga f retr dare m ste ges en central roll i alla delar n r tekniska system inf rs p arbetsplatserna. De europeiska arbetsmarknadensparterna har f rhandlat fram en processbeskrivni ng f r hur ett arbetstagarn ra angreppss tt kan tas p hela livscykeln f r digitala system. Detta kan utg ra riktm rke f r det generella syns ttet f r EU att involvera och verkligen s tta m nniskan i centrum f r AI. F rslaget till AI-f rordning inkluderar f rvisso arbetsplatsrelaterad AI men tar inte sikte p specifik reglering g llande handhavande eller arbetstagarnas inflytande ver AI -tekniken p arbetsplatsen. Detta r fr gor av yttersta vikt f r de fackliga organisationerna. Dock g r LO i nul get bed mningen att givet den r ttsliga grunden f r f rordningen s l mpar sig eventuella arbetsplatsrelaterade nyregleringar b ttre utanf r detta initiativ. 3 ( LO v lkomnar att AI -system i utbildning och yrkesutbildning samt syssels ttning och arbetet klassas som h g risk i f rslaget. Dock verkar det finns en diskrepans mellan de olika avsnitten i f rslagets texter som handlar om h g risk inom omr dena syssels ttning och arbete. F r LO r det av st rsta vikt att de omr den som n mns, inte minst i bilaga III ut kas att omfatta fler omr den som n mns i de inledande delarna av f rslaget. I f rslaget till maskinf rordning st r att l sa att e n annan f renklingsaspekt r komplementariteten mellan lagstiftningsf rslagen om AI och maskiner, d r bed m ningen av verensst mmelse delegeras till maskinf rordningen genom AI -f rordningen, s att riskbed mningen f r hela maskinen med AI - system endast g rs enligt den framtida f rordningen om maskinprodukter. LO delar logiken i att utg fr n maskinf rordningen men ser en stor komplexitet i hur den f reslagna f rordningen ska matchas med redan befintlig lagstiftning som indirekt eller direkt ber r delar av det f rslaget avser att reglera. Det r av yttersta vikt att f rslaget harmoniserar med vrig nationell och europeisk reglering. Det r ocks av stor vikt att d r ansvaret delegeras till andra r ttliga regleringar att detta sker i enlighet med f rslagets reglering s att det inte i praktiken uppst r s rregleringar. LO vill h r ocks passa p att lyfta de m nga s tandarder som ligger till grund f r m nga tekniska verktyg och som Kommissionen ocks h nvisar till i sitt f rslag. LO anser att det nogsamt b r s kerst llas att arbetsgivaren tillg ngligg r standarder f r skyddsombud och anst llda f r att ka insyn och un dvika risker vid anv ndningen. Med v nlig h lsning Landsorganisationen i Sverige Susanna Gideonsson Linda Larsson Handl ggare",sv
"COLEGIO DE REGISTRADORES DE LA PROPIEDAD, MERCANTILES Y DE BIENES MUEBLES DE ESPAÑA (Spain)",F2660134,24 June 2021,Public authority,Large (250 or more),Spain,"De conformidad con la consulta p blica previa relativa a la propuesta de R eglamento del Parlamento Europeo y del Consejo por el que se establecen normas armonizadas en materia de inteligencia artificial (Ley de Inteligencia Artificial) y se modifican determinados actos legislativos de la Uni n {SEC( 167 final} - {SWD( 84 final} - {SWD( 85 final} se propone que se recomiende , sin perjuicio de la inclusi n de los primeros en la base de datos prevista en el art culo 6 0 de la propuesta , la inscripci n en registros jur dicos nacionales tanto los sistemas de inteligencia artificial como de los algoritmos y dem s elementos que los componen . En este sentido art culo 6 0 establece que la Comisi n, en colaboraci n con los Estados miembros crear y mantendr una base de datos de la UE que debe c omprender los nombres y datos de contacto de las personas f sicas res ponsables del registro de sistema y que cuenten con autoridad legal para r epresentar al prov eedor. La participaci n de los registros jur dicos, tanto el Registro Mercantil como el Registro de Bienes Mueb les en los t rminos que m s adelante indicaremos permiten garantizar el control de legalidad ne cesario para el Registro de los sistemas de inteli gencia artifici al favoreciendo, asi mismo, su configuraci n como objeto espe c fico de derechos . Resulta de la propuesta de reglamento q ue siendo la inteligencia artificial (IA) un conjunto de tecnolog as que puede generar un amplio abanico de beneficios econ micos y sociales en todos los sectores y las actividades sociales es la voluntad de l Parlamento y del Consejo favorecer la iniciativa y uso de inteligencia artificial como elemento que puede proporcionar ventajas competitivas esenciales a las empresas y la econom a europea. Del mi smo modo , la Resoluci n del Parlamento Europeo, de 16 de febrero de 2017, con recomendaciones destinadas a la Comisi n sobre normas de Derecho civil sobre rob tica y de inteligencia artificial (2015/2103(INL) ) contiene un conjunto de recomendaciones sobre normas de derecho civil en materia de rob tica y de inteligencia artificial requiriendo que los implicados en el desarrollo y comercializa ci n de aplicaciones de inteligencia artificial incorporen desde el principio caracter sticas de seguridad y tica, reconociendo de ese modo que deben estar preparados para aceptar la responsabilidad jur dica respecto de la calidad de la tecnolog a que pro ducen y que dado el nivel de desarrollo alcanzado por la rob tica y la inteligencia artificial, procede empezar por las cuestiones relativas a la responsabilidad civil . Dicha resoluci n emplea indistintamente las palabras robots aut nomos e intel igencia artificial a la hora de asignar responsabilidad civil por el mal funcionamiento de los mismos extendi ndose a los algoritmos y dem s elementos que contiene la expresi n gen rica de inteligencia artificial. Es de destacar la Resoluci n del Parlamen to Europeo, de 20 de octubre de 2020, con recomendaciones destinadas a la Comisi n sobre un r gimen de responsabilidad civil en materia de inteligencia artificial (2020/2014(INL) ) y especialmente sus art culos 4 y 8 donde establece tanto la responsabilidad objetiva como la subjetiva derivada del funcion amiento de sistemas de inteligencia artificial. En diferentes textos se est demandando por parte de las instituciones europeas el dotar de seguridad jur dica, transparencia y publicidad de la titularidad y cargas de los sistemas de inteligencia artificia l, algoritmos y dem s elementos que la componen para fomentar la innovaci n a la vez que se garantizan los derechos de los ciudadanos y usuarios de la inteligencia artificial en caso de mal funcionamiento de la misma . La seguridad jur dica se podr a conse guir mediante la inscripci n de los sistemas de inteligencia artificial y elementos relacionados en los registros jur dicos nacionales (en el caso de Espa a el Registro de Bienes Muebles ). El Registro de Bienes Muebles espa ol, creado p or el mencionado Real Decreto 1828/1999, de 3 de diciembre, es un registro jur dico de titularidades y grav menes sobre bienes muebles, donde rigen y se aplican los principios hipotecarios reguladores del Registro de la Propiedad y Mercantil, que tiene por objeto la inscripci n de actos y contratos sobre bienes muebles, previo control de su legalidad, proporcionando publicidad y transparencia a la propiedad y a las cargas o grav menes que sobre bienes muebles se pudieran establecer . El Registro de Bienes Mu ebles est integrado, por raz n de su objeto, por las siguientes secciones: (i) Secci n de buques y aeronaves; (ii) Secci n de autom viles y otros veh culos a motor; (iii) Secci n de maquinaria industrial, establecimientos mercantiles y bienes de equipo; (iv) Secci n de garant as reales; (v) Secci n de otros bines muebles registrables y (vi) Secci n de condiciones generales de la contrataci n. La inscripci n en dichos registros jur dicos nacionales elevar a el nivel de protecci n jur dica de los ciudadanos que tienen relaci n con los sistemas de inteligencia artificial, algoritmos y dem s elementos relacionados con este tipo de tecnolog a ya que dicha inscripci n se producir a tras el cumplimiento de los requerimientos de publicidad, transparencia y segurida d jur dica prescritos en la legislaci n hipotecaria, especialmente el control de legalidad de la operaci n, exigido por el art culo 72 de la Ley de Hipoteca Mobiliaria y prenda sin desplazamiento. Esta normativa hipotecaria garantiza la oponibilidad erga o mnes y presunci n de exactitud, legitimaci n y fe p blica de los derechos inscritos sobre activos mobiliarios en los registros jur dicos de bienes muebles . La transparencia y seguridad jur dica de las titularidades y cargas de dichos activos est tambi n g arantizada mediante su publicidad, profesionalmente responsable y respetuosa con las exigencias de la normativa de protecci n de datos, que se puede obtener por canales telem ticos existentes en los mencionados registros p blicos conforme a lo establecido por el art culo 78 de la Ley de Hipoteca Mobiliaria y Prenda sin desplazamiento. Dicho incremento de la seguridad jur dica llevar a consigo asociado el fortalecimiento de las posibilidades de financiaci n de sus creadores, inversores o titulares ofreciendo dichos activos como garant a inscrita en los registros jur dicos correspondientes. Los usuarios de estos sistemas o algoritmos podr an identificar perfectamente qui nes ser an los responsables en cas o de mal funcionamiento de los mismos no teniendo que seguir un largo camino hasta su identificaci n. Siendo , por tanto , posible la f cil asignaci n a un titular de la responsabilidad por mal funcionamiento. En relaci n a dicha concreci n de titularidad par a la reclamaci n de responsabilidades en la Resoluci n de 2017 antes citada se va un paso m s y se indica como recomendaci n que se podr a dotar a los robots inteligentes de una personalidad jur dica espec fica de modo que los robots aut nomos m s compl ejos puedan ser considerados personas electr nicas responsables de reparar los da os que puedan causar y posiblemente aplicar la personalidad electr nica a aquellos supuestos en los que los robots tomen decisiones aut nomas inteligentes o interact en con t erceros de forma independiente. La inscripci n en el registro de bienes muebles correspondiente al lugar donde el titular de los sistemas de inteligencia artificial , algoritmos y dem s elementos tenga su centro de actividades, su residencia habitual o su centro de administraci n , o alternativamente, donde tuviera una relevante conexi n con el sistema empleado por causa de l archivo en una base de datos p blica nacional , podr a adem s vincularse a trav s de la referencia, v a art culo 75 LHMPSD, con la inscripci n correspondiente del titular (generalmente una sociedad) en el Registro Mercantil y con ello ser a perfectamente identificable el titular y responsable. Cabe recordar asimismo que el Registro Mercantil ser a f cilmente consultable en toda la Uni n Europea a trav s del sistema europeo de interconexi n de los registro s mercantiles (BRIS) . Esta soluci n podr a funcionar a nivel europeo mediante la red de interconexi n de Registros Mer cantiles europeos BRIS ya que , desde junio de 2017, los registros mercantiles de todos los pa ses de la UE est n interconectados. Esto supone que se puede buscar informaci n sobre las sociedades registradas en cualquier pa s de la UE, Islandia, Liechtenstein o Noruega adem s de que los registros pueden compartir informaci n sobre sucursales extranjeras y fusiones transfronterizas de empresas. Este s istema - sistema de interconexi n de los registros empresariales (BRIS) - constituye un esfuerzo conjunto por parte de los gobiernos de la UE y de la Comisi n Europea que permit ir a conectar el registro de los sistemas de inteligencia artificial est previsto tanto en la regulaci n nacional ( art culo 17 .5 CCo1) como comunitaria (Directiva 2017/1132/UE2 y Reglamento de Ejecuci n (UE) 2020/ y permitir a conectar las inscripciones en el Registros de Bienes Muebles no s lo con las sociedades espa olas sin o con otras entidades europeas . Si, como sugieren algunos autores y hemos mencionado anteriormente , llegamos al extremo de atribui r una personal idad jur dica a los sistemas de inteligencia artificial la inscripci n en el Registro de Bienes Muebles nacional en los t rminos mencionados puede configurarse, como el momento determinante, en su caso, del nacimiento de dicha personalidad electr nica , de modo an logo a lo que ya ocurre con el nacimiento de la personalidad jur dica de las sociedades y su inscripci n en el Registro Mercantil, conforme a lo dispuesto en los art culos 33 del Real Decreto Legislativo 1/2010, de 2 de junio, por el que se aprueba el texto refundido de la Ley de Sociedades de Capital. Sin perjuicio de su ulterior desarrollo , los requisitos para su inscripci n debe r an contener los siguientes elementos : clase de sistema de inteligencia artificial, algoritmo, (identificado con un hash SHA -256, su marca, nom bre comercial, patente de invenci n, etc.); t tulo o denominaci n, si la tuviere; explotaci n a que est dest inada, en su caso; fecha y n mero de inscripci n, renovaci n, rehabilita ci n o pr rroga en la base de datos especial o administrativ a correspondiente y tipo de derecho real que se adquiere, propiedad, derecho real de garant a o cualqu ier otro de la misma especie . 1 Art. 5 CCo. El Registro Mercantil asegurar la interconexi n con la plataforma central europea en la forma que se determine por las normas de la Uni n Europea y las normas reglamentarias que las desarrollen. El intercambio de informaci n a trav s del sistema de interconexi n facilitar a los interesados la obtenci n de informaci n sobre las indicaciones referentes al nombre y forma jur dica de la sociedad, su domicilio social, el Estado miembro en el que estuviera registrada y su n mero d e registro. 2 El sistema de inte rconexi n de registros mercantiles se regula en los art culos 22 y 23 de la DIRECTIVA (UE) 2017/1132 DEL PARLAMENTO EUROPEO Y DEL CONSEJO de 14 de junio de 2017 sobre determinad os aspectos del Derecho de sociedade s. Disponible en -lex.europa.eu/legal -content/ES/LSU/?uri=CELEX:32017L1132 3 REGLAMENTO DE EJECUCI N (UE) 2020/2244 DE LA COMISI N de 17 de diciembre de 2020 por el que se establecen disposiciones de aplicaci n de la Directiva (UE) 2017/1132 del Parlamento Europeo y del Consejo en lo que respecta a las especificaciones y los procedimientos t cnicos necesarios para el sistema de interconexi n de registros, y por el que se deroga el Reglamento de Ejecuci n (UE) 2015/884 de la Comisi n . Disponible en -lex.europa.eu/legal -content/ES/TXT/HTML/?uri=CELEX:32020R2244 Esta propuesta sirve para lograr facilitar la consecuci n de los cuatro objetivos del borrador: - garanti zar que los sistemas de IA introducidos y usados en el mercado de la UE sean seguros y respeten la legislaci n vigente en materia de derechos fundamentales y valores de la Uni n permitiendo la identificaci n de titulares de los sistemas; - garantizar la seg uridad jur dica para facilitar la inversi n e innovaci n en IA a trav s de la utilizaci n de las herramientas de financiaci n actuales reforzadas con la inscripci n en los registros correspondientes; - mejorar la gobernanza y la aplicaci n efectiva de la le gislaci n vigente en materia de derechos fundamentales y los requisitos de seguridad aplicables a los sistemas de IA; facilitar el desarrollo de un mercado nico para hacer un uso legal, seguro y fiable de las aplicaciones de IA y evitar la fragmentaci n del mercado empleando sistemas de interconexi n de registros como BRIS ya en funcionamiento.",es
Austrian Federal Economic Chamber (WKO) (Austria),F2636257,22 June 2021,Business association,Large (250 or more),Austria,"Die WK ist die gesetzliche Vertretung der gesamten sterreichischen Wirtschaft und repr sentiert alle sterreichischen Unternehmen - rund 000 Betriebe aus den Bereichen Gewerbe und Handwerk , Industrie, Handel, Banken und Versicherungen, Information und Consulting , Tourismus und Freizeit wirtschaft , Transport und Verkehr . 99,6% unserer Mitglieder sind KMU . Transparenz -Register -Nr.: 10405322962 -08 WK -Position spapier zum Rechtsrahmen f r K nstliche Intelligenz (COM ( 206 ) 2021 Die technische Entwicklung schreitet voran und KI -Anwendungen finden immer vielf ltigere Einsatzfelder, daher sind eigene einheitliche Regelungen grunds tzlich zu begr en. Um ein Level -Playing -Field zu garantieren, muss jedes KI -System im Binnenmarkt dens elben Vorgaben entsprechen. Die WK begr t grunds tzlich den Plan der Europ ischen Kommission ( Kommission ) , einen Rechtsrahmen f r KI zu schaffen. Dieser muss jedoch sicherstellen, dass das Potenzial k nstlicher Intelligenz in Zukunft weiter ausgesch p ft werden kann und Recht ssicherheit geschaffen wird, w hrend gleichzeitig ein hohes Schutzniveau gew hrleistet wird . Ein positives Narrativ gegen ber KI -Technologien ist eine Voraussetzung, um Europas digitale Eigenst ndigkeit zu erreichen. Besonders die e thischen Aspekte sind zu beachten. Klare Definition von KI Der zuk nftige europ ische Rahmen f r KI sollte sich auf eine einfache, klare und harmonisierte Definition von ""K nstlicher Intelligenz"" st tzen, technologieneutra l sein und sich auf das Erreichen w nschenswerter Ergebnisse konzentrieren, anstatt Werkzeuge zu regulieren. Insbesondere ist eine Konkretisierung der technischen Anforderungen notwendig, um Rechtssicherheit und Transparenz f r die Unternehmen zu schaffen und das reibungslose Funktionieren des Wirtschaftslebens zu f rdern. Die derzeitige Definition und der Anwendungsbereich, die der Verordnungsvorschlag vorsieht, w rden jedes Softwareprogramm umfassen, das z. B. statistische Ans tze, programmierte Berechnu ngen oder Suchmethoden verwendet. Diesen Anwendungen fehlt eindeutig die Eigenschaft, ""intelligentes Verhalten zu zeigen, indem sie ihre Umgebung analysieren und - mit einem gewissen Grad an Autonomie - Ma nahmen ergreifen, um bestimmte Ziele zu erreichen"" , die die Kommission fr her zur Definition von Systemen der k nstlichen Intelligenz verwendet hat (""K nstliche Intelligenz f r Europa"", COM( 237 final). Mit einer so weiten Definition w rde die Verordnung f r viele Anbieter und Nutzer solcher etablier ter Softwaresysteme einen unn tigen Aufwand und hohe Verwaltungskosten verursachen. Die Definition von KI -Systemen in Art. 3 ( sowie die in Anhang I des Verordnungsentwurfs f r vertrauensw rdige KI genannten Techniken und Ans tze m ssen deshalb entsprech end berarbeitet werden, um einen gezielteren Anwendungsbereich der Verordnung zu erm glichen. ber - und Doppelregulierung vermeiden Die WK erachtet es als besonders wichtig, dass bereits bestehende Normen und Vorgaben in einer Gesamtbetrachtung einbezo gen werden . KI-Anwendungen sind nur funktionsf hig, wenn sie entsprechende Daten zur Verf gung haben. Daher spielt das Datenschutzrecht und vor allem die Datenschutz -Grundverordnung (DSGVO) eine zentrale Rolle. Sobald ein KI -System mit personenbezogenen Da ten arbeitet, kommt das Regime der DSGVO zur Anwendung, d.h. die Datenverarbeitung muss einem legitimen Zweck dienen, transparent ausgestaltet und durch eine Rechtsgrundlage gedeckt sein. In der DSGVO verankerte Grunds tze, wie zum Beispiel das 2 Information s- und das Auskunftsrecht, das Verbot der Diskriminierung und das Prinzip der Zweckbindung sind auch f r den Einsatz von KI relevant. Der Einsatz und die Entwicklung von KI-Anwendungen bed rfen klarer Prozesse und nutzbare Daten (z.B. anonymisierte Daten). F r nat rliche Personen ist seit dem Inkrafttreten der DSGVO ein Regulatorium wirksam, welches die Einhaltung von Informations - und auch Sicherheitspflichten vorsieht. Daher werden zus tzliche Regulierungen, die kumulativ Erschwernisse oder Strafen f r einzuhaltende Vorgaben vorsehen, abgelehnt. Au erdem muss der Schutz von Gesch ftsgeheimnissen entsprechend aufrechterhalten werden. F r die Bundessparte Banken und Versicherungen der WK besteht auch die Gefahr von Doppel - und berregulierung beim Einsa tz von KI -Systemen f r Kreditscoring. Nach der derzeit vorgeschlagenen Klassifizierung von KI -Systemen mit hohem Risiko w rden KI -Systeme, die zur Bewertung der Kreditw rdigkeit nat rlicher Personen und zur Ermittlung ihres Kreditscores eingesetzt werden, in den Anwendungsbereich dieser Verordnung fallen und m ssten die f r KI - Systeme mit hohem Risiko festgelegten Anforderungen erf llen. Die Verwendung von KI - Systemen f r Bonit tsbewertungen und Kreditscoring durch Kreditinstitute ist bereits durch die Bestimmungen der Verordnung (EU) Nr. 575/2013 (CRR) geregelt. berschneidungen oder widerspr chliche Regelungen m ssen vermieden werden, und sektorspezifische Rechtsvorschriften wie zum Beispiel CRR sollten beachtet werden . Vorsichtige Abw gung geboten Die Einteilung in verschiedene Risikoklassen, vom minimalen Risiko ber geringes und hohes bis hin zum unannehmbaren Risiko, bietet die M glichkeit jeweils gezielt zu regulieren und somit ein ma geschneidertes und ergebnisorientiertes Sys tem zu schaffen. Es muss sichergestellt sein, dass die verschiedenen Risikoklassen genau abgegrenzt werden k nnen und hinreichend definiert wird, was erlaubt ist. Bez glich KI -Anwendungen mit hohem Risiko wird die ex -ante Bewertung in Verbindung mit der Ko nformit tsvermutung ( p resumption of conformity ) des Art 42 im Sinne der Rechtssicherheit grunds tzlich bef rwortet. In gewissen Bereichen bedarf es einer sehr vorsichtigen Nutzen -Risiko -Abw gung bei der Einstufung von KI -Systemen; eine Pauschalisierung ganzer Bereiche muss vermieden werden. Beispielsweise beim Einsatz von KI -Systemen bei der Bewertung des Kreditscores oder der Kreditw rdigkeit nat rlicher Personen. Auch eine generelle Zuordnung von KI-Anwendungen im Bildungs - und Trainingsbereich zu High-Risk-KI-Systems ist berschie end. KI macht nicht nur ein inhaltlich und hinsichtlich der Lernformate und Lernhilfen individualisiertes Lernangebot m glich, sondern tr gt auch zur Verbesserung der Bildungsformate bei. Rechtssicherheit und Verh ltnism igkeit muss gewahrt werden Im Zusammenhang mit den empfindlichen Strafen warnt die WK vor zu hohen P nalen und betont, dass der Grundsatz der Verh ltnism igkeit beachtet werden muss. Die Risiken von KI -Anwendungen beziehen sich prim r auf die Bereiche (Produkt)Sicherheit und Grundrechte. Das Regelwerk muss Rechtssicherheit durch gestreamlinte, einheitliche Anwendung und Definitionen schaffen . Sicherheitsrisiken von KI m ssen mit den be stehenden Rechtsvorschriften zur Produktsicherheit verkn pft werden. Grundrechtsschutz bei KI bedeutet insbesondere, dass Algorithmen, die Entscheidungen mit Wirkung f r Individuen treffen, Grund - und Freiheitsrechte achten m ssen. 3 Der vorgeschlagene Tex t sieht vor, dass die Liste von KI -Systemen mit hohem Risiko in Annex III durch delegierte Rechtsakte erweiterbar sein soll. Der Entwurf sieht jedoch keine bergangsfrist f r KI -Systeme vor, die neu in Annex III aufgenommen werden. Um Rechtssicherheit f r Unternehmen zu erm glichen, fordern wir, dass die Verordnung f r in diese r Hinsicht eine bergangsfrist von zwei Jahren nach Inkrafttreten vorsehen soll. Menschliche Aufsicht und Freir ume f r Forschung - und Innovation schaffen Der Einsatz menschlicher A ufsicht, um diskriminierende Ergebnisse auszumerzen wird positiv beurteilt. Die Einf hrung von freiwilligen Verhaltenskodizes f r KI -Anwendungen, die ein minimales Risiko darstellen, wird unterst tzt. Weiters ist es aus unserer Sicht wichtig, Forschungsr ume zu schaffen, innerhalb derer ein Test solcher Systeme unter weniger strengen Voraussetzungen m glich ist. Deshalb begr t die WK den Vorschlag, regulatory Sandboxes einzuf hren, um verantwortungsvolle Innovationen zu erleichtern. Um Wettbewerbsverze rrungen zu verhindern und um ein Level -Playing -Field zu gew hrleisten m ssen KMU, Start -Ups, und Gro unternehmen in diesem Zusammenhang an dieselben Regeln gebunden sein. Au erdem sollte hier der b rokratische Aufwand so gering wie m glich gehalten werden. Die WK betrachtet die Errichtung von Zentren f r digitale Innovation f r KMUs, die im Koordinierten Plan f r KI verankert sind, f r eine besonders wichtige Ma nahme, um KI - Exzellenz vom Labor bis zum Markt zu f rdern. Delegierte und Durchf hrungsr echtsakte Den in der Maschinen -Produkte -VO und dem Konzept f r vertrauensw rdige KI angestrebten Einsatz von delegie rten und Durchf hrungs echtsakten sehen wir kritisch, da der Erm chtigungsspielraum in den Rechtsakten oft sehr gro z gig definiert ist, und es hierf r keine ausreichende Begr ndung gibt. Die Kommission ist aktuell bestrebt, harmonisierte Europ ische Normen (hEN) durch technische Spezifikationen (Durchf hrungsr echtsakte) zu ersetzen. Durch diese Vorgehensweise wird der New Legislative Framework ( NLF) sukzessive ausgeh hlt, was nicht im Sinne der Wirtschaft ist . Die Normung bietet den essenziellen Vorteil einer breiten Stakeholderbeteiligung im Rahmen eines transparenten, konsensbasierten und f r alle offenen Verfahrens. Erg nzend spielt auch die internationale Dimension eine nicht unwesentliche Rolle, da zahlreiche ma gebliche Normen gemeinsam mit den internationalen Normungsorganisationen entwickelt werden. Ansprechpartner in der Abteilung f r Innovation und Digita lisierung : Dr. Florian Moosbeckhofer Leiter Innovation und Digitalisierung T +43 (5 90 900 -3994 | M +43 (664 817 91 21 E florian.moosbeckhofer@wko.at DI Wolf gang Lindner Referent Innovation und Digitalisierung T +43 5 90 900 4910 | M +43 ( 664 817 97 86 E Wolfgang.Lindner@wko.a t",de
Alliance VITA (France),F2625382,14 June 2021,Non-governmental organisation (NGO),Small (10 to 49 employees),France,"Alliance VITA tient insister aupr s de la Commission pour que celle-ci tienne davantage compte, dans sa proposition de r glement relatif l intelligence artificielle, de plusieurs principes-cl s relatifs au respect des droits fondamentaux et de la dignit des personnes, en particulier dans le domaine de la m decine et des soins de sant . Il convient en effet de rappeler que la mont e en puissance de l Intelligence Artificielle (IA) induit de nombreux enjeux in dits cet gard. Ainsi, le d veloppement de robots m dicaux vient par exemple r interroger les crit res d cisionnels et la place du m decin dans le champ des soins et des traitements m dicaux. La survalorisation de l IA conduirait r duire l intelligence humaine sa facette rationnelle au d triment des intelligences corporelle, relationnelle et spirituelle indispensables l humanit . La collecte massive de donn es (Big Data) pose quant elle la question de l utilisation des donn es personnelles et celle du consentement clair des personnes. Comme le souligne le Conseil National de l Ordre des M decins (M decins et patients dans le monde des data, des algorithmes et de l intelligence artificielle, Janvier , l essor d une soci t num rique d brid e de toute contrainte pourrait accentuer les in galit s entre les citoyens : Dans le monde des data et des algorithmes, les citoyens pourraient en arriver, en contrepartie de la facilit des acc s tout ( ), abdiquer d eux-m mes leurs libert s. Les populations les plus fragiles y seraient les plus vuln rables . Le principe d gale jouissance des droits et libert s par les individus ne peut tre remis en question du fait de la vuln rabilit de certaines personnes, en particulier lorsque cette vuln rabilit s av re renforc e par l IA, comme le rappelle d ailleurs juste titre la notice explicative du projet r glement aux points 5 et Aussi, tel que libell actuellement, le projet de r glement semble prendre insuffisamment en compte la n cessit d une protection particuli re et effective des droits fondamentaux des personnes, en particulier des personnes dont la vuln rabilit serait encore davantage accrue par le d veloppement de l IA. L attention port e l accessibilit des syst mes d IA aux personnes handicap es (art. , de m me que l interdiction des syst mes d IA qui viseraient exploiter les vuln rabilit s des personnes (art. sont videmment primordiales. Il convient toutefois d aller un pas plus loin en conditionnant effectivement l ensemble des dispositions du futur r glement au respect du principe thique fondamental selon lequel les technologies doivent tre au service de la personne humaine et de la soci t . En particulier en mati re m dicale, les crit res d cisionnels et les algorithmes doivent tre communs et lisibles. En tout tat de cause, doit demeurer une place la r flexion intuitive humaine et une approche thique des protocoles de recherche. Le futur r glement doit galement veiller ce que le consentement de la personne soit n cessaire en toute circonstance. Il n y a pas d algorithmes pertinents sans donn es de qualit . Chaque individu est en permanence le g n rateur de donn es digitales et ce, la plupart du temps, son insu. Il est donc primordial de redonner le pouvoir aux individus sur leurs donn es personnelles avec un libre arbitre. Enfin, il convient d int grer dans le r glement une obligation de non-ing rence. Les potentialit s pr dictives des technologies peuvent gravement entraver la vie conomique et sociale d une personne d s lors que la probabilit de survenance d une maladie l emp cherait de conclure une police d assurance ou d obtenir un pr t bancaire, par exemple. Il est donc essentiel d tablir des limites claires et fermes ne pas d passer.",fr
gauthier lasou (France),F2256463,28 April 2021,EU citizen,,France,"Un r glement europ en qui va d finir des exigences thiques et juridiques pour les usages de l'IA en Europe. crit en anglais, 108 pages + les annexes, tudes d'impact etc. A ma connaissance, vous vous adressez aux citoyens europ ens qui ne comprennent pas tous l'anglais, en particulier quand un jargon sp cifique est employ pour d finir des r gles communes. Pour ma part, bien que lisant l'anglais, je suis contre ce r glement, uniquement parce qu'il n'a pas t crit dans une langue que je ma trise suffisamment pour pouvoir me prononcer. en publiant ces documents uniquement dans une seule langue, qui ne constitue plus une r f rence un des pays de l'UE, vous cr ez de fait une in galit dans le traitement, la compr hension et l'acceptation des r gles que vous voulez fixer.",fr
